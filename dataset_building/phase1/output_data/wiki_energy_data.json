[{"url": "https://wiki.ros.org/rl_env", "package": "rl_env", "package_summary": ["rl_env is is a package containing reinforcement learning (RL) environments."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "Please take a look at the ", " on how to install, compile, and use this package. ", "Check out the code at: ", " ", "This package contains a variety of environments that can be used for reinforcement learning experiments. These can be used with new RL agents written to use the ", " framework, or with existing agents from the ", " package. The package contains the following environments: ", "The environment can interact with an RL agent in two ways. It can use the ROS messages defined in ", ", or another method can call the agent and environment methods directly, as done in the ", " package. ", "The rl_msgs package defines a set of ROS messages for the agent and  environment to communicate. These are similar to the messages used in  RL-Glue (", "), but simplified and defined in the ROS message format. The environment publishes three types of messages for the agent: ", "Experiments can also be run by calling the agent and environment methods directly (as done in the ", " package). Methods that all environments must implement are defined in the Environment interface in the ", " package (", ").  Seeds can be retrieved from the environment with the getSeedings() method. An action is applied to the environment with a call to apply(action). The current state can be retrieved by calling sensation() and terminal() will indicate if the agent is in a terminal state or not. "], "package_code": ["rosrun rl_env env --env type [options]", "taxi tworooms fourrooms energy fuelworld mcar cartpole car2to7 car7to2 carrandom stocks lightworld", "rosrun rl_env env --env carrandom --lag --stochastic --prints"]}
,{"url": "https://wiki.ros.org/rl_experiment", "package": "rl_experiment", "package_summary": ["rl_experiment is a package to run RL experiments using the rl_agent and rl_env packages."], "package_details": ["\n", "\n", "\n", " ", " ", "Please take a look at the ", " on how to install, compile, and use this package. ", "Check out the code at: ", " ", "This package provides a way of running reinforcement learning experiments with the agents from the ", " package and environments from the ", " package without using the ", " interface. Instead, the code instantiates agent and environment objects and calls their methods directly. It can be set to run for a particular number of episodes and trials, and prints out the sum of rewards for each episode to cerr. ", "There are a number of options available to set parameters of both the agent and environment used.  More details on the agent options are available in the ", " documentation, and more details on the env options are available in the ", " documentation. ", "In addition to these options, there a few variables that can be changed in the code, in the ", ". Near the top of the file are two variables: MAXSTEPS and NUMTRIALS. MAXSTEPS determines the maximum number of steps for an episode. A new episode will be started after this many steps even if the agent has not reached a terminal state. ", "As an example, here is how you would run Q-Learning (", ") on the stochastic Taxi task (", "): ", "Or to run real-time TEXPLORE (", ", ", ") at 10 Hz on the deterministic Fuel World task (", ") with 8 discrete trees: ", "While you should find that the qlearner, sarsa, dyna, and rmax agents work fine on the easier tasks (tworooms, taxi, etc), they will not converge within the default 1000 episodes on more complex tasks like Fuel World. As an example, here is how to run Q-Learning (", ") on the Fuel World task (", ") using the --nepisodes flag to run it for 1,000,000 episodes, which should be enough time for it to converge. ", "Another problem you may run into is when running these methods on the continuous domains (mcar, cartpole, car2to7, car7to2, and carrrandom). For these domains, the tabular RL methods (Q-Learning, SARSA, Dyna, R-Max) will need the state to be discretized. The following command will run Q-Learning (", ") on the Mountain Car task (", ") while discretizing each of the state features into 10 discrete values using the --nstates option. "], "package_code": ["rosrun rl_experiment experiment --agent type --env type [options]", "qlearner sarsa modelbased rmax texplore dyna savedpolicy", "taxi tworooms fourrooms energy fuelworld mcar cartpole car2to7 car7to2 carrandom stocks lightworld", "rosrun rl_experiment experiment --agent qlearner --env taxi --stochastic", "rosrun rl_experiment experiment --agent texplore --nmodels 8 --planner parallel-uct --actrate 10 --env fuelworld --deterministic", "rosrun rl_experiment experiment --agent qlearner --env fuelworld --nepisodes 1000000", "rosrun rl_experiment experiment --agent qlearner --env mcar --nstates 10"]}
,{"url": "https://wiki.ros.org/laptop_battery_monitor", "package": "laptop_battery_monitor", "package_summary": ["Simple script to check battery status"]}
,{"url": "https://wiki.ros.org/ps3joy", "package": "ps3joy", "package_summary": ["Playstation 3 SIXAXIS or DUAL SHOCK 3 joystick driver.\n    Driver for the Sony PlayStation 3 SIXAXIS or DUAL SHOCK 3\n    joysticks. In its current state, this driver is not compatible\n    with the use of other Bluetooth HID devices. The driver listens\n    for a connection on the HID ports, starts the joystick\n    streaming data, and passes the data to the Linux uinput device\n    so that it shows up as a normal joystick."], "package_details": ["\n", "\n", "\n", " is known to work with Ubuntu 12.10, Ubuntu 12.04, Ubuntu Jaunty 9.04, and Ubuntu Hardy 8.04. To make it work with Ubuntu Karmic 9.10, you will have to follow these ", ". ", "\n", "\n", "\n", "\n", " ", "\n", " ", "\n", "\n", " ", " ", "  ", " ", " ", "\n", "\n", "\n", "\n", " ", " ", " ", " also exposes the joystick's three-axis accelerometer and the single-axis gyroscope: ", "\n", "This driver exists because Linux's native support for the PS3 joystick is unreliable, and does not give access to the joystick's accelerometers and gyroscope. This driver solves both problems. However in its current form, ", ". In future releases, we plan to allow first non-HID and later any bluetooth device to coexist with this driver. If you have a need for such functionality, let it be known. ", "The ", " is a good starting point for how to use this package. ", "This is the same for ", " and ", ". ", "Or you could write a sudo script for sourcing ROS and starting ps3joy_node; I use ", " to automatically start the ", " after booting and a ROS-check. ", "There is ", ". ", "With these #defines you can access the PS3 buttons within the ", " without worrying about magic numbers: "], "package_tt": ["ps3joy.py", "sudo", "joy/set_feedback", "/diagnostics", "ps3joy.py", "ps3joy_node.py", "--inactivity-timeout", "--no-disable-bluetoothd", "ps3joy.py", "--redirect-output", "ps3joy.py", "--continuous-output", "ps3joy_node"], "package_code": ["sudo apt-get install ros-%ROSDISTRO%-joystick-drivers\n", "sudo apt-get install ros-indigo-joystick-drivers       (ROS Indigo for example)", "$ ./ps3joy.py --help\n", "usage: ps3joy.py [--inactivity-timeout=<n>] [--no-disable-bluetoothd] [--redirect-output]=<f>\n", "<n>: inactivity timeout in seconds (saves battery life).\n", "<f>: file name to redirect output to.\n", "Unless --no-disable-bluetoothd is specified, bluetoothd will be stopped.", ".../ps3joy$ sudo bash -c \"source /home/myself/.bashrc; ./scripts/ps3joy_node.py --inactivity-timeout=300\"", "rostopic pub  /joy/set_feedback sensor_msgs/JoyFeedbackArray '[ [0, 3, 1], [1, 1, 0.8] ]'", "// note on plain values:\n", "// buttons are either 0 or 1\n", "// button axes go from 0 to -1\n", "// stick axes go from 0 to +/-1\n", "\n", "#define PS3_BUTTON_SELECT            0\n", "#define PS3_BUTTON_STICK_LEFT        1\n", "#define PS3_BUTTON_STICK_RIGHT       2\n", "#define PS3_BUTTON_START             3\n", "#define PS3_BUTTON_CROSS_UP          4\n", "#define PS3_BUTTON_CROSS_RIGHT       5\n", "#define PS3_BUTTON_CROSS_DOWN        6\n", "#define PS3_BUTTON_CROSS_LEFT        7\n", "#define PS3_BUTTON_REAR_LEFT_2       8\n", "#define PS3_BUTTON_REAR_RIGHT_2      9\n", "#define PS3_BUTTON_REAR_LEFT_1       10\n", "#define PS3_BUTTON_REAR_RIGHT_1      11\n", "#define PS3_BUTTON_ACTION_TRIANGLE   12\n", "#define PS3_BUTTON_ACTION_CIRCLE     13\n", "#define PS3_BUTTON_ACTION_CROSS      14\n", "#define PS3_BUTTON_ACTION_SQUARE     15\n", "#define PS3_BUTTON_PAIRING           16\n", "\n", "#define PS3_AXIS_STICK_LEFT_LEFTWARDS    0\n", "#define PS3_AXIS_STICK_LEFT_UPWARDS      1\n", "#define PS3_AXIS_STICK_RIGHT_LEFTWARDS   2\n", "#define PS3_AXIS_STICK_RIGHT_UPWARDS     3\n", "#define PS3_AXIS_BUTTON_CROSS_UP         4\n", "#define PS3_AXIS_BUTTON_CROSS_RIGHT      5\n", "#define PS3_AXIS_BUTTON_CROSS_DOWN       6\n", "#define PS3_AXIS_BUTTON_CROSS_LEFT       7\n", "#define PS3_AXIS_BUTTON_REAR_LEFT_2      8\n", "#define PS3_AXIS_BUTTON_REAR_RIGHT_2     9\n", "#define PS3_AXIS_BUTTON_REAR_LEFT_1      10\n", "#define PS3_AXIS_BUTTON_REAR_RIGHT_1     11\n", "#define PS3_AXIS_BUTTON_ACTION_TRIANGLE  12\n", "#define PS3_AXIS_BUTTON_ACTION_CIRCLE    13\n", "#define PS3_AXIS_BUTTON_ACTION_CROSS     14\n", "#define PS3_AXIS_BUTTON_ACTION_SQUARE    15\n", "#define PS3_AXIS_ACCELEROMETER_LEFT      16\n", "#define PS3_AXIS_ACCELEROMETER_FORWARD   17\n", "#define PS3_AXIS_ACCELEROMETER_UP        18\n", "#define PS3_AXIS_GYRO_YAW                19"]}
,{"url": "https://wiki.ros.org/rr_openrover_driver_msgs", "package": "rr_openrover_driver_msgs", "package_summary": ["The rr_openrover_driver_msgs package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package contains the messages used to publish hardware data from the ", ". "], "package_code": ["std_msgs/Header header\n", "std_msgs/int32 left_motor\n", "std_msgs/int32 right_motor\n", "std_msgs/int32 flipper_motor", "std_msgs/Header header\n", "std_msgs/int32 reg_pwr_total_current\n", "std_msgs/int32 reg_motor_fb_rpm_left\n", "std_msgs/int32 reg_motor_fb_rpm_right\n", "std_msgs/int32 reg_flipper_fb_position_pot1\n", "std_msgs/int32 reg_flipper_fb_position_pot2\n", "std_msgs/int32 reg_motor_fb_current_left\n", "std_msgs/int32 reg_motor_fb_current_right\n", "std_msgs/int32 reg_motor_charger_state\n", "std_msgs/int32 reg_power_a_current\n", "std_msgs/int32 reg_power_b_current\n", "std_msgs/int32 reg_motor_flipper_angle\n", "std_msgs/int16 battery_current_a\n", "std_msgs/int16 battery_current_b", "std_msgs/Header header\n", "std_msgs/int32 reg_motor_fault_flag_left\n", "std_msgs/int32 reg_motor_temp_left\n", "std_msgs/int32 reg_motor_temp_right\n", "std_msgs/int32 reg_power_bat_voltage_a\n", "std_msgs/int32 reg_power_bat_voltage_b\n", "std_msgs/int32 reg_robot_rel_soc_a\n", "std_msgs/int32 reg_robot_rel_soc_b\n", "std_msgs/uint16 battery_mode_a\n", "std_msgs/uint16 battery_mode_b\n", "std_msgs/uint16 battery_temp_a\n", "std_msgs/uint16 battery_temp_b\n", "std_msgs/uint16 battery_voltage_a\n", "std_msgs/uint16 battery_voltage_b\n", "std_msgs/int32 buildno", "std_msgs/Header header\n", "\n", "std_msgs/bool over_charged_alarm\n", "std_msgs/bool terminate_charge_alarm\n", "std_msgs/bool over_temp_alarm\n", "std_msgs/bool terminate_discharge_alarm\n", "std_msgs/bool remaining_capacity_alarm\n", "std_msgs/bool remaining_time_alarm\n", "\n", "std_msgs/bool initialized\n", "std_msgs/bool discharging\n", "std_msgs/bool fully_charged\n", "std_msgs/bool fully_discharged"]}
,{"url": "https://wiki.ros.org/mavros", "package": "mavros", "package_summary": ["MAVROS -- MAVLink extendable communication node for ROS\n    with proxy for Ground Control Station."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " only. ", "\n", "\n", "\n", "\n", "\n", "\n", "Main node can be extended by plugins (see ", "). See also ", " package. ", "If you unsure what firmware your FCU runs start apm.launch and see ", ". ", "Starting from 0.11 mavros knows string representation for autopilot mavlink enum. ", "For older you shall manually find autopilot type value in mavlink documentation.  ", "All utilities provides ", " and ", " information. ", "Supported custom modes listed at ", ". ", "Standard set of communication plugins loaded by ", ". ", "Note: this list for ", " version. ", "Older versions: ", ", ", ", ", ", ", ", ", ", ", ", ", ". "], "package_tt": ["mavlink/to", "mavlink/from", "diagnostics", "~system_id", "int", "~component_id", "int", "~target_system_id", "int", "~target_component_id", "int", "~startup_px4_usb_quirk", "bool", "~plugin_blacklist", "string[]", "~plugin_whitelist", "string[]", "~fcu_url", "string", "~fcu_protocol", "string", "~gcs_url", "string", "ros_udp", "mavlink/from", "mavlink/to", "~gcs_url", "string", "mavros/state", "<trigger_event>", "~<event_name>/service", "string", "~<event_handler>/event", "string[]", "~<event_handler>/action", "string[]", "~<event_handler>/shell", "string", "~<event_handler>/logfile", "string", "/path/to/serial/device[:baudrate]", "serial:///path/to/serial/device[:baudrate][/?ids=sysid,compid]", "serial-hwfc:///path/to/serial/device[:baudrate][?ids=sysid,compid]", "udp://[bind_host][:port]@[remote_host][:port][/?ids=sysid,compid]", "udp-b://[bind_host][:port]@[:port][/?ids=sysid,compid]", "tcp://[server_host][:port][/?ids=sysid,compid]", "tcp-l://[bind_host][:port][/?ids=sysid,compid]", "~system_id", "~component_id", "baudrate", "bind_host", "remote_host", "server_host", "port", "<util>\u00a0--help", "<util>\u00a0<command>\u00a0--help", "~radio_status", "~actuator_control", "~hil_controls/hil_controls", "~frame_id", "string", "~cmd/command", "~cmd/command_int", "~cmd/arming", "~cmd/set_home", "~cmd/takeoff", "~cmd/land", "~cmd/trigger_control", "~cmd/use_comp_id_system_control", "bool", "SYSTEM_CONTROL", "~ftp/open", "~ftp/close", "~ftp/read", "~ftp/write", "~ftp/list", "~ftp/truncate", "~ftp/remove", "~ftp/rename", "~ftp/mkdir", "~ftp/rmdir", "~ftp/checksum", "~ftp/reset", "~global_position/global", "~global_position/local", "~global_position/gp_vel", "~global_position/rel_alt", "~global_position/compass_hdg", "~global_position/raw/fix", "~global_position/raw/gps_vel", "~global_position/frame_id", "string", "~global_position/tf/send", "bool", "~global_position/tf/frame_id", "string", "~global_position/tf/child_frame_id", "string", "~imu/data", "~imu/data_raw", "~imu/mag", "~imu/temperature", "~imu/atm_pressure", "~imu/frame_id", "string", "~imu/linear_acceleration_stdev", "double", "~imu/angular_velocity_stdev", "double", "~imu/orientation_stdev", "double", "~imu/magnetic_stdev", "double", "~local_position/pose", "~local_position/velocity", "~local_position/frame_id", "string", "~local_position/tf/send", "bool", "~local_position/tf/frame_id", "string", "~local_position/tf/child_frame_id", "string", "~manual_control/send", "~manual_control/control", "~param/", "~param/pull", "~param/push", "~param/get", "~param/set", "~rc/override", "SYSID_MYGCS", "~rc/in", "~rc/out", "~safety_area/set", "~safety_area/p1/x", "double", "~safety_area/p1/y", "double", "~safety_area/p1/z", "double", "~safety_area/p2/x", "double", "~safety_area/p2/y", "double", "~safety_area/p2/z", "double", "~setpoint_accel/accel", "~setpoint_accel/send_force", "bool", "~setpoint_attitude/cmd_vel", "~setpoint_attitude/attitude", "~setpoint_attitude/thrust", "~setpoint_attitude/reverse_throttle", "bool", "~setpoint_attitude/use_quaternion", "bool", "~setpoint_attitude/tf/listen", "bool", "~setpoint_attutude/tf/frame_id", "string", "~setpoint_attitude/tf/child_frame_id", "string", "~setpoint_attitude/tf/rate_limit", "double", "~setpoint_position/global", "~setpoint_position/local", "~setpoint_position/tf/listen", "bool", "~setpoint_position/tf/frame_id", "string", "~setpoint_position/tf/child_frame_id", "string", "~setpoint_position/tf/rate_limit", "double", "~setpoint_raw/local", "~setpoint_raw/global", "~setpoint_raw/attitude", "~setpoint_raw/target_local", "~setpoint_raw/target_global", "~setpoint_raw/target_attitude", "~setpoint_velocity/cmd_vel_unstamped", "~state", "~battery", "~battery", "~extended_state", "~set_stream_rate", "~set_mode", "~conn/timeout", "double", "~conn/heartbeat_rate", "double", "~sys/min_voltage", "double", "~sys/disable_diag", "bool", "~time_reference", "~conn/system_time_rate", "double", "SYSTEM_TIME", "~conn/timesync_rate", "double", "~time/time_ref_source", "string", "~time/timesync_avg_alpha", "double", "~vfr_hud", "~wind_estimation", "~mission/reached", "~mission/waypoints", "~mission/pull", "~mission/push", "~mission/clear", "~mission/set_current", "~mission/pull_after_gcs", "bool", "tf/"], "package_code": ["roslaunch mavros px4.launch", "roslaunch mavros apm.launch", "usage: mavcmd [-h] [-n MAVROS_NS] [-v] [--wait]\n", "              {long,int,sethome,takeoff,land,takeoffcur,landcur,trigger_control}\n", "              ...\n", "\n", "Commad line tool for sending commands to MAVLink device.\n", "\n", "positional arguments:\n", "  {long,int,sethome,takeoff,land,takeoffcur,landcur,trigger_control}\n", "    long                Send any command (COMMAND_LONG)\n", "    int                 Send any command (COMMAND_INT)\n", "    sethome             Request change home position\n", "    takeoff             Request takeoff\n", "    land                Request land\n", "    takeoffcur          Request takeoff from current GPS coordinates\n", "    landcur             Request land on current GPS coordinates\n", "    trigger_control     Control onboard camera trigerring system (PX4)\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output\n", "  --wait                Wait for establishing FCU connection", "usage: mavftp [-h] [-n MAVROS_NS] [-v]\n", "              {cd,list,cat,remove,mkdir,rmdir,download,upload,verify,reset}\n", "              ...\n", "\n", "File manipulation tool for MAVLink-FTP.\n", "\n", "positional arguments:\n", "  {cd,list,cat,remove,mkdir,rmdir,download,upload,verify,reset}\n", "    cd                  change directory\n", "    list                list files and dirs\n", "    cat                 cat file\n", "    remove              remove file\n", "    mkdir               create direcotory\n", "    rmdir               remove directory\n", "    download            download file\n", "    upload              upload file\n", "    verify              verify files\n", "    reset               reset\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavparam [-h] [-n MAVROS_NS] [-v] {load,dump,get,set} ...\n", "\n", "Commad line tool for getting, setting, parameters from MAVLink device.\n", "\n", "positional arguments:\n", "  {load,dump,get,set}\n", "    load                load parameters from file\n", "    dump                dump parameters to file\n", "    get                 get parameter\n", "    set                 set parameter\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavsafety [-h] [-n MAVROS_NS] [-v] {arm,disarm,safetyarea} ...\n", "\n", "Commad line tool for manipulating safty on MAVLink device.\n", "\n", "positional arguments:\n", "  {arm,disarm,safetyarea}\n", "    arm                 Arm motors\n", "    disarm              Disarm motors\n", "    safetyarea          Send safety area\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavsetp [-h] [-n MAVROS_NS] [-V] {local} ...\n", "\n", "Commad line tool for control the device by setpoints.\n", "\n", "positional arguments:\n", "  {local}\n", "    local               Send local setpoint\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -V, --verbose         verbose output", "usage: mavsys [-h] [-n MAVROS_NS] [-v] [--wait] {mode,rate} ...\n", "\n", "Change mode and rate on MAVLink device.\n", "\n", "positional arguments:\n", "  {mode,rate}\n", "    mode                Set mode\n", "    rate                Set stream rate\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output\n", "  --wait                Wait for establishing FCU connection", "usage: mavwp [-h] [-n MAVROS_NS] [-v]\n", "             {show,load,pull,dump,clear,setcur,goto} ...\n", "\n", "Commad line tool for manipulating mission on MAVLink device.\n", "\n", "positional arguments:\n", "  {show,load,pull,dump,clear,setcur,goto}\n", "    show                Show waypoints\n", "    load                load waypoints from file\n", "    pull                pull waypoints from FCU\n", "    dump                dump waypoints to file\n", "    clear               clear waypoints on device\n", "    setcur              set current waypoints on device\n", "    goto                send goto waypoint (APM only)\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output"]}
,{"url": "https://wiki.ros.org/xbot_node", "package": "xbot_node", "package_summary": ["ROS nodelet for Xbot: ROS wrapper for the Xbot driver."], "package_details": ["\n", "\n", "xbot_node\u529f\u80fd\u5305\u4e3a", "\u63d0\u4f9bROS API\u3002 "], "package_tt": ["/commands/motor_disable", "/commands/velocity", "/commands/yaw_platform", "/commands/pitch_platform", "/commands/sound_enable", "/commands/led", "/commands/lift", "/commands/reset_odometry", "/joint_states", "/sensors/core", "/sensors/extra", "/sensors/yaw_platform_degree", "/sensors/pitch_platform_degree", "/sensors/motor_disabled", "/sensors/sound_enabled", "/sensors/battery", "/sensors/echo", "/sensors/infrared", "/sensors/imu_data", "/sensors/raw_imu_data", "/xbot/state", "/commands/velocity", "/xbot/chat", "~base_path", "string", "\"$(find\u00a0xbot_talker)\""]}
,{"url": "https://wiki.ros.org/rosflight", "package": "rosflight", "package_summary": ["Package for interfacing to the ROSflight autopilot firmware over MAVLink"], "package_details": ["\n", "\n", "\n", " ", "\n", " ", "ROSflight provides a simple, low-latency interface between a flight controller running the ROSflight firmware and ROS. ROSflight can stream both sensor data and motor commands at high speed. ROSflight is written to work with a variety of airframes, including multirotor and fixed-wing aircraft. The ROSflight package provided the interface for autopilots, but does not include any control code. For examples of autopilots using ROSflight, see ", " or ", ". For documentation on the firmware, see ", ". "], "package_tt": ["command", "mode", "ignore", "aux_command", "type_array", "values", "external_attitude", "external_attitude", "attitude", "airspeed", "attitude", "attitude/euler", "baro", "battery", "gnss", "gnss_raw", "imu/data", "imu/temperature", "magnetometer", "navsat_compat/fix", "navsat_compat/time_reference", "time", "navsat_compat/vel", "linear", "output_raw", "rc_raw", "rosflight_errors", "sonar", "status", "unsaved_params", "version", "named_value/int/<name>", "named_value/float/<name>", "param_get", "param_set", "param_write", "param_save_to_file", "param_load_from_file", "calibrate_imu", "calibrate_rc_trim", "calibrate_baro", "calibrate_airspeed", "reboot", "reboot_to_bootloader", "~port", "string", "~baud_rate", "int", "~frame_id", "string", "~udp", "bool", "~bind_host", "string", "~bind_port", "int", "~remote_host", "string", "~remote_port", "int"], "package_code": ["$ rosrun rosflight rosflight_io _port:=/dev/ttyUSB0"]}
,{"url": "https://wiki.ros.org/turtlebot3_bringup", "package": "turtlebot3_bringup", "package_summary": ["roslaunch scripts for starting the TurtleBot3"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["cmd_vel", "motor_power", "reset", "sound", "battery_state", "cmd_vel_rc100", "diagnostics", "imu", "joint_states", "magnetic_field", "odom", "sensor_state", "tf", "version_info", "~baud", "int", "~port", "string", "imu", "scan", "sensor_state", "version_info", "diagnostics", "rpms", "scan", "~frame_id", "string", "~port", "string"]}
,{"url": "https://wiki.ros.org/rr_openrover_basic", "package": "rr_openrover_basic", "package_summary": ["The rr_openrover_basic package"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This code is for those working with the Rover Robotics ", ". The ", " communicates via UART, this package abstracts away the UART communications and allows users to quickly get their robots moving around and doing cool things! We recommend using an FTDI cable which will convert the UART to USB for communicating with a computer. "], "package_tt": ["/cmd_vel/managed", "/rr_openrover_basic/fan_speed", "/rr_openrover_basic/odom_encoder", "/rr_openrover_basic/raw_fast_rate_data", "/rr_openrover_basic/raw_med_rate_data", "/rr_openrover_basic/raw_slow_rate_data", "/rr_openrover_basic/battery_status_a", "/rr_openrover_basic/battery_status_b", "~port", "string", "\"/dev/ttyUSB0\"", "~enable_timeout", "bool", "true", "~timeout", "float", "0.5", "~drive_type", "string", "\"4wd\"", "~total_weight", "float", "20.0", "~traction_factor", "float", "depends\u00a0on\u00a0drive\u00a0type\u00a0chosen", "~odom_covariance_0", "float", "0.01", "~odom_covariance_35", "float", "0.03"], "package_code": ["sudo apt-get install ros-kinetic-rr-openrover-basic", "roslaunch rr_openrover_basic example.launch", "rostopic echo /rr_openrover_basic/r_slow_rate_data/reg_robot_rel_soc_a\n", "rostopic echo /rr_openrover_basic/r_slow_rate_data/reg_robot_rel_soc_b", "managed_pub = rospy.Publisher('/cmd_vel/managed', TwistStamped, queue_size=1)\n", "managed_control_input.header.stamp = rospy.Time.now()\n", "managed_control_input.header.frame_id = 'none'\n", "managed_control_input.twist.linear.x=0.0\n", "managed_control_input.twist.angular.y=0.0\n", "managed_control_input.twist.angular.z=0.5\n", "managed_pub.publish(managed_control_input)", "rosrun rr_openrover_basic openrover_basic_node", "<launch>\n", "    <arg name=\"openrover_node_name\" default=\"rr_openrover_basic\"/>\n", "\n", "    <!-- OpenRover Driver -->\n", "    <node pkg=\"rr_openrover_basic\" type=\"openrover_basic_node\" name=\"$(arg openrover_node_name)\" respawn=\"false\" output=\"screen\">\n", "        <param name=\"port\" value=\"/dev/rover\" />\n", "        <param name=\"drive_type\" value=\"4wd\" />\n", "        <param name=\"enable_timeout\" type=\"bool\" value=\"true\"/>\n", "        <param name=\"timeout\" type=\"double\" value=\"0.3\"/>\n", "        <param name=\"total_weight\" type=\"double\" value=\"20.41\"/>\n", "        <param name=\"traction_factor\" value=\"0.610\"/>\n", "        <param name=\"odom_covariance_0\" value=\"0.01\"/>\n", "        <param name=\"odom_covariance_35\" value=\"0.03\"/>\n", "    </node>\n", "\n", "    <!-- OpenRover InOrbit Diagnostics -->\n", "    <node pkg=\"rr_openrover_basic\" type=\"diagnostics.py\" name=\"rr_openrover_diagnostics_node\">\n", "        <remap from=\"/raw_slow_rate_data\" to=\"/$(arg openrover_node_name)/raw_slow_rate_data\"/>\n", "    </node>\n", "</launch>"]}
,{"url": "https://wiki.ros.org/rr_openrover_driver", "package": "rr_openrover_driver", "package_summary": ["Provides an interface between ros and Rover Robotics rover hardware. Inputs to rr_openrover_driver\n    include emergency stop and velocity commands.  It outputs diagnostic data such as encoder\n    readings and battery charge."], "package_details": [" ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "This code is for those working with the Rover Robotics ", ". The ", " communicates via UART, this package abstracts away the UART communications and allows users to quickly get their robots moving around and doing cool things! We recommend using an FTDI cable which will convert the UART to USB for communicating with a computer. "], "package_tt": ["/cmd_vel/managed", "/rr_openrover_driver/fan_speed", "/rr_openrover_driver/soft_estop/enable", "/rr_openrover_driver/soft_estop/reset", "/rr_openrover_driver/odom_encoder", "/rr_openrover_driver/raw_fast_rate_data", "/rr_openrover_driver/raw_med_rate_data", "/rr_openrover_driver/raw_slow_rate_data", "/rr_openrover_driver/battery_status_a", "/rr_openrover_driver/battery_status_b", "~use_legacy", "bool", "false", "~port", "string", "\"/dev/ttyUSB0\"", "~enable_timeout", "bool", "true", "~timeout", "float", "0.5", "~drive_type", "string", "\"4wd\"", "~total_weight", "float", "20.0", "~traction_factor", "float", "depends\u00a0on\u00a0drive\u00a0type\u00a0chosen", "~odom_covariance_0", "float", "0.01", "~odom_covariance_35", "float", "0.03"], "package_code": ["roslaunch rr_openrover_driver example.launch", "rostopic echo /rr_openrover_driver/r_slow_rate_data/reg_robot_rel_soc_a\n", "rostopic echo /rr_openrover_driver/r_slow_rate_data/reg_robot_rel_soc_b", "managed_pub = rospy.Publisher('/cmd_vel/managed', TwistStamped, queue_size=1)\n", "managed_control_input.header.stamp = rospy.Time.now()\n", "managed_control_input.header.frame_id = 'none'\n", "managed_control_input.twist.linear.x=0.0\n", "managed_control_input.twist.angular.y=0.0\n", "managed_control_input.twist.angular.z=0.5\n", "managed_pub.publish(managed_control_input)", "rosrun rr_openrover_driver openrover_driver_node", "<launch>\n", "    <arg name=\"openrover_node_name\" default=\"rr_openrover_driver\"/>\n", "\n", "    <!-- OpenRover Driver -->\n", "    <node pkg=\"rr_openrover_driver\" type=\"openrover_driver_node\" name=\"$(arg openrover_node_name)\" respawn=\"false\" output=\"screen\">\n", "        <param name=\"port\" value=\"/dev/rover\" />\n", "        <param name=\"drive_type\" value=\"4wd\" />\n", "        <param name=\"enable_timeout\" type=\"bool\" value=\"true\"/>\n", "        <param name=\"timeout\" type=\"double\" value=\"0.3\"/>\n", "        <param name=\"total_weight\" type=\"double\" value=\"20.41\"/>\n", "        <param name=\"traction_factor\" value=\"0.610\"/>\n", "        <param name=\"odom_covariance_0\" value=\"0.01\"/>\n", "        <param name=\"odom_covariance_35\" value=\"0.03\"/>\n", "    </node>\n", "\n", "    <!-- OpenRover Diagnostics -->\n", "    <node pkg=\"rr_openrover_driver\" type=\"diagnostics.py\" name=\"rr_openrover_diagnostics_node\">\n", "        <remap from=\"/raw_slow_rate_data\" to=\"/$(arg openrover_node_name)/raw_slow_rate_data\"/>\n", "    </node>\n", "</launch>slow_rate_pub"]}
,{"url": "https://wiki.ros.org/power_monitor", "package": "power_monitor", "package_summary": ["The power_monitor collects messages from the ocean_battery_server and\n     the pr2_power_board, and publishes a summary of their data in a\n     friendlier message format."], "package_details": ["\n", "\n", " takes data from ", " and ", " and republishes it in a more user-friendly message format. ", "\n", " (", ") ", "\n", " (", ") ", "\n", " (", ", default: 0.1) ", "The estimation method that ", " uses is reconfigurable via ", ". Two methods are currently available: "], "package_tt": ["power_monitor", "power_monitor", "/var/ros/power_monitor/power.log", "battery/server2", "power_board/power_state", "power_state", "~frequency", "float", "power_state", "~estimation_method", "string", "~advanced_log_file", "string", "~battery_update_timeout", "double"]}
,{"url": "https://wiki.ros.org/kobuki_node", "package": "kobuki_node", "package_summary": ["ROS nodelet for Kobuki: ROS wrapper for the Kobuki driver."], "package_details": [" "], "package_tt": ["~commands/motor_power", "~commands/external_power", "~commands/reset_odometry", "~commands/sound", "~commands/led1", "~commands/led2", "~commands/digital_output", "~commands/velocity", "odom", "diagnostics", "joint_states", "~events/button", "~events/bumper", "~events/cliff", "~events/wheel_drop", "~events/power_system", "~events/robot_state", "~events/digital_input", "~sensors/imu_data", "~sensors/imu_data_raw", "~sensors/dock_ir", "~sensors/core", "~version_info", "~device_port", "string", "/dev/kobuki", "~wheel_left_joint_name", "string", "wheel_left_joint", "~wheel_right_joint_name", "string", "wheel_right_joint", "~battery_capacity", "double", "16.5", "~battery_low", "double", "13.5", "~battery_dangerous", "double", "13.2", "~cmd_vel_timeout", "double", "0.6", "~publish_tf", "bool", "False", "~odom_frame", "string", "~base_frame", "string", "~acceleration_limiter", "bool", "~commands/motor_power", "~commands/external_power", "~commands/reset_odometry", "~commands/sound", "~commands/led1", "~commands/led2", "~commands/digital_output", "~commands/velocity", "~commands/controller_info", "odom", "diagnostics", "joint_states", "~events/button", "~events/bumper", "~events/cliff", "~events/wheel_drop", "~events/power_system", "~events/robot_state", "~events/digital_input", "~sensors/imu_data", "~sensors/imu_data_raw", "~sensors/dock_ir", "~sensors/core", "~version_info", "~controller_info", "~debug/raw_data_stream", "~debug/raw_data_command", "~debug/raw_control_command", "~device_port", "string", "/dev/kobuki", "~wheel_left_joint_name", "string", "wheel_left_joint", "~wheel_right_joint_name", "string", "wheel_right_joint", "~battery_capacity", "double", "16.5", "~battery_low", "double", "13.5", "~battery_dangerous", "double", "13.2", "~cmd_vel_timeout", "double", "0.6", "~publish_tf", "bool", "False", "~use_imu_heading", "bool", "True", "~odom_frame", "string", "~base_frame", "string", "~acceleration_limiter", "bool"]}
,{"url": "https://wiki.ros.org/rmp_base", "package": "rmp_base", "package_summary": ["The rmp_base package provides a ros interface to control a Segway Robotics Mobility Platform. \n    In addition, navigation and status data are also published such as odometry, imu, mottor and battery status, ..."], "package_details": ["\n", "\n", "\n", "\n", "The rmp_base package provides a ros interface to control a Segway Robotics Mobility Platform (", "). It supports USB and UDP interfaces. ", "This package has only been tested on the RMP 440LE (", "). "], "package_tt": ["/rmp440le/base/vel_cmd", "/rmp440le/deadman", "/rmp440le/audio_cmd", "/rmp440le/odom", "/rmp440le/joint_states", "/rmp440le/inertial", "/rmp440le/pse", "/rmp440le/motor_status", "/rmp440le/battery", "/rmp440le/fault_status", "transport_type", "string", "ip_address", "string", "port_number", "int", "device_port", "string", "update_frequency", "double", "odometry_topic", "string", "joint_states_topic", "string", "inertial_topic", "string", "pse_topic", "string", "motor_status_topic", "string", "battery_topic", "string", "velocity_command_topic", "string", "deadman_topic", "string", "audio_command_topic", "string", "fault_status_topic", "string", "max_translational_velocity", "double", "max_turn_rate", "string"], "package_code": ["$ roslaunch rmp_base rmp440le.launch"]}
,{"url": "https://wiki.ros.org/m4atx_battery_monitor", "package": "m4atx_battery_monitor", "package_summary": ["Battery Monitor for the M4-ATX Power Module"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package will read the information from a m4atx battery supply and publish it as a ros message. ", "Locate the bus and device number of the device called \"", " Technology, Inc.\". ", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file. This file launches an instance of the ", ". To launch these nodes the following command can be used: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["m4atx_battery_monitor", "m4atx_battery_monitor_node", "battery_status_m4atx", "~diag_frequency", "~input_nominal", "~battery_dead_voltage", "m4atx_battery_monitor", "ros_ethernet_rmp", "m4atx-battery-monitor.launch", "m4atx_battery_monitor_node"], "package_code": ["lsusb ", "sudo chmod a+rw /dev/bus/usb/<bus_num>/<device_num>", "\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-m4atx-battery-monitor", "roslaunch m4atx_battery_monitor_node m4atx_battery_monitor_node.launch "]}
,{"url": "https://wiki.ros.org/ridgeback_msgs", "package": "ridgeback_msgs", "package_summary": ["Messages exclusive to Ridgeback, especially for representing low-level motor commands and sensors."], "package_details": ["\n", "\n", "These messages are the low-level interface between ", "'s ARM MCU and integrated PC. Most users of Ridgeback should be able to use standard ROS interfaces (eg. ", ", ", ") to command and monitor the robot. A possible exception is to programmatically monitor system state such as voltage, current, battery, faults, etc. "]}
,{"url": "https://wiki.ros.org/smart_battery_msgs", "package": "smart_battery_msgs", "package_summary": ["Smart Battery Messages"], "package_details": ["Newly proposed, mistyped, or obsolete package. Could not find package \"smart_battery_msgs\" in rosdoc: /home/rosbot/docs/api/smart_battery_msgs/manifest.yaml "]}
,{"url": "https://wiki.ros.org/wiimote", "package": "wiimote", "package_summary": ["The wiimote package allows ROS nodes to communicate with a Nintendo Wiimote\n    and its related peripherals, including the Nunchuk, Motion Plus, and\n    (experimentally) the Classic. The package implements a ROS node that uses\n    Bluetooth to communicate with the Wiimote device, obtaining accelerometer\n    and gyro data, the state of LEDs, the IR camera, rumble (vibrator),\n    buttons, joystick, and battery state. The node additionally enables ROS\n    nodes to control the Wiimote's LEDs and vibration for feedback to the human\n    Wiimote operator. LEDs and vibration may be switched on and off, or made to\n    operate according to a timed pattern."], "package_details": [" ", "\n", "\n", " The cwiid library currently only recognizes Wiimotes which report the name as \"Nintendo RVL-CNT-01\"; the latest Wiimotes will not be discovered. See ", ". ", "\n", "\n", "\n", " ", "\n", " ", "The ", " array shows which buttons are currently depressed on the ", "Wiimtoe device. The position mapping is as follows: ", "This package should be considered as ", " except for support of the Classic controller, which requires additional testing. ", "Check out the wiimote package, and ", " to ready the package for ", "operation. Plug the Bluetooth dongle into your machine's USB port. ", "The ", " message communicates all data that is available from ", "your Wiimote device. Samples are taken and broadcast at 100Hz. Here ", "are comments on some of the fields: ", "The message header's time ", " is set to reflect the time when the respective message's sample was taken from the Wiimote device. ", "The ", " shows the Motion+ gyroscope ", "reading. These values are valid only if the Motion+ attachment is ", "plugged into the Wiimote. Else they are held at constant zero, and ", "matrix entry [0,0] in message field angular_velocity_covariance is set ", "to -1. ", "The ", " are four sets of x/y/[z], and size measures, for the four ", "infrared light sources that the Wiimote device can track. When no ", "lights are detected, the respective values are set to -1. The z axis ", "is always -1, as it is not measured. ", "The ", " array are four intensity measures of the lights that ", "the camera observes. The meaning of these measures are unclear to the ", "author. ", "The ", " entry is the battery charge reading. The unit of ", "this number is unclear. Field ", " returns the remaining ", "charge as a percentage of full charge. ", "The ", " is the time of the most recent device calibration. ", "The ", " field is currently not used. "], "package_tt": ["cwiid", "rosmake", "wiimote_node.py", "set_feedback", "joy", "imu/data", "wiimote/state", "wiimote/nunchuk", "wiimote/classic", "imu/is_calibrated", "imu/calibrate", "State", "stamp", "angular_velocity_zeroed", "angular_velocity_raw", "buttons", "ir_tracking", "ir_sizes", "raw_battery", "percent_battery", "zeroing_time", "errors"], "package_code": ["Position   Button Name\n", "0         1\n", "1         2\n", "2         A\n", "3         B (toggle button on back of device)\n", "4         Plus\n", "5         Minus\n", "6         Rocker Left\n", "7         Rocker Right\n", "8         Rocker Up\n", "9         Rocker Down\n", "10        HOME"]}
,{"url": "https://wiki.ros.org/kobuki_dashboard", "package": "kobuki_dashboard", "package_summary": ["The Kobuki dashboard is a RQT-based plug-in for visualising data from Kobuki and giving easy access\n    to basic functionalities."], "package_details": [" ", "\n", "\n", "The kobuki_dashboard is also part of the ", ". In order to get the battery statuses, you need to launch the ", ". "], "package_code": ["$ roslaunch kobuki_node minimal.launch", "$ rosrun kobuki_dashboard kobuki_dashboard"]}
,{"url": "https://wiki.ros.org/ros_ethernet_rmp", "package": "ros_ethernet_rmp", "package_summary": ["ROS Wrapper for the Segway RMP Ethernet Python Driver"], "package_details": ["\n", "\n", "\n", "\n", " broadcasts the robot frame ('/base_footprint') with respect to the odometry frame (", "). ", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package is used to bridge ROS and a Segway RMP. It will convert ", " topic messages to the RMPCommand format and then publish the feedback from the RMP. There is also a joint state publisher to read in the feedback and publish the changing joint states as necessary. ", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file. This file launches an instance of the ", ", 'rmp_pose_updater.py' and ", " nodes. 'battery_monitor_rmp.launch' from 'battery_monitor_rmp' will also be launched if the argument, include_batt_monitor, is true. It is defaulted to true. To launch these nodes, ", " the battery monitor the following command can be used: ", "To launch these nodes ", " the battery monitor, the following command can be used: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["ros_ethernet_rmp", "cmd_vel", "ethernet_rmp.py", "cmd_vel", "rmp_command", "rmp_feedback", "~update_delay_sec", "~log_data", "~current_rmp_ip_addr", "~current_rmp_port_num", "~is_omni", "~my_velocity_limit_mps", "~my_accel_limit_mps2", "~my_decel_limit_mps2", "~my_dtz_rate_mps2", "~my_coastdown_accel_mps2", "~my_yaw_rate_limit_rps", "~my_yaw_accel_limit_rps2", "~my_tire_diameter_m", "~my_wheel_base_length_m", "~my_wheel_track_width_m", "~my_gear_ratio", "~my_config_bitmap", "~my_ip_address", "~my_port_num", "~my_subnet_mask", "~my_gateway", "~my_user_defined_feedback_bitmap_1", "~my_user_defined_feedback_bitmap_2", "~my_user_defined_feedback_bitmap_3", "~my_user_defined_feedback_bitmap_4", "rmp_pose_updater.py", "rmp_feedback", "odom", "~publish_tf", "rmp_pose_updater", "/odom", "rmp_joint_state.py", "rmp_feedback", "rmp_joint_states", "~has_two_wheels", "~link_left_front", "~link_right_front", "~link_left_rear", "~link_right_rear", "ros_ethernet_rmp", "ros_ethernet_rmp", "ros_ethernet_rmp.launch", "ethernet_rmp.py", "rmp_joint_states.py"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-ros-ethernet-rmp", "roslaunch ros_ethernet_rmp ros_ethernet_rmp.launch ", "roslaunch ros_etehrnet_rmp ros_ethernet_rmp.launch include_batt_monitor:=false"]}
,{"url": "https://wiki.ros.org/ocean_battery_driver", "package": "ocean_battery_driver", "package_summary": ["This is an interface to the Ocean Server Technology Intelligent Battery and Power System."], "package_details": ["\n", "\n", "\n", " controls an array of battery controllers.  The API below is for informational purposes only; it is not intended for use by anything other than ", ", which is where you should look for power data.  ", "\n", " (", ") ", "\n", " (", ", default: if no value specified on command-line, 4) ", "The ", " node will report the status of the batteries to diagnostics. It will warn on the diagnostics if a battery does not update within a timeout. "], "package_tt": ["ocean_server", "ocean_server", "/diagnostics", "/battery/server2", "/battery/server", "~number_of_ports", "int", "~debug_level", "int", "~port<ID>", "string", "\"/dev/ttyUSB<ID>\"", "~lag_timeout", "int", "60", "~stale_timeout", "int", "120"]}
,{"url": "https://wiki.ros.org/pr2_power_board", "package": "pr2_power_board", "package_summary": ["This provides a ROS node for the PR2 Power Board."], "package_details": ["\n", " controls with the PR2 power board.  The API below is for informational purposes only; it is not intended for use by anything other than ", ", which is where you should look for power data. ", "\n", "\n", "\n", "The ", " runs on the PR2 and controls the PR2 power board. The node regulates the main fan speed of the PR2 based on battery and power board temperature.  "], "package_tt": ["power_node2", "power_node2", "battery/server2", "/diagnostics", "~state", "~control2", "~control", "~sample_frequency", "float", "~transition_frequency", "float", "/diagnostics", "~state", "~control"]}
,{"url": "https://wiki.ros.org/phm_tools", "package": "phm_tools", "package_summary": ["The phm_tools meta package"], "package_details": ["\n", "\n", " ", " ", " Autonomous Transfer Vehicle ", " ", "Use Case Scenario Module, Sub-Module and Components List ", " ", " Use Case General Block Diagram ", " ", " General Failure Rates and Reliabilities of Components ", " ", " System Hazard Rate and Reliability at Different Temperature Conditions ", " Reliability of System at Different Temperatures ", " ", " ", " GAZEBO Test Environment ", " Locations of Some Specific Points ", " Followed Paths and Distance Between Each Neighbour Points ", " System PoTC for Each Route Segment ", "\n", "In the motor sub-module, failure rate of this component is selected as ", ". In encoder sub-module, we selected magnetic rotary encoder unit. Only use parameters  \u03bb", " (other parameters are negligible), the failure rate of encoder unit selected as ", ". ", "In the sensor module, there is only one component which is SICK S300 Laser Sensor and the failure rate of this component selected as ", " using product datasheet.  ", "In order to calculate hazard rate of the power card sub-module, we utilized diodes, capacitors and inductors. In addition, hazard rate of the fuse in the power card sub-modules selected as ", ". Hazard rate of the selected buck converter (LM 2596), is found as ", ". There is one more component in the Power Module which is battery and the failure rate of this component selected as ", ". ", "General failure rates and reliabilities of the all components at 35 \u2103 are shown in Table 2.  ", "Using Table 2, hazard rate of the system \u03bb", " calculated as ", ". In order to calculate the reliability of the system, we use Exponential Distribution function with the system hazard rate and time. Usage time selected as 1000 hours. The reliability of the system  R", " calculated as ", ".  "]}
,{"url": "https://wiki.ros.org/battery_monitor_rmp", "package": "battery_monitor_rmp", "package_summary": ["Monitor for the Segway Batteries"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package uses the feedback provided by the RMP to monitor the segway batteries and then uses espeak to tell the user if a battery is getting low. It also publishes this information. ", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file. This file launches an instance of the ", ". To launch these nodes the following command can be used: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["battery_monitor_rmp", "monitor_rmp.py", "rmp_feedback", "battery_status_rmp", "~front_base_batt_1", "~front_base_batt_2", "~rear_base_batt_1", "~rear_base_batt_2", "~aux_batt", "battery_monitor_rmp", "battery_monitor_rmp", "battery_monitor_rmp.launch", "battery_monitor_rmp.py"], "package_code": ["\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-battery-monitor-rmp", "roslaunch battery_monitor_rmp battery_monitor_rmp.launch "]}
,{"url": "https://wiki.ros.org/power_msgs", "package": "power_msgs", "package_summary": ["ROS messages for power measurement and breaker control."], "package_details": [" "]}
,{"url": "https://wiki.ros.org/webui", "package": "webui", "package_summary": ["A web interface to install and launch applications for the PR2."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Ergo, the easiest way to install the webui from the binary is to ", " the webui directory.  ", "... where <robot name> would usually be of the form prX and <robot type> would usually be pr2. ", "Add the following line to /etc/apache2/sites-available/default just above <", "> near the end of the file: "], "package_tt": ["ros-RELEASE-web-interface", "python-clearsilver", "apache2-mpm-prefork", "libapache2-mod-python", "ruby1.8-dev", "chown", "/etc/ros/env", "ROBOT", "ROBOT_NAME", "ROS_ROOT", "ROS_MASTER_URI", "ROS_PACKAGE_PATH"], "package_code": ["roscd webui\n", "make -f setup.make\n", "sudo ./install.py <robot name> <robot type> www-data", "sudo ./install_root", "Include /etc/ros/ros_webui_apache.cfg", "sudo cp varwww/index.html /var/www/index.html", "sudo apache2ctl restart", "    gPump.publish(\"/hoge\",\"std_msgs/String\",[\"hoga\"]);", "    gPump.service_call2(\"/service/knowrob\",\n", "                       {'str': command},\n", "                       function(res){\n", "                         document.getElementById('displaybox') , res.str);\n", "                       }\n", "                       );", "<div class=\"nav_element\" objtype=PercentTextWidget topic=\"/power_state\" num=\"a\" div=\"b\"/></div>", "var PercentTextWidget = Class.create({\n", "  initialize: function(domobj) {\n", "    this.pump = null;\n", "    this.domobj = domobj;\n", "    this.topics = [domobj.getAttribute(\"topic\")];\n", "    this.numerator = domobj.getAttribute(\"num\");\n", "    this.denominator = domobj.getAttribute(\"den\");\n", "  }, \n", "\n", "  init: function() {\n", "  }, \n", "\n", "  receive: function(topic, msg) {\n", "    if(msg[this.numerator] != null) {\n", "      var percent = parseFloat(msg[this.numerator]) / parseFloat(msg[this.denominator]);\n", "      this.domobj.innerHTML = (100. * percent).toFixed(2) + \"%\";\n", "    }\n", "  } \n", "});\n", "\n", "gRosClasses[\"PercentTextWidget\"] = function(dom){\n", "  return new PercentTextWidget(dom);\n", "}"]}
,{"url": "https://wiki.ros.org/rr_openrover_driver_msgs", "package": "rr_openrover_driver_msgs", "package_summary": ["The rr_openrover_driver_msgs package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package contains the messages used to publish hardware data from the ", ". "], "package_code": ["std_msgs/Header header\n", "std_msgs/int32 left_motor\n", "std_msgs/int32 right_motor\n", "std_msgs/int32 flipper_motor", "std_msgs/Header header\n", "std_msgs/int32 reg_pwr_total_current\n", "std_msgs/int32 reg_motor_fb_rpm_left\n", "std_msgs/int32 reg_motor_fb_rpm_right\n", "std_msgs/int32 reg_flipper_fb_position_pot1\n", "std_msgs/int32 reg_flipper_fb_position_pot2\n", "std_msgs/int32 reg_motor_fb_current_left\n", "std_msgs/int32 reg_motor_fb_current_right\n", "std_msgs/int32 reg_motor_charger_state\n", "std_msgs/int32 reg_power_a_current\n", "std_msgs/int32 reg_power_b_current\n", "std_msgs/int32 reg_motor_flipper_angle\n", "std_msgs/int16 battery_current_a\n", "std_msgs/int16 battery_current_b", "std_msgs/Header header\n", "std_msgs/int32 reg_motor_fault_flag_left\n", "std_msgs/int32 reg_motor_temp_left\n", "std_msgs/int32 reg_motor_temp_right\n", "std_msgs/int32 reg_power_bat_voltage_a\n", "std_msgs/int32 reg_power_bat_voltage_b\n", "std_msgs/int32 reg_robot_rel_soc_a\n", "std_msgs/int32 reg_robot_rel_soc_b\n", "std_msgs/uint16 battery_mode_a\n", "std_msgs/uint16 battery_mode_b\n", "std_msgs/uint16 battery_temp_a\n", "std_msgs/uint16 battery_temp_b\n", "std_msgs/uint16 battery_voltage_a\n", "std_msgs/uint16 battery_voltage_b\n", "std_msgs/int32 buildno", "std_msgs/Header header\n", "\n", "std_msgs/bool over_charged_alarm\n", "std_msgs/bool terminate_charge_alarm\n", "std_msgs/bool over_temp_alarm\n", "std_msgs/bool terminate_discharge_alarm\n", "std_msgs/bool remaining_capacity_alarm\n", "std_msgs/bool remaining_time_alarm\n", "\n", "std_msgs/bool initialized\n", "std_msgs/bool discharging\n", "std_msgs/bool fully_charged\n", "std_msgs/bool fully_discharged"]}
,{"url": "https://wiki.ros.org/turtlebot3_bringup", "package": "turtlebot3_bringup", "package_summary": ["roslaunch scripts for starting the TurtleBot3"], "package_details": [" ", "\n", "\n", "\n", "\n", "\n"], "package_tt": ["cmd_vel", "motor_power", "reset", "sound", "battery_state", "cmd_vel_rc100", "diagnostics", "imu", "joint_states", "magnetic_field", "odom", "sensor_state", "tf", "version_info", "~baud", "int", "~port", "string", "imu", "scan", "sensor_state", "version_info", "diagnostics", "rpms", "scan", "~frame_id", "string", "~port", "string"]}
,{"url": "https://wiki.ros.org/linksys_access_point", "package": "linksys_access_point", "package_summary": ["\n    A ROS node that controls a Linksys access point with\n    a Linksys WRT610n-compatible web interface.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package implements the ", " dynamic_reconfigure interface for controlling an access point for Linksys access points.  "], "package_tt": ["txpower_auto", "False", "Manual", "Wireless/Basic\u00a0Wireless\u00a0Settings", "Wi-Fi\u00a0Protected\u00a0Setup", "update_configuration()", "wmm", "a", "b", "g", "n", "a", "a-only", "a", "n", "mixed", "b", "b-only", "b", "n", "g", "g-only", "g", "n", "mixed", "linksys_apcontrol_node.py", "~interface", "string", "wl0", "wl0", "wl1", "~ip", "string", "192.168.1.1", "~user", "string", "~password", "string", "admin"]}
,{"url": "https://wiki.ros.org/pr2_dashboard_aggregator", "package": "pr2_dashboard_aggregator", "package_summary": ["A simple script that aggregates all of the topics that a \"pr2_dashboard\" app might be interested in."], "package_details": ["\n", "\n"], "package_tt": ["pr2_dashboard_aggregator", "pr2.launch", "pr2_dashboard_aggregator", "power_board/state", "power_state", "ddwrt/accesspoint", "pr2_etherCAT/motors_halted", "dashboard_agg"]}
,{"url": "https://wiki.ros.org/access_point_control", "package": "access_point_control", "package_summary": ["\n    Defines an API for access point control based on \n    dynamic_reconfigure. Other packages must\n    implement the API for various access-point models: \n    for example: hostapd_access_point for hostapd-based control or\n    linksys_access_point for Linksys router web interface.\n  "], "package_details": ["\n", "\n", "The following dynamic_reconfigure API must be implemented by packages specific to access point model such as ", ", ", ", ", ". "], "package_tt": ["~enabled", "bool", "True", "False", "~ssid", "str", "test", "~wmm", "bool", "~mode", "str", "b", "a", "b", "g", "~freq", "double", "a", "~ieee80211n", "bool", "~encryption_mode", "string", "open", "wep", "wpa", "wpa2", "wpa_wpa2", "~encryption_pass", "string", "~txpower_auto", "bool", "~txpower", "int", "txpower_auto", "False", "~bitrate", "int", "1000000", "b", "24000000", "g", "a", "~status", "string", "OK", "FAIL", "errmsg", "~errmsg", "string"]}
,{"url": "https://wiki.ros.org/pr2_gazebo_plugins", "package": "pr2_gazebo_plugins", "package_summary": ["Gazebo Plugins for various PR2-specific sensors and actuators on the robot."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " plugin provides ROS topic and service interfaces similar to those provided by the ", " on PR2. ", "\n", "\n", "\n", " plugin provides ROS topics and services similar to those provided by ", " on physical PR2. ", "\n", "\n", "\n", "\n", "\n", "\n", " plugin provides similar ROS interface as ", " on the physical PR2 robot.  This plugin is written in a way that ", " works transparently with either this simulated plugin or the ", " hardware.  For more information on using ", " or ", " with this plugin, please see ", ". ", "\n", "\n", "This package contains dynamic plugins for ", " and ", " integration with simulated hardware. ", "Please see ", " for additional supported hardware components in simulation. ", "This stack will be updated with new features as the PR2 hardware itself is updated. Future versions will also incorporate ", " options to match ORS driver functionality. "], "package_tt": ["GazeboRosControllerManager", "GazeboRosProsilica", "GazeboRosPowerMonitor", "<robotParam>", "<robotNamespace>", "GazeboRosProsilica", "<robotNamespace>", "<imageTopicName>", "<cameraInfoTopicName>", "<pollServiceName>", "<frameName>", "<CxPrime>", "<Cx>", "<Cy>", "<focal_length>", "<distortion_k1>", "<distortion_k2>", "<distortion_k3>", "<distortion_t1>", "<distortion_t2>", "<hackBaseline>", "GazeboRosPowerNode", "<robotNamespace>", "<powerStateTopic>", "<powerStateRate>", "<fullChargeCapacity>", "<chargeRate>", "<dischargeVoltage>", "<dischargeRate>", "<chargeVoltage>", "plugged_in", "<powerStateTopic>", "<imageTopicName>", "<cameraInfoTopicName>", "request_image", "GazeboRosControllerManager"], "package_code": ["    <!-- GazeboMechanismControl -->\n", "    <controller:gazebo_ros_controller_manager name=\"gazebo_ros_controller_manager\" plugin=\"libgazebo_ros_controller_manager.so\">\n", "      <alwaysOn>true</alwaysOn>\n", "      <updateRate>1000.0</updateRate>\n", "      <robotParam>robot_description</robotParam>\n", "      <robotNamespace>/</robotNamespace>\n", "    </controller:gazebo_ros_controller_manager>", "  <body:empty name=\"camera_body_name\">\n", "    <sensor:camera name=\"high_def_sensor\">\n", "      <imageFormat>R8G8B8</imageFormat>\n", "      <imageSize>2448 2050</imageSize>\n", "      <hfov>45</hfov>\n", "      <nearClip>0.1</nearClip>\n", "      <farClip>100</farClip>\n", "      <updateRate>20.0</updateRate>\n", "      <controller:gazebo_ros_prosilica name=\"high_def_controller\" plugin=\"libgazebo_ros_prosilica.so\">\n", "        <alwaysOn>true</alwaysOn>\n", "        <updateRate>20.0</updateRate>\n", "        <imageTopicName>/prosilica/image_raw</imageTopicName>\n", "        <cameraInfoTopicName>/prosilica/camera_info</cameraInfoTopicName>\n", "        <pollServiceName>/prosilica/request_image</pollServiceName>\n", "        <frameName>high_def_frame</frameName>\n", "        <CxPrime>1224.5</CxPrime>\n", "        <Cx>1224.5</Cx>\n", "        <Cy>1025.5</Cy>\n", "        <focal_length>2955</focal_length> <!-- image_width / (2*tan(hfov_radian /2)) -->\n", "        <distortion_k1>0.00000001</distortion_k1>\n", "        <distortion_k2>0.00000001</distortion_k2>\n", "        <distortion_k3>0.00000001</distortion_k3>\n", "        <distortion_t1>0.00000001</distortion_t1>\n", "        <distortion_t2>0.00000001</distortion_t2>\n", "        <interface:camera name=\"high_def_iface\"/>\n", "      </controller:gazebo_ros_prosilica>\n", "    </sensor:camera>\n", "  </body:empty>", "    <controller:gazebo_ros_power_monitor name=\"gazebo_ros_power_monitor_controller\" plugin=\"libgazebo_ros_power_monitor.so\">\n", "        <alwaysOn>true</alwaysOn>\n", "        <updateRate>1.0</updateRate>\n", "        <timeout>5</timeout>\n", "        <interface:audio name=\"power_monitor_dummy_interface\" />\n", "        <powerStateTopic>power_state</powerStateTopic>\n", "        <powerStateRate>10.0</powerStateRate>\n", "        <fullChargeCapacity>87.78</fullChargeCapacity>\n", "        <dischargeRate>-474</dischargeRate>\n", "        <chargeRate>525</chargeRate>\n", "        <dischargeVoltage>15.52</dischargeVoltage>\n", "        <chargeVoltage>16.41</chargeVoltage>\n", "    </controller:gazebo_ros_power_monitor>"]}
,{"url": "https://wiki.ros.org/pr2_run_stop_auto_restart", "package": "pr2_run_stop_auto_restart", "package_summary": ["This package provides a node that monitors the state of the run stops of the pr2_robot. When the state of the\n   run stop changes from off to on, this node will automatically enable the power to the motors, and reset\n   the motors. This allows you to use the run stop as a 'pause' button. By using the run stop as a tool to\n   power up the robot, the run stop is also in reach of the user once the robot starts moving."], "package_details": ["\n", "\n"], "package_tt": ["run_stop_auto_restart", "power_board/state", "power_board/control", "pr2_etherCAT/reset_motors"]}
,{"url": "https://wiki.ros.org/kobuki_auto_docking", "package": "kobuki_auto_docking", "package_summary": ["Automatic docking for Kobuki:\n\t    Users owning a docking station for Kobuki can use this tool to let Kobuki find its nest autonomously."], "package_tt": ["~odom", "~core", "~dock_ir", "~motor_power", "~velocity", "~odom", "~core", "~dock_ir", "~motor_power", "~velocity", "~min_abs_v", "double", "~min_abs_w", "double"]}
,{"url": "https://wiki.ros.org/power_monitor", "package": "power_monitor", "package_summary": ["The power_monitor collects messages from the ocean_battery_server and\n     the pr2_power_board, and publishes a summary of their data in a\n     friendlier message format."], "package_details": ["\n", "\n", " takes data from ", " and ", " and republishes it in a more user-friendly message format. ", "\n", " (", ") ", "\n", " (", ") ", "\n", " (", ", default: 0.1) ", "The estimation method that ", " uses is reconfigurable via ", ". Two methods are currently available: "], "package_tt": ["power_monitor", "power_monitor", "/var/ros/power_monitor/power.log", "battery/server2", "power_board/power_state", "power_state", "~frequency", "float", "power_state", "~estimation_method", "string", "~advanced_log_file", "string", "~battery_update_timeout", "double"]}
,{"url": "https://wiki.ros.org/kobuki_node", "package": "kobuki_node", "package_summary": ["ROS nodelet for Kobuki: ROS wrapper for the Kobuki driver."], "package_details": [" "], "package_tt": ["~commands/motor_power", "~commands/external_power", "~commands/reset_odometry", "~commands/sound", "~commands/led1", "~commands/led2", "~commands/digital_output", "~commands/velocity", "odom", "diagnostics", "joint_states", "~events/button", "~events/bumper", "~events/cliff", "~events/wheel_drop", "~events/power_system", "~events/robot_state", "~events/digital_input", "~sensors/imu_data", "~sensors/imu_data_raw", "~sensors/dock_ir", "~sensors/core", "~version_info", "~device_port", "string", "/dev/kobuki", "~wheel_left_joint_name", "string", "wheel_left_joint", "~wheel_right_joint_name", "string", "wheel_right_joint", "~battery_capacity", "double", "16.5", "~battery_low", "double", "13.5", "~battery_dangerous", "double", "13.2", "~cmd_vel_timeout", "double", "0.6", "~publish_tf", "bool", "False", "~odom_frame", "string", "~base_frame", "string", "~acceleration_limiter", "bool", "~commands/motor_power", "~commands/external_power", "~commands/reset_odometry", "~commands/sound", "~commands/led1", "~commands/led2", "~commands/digital_output", "~commands/velocity", "~commands/controller_info", "odom", "diagnostics", "joint_states", "~events/button", "~events/bumper", "~events/cliff", "~events/wheel_drop", "~events/power_system", "~events/robot_state", "~events/digital_input", "~sensors/imu_data", "~sensors/imu_data_raw", "~sensors/dock_ir", "~sensors/core", "~version_info", "~controller_info", "~debug/raw_data_stream", "~debug/raw_data_command", "~debug/raw_control_command", "~device_port", "string", "/dev/kobuki", "~wheel_left_joint_name", "string", "wheel_left_joint", "~wheel_right_joint_name", "string", "wheel_right_joint", "~battery_capacity", "double", "16.5", "~battery_low", "double", "13.5", "~battery_dangerous", "double", "13.2", "~cmd_vel_timeout", "double", "0.6", "~publish_tf", "bool", "False", "~use_imu_heading", "bool", "True", "~odom_frame", "string", "~base_frame", "string", "~acceleration_limiter", "bool"]}
,{"url": "https://wiki.ros.org/rc_visard_driver", "package": "rc_visard_driver", "package_summary": ["The rc_visard_driver provides data from a Roboception rc_visard 3D sensor on several ROS topics."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "\n", " ", "Official ROS driver for ", " rc_visard 3D sensor. ", "See ", " and ", " for more details. ", "The ", " is the world\u2019s first 3D sensor that allows robots to perceive their environment in 3D and localize themselves in space. ", "The ", " is the official ROS driver for the ", " which provides ROS parameters (configuration), ROS services (control of rc_visards dynamic module) and ROS topics (sensor data: Images, Stereo Data, Point Clouds, Dynamic State i.e. poses and IMU data, TF).  ", "If the connected rc_visard has an ", " license, then the following ", "topics are additionally provided for images where the GPIO out1 is either low ", "or high. These topics only useful if ", " is set to the special mode ", ". ", "For color sensors with an ", " license, the following topics are ", "additionally available: ", "If the parameter ", " is set to true, the node subscribes to the ", "rc_visard's pose stream (same data published on ", " topic) and publishes them on tf. ", "The trajectory constructed and stored by the ", " node ", "can be retrieved by ", "The onboard map of the ", " node can be saved on the rc_visard for loading it ", "after a SLAM restart or power cycle: ", "The onboard ", " node can be \"reset\" (clears the internal state of the SLAM component, ", "including the trajectory) to free the memory with "], "package_tt": ["device", "02912345", ":02912345", "gev_access", "control", "exclusive", "off", "max_reconnects", "enable_tf", "enable_visualization_markers", "/dynamics_visualization_markers", "autostart_dynamics", "autostart_dynamics_with_slam", "autostop_dynamics", "autopublish_trajectory", "/trajectory", "ptp_enabled", "camera_fps", "camera_exp_auto", "camera_exp_max", "camera_exp_value", "camera_gain_value", "camera_exp_width", "camera_exp_height", "camera_exp_offset_x", "camera_exp_offset_y", "depth_acquisition_mode", "SingleFrame", "Continuous", "S", "C", "depth_quality", "Low", "Medium", "High", "StaticHigh", "L", "M", "H", "S", "StaticHigh", "High", "Medium", "Low", "High", "depth_static_scene", "depth_disprange", "depth_fill", "depth_seg", "depth_smooth", "depth_median", "depth_minconf", "depth_mindepth", "depth_maxdepth", "depth_maxdeptherr", "out1_mode", "Low", "High", "ExposureActive", "ExposureAlternateActive", "IO\u00a0Control", "ExposureActive", "out2_mode", "out1_mode", "Low", "camera_wb_auto", "camera_wb_ratio_red", "camera_wb_auto", "camera_wb_ratio_blue", "camera_wb_auto", "IO\u00a0Control", "out1_mode", "ExposureAlternateActive", "IO\u00a0Control", "enable_tf", "enable_tf", "/pose", "camera", "world", "camera", "imu", "my_visard", "my_visard_world", "my_visard_camera", "dynamics_start", "dynamics_restart", "dynamics_stop", "dynamics_start_slam", "dynamics_restart_slam", "dynamics_stop_slam", "rc_slam", "slam_get_trajectory", "rc_slam", "slam_save_map", "slam_load_map", "slam_remove_map", "rc_slam", "slam_reset", "my_visard", "my_visard_camera", "my_visard_world", "my_visard_imu"], "package_code": ["rosrun rc_visard_driver rc_visard_driver _device:=:02912345 _enable_tf:=True _autostart_dynamics:=True _autostop_dynamics:=True", "ROS_NAMESPACE=my_visard rosrun nodelet nodelet standalone rc_visard_driver _device:=:02912345"]}
,{"url": "https://wiki.ros.org/ros_control", "package": "ros_control", "package_summary": ["A set of packages that include controller interfaces, controller managers, transmissions and hardware_interfaces."], "package_details": ["\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ros_control packages are a rewrite of the ", " packages to make controllers generic to all robots beyond just the PR2. ", "A high-level overview of the project can be found in the ROScon 2014 talk entitled ", " (", ", ", "). ", "A short summary of CombinedRobotHW can be found in ", " ROScon 2016 talk. ", "Additional documentation is available at the ", " ", "A list of available controller plugins, contained in ", ", as of this writing. You can of course create your own and are not limited to the below list. All controllers use the ", " to send commands to a hardware interface. ", "Take a look at the ", " to understand how the joint_trajectory_controller is namespaced with the position_controller, velocity_controller, etc. ", "Also refer to the ", " of the hardware_interface and the ", ". ", "From the above it can be seen that power remains constant between input and output. Complementary ", " (first part will do). ", "See ", ". ", "Transmission-specific code (not robot-specific) implementing bidirectional (actuator <-> joint) effort and flow maps under a uniform interface shared across transmission types. This is hardware-interface-agnostic. A list of available transmission types as of this writing: ", "See ", " ", "The ", " contains data structures for representing joint limits, methods for populating them from common formats such as URDF and rosparam, and methods for enforcing limits on different kinds of joint commands. ", "The joint_limits_interface is not used by controllers themselves (it does not implement a ", ") but instead operates after the controllers have updated, in the ", " method (or equivalent) of the robot abstraction. Enforcing limits will ", " the commands set by the controllers, it does not operate on a separate raw data buffer. ", "See ", " ", "Or on Ubuntu and other platforms from source. To ease installing from source a ", " file is provided: ", "Not exactly a roadmap, but this ", " contains discussion and proposed solutions to allow ros_control to better accommodate more complex control setups and address shortcomings in the current implementation. ", "A ", " exists with a mailing list for discussing ros_control issues and features. You are encouraged to join and help with ros_control's development! "], "package_code": ["@article{ros_control,\n", "author = {Chitta, Sachin and Marder-Eppstein, Eitan and Meeussen, Wim and Pradeep, Vijay and Rodr{\\'i}guez Tsouroukdissian, Adolfo  and Bohren, Jonathan and Coleman, David and Magyar, Bence and Raiola, Gennaro and L{\\\"u}dtke, Mathias and Fern{\\'a}ndez Perdomo, Enrique},\n", "title = {ros\\_control: A generic and simple control framework for ROS},\n", "journal = {The Journal of Open Source Software},\n", "year = {2017},\n", "doi = {10.21105/joss.00456},\n", "URL = {http://www.theoj.org/joss-papers/joss.00456/10.21105.joss.00456.pdf}\n", "}", "P_in        = P_out\n", "\n", "F_in x V_in = F_out x V_out", "effort map: F_joint = F_actuator * n\n", "\n", "flow map:   V_joint = V_actuator / n", "sudo apt-get install ros-$ROS_DISTRO-ros-control ros-$ROS_DISTRO-ros-controllers", "cd CATKIN_WORKSPACE/src\n", "wstool init\n", "wstool merge https://raw.github.com/ros-controls/ros_control/$ROS_DISTRO-devel/ros_control.rosinstall\n", "wstool update\n", "cd ..\n", "rosdep install --from-paths . --ignore-src --rosdistro $ROS_DISTRO -y\n", "catkin_make"]}
,{"url": "https://wiki.ros.org/schunk_powercube_chain", "package": "schunk_powercube_chain", "package_summary": ["This packages provides a configurable driver of a chain\n  of Schunk powercubes. The powercube chain is configured\n  through parameters. Most users will not directly interact\n  with this package but with the corresponding launch files\n  in other packages, e.g. schunk_bringup, cob_bringup, ..."], "package_details": ["\n", "\n", "\n", "\n", "To use this package you need one or more powercubes ", ". Alternatively you can use a simulated version without any hardware, see ", ". ", "The installation is tested for Ubuntu 14.04 using ROS ", ". If you discover problems installing them on other platforms, please ", ". ", "The ", " package provides a configurable node for operating a chain of powercube modules. ", "\n", "This package is not intended to be used directly, but with the corresponding launch and yaml files from e.g. ", " in the ", " stack. ", "For starting only the lwa use ", "All hardware configuration is done in the ", " package. A sample parameter file in \"schunk_hardware_config/lwa/config/lwa.yaml\" could look like this "], "package_tt": ["schunk_powercube_chain", "joint_group_velocity_controller/command", "joint_group_position_controller/command", "/joint_states", "joint_trajectory_controller/state", "driver/current_operationmode", "/diagnostics", "driver/init", "driver/stop", "driver/recover", "driver/set_operation_mode", "can_module", "string", "can_device", "string", "can_baudrate", "int", "module_ids", "list\u00a0of\u00a0ints", "force_use_movevel", "bool", "joint_names", "list\u00a0of\u00a0strings", "max_accelerations", "list\u00a0of\u00a0doubles", "horizon", "double", "frequency", "double", "min_publish_duration", "double", "/robot_description", "urdf\u00a0model"], "package_code": ["roslaunch schunk_bringup lwa_solo.launch", "<include file=\"$(find schunk_bringup)/components/lwa.launch\" />", "can_module: PCAN\n", "can_device: /dev/pcan1\n", "can_baudrate: 1000\n", "modul_ids: [1,2,3,4,5,6,7]\n", "joint_names: [arm_1_joint, arm_2_joint, arm_3_joint, arm_4_joint, arm_5_joint, arm_6_joint, arm_7_joint]\n", "max_accelerations: [0.8,0.8,0.8,0.8,0.8,0.8,0.8]\n", "frequency: 68\n", "OperationMode: position\n", "ptp_vel: 0.4 # rad/sec\n", "ptp_acc: 0.1 # rad/sec^2\n", "max_error: 0.2 # rad"]}
,{"url": "https://wiki.ros.org/rosserial_embeddedlinux", "package": "rosserial_embeddedlinux", "package_summary": ["rosserial for embedded Linux enviroments"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "There are a variety of great embedded linux systems on the market today which enable quickly and easily programming hardware. Some, like the ", " support an entire electro-mechanical robotics platform. Others, like the Chumby alarm clock or WRT54-class routers provide just an inexpensive linux controller. This class of device typically supports USB and wifi, has USB drivers for webcam and USB-serial dongles, is physically small, and consumes under 10 watts of electrical power. This makes them expandable and interesting for use on smaller robots, especially when vision is desired.  ", "Using the ", " package, you can use ROS directly with the these systems. ", " provides a ROS communication protocol that works over your embedded linux system's serial UART, or its wifi or network connection. It allows your embedded linux system to run linux processes that are full fledged ROS nodes that can directly publish and subscribe to ROS topics, advertise services and request services, publish TF transforms, and get the ROS system time over any of the supported connection types. ", "The ", " package supports the following major connection types and capabilities: ", "This package contains embedded-linux-specific extensions required to run ", " on a small embedded linux system such as the VEXPro controller, Chumby alarm clock, WRT54GL router, Raspberry Pi, or many similar devices. It is meant to demonstrate how easy it is to integrate custom hardware and cheap sensors including USB cameras into your ROS project using an embedded linux system. The Tutorials of this package will walk you through setting up your run environment and creating a few example programs.  ", "Go to the ", " to learn how to install and use the package to connect your embedded linux system to ROS. ", "Please file new bugs on the project's ", ". The bugs listed below are the most serious, which you would want to be aware of when considering use of this technology. You are encouraged to contribute fixes. "]}
,{"url": "https://wiki.ros.org/hostapd_access_point", "package": "hostapd_access_point", "package_summary": ["\n    A ROS node that controls a hostapd-based access\n    point. It is mainly intended for use with a wireless \n    network adapter running in master mode. It implements \n    the dynamic_reconfigure interface defined\n    in the [[access_point_control]] package.\n  "], "package_details": ["\n", "\n", "\n", "\n", "\n", " ", " ", " ", "\n", "\n", "\n", "\n", ":  ", "\n", "A ROS node for starting and controlling a hostapd-based access point. This node works with wifi adapters that have ", "-compatible drivers which support master mode (see ", " for more information). ", "This is an example that shows how to set up an access point and control its parameters using the ", " interface. ", "The following launch file starts an AP node on the ", " interface and the ", ": ", "The desired configuration is selected: mode ", ", channel 44, WPA security with the chosen password, a TX power level of 8 dBm and a TX bitrate of 24Mbit/s. Next the ", " checkbox is checked at the AP is started: ", "This script is useful for setting up a ", "-based setup. mac80211_hwsim is a 802.11 radio simulator. The script takes two parameters: ", "If the mac80211_hwsim is not loaded or if the number of radios it has currently spawned is smaller than ", " then it is re-loaded with the proper radio count. The script prints to its output the name of the ", "-th interface. ", "For example (this is taken from a real setup), suppose that the system has a real wireless interface with name ", " and we need to spawn three virtual interfaces. Their names will be ", ", ", " and ", ".  ", "Using ", ": ", "The script can be used to launch nodes on the ", " with roslaunch. The following example, launches two nodes on the first and second mac80211_hwsim interfaces while ensuring that there are at least three total interfaces: "], "package_tt": ["ap_hostapd_node.py", "~interface", "string", "wlan0", "wlan1", "~ip", "string", "~netmask", "string", "~hostapd_path", "string", "hostapd", "~enabled", "bool", "True", "False", "~ssid", "str", "test", "~wmm", "bool", "~mode", "str", "b", "a", "b", "g", "~freq", "double", "a", "~ieee80211n", "bool", "~encryption_mode", "string", "open", "wep", "wpa", "wpa2", "wpa_wpa2", "~encryption_pass", "string", "~txpower_auto", "bool", "~txpower", "int", "txpower_auto", "False", "~bitrate", "int", "1000000", "b", "24000000", "g", "a", "~status", "string", "OK", "FAIL", "errmsg", "~errmsg", "string", "reconfigure_gui", "wlan0", "reconfigure_gui", "a", "enabled", "mac80211_hwsim", "radio\u00a0index", "total\u00a0number\u00a0of\u00a0radios", "total\u00a0number\u00a0of\u00a0radios", "radio\u00a0index", "wlan1", "wlan0", "wlan1", "wlan2", "find_hwsim_iface.py", "wlan0", "hwsim_nat_setup.sh", "network_traffic_control", "ap_hostapd_node.py"], "package_code": ["<launch>\n", "    <node name=\"ap_wlan0\" pkg=\"hostapd_access_point\" type=\"ap_hostapd_node.py\">\n", "        <param name=\"interface\" value=\"wlan0\"/>\n", "        <param name=\"ip\" value=\"192.168.68.1\"/>\n", "        <param name=\"netmask\" value=\"255.255.255.0\"/>\n", "    </node>\n", "    <node name=\"reconfigure_node\" pkg=\"dynamic_reconfigure\" type=\"reconfigure_gui\"/>\n", "</launch>", "import dynamic_reconfigure.client\n", "\n", "ap = dynamic_reconfigure.client.Client(\"ap_wlan0\")\n", "\n", "freq = IEEE80211_Channels.get_freq(44, IEEE80211_Channels.BAND_5000_MHz)\n", "config = ap.update_configuration({\"enabled\": True, \"mode\": 'a', \"freq\": freq, \"encryption_mode\": \"wpa\", \"encryption_pass\": \"sample_password\", \"txpower_auto\": False, \"txpower\": 8, \"bitrate\": 24*10**6})\n", "\n", "if config['status'] != \"OK\":\n", "    raise Exception(\"AP failed to start: \" + config['errmsg'])\n", "\n", "freq = IEEE80211_Channels.get_freq(1, IEEE80211_Channels.BAND_2400_MHz)\n", "config = ap.update_configuration({\"freq\": freq})\n", "\n", "if config['status'] != \"OK\":\n", "    raise Exception(\"AP failed to start: \" + config['errmsg'])", "$ echo `rosrun hostapd_access_point find_hwsim_iface.py 1 3`\n", "wlan0\n", "$ echo `rosrun hostapd_access_point find_hwsim_iface.py 2 3`\n", "wlan1\n", "$ echo `rosrun hostapd_access_point find_hwsim_iface.py 3 3`\n", "wlan1", "<launch>\n", "    <node name=\"ap1\" pkg=\"hostapd_access_point\" type=\"ap_hostapd_node.py\">\n", "        <param name=\"interface\" command=\"$(find hostapd_access_point)/scripts/find_hwsim_iface.py 1 3\"/>\n", "    </node>\n", "\n", "    <node name=\"ap2\" pkg=\"hostapd_access_point\" type=\"ap_hostapd_node.py\">\n", "        <param name=\"interface\" command=\"$(find hostapd_access_point)/scripts/find_hwsim_iface.py 2 3\"/>\n", "    </node>\n", "</launch>", "# rosrun hostapd_access_point hwsim_nat_setup.sh wlan0 192.168.68.1 192.168.69.1 wlan1 192.168.69.2 192.168.68.2\n", "\n", "# ifconfig wlan0\n", "wlan0     Link encap:Ethernet  HWaddr 02:00:00:00:00:00  \n", "          inet addr:192.168.68.1  Bcast:192.168.68.255  Mask:255.255.255.0\n", "\n", "# ifconfig wlan1\n", "wlan1     Link encap:Ethernet  HWaddr 02:00:00:00:01:00  \n", "          inet addr:192.168.69.2  Bcast:192.168.69.255  Mask:255.255.255.0"]}
,{"url": "https://wiki.ros.org/stereo_slam", "package": "stereo_slam", "package_summary": ["Stereo Slam"], "package_details": [" ", "stereo_slam is a ROS node to execute Simultaneous Localization And Mapping (SLAM) using only one stereo camera. The algorithm was designed and tested for underwater robotics. This node is based on the ", " library for graph optimization and uses the power of ", " to find loop closures between graph nodes. It uses a keyframe to multi-keyframe loop closing mechanism, based on keypoint clustering, to improve the SLAM corrections on feature-poor environments. ", "See the documentation on ", ". "]}
,{"url": "https://wiki.ros.org/ocean_battery_driver", "package": "ocean_battery_driver", "package_summary": ["This is an interface to the Ocean Server Technology Intelligent Battery and Power System."], "package_details": ["\n", "\n", "\n", " controls an array of battery controllers.  The API below is for informational purposes only; it is not intended for use by anything other than ", ", which is where you should look for power data.  ", "\n", " (", ") ", "\n", " (", ", default: if no value specified on command-line, 4) ", "The ", " node will report the status of the batteries to diagnostics. It will warn on the diagnostics if a battery does not update within a timeout. "], "package_tt": ["ocean_server", "ocean_server", "/diagnostics", "/battery/server2", "/battery/server", "~number_of_ports", "int", "~debug_level", "int", "~port<ID>", "string", "\"/dev/ttyUSB<ID>\"", "~lag_timeout", "int", "60", "~stale_timeout", "int", "120"]}
,{"url": "https://wiki.ros.org/lex_node", "package": "lex_node", "package_summary": ["Package providing a ROS node for interacting with Amazon Lex"], "package_details": ["\n", ": Amazon Lex is a service for building conversational interfaces into any application using voice and text. Amazon Lex provides the advanced deep learning functionality of automatic speech recognition (ASR) for converting speech to text, and natural language understanding (NLU) to recognize the intent of the text, to enable you to build applications with highly engaging user experiences and lifelike conversational interactions. With Amazon Lex, the same deep learning technologies that power Amazon Alexa are now available to any developer, enabling you to quickly and easily build sophisticated, natural language, conversational bots (\u201cchatbots\u201d). ", "\n", "\n", "The ROS ", " node enables a robot to comprehend natural language commands by voice or textual input and respond through a set of actions, which an Amazon Lex Bot maps to ROS messages. Out of the box this node provides a ROS interface to communicate with a specified Amazon Lex bot (configured via lex_config.yaml) and requires configuration of AWS credentials. The Amazon Lex bot needs to be defined with responses and slots for customer prompts. A set of default slots and mappings are demonstrated in the ", " and include actions as \u201cCreate <location_name>,\u201d \u201cGo to <location_name>\u201d and \u201cStop.\u201d Additional guides on configuring bots with are available at ", ". ", "The ROS ", "  wraps the ", " in a ROS service API. ", "The source code is released under an ", ". "], "package_tt": ["lex_node", "lex_node"]}
,{"url": "https://wiki.ros.org/pr2_bringup", "package": "pr2_bringup", "package_summary": ["Launch files and scripts needed to bring a PR2 up into a running state."], "package_details": [" is a package that collects together the scripts, ", " files, and dependencies that are required to bring a PR2 robot into a running state. ", "\n", "\n", "\n", " ", " ", "\n", "The user's entry point for this package is the file ", ".  This launch file contains all nodes to run a complete PR2 system. However, you cannot use pr2.launch to start up the robot (see ", " for instructions), because pr2.launch requires another launch file to load the robot description and robot analyzer on the parameter server first. ", "To disable the ", " set the \"no-prosilica\" arg to \"true\" in \"/etc/ros/robot.launch\" when launching your PR2: ", "This manual will take you step by step through starting the PR2 robot, ", ". Note: If you have a PR2 that is running both ROS Groovy and ROS Hydro, this is then the start sequence: ", "When the PR2 starts up for the first time since a power down, it will move its arms, casters, head and later platform to find the reference position of each joint.  This is done by the calibration script ", ". When finished, the PR2 joint calibration script stores the joint reference positions locally in the motor controller board (MCB) of the corresponding joint.  So the next time you start the PR2, it will remember the reference positions and won't have to repeat the same calibration routine over and over again. "], "package_tt": ["pr2_bringup", "pr2.launch", "pr2_bringup/scripts/calibrate_pr2.py"], "package_code": ["<launch>\n", "  <arg name=\"no-prosilica\" value=\"true\" />\n", "  <include file=\"$(find pr2_bringup)/pr2.launch\" />\n", "\n", "  <!-- Other stuff -->\n", "</launch>", "robot groovy", "export ROS_ENV_LOADER=/etc/ros/env.sh", "roslaunch /etc/ros/robot.launch", "robot hydro", "export ROS_ENV_LOADER=/etc/ros/env.sh", "roslaunch /etc/ros/robot.launch", "robot start"]}
,{"url": "https://wiki.ros.org/pr2_power_drivers", "package": "pr2_power_drivers", "package_summary": ["Power drivers for the PR2 robot."], "package_details": ["\n", " contains the drivers that control the PR2 power system.  You should look at ", " for reading the power state of the robot. ", "\n", "Report new issues on ", " "], "package_tt": ["pr2_power_drivers"]}
,{"url": "https://wiki.ros.org/pr2_power_board", "package": "pr2_power_board", "package_summary": ["This provides a ROS node for the PR2 Power Board."], "package_details": ["\n", " controls with the PR2 power board.  The API below is for informational purposes only; it is not intended for use by anything other than ", ", which is where you should look for power data. ", "\n", "\n", "\n", "The ", " runs on the PR2 and controls the PR2 power board. The node regulates the main fan speed of the PR2 based on battery and power board temperature.  "], "package_tt": ["power_node2", "power_node2", "battery/server2", "/diagnostics", "~state", "~control2", "~control", "~sample_frequency", "float", "~transition_frequency", "float", "/diagnostics", "~state", "~control"]}
,{"url": "https://wiki.ros.org/smacha", "package": "smacha", "package_summary": ["SMACHA (short for \"State Machine Assembler\", pronounced \"smasha\") aims at distilling the task-level simplicity of SMACH into compact YAML-based scripts in the foreground, while retaining all of its power and flexibility in Jinja2-based templates and a custom code generation engine in the background."], "package_details": ["\n", " (short for \"State Machine Assembler\", pronounced \"smasha\") aims at distilling the task-level simplicity of ", " into compact YAML-based scripts in the foreground, while retaining all of its power and flexibility in Jinja2-based templates and a custom code generation engine in the background. ", "\n", "\n", "\n", "Use GitHub to ", ". [", "]", "\n  ", "The ", " provides an overview of the functionalities and core concepts of SMACHA. "]}
,{"url": "https://wiki.ros.org/omip", "package": "omip", "package_summary": ["This metapackage groups all the packages for Online Multimodal Interactive Perception (OMIP)."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "(Main author) Roberto Mart\u00edn-Martin (", ", ", ") ", "Sebastian H\u00f6fer (", ", ", ") ", "Oliver Brock (", ") ", "1. ", ". Three estimation levels: feature tracking, feature-based rigid body tracking, kinematic model estimation. This option can execute only using RGB-D images and therefore requires less computational power.  ", "To try this option, download one of the rosbags with the \"_imgs\" suffix and launch OMIP using the option \"--omip=1\" (or \"--omip=2\" if you want that the terminals  ", "remain open after finishing the execution, for debugging purposes). ", "More frequent problem: The feature tracking is not running and looks like frozen -> Check in feature_tracker/cfg/feature_tracker_cfg.yaml the depth_img_topic name. Depending if you are using ", "openni or openni2 (or rosbags generated from one or the other package) the name of the topic for the depth maps is different. ", "Based on the recursive estimation schema - prediction/correction -  our framework can cope with the high amount of data provided by the robot's sensors ", ". ", "The key (and the main idea of our framework) is to factorize the perceptual problem into smaller *perceptual units*, solve them with single recursive estimation loops and connect all the loops tightly.  ", "The connection of the loops defines a bidirectional information flow between loops: a bottom-up flow to pass estimations as measurements to more abstract levels, and a top-down flow to pass predicted measurements as predicted next states to less abstract levels. ", "By connecting the loops our framework can interpret the combined sensor-action stream as evidence of concepts of different level of abstraction. ", "Each recursive estimation level is realized as a ROS node that implements the interface ", ".  ", "A recursive estimation level is defined by: ", "* Measurement ", "* State ", "* Priors: ", "Internally, each level contains at least one recursive estimation filter. These filters implement the interface ", ". ", "The levels call the corresponding correct-predict methods of the filters and pass the measurements/states up and down. "], "package_tt": ["rosrun\u00a0omip_launch\u00a0omip.sh\u00a0--help"], "package_code": ["git clone https://github.com/tu-rbo/omip.git\n", "git clone https://github.com/tu-rbo/omip_msgs.git", "gsettings set org.gnome.desktop.default-applications.terminal exec 'gnome-terminal'", "cp ~/.config/terminator/config ~/.config/terminator/config.bak\n", "cp omip/omip_launch/cfg/terminator/config ~/.config/terminator/", "sudo apt-get install ros-indigo-pcl-ros ros-indigo-openni-launch ros-indigo-openni-camera\n", "ros-indigo-openni2-launch ros-indigo-openni2-camera ros-indigo-cmake-modules", "sudo apt-get install ros-indigo-bfl", "sudo cp omip/omip/third_party/bflConfig.cmake /opt/ros/indigo/share/bfl/", "git clone https://github.com/roberto-martinmartin/rviz_plugin_camerarenderpublisher.git", "git clone https://github.com/laas/rviz_plugin_covariance.git", "sudo apt-get install ros-indigo-libpointmatcher", "sudo cp your_ros_install_dir/share/libpointmacher/libpointmatcherConfig.cmake your_ros_install_dir/share/libpointmacher/libpointmatcherConfig.cmake.bak", "sudo cp omip/omip/third_party/libpointmatcherConfig.cmake your_ros_install_dir/share/libpointmacher/", "touch omip/shape_tracker/CATKIN_IGNORE", "catkin build (omip)", "rosbag decompress rosbagname.bag", "rosrun omip_launch omip.sh --omip=1 --rgbd=0", "rosrun omip_launch omip.sh --help", "rosbag play rosbagname.bag"]}
,{"url": "https://wiki.ros.org/retalis", "package": "retalis", "package_summary": ["Retalis Language for Information Processing and Management in Autonomous Robot Software"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", " ", " ", " ", " ", " ", "\n", "\n", " ", " ", " ", "\n", " ", " ", "\n", "\n", " ", "Messages received by retalis from the subscribed topics are automatically converted to events. For example, the following message of type ", " ", "Events are time-stamped according to header times of ros messages. If a message does not have a header, it is time stamped with ", ".  The format of time-stampes are  ", " where ", " encodes nanoseconds since seconds (i.e. stamp.nsec in ros messages). For example, the above ", " message contains a list of ", " messages (only one here). While each  ", " message is time-stamped, the ", " itself does not have a header. Therefore, the corresponding event is stamped with the current time. ", "The following rule calls  the ", " function for every ", " event received by retalis. ", "Each ", " message from ", " contains a list of recognized objects, each represented by a  ", " message. The following rule generates a separate event for each object. ", "where ", " represents a recognized object and ", " encodes the time of recognition. This time corresponds to the time of taking the picture at which the object was recognized. This time is taken from the header file of the corresponding ", " message. The events is also time stamped with ", ". ", "Retalis integrates the '", ". ", " supports temporal and logical reasoning on flow of events. Please see ", "  for publications and for examples of rules implementing various event-processing functionalities. ", "This memory instance keeps the history of events of the form ", ", specified by the first argument. The second argument specifies a list of conditions, being empty here. A memory instance only records events that satisfy the conditions. The third argument specifies the format for recording events. The fourth argument is the Id of the memory instance. The last argument is the size. Only the last 2500 events of the given form are maintained by this memory instance. ", "The ", " event from Section 4.1.3 matches this memory instance. This events is recorded by this memory instance as ", ". ", "We saw in Section 4.1.3 that the ", " and ", " functions are implemented as Prolog clauses. The ", " file can include an arbitrary Prolog program to encode a domain knowledge. We also saw in Section 4.1.4  that how memory instances are used to maintain histories of events ", "The Prolog program in ", " together with the the dynamic knowledge maintained by memory instances represent a Prolog-based knowledge base. This knowlede base can be queries by event-processing rules, for instance, as in Section 4.1.3. It can be also queried directly by a ros service (in our ", " list). ", "An example of using ", " and ", " terms is in implementation of the ", " function, in the eventRules.txt. The input values to this function is the ", " of a memory instance, keeping the history of some ", " events, and a time point. The ", " events represent observations of the transformation between two coordinate frames over time. From these observations, this function interpolates the transformation between the frames at time ", ". This is implemented as follows. The last observation before ", " and the first observation after ", " are found using the ", " and ", " terms. Then the position is linearly interpolated by making a function call to the ", " library that has been integrated with retalis. ", "The ", " function in eventRules.txt uses the ", " function to position an object in the world reference frame. Given ", ", the position of an object relative to the camera at time ", ", this function computes ", ", the position in the world, as follows. First, it changes the time format from ros time to datime. Then, it interpolates the transformation between ", ", ", ", ", ", ", " and ", " at the time ", ". Third, it applies these transformations on the ", " by making a function call to the ", " library. It is assumed that the ", " frame is aligned with the world reference frame. ", "We saw in Section 4.1.6 that how calling ", " function interpolates the position between the ", " and ", " coordination frames at time ", ". This function uses ", " and ", " terms to access the first and the last observations after and before ", ", respectively. To interpolate the position at ", ", the position should have been observed, at least once, after ", ". The observations, ", " messages here, are received asynchronously. Therefore, the ", " function should be evaluated only after the ", " memory instance has been updated with an event occurring after ", ". This is realized in retalis using a synchronized event, as follows. ", "The ", " function, performs the ", ", when the ", " are satisfied and then generate the ", ". Consider the following clause from eventRules.txt: ", "This rule computes the position of recognized markers in the world and is read as follows.   For each ", " event, specified in line 6, the position is computed by calling the ", " function, as in line 3. After computing the position, an event of the following form is generated, specified in line 2: ", "Such a ", " event encodes the marker's name, its position in the world and the time of recogntion. The ", " are the followings, specified in line 4: ", "These conditions specify that the ", " function should be evaluated, only after all ", ", ", ", ", ", ", " and ", " memory instances have been updated, at least once, with events occurring after time ", ". The time ", " is the time of recognition of the marker. ", "Retalis performs the synchronization of events in an event-driven and efficient way. The generation of a synchronized ", " is posponed, until the ", " are satisfied. Postponing an event does not postpone the generation of other events and postponed events are generated as soon as necessary conditions are met. ", "The subscription subscribes the topic ", " to the ", " events in which ", " is ", ". Such events are generated by the synchronized rule, presented in Section 4.1.7. They contain the position of the marker ", " in the world coordination frame.  The id of the subscription is ", " which can be used to cancel the subscrition at any time. ", "The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes when running the NAO example. The retalis node calculates the position of objects in real-time. It processes about 1900 events, memorizes 130 new events and prunes 130 outdated events per second.  It also queries memory instances, 70 times per second. These tasks are performed using about 18 percent of the CPU time. In this experience, the retalis node has been directly subscribed to the ", " and ", " ros topics. The retalis-ros-converter only subscribes retalis to the ", " topic and converts and publishes events about objects' positions to ros topics. To have this setup, comments out the subscriptions to ", " and ", " topics in the pub-sub.xml file and instead, set the ", " boolean variable in the retalis_interface.cpp file to ", ". You should also recompile the package. ", "As we saw in Section 4.1.2, retalis provides an easy way to subscribe to ros topics and automatically convert ros messages to events. This is implemented by the retalis-ros-converter node. The implementation is in Python and is realized by inspecting classes and objects at runtime and therefore is expensive. The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes for the NAO example, when the retalis-ros-converter is used to subscribe to ", " and ", " topics. This results show that while the automatic conversion among messages and events are desirable in a prototyping phase, the final application should implement it in C++ for performance reasons. We will investigate the possibility to re-implement the retalis-ros-converter node in C++. ", "The following figure shows the CPU time for a number of runs where up to 160 memory instances are added to the NAO example. These memory instances record ", " events. Among the events processed by retalis, there are no such events. The results show that the increase in CPU time is negligible. This shows that a memory instance consumes CPU time only if the input stream of events contains events whose type matches the type of events the memory instance records.  ", "In the following figure, the green and blue lines show the CPU time for cases where 20 memory instances of type ", " are added to the NAO example. These memory instances match all ", " events, about 1900 of such is processed every second. The size of memory instances for the green line is 2500. These memory instances reach their size limit in two seconds. After this time, the CPU time usage is constant over time and includes the costs of unification, assertion and retraction for updating 20 memory instances with 1900 events per second. The size of memory instances for the blue line is 150,000. It takes about 80 seconds for this memory instances to reach their size limit. Consequently, the CPU time before the time 80 only includes the costs of unification and assertion, but not the costs of retraction. After the time 100, the CPU usages of both runs are equal. This shows that the cost of a memory instance does not depend on its size. The purple line shows the CPU time for the case where similarely there are 20 memory instances of type ", ". However, these memory instances record events until their reach their size limit. We added a condition for these memory instances such that after reaching their size limit, they perform no operation when receiving new events. After the time 100, the CPU time is constant about 23 percent, being 5 percent more than the CPU time of the NAO example, represented by the red line. This 5 percent increase represents the unification cost. This also shows that the costs of about 38000 assertions and 38000 retractions per second is about 30 percent of CPU time. In other words, 2500 memory updates (i.e. assertions or retractions) are processed using one percent of CPU time. ", "The following figure shows the CPU time for a number of runs where up to 40 memory instances of type ", " and size 2500 are added to the NAO example.  The red line at the bottom shows the CPU time for the NAO example. We make the following observations. Adding first 10 memory instances to the NAO example increases the CPU time about 20 percent. After that, adding each set of 10 memory instances increases the CPU time about 13 percents. This shows that the cost grows less than linearly. The implementation of memory instances is in a way that the cost of an assertion or a retraction can be assumed constant. This means that the unification cost for the first set of memory instances is the highest. In other words, the unification cost per memory instance decreases when the number of memory instances are increased.  ", "The following figure shows the CPU time for a number of runs where up to 640 memory instances of type ", " and size 2500 are added to the NAO example. The events matching these memory instances are received with the frequency of 50 Hz. We make the following observaitons. First, it takes 50 seconds for these memory instances to reach their size limit. After 50 seconds, these memory instances reach their maximum CPU usages, as the costs of retraction is added. Second, each memory instance filters 1900 events per second recording about two percents of them. The cost of 640 memory instances is about 35 percent of CPU time. Third, the unification cost per memory instance is decreased when the number of memory instances are increased. ", "The following figure compares the costs of different types of memory instances. The purple line shows the CPU time for the case where there are 10 memory instances of type ", ". The green line shows the CPU time for the case where there are 320 memory instances of type ", ". We observe that the costs of both cases are equal. The memory instances in the former case record 19,000 events per second (i.e. 10*1900). The memory instances in the latter case filter 1900 events per seconds for ", " events, recording 16000 events per second (i.e. 320*50). The results show the efficiency of the filtering mechanism. ", "The brown line shows the CPU time for the case where there are 10 memory instances of type ", " and 320 memory instances of type ", ". ", "Comparing it with the green and purple lines shows that the CPU time usage of these memory instances is less than sum of the CPU usages by 10 ", " memory instances and 320 ", " memory instances. This shows that the  unification cost per memory instance is decreased when the number of memory instances are increased, even when the memory instances are not of the same type. ", "The green line in the following figure shows the CPU time of the NAO example adapted as follows. There is an additional ", " memory instance of size 128. This memory instance is queried by 1000 ", " terms for each recognition of an object. In average, 7000 ", " terms are evaluated per second. The blue line visualize the CPU time of a similar program in which 7000 ", " terms are evaluated per seconds. The figure shows that the costs of the evaluations of ", " and ", " terms are similar. The purple line shows the CPU time of the case where 14,000 ", " terms are evaluated per second. We observe that the cost grows linearly, as expected. ", "The blue line in the following figure visualizes the CPU time of the case where 7000 ", " terms are evaluated per second. The green line visualizes the CPU time of the case where there are 320 ", " memory instances. The purple line visualizes the CPU time of the case where 7000 ", " terms are evaluated per second and there are 320 ", " memory instances. We observe that the cost of accessing a memory instance does not depend on existance of other memory instances. ", "The green line in the following figure visualizes the CPU time of evaluating 7000 ", " terms per second on a memory instance of size 128. The blue linevisualizes the CPU time of evaluating 7000 ", " terms per second on a memory instance of size 16384. The size of the memory instance in the latter case is the power of two of the size of the memory instance in the former case. The increase in the CPU time for the latter case, with respect to the NAO example, is less than two times of the increase in the CPU time for the former case.     ", "The red line in the following figure visualized the CPU time of the NAO example where in each second, 1000 ", " queries on a memory instance of size 2500 are evaluated. In addition, for each ", " query, a new event is generated. The green line visualizes the CPU time of a similar case where the next queries are synchronized. This experiment is conducted in a way that no query needs to be delayed. Coparing these two cases shows that when queries are not delayed, the synchronization cost is negligible. ", "Information flow processing systems such as Etalis are designed for applications that require a real-time processing of a large volume of data flow. Please see ", " for the evaluation of the performance of on-flow functionalities. The evaluation results show, in terms of performance, Etalis is competitive with respect to the state-of-the-art on-flow processing systems. "], "package_tt": ["add_output_subscription", "delete_output_subscription", "add_memory", "delete_memory", "add_input_subscription", "delete_input_subscription", "__0__", "__0__", "__0__", "__0__", "'\"/odom\"','\"/base_link\"'", "'\u201c/odom\u201d',\u00a0'\u201c/base_link\u201d'", "ToDo", "Event", "RelativePos", "AbsolutePose", "RelativePos", "AbsolutePose", "CameraTop", "RelativePos", "SynchConditions", "Query", "SynchConditions", "Event", "PoseStamped", "SyncConditions", "PoseStamped", "'\"4x4_1\"'", "__0__", "__0__", "CameraTop_frame"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]}
,{"url": "https://wiki.ros.org/phm_tools", "package": "phm_tools", "package_summary": ["The phm_tools meta package"], "package_details": ["\n", "\n", " ", " ", " Autonomous Transfer Vehicle ", " ", "Use Case Scenario Module, Sub-Module and Components List ", " ", " Use Case General Block Diagram ", " ", " General Failure Rates and Reliabilities of Components ", " ", " System Hazard Rate and Reliability at Different Temperature Conditions ", " Reliability of System at Different Temperatures ", " ", " ", " GAZEBO Test Environment ", " Locations of Some Specific Points ", " Followed Paths and Distance Between Each Neighbour Points ", " System PoTC for Each Route Segment ", "\n", "In the motor sub-module, failure rate of this component is selected as ", ". In encoder sub-module, we selected magnetic rotary encoder unit. Only use parameters  \u03bb", " (other parameters are negligible), the failure rate of encoder unit selected as ", ". ", "In the sensor module, there is only one component which is SICK S300 Laser Sensor and the failure rate of this component selected as ", " using product datasheet.  ", "In order to calculate hazard rate of the power card sub-module, we utilized diodes, capacitors and inductors. In addition, hazard rate of the fuse in the power card sub-modules selected as ", ". Hazard rate of the selected buck converter (LM 2596), is found as ", ". There is one more component in the Power Module which is battery and the failure rate of this component selected as ", ". ", "General failure rates and reliabilities of the all components at 35 \u2103 are shown in Table 2.  ", "Using Table 2, hazard rate of the system \u03bb", " calculated as ", ". In order to calculate the reliability of the system, we use Exponential Distribution function with the system hazard rate and time. Usage time selected as 1000 hours. The reliability of the system  R", " calculated as ", ".  "]}
,{"url": "https://wiki.ros.org/laser_filters", "package": "laser_filters", "package_summary": ["Assorted filters designed to operate on 2D planar laser scanners,\n    which use the sensor_msgs/LaserScan type."], "package_details": ["\n", "\n", " are configured from the parameter server.  They expect a parameter which is a list made up of repeating blocks of filter configurations.  These should almost always  be specified in a ", " file to be pushed to the parameter server.  Each filter specified in the chain will be applied in order. ", " that the ", " should be specified as ", " as the ", " is ", ", if only the ", " is used. ", ": ", "\n", " ", "\n", " ", "\n", " (list) ", " (string) ", "\n", " (", ") ", "\n", " (", ") ", "\n", ": ", ": ", " ", "\n", " ", "\n", " (list) ", " (list) ", " (string) ", " (bool, default: false) ", "\n", " (", ") ", "\n", " (", ") ", "\n", ": ", ": ", ": ", " ", "\n", "\n", "\n", " (", ") ", " (", ") ", " ", "\n", "\n", "\n", " (", ") ", " (", ") ", " (", ") ", " (", ") ", "\n", "\n", "\n", "\n", "\n", "\n", " (", ") ", " (", ") ", " (", ") ", "\n", "\n", "\n", " (", ") ", " (", ") ", " (", ") ", " (", ") ", " (", ") ", "\n", "\n", "\n", " (", ") ", " (", ") ", "\n", "\n", "\n", " (", ") ", " (", ") ", "\n", "\n", "\n", " (", ") ", " (", ") ", " (", ") ", " (", ") ", " (", ") ", " (", ") ", " (", ") ", "\n", "The primary content of the ", " package is a number of general purpose filters for processing ", " messages.  These filters are exported as plugins designed to work with with the ", ".  At the moment all of these filters run directly on ", ", but filters may be added in the future which process ", " instead.  Please review the ", " for an overview of how filters and filter chains are intended to work. ", "This package provides two nodes that can run multiple filters internally. Using these nodes to run your filters is considered best practice, since it allows multiple nodes to consume the output while only performing the filtering computation once.  The nodes are minimal wrappers around filter chains of the given type.  The ", " applies a series of filters to a ", ".  The ", " first applies a series of filters to a ", ", transforms it into a ", ", and then applies a series of filters to the ", ". ", "Each ", " is a separate plugin exported by the laser_filters package.  This allows them to be specified in a configuration file which can be loaded into an arbitrary filter_chain templated on a ", ". You can instantiate a laser filter into a filter_chain in C++ (", "), or you can use the ", " and ", " nodes which contain appropriate filter chains internally (", "). ", "The individual filters configurations contain a ", " which is used for debugging purposes, a ", " which is used to locate the plugin, and a ", " which is a dictionary of additional variables.  Consult the documentation for the particular filter plugin to see what variables may be set in the params field. ", "For example, in a package, ", ", to launch a ", " with two filters: ", " and ", ", you could use the file: ", "You could then push this configuration to the parameter server using ", " by running: ", "And then launching the ", ": ", "The scan_to_scan_filter_chain is a very minimal node which wraps an instance of a ", ".  This node can be used to run any filter in this package on an incoming laser scan.  If the ", " parameter is set, it will wait for the transform between the laser and the target_frame to be available before running the filter chain. ", "The scan_to_cloud_filter_chain is a very minimal node which wraps an instances of ", " and ", ".  This node can be used to run any filter in this package on an incoming laser scan.  After performing the laser filtering, it will use the ", " from ", " to transform each scan into a point cloud.  It will then run any cloud-based filtering, and finally publish the resultant cloud. ", "This filter internally makes use of the the ", " implementation of float-array filters.  It extracts the range and intensity values and treats each as an independent float array passed through an internal filter chain. ", "This filter removes laser readings that are most likely caused by the veiling effect when the edge of an object is being scanned.  For any two points ", " and ", ", we do this by computing the perpendicular angle.  That is, assuming the origin of the laser is ", ", the angle formed ", ".  If the perpendicular angle is less than a particular min or greater than a particular max, we remove all neighbors further away than that point. ", "This filter removes all measurements from the ", " which have an intensity greater than ", " or less than ", ".  These points are \"removed\" by setting the corresponding range value to ", " + 1, which is assumed to be an error case. ", "This filter removes all measurements from the ", " which are greater than ", " or less than ", ".  These points are \"removed\" by setting the corresponding range value to ", ", which is assumed to be an error case or ", "/", ". If ", " is true, the range within the laserscan message is used. ", "This filter removes points in a ", " outside of certain angular bounds by changing the minimum and maximum angle. ", "This filter removes points in a ", " inside of certain angular bounds. These points are \"removed\" by setting the corresponding range value to ", " + 1, which is assumed to be an error case. ", "This filter removes points in a ", " inside of a cartesian box. These points are \"removed\" by setting the corresponding range value to NaN which is assumed to be an error case. "], "package_tt": ["laser_filters", ".yaml", "name", "type", "params", "type", "pkg_name/FilterClass", "FilterClass", "mypkg", "LaserFilterClass1", "LaserFilterClass2", "my_laser_config.yaml", "scan_to_scan_filter_chain", "filters::FilterChain<sensor_msgs::LaserScan>", "~tf_message_filter_target_frame", "~scan_filter_chain", "~tf_message_filter_target_frame", "tf::MessageFilter", "scan", "scan_filtered", "my_laser_filter.launch", "my_laser_config.yaml", "filters::FilterChain<sensor_msgs::LaserScan>", "filters::FilterChain<sensor_msgs::PointCloud>", "LaserProjection", "~scan_filter_chain", "~cloud_filter_chain", "~target_frame", "~high_fidelity", "scan", "cloud_filtered", "my_laser_cloud_filter.launch", "my_laser_config.yaml", "my_cloud_config.yaml", "range_filter_chain", "FilterChain", "MultiChannelMedianFilterFloat", "intensity_filter_chain", "FilterChain", "MultiChannelMedianFilterFloat", "min_angle", "double", "max_angle", "double", "window", "int", "neighbors", "int", "upper_threshold", "lower_threshold", "range_max", "lower_threshold", "double", "upper_threshold", "double", "disp_histogram", "int", "upper_threshold", "lower_threshold", "NaN", "lower_replacement_value", "upper_replacement_value", "use_message_range_limits", "lower_threshold", "double", "upper_threshold", "double", "use_message_range_limits", "bool", "range_min", "range_max", "false", "lower_replacement_value", "double", "lower_threshold", "NaN", "upper_replacement_value", "double", "upper_threshold", "NaN", "lower_angle", "double", "upper_angle", "double", "range_max", "lower_angle", "double", "upper_angle", "double", "box_frame", "string", "min_x", "double", "max_x", "double", "min_y", "double", "max_y", "double", "min_z", "double", "max_z", "double"], "package_code": ["scan_filter_chain:\n", "- name: unique_name1\n", "  type: mypkg/LaserFilterClass1\n", "  params:\n", "    param1: a\n", "    param2: b\n", "- name: unique_name2\n", "  type: mypkg/LaserFilterClass2\n", "  params:\n", "    param1: a\n", "    param2: b", "$ rosparam load my_laser_config.yaml scan_to_scan_filter_chain", "$ rosrun laser_filters scan_to_scan_filter_chain", "<launch>\n", "  <node pkg=\"laser_filters\" type=\"scan_to_scan_filter_chain\"\n", "      name=\"laser_filter\">\n", "    <rosparam command=\"load\" file=\"$(find mypkg)/my_laser_config.yaml\" />\n", "    <remap from=\"scan\" to=\"base_scan\" />\n", "  </node>\n", "</launch>", "scan_filter_chain:\n", "- name: shadows\n", "  type: laser_filters/ScanShadowsFilter\n", "  params:\n", "    min_angle: 10\n", "    max_angle: 170\n", "    neighbors: 20\n", "    window: 1\n", "- name: dark_shadows\n", "  type: laser_filters/LaserScanIntensityFilter\n", "  params:\n", "    lower_threshold: 100\n", "    upper_threshold: 10000\n", "    disp_histogram: 0", "<launch>\n", "  <node pkg=\"laser_filters\" type=\"scan_to_cloud_filter_chain\"\n", "      name=\"tilt_shadow_filter\">\n", "    <rosparam command=\"load\" file=\"$(find mypkg)/my_laser_config.yaml\" />\n", "    <rosparam command=\"load\" file=\"$(find mypkg)/my_cloud_config.yaml\" />\n", "    <param name=\"high_fidelity\" value=\"true\" />\n", "    <param name=\"target_frame\" type=\"string\" value=\"base_link\" />\n", "    <remap from=\"scan\" to=\"tilt_scan\" />\n", "    <remap from=\"cloud_filtered\" to=\"tilt_scan_cloud_filtered\" />\n", "  </node>\n", "</launch>", "scan_filter_chain:\n", "- name: shadows\n", "  type: laser_filters/ScanShadowsFilter\n", "  params:\n", "    min_angle: 10\n", "    max_angle: 170\n", "    neighbors: 20\n", "    window: 1\n", "- name: dark_shadows\n", "  type: laser_filters/LaserScanIntensityFilter\n", "  params:\n", "    lower_threshold: 100\n", "    upper_threshold: 10000\n", "    disp_histogram: 0", "cloud_filter_chain:\n", "- type: PR2PointCloudFootprintFilter\n", "  name: footprint_filter\n", "  params:\n", "    inscribed_radius: 0.325", "scan_filter_chain:\n", "- type: laser_filters/LaserArrayFilter\n", "  name: laser_median_filter\n", "  params:\n", "    range_filter_chain:\n", "      - name: median_5\n", "        type: filters/MultiChannelMedianFilterFloat\n", "        params:\n", "          number_of_observations: 5\n", "          unused: 10\n", "    intensity_filter_chain:\n", "      - name: median_5\n", "        type: filters/MultiChannelMedianFilterFloat\n", "        params:\n", "          number_of_observations: 5\n", "          unused: 10", "scan_filter_chain:\n", "- name: shadows\n", "  type: laser_filters/ScanShadowsFilter\n", "  params:\n", "    min_angle: 10\n", "    max_angle: 170\n", "    neighbors: 20\n", "    window: 1", "scan_filter_chain:\n", "- name: interpolation\n", "  type: laser_filters/InterpolationFilter", "scan_filter_chain:\n", "- name: intensity\n", "  type: laser_filters/LaserScanIntensityFilter\n", "  params:\n", "    lower_threshold: 8000\n", "    upper_threshold: 100000\n", "    disp_histogram: 0", "scan_filter_chain:\n", "- name: range\n", "  type: laser_filters/LaserScanRangeFilter\n", "  params:\n", "    use_message_range_limits: false\n", "    lower_threshold: 0.3\n", "    upper_threshold: .inf\n", "    lower_replacement_value: -.inf\n", "    upper_replacement_value: .inf", "scan_filter_chain:\n", "- name: angle\n", "  type: laser_filters/LaserScanAngularBoundsFilter\n", "  params:\n", "    lower_angle: -1.57\n", "    upper_angle: 1.57", "scan_filter_chain:\n", "- name: angle\n", "  type: laser_filters/LaserScanAngularBoundsFilterInPlace\n", "  params:\n", "    lower_angle: 0.685398163\n", "    upper_angle: 0.885398163", "scan_filter_chain:\n", "- name: box\n", "  type: laser_filters/LaserScanBoxFilter\n", "  params:\n", "    box_frame: scan_link\n", "    min_x: -1.0\n", "    max_x: 1.0\n", "    min_y: -1.0\n", "    max_y: 1.0\n", "    min_z: -1.0\n", "    max_z: 1.0"]}
,{"url": "https://wiki.ros.org/pr2_common", "package": "pr2_common", "package_summary": ["URDF description of the robot kinematics and dynamics, 3D models of robot components, information required for gazebo to simulate the PR2, and messages specific to the PR2 such as detailed information about its power board and fingertip pressure sensors."], "package_details": ["\n", "\n", "\n", "  ", "This stack is not intended for user consumption. Check the ", " documentation for how to interpret this data, or  look at the examples in ", " "]}
,{"url": "https://wiki.ros.org/pr2_mechanism_model", "package": "pr2_mechanism_model", "package_summary": ["\n        This package contains the robot model that is used by the realtime\n        controllers\n        inside ", ". This robot model focuses on controlling the robot\n        mechanism in a realtime control loop, and therefore it only contains\n        the components of a robot that are relevant in realtime: the robot\n        joints (with encoders, transmisisons and actuators) and the\n        kinematic/dynamic model of the robot.\n     ", "\n        The pr2_mechanism_model package is well tested and is released with a stable API.\n     "], "package_details": ["\n", " ", "\n", "\n", " is the main class in this package.  When a controller gets initialized, the ", " passes the controller a pointer to the ", " (see the ", "). The robot state describes both the kinematic/dynamic model of the robot and the current state of the robot. The state of the robot is defined by the position/velocity/effort of the joints in the robot. The model of the robot is a ", " object, as defined in the ", ". Additionally, the ", " provides access to the 'controller time', the time at which a controller cycle is started. To see an example on how to use the ", ", check out the ", ". ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package contains the ", " C++ class, which is an interface to the robot joints and a description of the robot model. The ", " gives easy access to individual joints. To work with a kinematic chain that contains multiple joints, ", " contains a ", " tool that represents a full kinematic chain and interfaces with the ", ". ", "The ", " provides access by name to all the ", "s it contains. To get access to a ", ", use the following method: ", "From a ", " you can extract joint position, effort, velocity, and command the desired joint effort: ", "To get e.g. the measured joint position from the ", ", use: ", "or, to set the commanded effort on ", ", use: ", "The ", " give more examples on how to use the ", ". ", "The ", " also gives access to the joint model, which contains things like the joint type, axis, reference position, etc. To e.g. get the joint type, use: ", "The ", " API documentation provides all details. ", "For reference documentation, check out the  ", ". From a ", " you can read the measured position, measured velocity and measured effort effort, and write the commanded effort. ", "Class member ", " ", "The ", " also provides access to the transmissions between the motors and the joints. Typically you should not need the transmissions, unless you are using some advanced dynamic model, or you are calibrating the joints. To get access to a ", ", use the following method: ", "See the ", " for more details. ", "For details on the transmission description format, check out the ", " page. ", "Every time a controller cycle is started, the ", " records the time. This time can be accessed by all controllers through the ", ". When a controller e.g. needs to compute the duration between two consecutive update loops, it should ", ". In contrast to the system time, the controller time is not affected by the time other controllers consume in their update loop. Moreover, the controller time is the best measure of when the communication with the hardware actually occurs. To get access to the controller time, use: ", "The ", " contains a ", " robot description object. There is lots of ", " on the urdf model, and there are even a number of ", " you could look at. To get access to the urdf model use: ", "The ", " class provides an easy way to work with a kinematic chain that consists of multiple joints. Instead of finding all the joints by iterating through the ", ", the ", " will pull out all the joints between a given root and tip link: ", "From a ", " you can get the positions/velocities/efforts of all the joints, and set the efforts of all joints: ", "From a chain you can also extract a ", ": ", "See the ", " for more details. ", "The ", " is used when writing a realtime controller. For example code on how to use the ", " and the ", " classes, check out ", ". To see an example on how to use the ", " object for Cartesian control, check out ", ". "], "package_tt": ["pr2_mechanism_model", "pr2_mechanism_model::RobotState", "RobotState", "pr2_mechanism_model", "pr2_mechanism_model::Chain", "RobotState", "pr2_mechanism_model::RobotState", "RobotState", "RobotState", "RobotState", "pr2_mechanism_model::RobotState", "pr2_mechanism_model::JointState", "JointState", "JointState", "JointState", "JointState", "JointState", "JointState", "JointState", "urdf::Joint::safety", "pr2_mechanism_model::RobotState", "JointState", "pr2_mechanism_model::RobotState", "pr2_mechanism_model::RobotState", "pr2_mechanism_model::Chain", "RobotState", "Chain", "Chain", "KDL::Chain", "pr2_mechanism_model", "pr2_mechanism_model::RobotState", "pr2_mechanism_model::JointState", "pr2_mechanism_model::Chain"], "package_code": ["JointState* js = robot_state_->getJointState(name);", "double position = js->position_;", "js->commanded_effort_ = my_command;", "if (js->joint_->type == urdf::Joint::Continuous)\n", "ROS_INFO(\"This is a continuous joint\");", "js->joint_->safety", "Transmission* tr = robot_state_->getTransmission(name);", "ros::Time time = robot_state_->getTime();", "urdf::Model m = robot_state_->robot_->robot_model_;", "pr2_mechanism_model::Chain chain;\n", "chain.init(robot_state, root_name, tip_name);", "KDL::JointArray jnt_pos;\n", "chain.getPositions(jnt_pos);\n", "\n", "KDL::JointArrayVel jnt_pos_vel;\n", "chain.getVelocities(jnt_pos_vel);\n", "\n", "KDL::JointArray jnt_eff;\n", "chain.getEfforts(jnt_eff);\n", "\n", "KDL::JointArray jnt_eff;\n", "chain.setEfforts(jnt_eff);", "KDL::Chain kdl_chain;\n", "chain.toKDK(kdl_chain);"]}
,{"url": "https://wiki.ros.org/rosserial_embeddedlinux", "package": "rosserial_embeddedlinux", "package_summary": ["rosserial for embedded Linux enviroments"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "There are a variety of great embedded linux systems on the market today which enable quickly and easily programming hardware. Some, like the ", " support an entire electro-mechanical robotics platform. Others, like the Chumby alarm clock or WRT54-class routers provide just an inexpensive linux controller. This class of device typically supports USB and wifi, has USB drivers for webcam and USB-serial dongles, is physically small, and consumes under 10 watts of electrical power. This makes them expandable and interesting for use on smaller robots, especially when vision is desired.  ", "Using the ", " package, you can use ROS directly with the these systems. ", " provides a ROS communication protocol that works over your embedded linux system's serial UART, or its wifi or network connection. It allows your embedded linux system to run linux processes that are full fledged ROS nodes that can directly publish and subscribe to ROS topics, advertise services and request services, publish TF transforms, and get the ROS system time over any of the supported connection types. ", "The ", " package supports the following major connection types and capabilities: ", "This package contains embedded-linux-specific extensions required to run ", " on a small embedded linux system such as the VEXPro controller, Chumby alarm clock, WRT54GL router, Raspberry Pi, or many similar devices. It is meant to demonstrate how easy it is to integrate custom hardware and cheap sensors including USB cameras into your ROS project using an embedded linux system. The Tutorials of this package will walk you through setting up your run environment and creating a few example programs.  ", "Go to the ", " to learn how to install and use the package to connect your embedded linux system to ROS. ", "Please file new bugs on the project's ", ". The bugs listed below are the most serious, which you would want to be aware of when considering use of this technology. You are encouraged to contribute fixes. "]}
,{"url": "https://wiki.ros.org/kinesis_video_streamer", "package": "kinesis_video_streamer", "package_summary": ["Kinesis Video Streams producer node"], "package_details": ["\n", ": Amazon Kinesis Video Streams makes it easy to securely stream video from connected ", "devices to AWS for analytics, machine learning (ML), playback, and other processing. Kinesis Video Streams automatically provisions and elastically scales all the infrastructure needed to ingest streaming video data from millions ", "of devices. It also durably stores, encrypts, and indexes video data in your streams, and allows you to access your data through easy-to-use APIs. Kinesis Video Streams enables you to playback video for live and on-demand ", "viewing, and quickly build applications that take advantage of computer vision and video analytics through integration with Amazon Recognition Video, and libraries for ML frameworks such as Apache Mx", "Net, Tensor", "Flow, and Open", "CV. ", ": The easy-to-use Rekognition API allows you to automatically identify objects, people, text, scenes, and activities, as well as detect any inappropriate content. Developers can quickly build a searchable ", "content library to optimize media workflows, enrich recommendation engines by extracting text in images, or integrate secondary authentication into existing applications to enhance end-user security. With a wide variety of use ", "cases, Amazon Rekognition enables you to easily add the benefits of computer vision to your business. ", ": ROS, AWS, Kinesis Video Streams ", "\n", "\n", "The Amazon Kinesis Video Streams ROS package enables robots to stream video to the cloud for analytics, playback, and archival use. Out of the box, the nodes provided make it possible to encode & stream image data (e.g. video feeds and LIDAR scans) ", "from a ROS \u201cImage\u201d topic to the cloud, enabling you to view the live video feed through the Kinesis Video Console, consume the stream via other applications, or perform intelligent analysis, face detection and face recognition ", "using Amazon Rekognition. ", "The node will transmit standard ", " data from ROS topics to Kinesis Video streams, optionally encoding the images as h264 video frames along the way (using the included h264_video_encoder), ", "and optionally fetches Amazon Rekognition results from corresponding Kinesis Data Streams and publishing them to local ROS topics. ", "The source code is released under ", ". "], "package_tt": ["sensor_msgs/Image", "codec", "Keywords"]}
,{"url": "https://wiki.ros.org/retalis", "package": "retalis", "package_summary": ["Retalis Language for Information Processing and Management in Autonomous Robot Software"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", " ", " ", " ", " ", " ", "\n", "\n", " ", " ", " ", "\n", " ", " ", "\n", "\n", " ", "Messages received by retalis from the subscribed topics are automatically converted to events. For example, the following message of type ", " ", "Events are time-stamped according to header times of ros messages. If a message does not have a header, it is time stamped with ", ".  The format of time-stampes are  ", " where ", " encodes nanoseconds since seconds (i.e. stamp.nsec in ros messages). For example, the above ", " message contains a list of ", " messages (only one here). While each  ", " message is time-stamped, the ", " itself does not have a header. Therefore, the corresponding event is stamped with the current time. ", "The following rule calls  the ", " function for every ", " event received by retalis. ", "Each ", " message from ", " contains a list of recognized objects, each represented by a  ", " message. The following rule generates a separate event for each object. ", "where ", " represents a recognized object and ", " encodes the time of recognition. This time corresponds to the time of taking the picture at which the object was recognized. This time is taken from the header file of the corresponding ", " message. The events is also time stamped with ", ". ", "Retalis integrates the '", ". ", " supports temporal and logical reasoning on flow of events. Please see ", "  for publications and for examples of rules implementing various event-processing functionalities. ", "This memory instance keeps the history of events of the form ", ", specified by the first argument. The second argument specifies a list of conditions, being empty here. A memory instance only records events that satisfy the conditions. The third argument specifies the format for recording events. The fourth argument is the Id of the memory instance. The last argument is the size. Only the last 2500 events of the given form are maintained by this memory instance. ", "The ", " event from Section 4.1.3 matches this memory instance. This events is recorded by this memory instance as ", ". ", "We saw in Section 4.1.3 that the ", " and ", " functions are implemented as Prolog clauses. The ", " file can include an arbitrary Prolog program to encode a domain knowledge. We also saw in Section 4.1.4  that how memory instances are used to maintain histories of events ", "The Prolog program in ", " together with the the dynamic knowledge maintained by memory instances represent a Prolog-based knowledge base. This knowlede base can be queries by event-processing rules, for instance, as in Section 4.1.3. It can be also queried directly by a ros service (in our ", " list). ", "An example of using ", " and ", " terms is in implementation of the ", " function, in the eventRules.txt. The input values to this function is the ", " of a memory instance, keeping the history of some ", " events, and a time point. The ", " events represent observations of the transformation between two coordinate frames over time. From these observations, this function interpolates the transformation between the frames at time ", ". This is implemented as follows. The last observation before ", " and the first observation after ", " are found using the ", " and ", " terms. Then the position is linearly interpolated by making a function call to the ", " library that has been integrated with retalis. ", "The ", " function in eventRules.txt uses the ", " function to position an object in the world reference frame. Given ", ", the position of an object relative to the camera at time ", ", this function computes ", ", the position in the world, as follows. First, it changes the time format from ros time to datime. Then, it interpolates the transformation between ", ", ", ", ", ", ", " and ", " at the time ", ". Third, it applies these transformations on the ", " by making a function call to the ", " library. It is assumed that the ", " frame is aligned with the world reference frame. ", "We saw in Section 4.1.6 that how calling ", " function interpolates the position between the ", " and ", " coordination frames at time ", ". This function uses ", " and ", " terms to access the first and the last observations after and before ", ", respectively. To interpolate the position at ", ", the position should have been observed, at least once, after ", ". The observations, ", " messages here, are received asynchronously. Therefore, the ", " function should be evaluated only after the ", " memory instance has been updated with an event occurring after ", ". This is realized in retalis using a synchronized event, as follows. ", "The ", " function, performs the ", ", when the ", " are satisfied and then generate the ", ". Consider the following clause from eventRules.txt: ", "This rule computes the position of recognized markers in the world and is read as follows.   For each ", " event, specified in line 6, the position is computed by calling the ", " function, as in line 3. After computing the position, an event of the following form is generated, specified in line 2: ", "Such a ", " event encodes the marker's name, its position in the world and the time of recogntion. The ", " are the followings, specified in line 4: ", "These conditions specify that the ", " function should be evaluated, only after all ", ", ", ", ", ", ", " and ", " memory instances have been updated, at least once, with events occurring after time ", ". The time ", " is the time of recognition of the marker. ", "Retalis performs the synchronization of events in an event-driven and efficient way. The generation of a synchronized ", " is posponed, until the ", " are satisfied. Postponing an event does not postpone the generation of other events and postponed events are generated as soon as necessary conditions are met. ", "The subscription subscribes the topic ", " to the ", " events in which ", " is ", ". Such events are generated by the synchronized rule, presented in Section 4.1.7. They contain the position of the marker ", " in the world coordination frame.  The id of the subscription is ", " which can be used to cancel the subscrition at any time. ", "The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes when running the NAO example. The retalis node calculates the position of objects in real-time. It processes about 1900 events, memorizes 130 new events and prunes 130 outdated events per second.  It also queries memory instances, 70 times per second. These tasks are performed using about 18 percent of the CPU time. In this experience, the retalis node has been directly subscribed to the ", " and ", " ros topics. The retalis-ros-converter only subscribes retalis to the ", " topic and converts and publishes events about objects' positions to ros topics. To have this setup, comments out the subscriptions to ", " and ", " topics in the pub-sub.xml file and instead, set the ", " boolean variable in the retalis_interface.cpp file to ", ". You should also recompile the package. ", "As we saw in Section 4.1.2, retalis provides an easy way to subscribe to ros topics and automatically convert ros messages to events. This is implemented by the retalis-ros-converter node. The implementation is in Python and is realized by inspecting classes and objects at runtime and therefore is expensive. The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes for the NAO example, when the retalis-ros-converter is used to subscribe to ", " and ", " topics. This results show that while the automatic conversion among messages and events are desirable in a prototyping phase, the final application should implement it in C++ for performance reasons. We will investigate the possibility to re-implement the retalis-ros-converter node in C++. ", "The following figure shows the CPU time for a number of runs where up to 160 memory instances are added to the NAO example. These memory instances record ", " events. Among the events processed by retalis, there are no such events. The results show that the increase in CPU time is negligible. This shows that a memory instance consumes CPU time only if the input stream of events contains events whose type matches the type of events the memory instance records.  ", "In the following figure, the green and blue lines show the CPU time for cases where 20 memory instances of type ", " are added to the NAO example. These memory instances match all ", " events, about 1900 of such is processed every second. The size of memory instances for the green line is 2500. These memory instances reach their size limit in two seconds. After this time, the CPU time usage is constant over time and includes the costs of unification, assertion and retraction for updating 20 memory instances with 1900 events per second. The size of memory instances for the blue line is 150,000. It takes about 80 seconds for this memory instances to reach their size limit. Consequently, the CPU time before the time 80 only includes the costs of unification and assertion, but not the costs of retraction. After the time 100, the CPU usages of both runs are equal. This shows that the cost of a memory instance does not depend on its size. The purple line shows the CPU time for the case where similarely there are 20 memory instances of type ", ". However, these memory instances record events until their reach their size limit. We added a condition for these memory instances such that after reaching their size limit, they perform no operation when receiving new events. After the time 100, the CPU time is constant about 23 percent, being 5 percent more than the CPU time of the NAO example, represented by the red line. This 5 percent increase represents the unification cost. This also shows that the costs of about 38000 assertions and 38000 retractions per second is about 30 percent of CPU time. In other words, 2500 memory updates (i.e. assertions or retractions) are processed using one percent of CPU time. ", "The following figure shows the CPU time for a number of runs where up to 40 memory instances of type ", " and size 2500 are added to the NAO example.  The red line at the bottom shows the CPU time for the NAO example. We make the following observations. Adding first 10 memory instances to the NAO example increases the CPU time about 20 percent. After that, adding each set of 10 memory instances increases the CPU time about 13 percents. This shows that the cost grows less than linearly. The implementation of memory instances is in a way that the cost of an assertion or a retraction can be assumed constant. This means that the unification cost for the first set of memory instances is the highest. In other words, the unification cost per memory instance decreases when the number of memory instances are increased.  ", "The following figure shows the CPU time for a number of runs where up to 640 memory instances of type ", " and size 2500 are added to the NAO example. The events matching these memory instances are received with the frequency of 50 Hz. We make the following observaitons. First, it takes 50 seconds for these memory instances to reach their size limit. After 50 seconds, these memory instances reach their maximum CPU usages, as the costs of retraction is added. Second, each memory instance filters 1900 events per second recording about two percents of them. The cost of 640 memory instances is about 35 percent of CPU time. Third, the unification cost per memory instance is decreased when the number of memory instances are increased. ", "The following figure compares the costs of different types of memory instances. The purple line shows the CPU time for the case where there are 10 memory instances of type ", ". The green line shows the CPU time for the case where there are 320 memory instances of type ", ". We observe that the costs of both cases are equal. The memory instances in the former case record 19,000 events per second (i.e. 10*1900). The memory instances in the latter case filter 1900 events per seconds for ", " events, recording 16000 events per second (i.e. 320*50). The results show the efficiency of the filtering mechanism. ", "The brown line shows the CPU time for the case where there are 10 memory instances of type ", " and 320 memory instances of type ", ". ", "Comparing it with the green and purple lines shows that the CPU time usage of these memory instances is less than sum of the CPU usages by 10 ", " memory instances and 320 ", " memory instances. This shows that the  unification cost per memory instance is decreased when the number of memory instances are increased, even when the memory instances are not of the same type. ", "The green line in the following figure shows the CPU time of the NAO example adapted as follows. There is an additional ", " memory instance of size 128. This memory instance is queried by 1000 ", " terms for each recognition of an object. In average, 7000 ", " terms are evaluated per second. The blue line visualize the CPU time of a similar program in which 7000 ", " terms are evaluated per seconds. The figure shows that the costs of the evaluations of ", " and ", " terms are similar. The purple line shows the CPU time of the case where 14,000 ", " terms are evaluated per second. We observe that the cost grows linearly, as expected. ", "The blue line in the following figure visualizes the CPU time of the case where 7000 ", " terms are evaluated per second. The green line visualizes the CPU time of the case where there are 320 ", " memory instances. The purple line visualizes the CPU time of the case where 7000 ", " terms are evaluated per second and there are 320 ", " memory instances. We observe that the cost of accessing a memory instance does not depend on existance of other memory instances. ", "The green line in the following figure visualizes the CPU time of evaluating 7000 ", " terms per second on a memory instance of size 128. The blue linevisualizes the CPU time of evaluating 7000 ", " terms per second on a memory instance of size 16384. The size of the memory instance in the latter case is the power of two of the size of the memory instance in the former case. The increase in the CPU time for the latter case, with respect to the NAO example, is less than two times of the increase in the CPU time for the former case.     ", "The red line in the following figure visualized the CPU time of the NAO example where in each second, 1000 ", " queries on a memory instance of size 2500 are evaluated. In addition, for each ", " query, a new event is generated. The green line visualizes the CPU time of a similar case where the next queries are synchronized. This experiment is conducted in a way that no query needs to be delayed. Coparing these two cases shows that when queries are not delayed, the synchronization cost is negligible. ", "Information flow processing systems such as Etalis are designed for applications that require a real-time processing of a large volume of data flow. Please see ", " for the evaluation of the performance of on-flow functionalities. The evaluation results show, in terms of performance, Etalis is competitive with respect to the state-of-the-art on-flow processing systems. "], "package_tt": ["add_output_subscription", "delete_output_subscription", "add_memory", "delete_memory", "add_input_subscription", "delete_input_subscription", "__0__", "__0__", "__0__", "__0__", "'\"/odom\"','\"/base_link\"'", "'\u201c/odom\u201d',\u00a0'\u201c/base_link\u201d'", "ToDo", "Event", "RelativePos", "AbsolutePose", "RelativePos", "AbsolutePose", "CameraTop", "RelativePos", "SynchConditions", "Query", "SynchConditions", "Event", "PoseStamped", "SyncConditions", "PoseStamped", "'\"4x4_1\"'", "__0__", "__0__", "CameraTop_frame"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]}
,{"url": "https://wiki.ros.org/rocon_app_manager", "package": "rocon_app_manager", "package_summary": ["The public interface and retaskable interface for a robot."], "package_details": ["\n", "\n", "\n", "\n", " (", ") ", "\n", " (", ") ", "\n", "\n", "These services are freely shared to any ros subsystem that wants to consume them via the ", " advertise/pull mechanisms. The purpose is to provide introspection to the robot (i.e. the system that runs the app manager) to make a decision as to whether it wishes to assume control of the robot. Assuming control is managed by making a request to invite the robot. ", "The list of arguments to use for standalone mode robot launcher. ", " ", "The list of arguments to use for concert mode robot launcher. ", " "], "package_tt": ["/platform_info", "/list_rapps", "/status", "/invite", "/start_rapp", "/stop_rapp", "platform_info", "list_rapps", "status", "invite", "start_rapp", "stop_rapp"], "package_code": ["Required Arguments:\n", "  auto_start_rapp: autostart a rapp, e.g. rocon_apps/talker\n", "Optional Arguments:\n", "  auto_rapp_installation (default \"false\"): http://wiki.ros.org/rocon_app_manager/Tutorials/indigo/Automatic Rapp Installation\n", "  capabilities (default \"false\"): enable/disable a capability server\n", "  capabilities_blacklist (default \"[]\"): blacklist specific capabilities\n", "  capabilities_nodelet_manager_name (default \"capability_server_nodelet_manager\")\n", "  capabilities_package_whitelist (default \"[std_capabilities]\"): get capabilities from these packages only\n", "  capabilities_parameters (default \"/opt/ros/indigo/share/rocon_app_manager/param/capabilities.yaml\"): detailed parameter configuration for the providers\n", "  capabilities_server_name (default \"capability_server\") \n", "  interactions (default \"false\")\n", "  interactions_list (default \"[]\")\n", "  rapp_package_blacklist (default \"[]\")\n", "  rapp_package_whitelist (default \"[rocon_apps]\"): comma separated list of package names\n", "  rapp_preferred_configuration_file (default \"/opt/ros/indigo/share/rocon_app_manager/param/preferred_default.yaml\")\n", "  robot_description (default \"To err is human, to 'arr is pirate.\")\n", "  robot_icon (default \"rocon_icons/cybernetic_pirate.png\") \n", "  robot_name (default \"Cybernetic Pirate\") \n", "  robot_type (default \"pc\")\n", "  rosbridge_address (default \"localhost\")\n", "  rosbridge_port (default \"9090\")\n", "  screen (default \"true\"): verbose output from running apps\n", "  simulation (default \"false\"): if simulated robot\n", "  zeroconf (default \"false\")\n", "  zeroconf_name (default \"Cybernetic Pirate\")\n", "  zeroconf_port (default \"11311\")", "Required Arguments:\n", "  concert_uri: configure concert hub uri for direct connection.\n", "Optional Arguments:\n", "  capabilities (default \"false\"): enables/disables a default capability server in this concert client\n", "  capabilities_blacklist (default \"[]\"): blacklist specific capabilities\n", "  capabilities_package_whitelist (default \"[]\"): get capabilities from these packages only (e.g. std_capabilities)\n", "  capabilities_parameters (default \"/opt/ros/indigo/share/rocon_app_manager/param/capabilities.yaml\"): detailed parameter configuration for the providers\n", "  concert_watch_period (default \"10\"): the period used by gateways for watching concert connections\n", "  concert_whitelist (default \"[]\"): list of concert names this robot will work with\n", "  disable_zeroconf (default \"false\"): disable zeroconfiguration\n", "  firewall (default \"false\"): typically false (don't let anything in), only for simulation clients\n", "  interactions (default \"false\")\n", "  interactions_list (default \"[]\")\n", "  local_machine_only (default \"false\"): only work with local concerts (testing, simulations)\n", "  rapp_auto_installation (default \"false\"): http://wiki.ros.org/rocon_app_manager/Tutorials/indigo/Automatic Rapp Installation\n", "  rapp_package_blacklist (default \"[]\")\n", "  rapp_package_whitelist (default \"[rocon_apps]\"): comma separated list of package names\n", "  rapp_preferred_configuration_file (default \"/opt/ros/indigo/share/rocon_app_manager/param/preferred_default.yaml\")\n", "  robot_description (default \"To err is human, to 'arr is pirate.\")\n", "  robot_icon (default \"rocon_icons/cybernetic_pirate.png\")\n", "  robot_name (default \"Cybernetic Pirate\")\n", "  robot_type (default \"turtlebot\")\n", "  robot_unique_name (default \"true\"): postfix a uuid to the robot name for uniqueness\n", "  screen (default \"false\"): verbose output from running apps\n", "  simulation (default \"false\"): if simulated robot"]}
,{"url": "https://wiki.ros.org/simple_drive", "package": "simple_drive", "package_summary": ["A simple robot drive system that includes skid steering joystick teleoperation, control of a panning servo to look around the robot, and Arduino firmware."], "package_details": ["\n", " ", "\n ", " ", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " If your microcontroller supports subscribing to ROS ", " messages (Arduinos can use ", ") then it would be simpler to do that and skip this node. However, this node is written in python so you could more easily add complex functionality in python and then in your microcontroller do the minimum amount of work necessary. ", "\n", "\n", " Caution! This software does not stop moving the robot if no messages are received for certain period of time. A pull request for this is very welcome. ", "\n", " We like PlatformIO: \"Single source code. Multiple platforms.\" PlatformIO supports approximately 200", " and all major", ". Learn more on", ". ", "\n", " ", " ", " ", " ", " ", " ", " ", "\n", "\n", "\n", "\n", " ", " - Differential drive software with support for a velocity PID target, a small GUI to control the robot, and more. ", " - Differential drive software that is real-time safe, integrates with ", ", and more. ", " ", " - This teleop node converts joy messages to twist messages. ", " - This teleop node takes joy messages and publishes topics or calls actions according a configuration file. ", " ", " - Multiplex several velocity command topics with prioritization or disabling according to a configuration file. ", "\n", "A simple robot drive system. ", ": ", "This package ", ": ", "Package created by Ryerson University students for the ", ", summer 2017. ", "3. Install the ", " onto a microcontroller connected to motors and wheels by PWM. The microcontroller must also be connected to the computer running the simple_drive ROS node by a serial connection (ex. USB). ", "This diagram is also available in ", ". ", "This node converts ", " messages from the ", " node into a variety of commands to drive the robot at low, medium, and high speed, look around with a servo, and cancel move_base goals at any moment. This node simply sends commands to other nodes. Typically the servo is used to move a camera so that the teleoperator can look around the robot. ", "The ", " node receives movement commands on two ", " topics, one for teleoperation and one for autonomous control, typically ", ". Movement commands are multiplexed to a final topic for robot consumption. If any teleoperation command is received autonomous commands are blocked for a set time defined by the ", " parameter. ", "This node communicates with the ", " using a custom serial protocol described below. An example serial data packet could be 0,0.5,0.5 which would mean drive motors forward at half speed and rotate at half speed.   ", "The ", " microcontroller code does the minimum amount of work possible to receive motor commands from a USB serial connection and output voltages to digital PWM output to be received by motor controllers.  ", "We deploy the ", " to an Arduino microcontroller using PlatformIO. ", "More PlatformIO install info: ", " ", "More PlatformIO info: ", " ", "When a left and right joystick inputs are received by the ", " node, representing left and right wheel velocities (ie. skid steering or differential drive), a ", " with linear and rotational velocities is calculated as: ", "When a ", " containing linear and rotational velocities is received by the ", ", wheel velocities are calculated as: ", "Feature requests, bug reports, and contributions are welcome at ", ". "], "package_tt": ["joy", "teleop/cmd_vel", "servo_pos", "~servo_pan_speed", "int", "~servo_pan_max", "int", "~servo_pan_min", "int", "cmd_vel_mux", "block_duration", "teleop/cmd_vel", "move_base/cmd_vel", "cmd_vel", "block_duration", "~block_duration", "int", "(BYTE)\u00a00,\u00a0(FLOAT)\u00a0LINEAR_VELOCITY,\u00a0(FLOAT)\u00a0ANGULAR_VELOCITY", "(BYTE)\u00a02,\u00a0(FLOAT)\u00a0SERVO_ANGLE", "twist", "cmd_vel", "servo_pos", "~serial_dev", "string", "~baudrate", "int", "drive_firmware", "drive_firmware", "(left_speed\u00a0+\u00a0right_speed)\u00a0/\u00a02.0", "(right_speed\u00a0-\u00a0left_speed)\u00a0/\u00a02.0", "linear_speed\u00a0+\u00a0angular_speed", "linear_speed\u00a0-\u00a0angular_speed"], "package_code": ["$ sudo apt-get install ros-kinetic-simple-drive", "$ roslaunch simple_drive drive_teleop.launch joy_dev:=/dev/input/js0\n", "$ roslaunch simple_drive cmd_vel_mux.launch\n", "$ roslaunch simple_drive simple_drive.launch serial_dev:=/dev/ttyACM0\n", "\n", "OR all-in-one launch:\n", "$ roslaunch simple_drive drive.launch", "$ roslaunch simple_drive drive_teleop.launch joy_dev:=/dev/input/js0", "$ roslaunch simple_drive cmd_vel_mux.launch", "$ roslaunch simple_drive simple_drive.launch serial_dev:=/dev/ttyACM0", "$ sudo python -c \"$(curl -fsSL https://raw.githubusercontent.com/platformio/platformio/master/scripts/get-platformio.py)\"\n", "\n", "# Enable Access to Serial Ports (USB/UART)\n", "$ sudo usermod -a -G dialout <your username here>\n", "$ curl\u00a0https://raw.githubusercontent.com/platformio/platformio/develop/scripts/99-platformio-udev.rules\u00a0\u00a0> /etc/udev/rules.d/99-platformio-udev.rules\n", "# After this file is installed, physically unplug and reconnect your board.\n", "$ sudo service udev restart", "$ roscd simple_drive\n", "$ cd ./drive_firmware/\n", "# Find the microcontroller that you have in the list of PlatformIO boards\n", "$ pio boards | grep -i mega2560\n", "# Use the name of your board to initialize your project\n", "$ pio init --board megaatmega2560", "$ vim src/main.cpp +4", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "$ vim src/main.cpp +17", "\n", "\n", "\n", "\n", "\n", "$ pio run --target upload"]}
,{"url": "https://wiki.ros.org/mrpt_icp_slam_2d", "package": "mrpt_icp_slam_2d", "package_summary": ["mrpt_icp_slam_2d contains a wrapper on MRPT's 2D ICP-SLAM algorithms."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The sections below describe the API of this package which allows ICP-based SLAM in 2D ", ". ", "The SLAM algorithm is a simple ", " using ICP to align 2D laser scans to the map, which can be either a ", " or an  ", ". [For now, only point maps] ", "Using this technique allows building ", ", as long as errors do not grow excessively before closing any long loop. Building larger maps requires more advanced SLAM techniques. However, this simple icp-slam algorithm is an efficient and well-tested method which suffices for many practical situations. ", "The ROS node ", " is a wrapper for the C++ class ", ",  part of MRPT. Thus, check out the documentation of that class for further  details. ", "This node has been designed to provide an interface similar to that of ", "  for the convenience of users which already knew that package. ", "For the convention on coordinate frames see ", ". ", "Using ", " requires a horizontally-mounted, fixed, laser range-finder. Odometry is optional. ", "The ", " node will attempt to transform each incoming scan  into the ", " (odometry) ", " frame.  See the \"", "\"  for more on required transforms. ", "In order to use mrpt_icp_slam_2d package it is necessary to install the last ", " build and the", "(see also the ", ") . "], "package_tt": ["mrpt_icp_slam_2d", "mrpt_icp_slam_2d", "mrpt_icp_slam_2d", "odom", "mrpt_icp_slam_2d", "tf", "scan", "PointCloudMap", "map", "robot_pose", "~global_frame_id", "string", "\"map\"", "~base_frame_id", "string", "\"base_link\"", "~odom_frame_id", "string", "\"odom\"", "~sensor_source", "string", "\"scan\"", "\"scan\"", "~ini_filename", "string", "~rawlog_filename", "string", "~rawlog_play_delay", "float", "<the\u00a0frame\u00a0attached\u00a0to\u00a0incoming\u00a0scans>", "base_link", "tf", "base_link", "odom", "map", "odom"], "package_code": ["roslaunch mrpt_icp_slam_2d icp_slam.launch", "roslaunch mrpt_icp_slam_2d icp_slam_rawlog.launch"]}
,{"url": "https://wiki.ros.org/spatio_temporal_voxel_layer", "package": "spatio_temporal_voxel_layer", "package_summary": ["The spatio-temporal 3D obstacle costmap package"], "package_details": ["\n", " ", "The spatio-temporal voxel layer incorporates information from the sensors in the form of ", " or ", ". This information is converted into 3D and populated into an efficient voxel grid for each sensor cycle. ", "More information, ROS API, demos, and resources are given in the ", " page. "]}
,{"url": "https://wiki.ros.org/pointcloud_to_laserscan", "package": "pointcloud_to_laserscan", "package_summary": ["Converts a 3D Point Cloud into a 2D laser scan. This is useful for making devices like the Kinect appear like a laser scanner for 2D-based algorithms (e.g. laser-based SLAM)."], "package_details": ["\n", "\n", "\n", "If you're trying to create a virtual laserscan from your RGBD device, and your sensor is forward-facing, you'll find ", " will be much more straightforward and efficient since it operates on image data instead of bulky pointclouds. However, if your sensor is angled, or you have some other esoteric use case, you may find this node to be very helpful! ", "Please check the ", " for common problems, or open an ", " if still unsolved. ", "Same API as node, available as ", ". "], "package_tt": ["pointcloud_to_laserscan_node", "cloud_in", "scan", "~min_height", "double", "~max_height", "double", "~angle_min", "double", "~angle_max", "double", "~angle_increment", "double", "~scan_time", "double", "~range_min", "double", "~range_max", "double", "~target_frame", "str", "~concurrency_level", "int", "~use_inf", "boolean", "range_max\u00a0+\u00a01", "+inf", "inf_is_valid", "pointcloud_to_laserscan/pointcloud_to_laserscan_nodelet"]}
,{"url": "https://wiki.ros.org/laser_geometry", "package": "laser_geometry", "package_summary": ["This package contains a class for converting from a 2D laser scan as defined by\n    sensor_msgs/LaserScan into a point cloud as defined by sensor_msgs/PointCloud\n    or sensor_msgs/PointCloud2. In particular, it contains functionality to account\n    for the skew resulting from moving robots or tilting laser scanners."], "package_details": ["\n", "\n", "\n", " To convert a ", " to a ", " ", "\n", " To convert a ", " to a ", " in the base_link frame, using a high fidelity transform: ", "\n", "\n", "\n", "The laser_geometry package contains a single C++ class: ", ".  There is no ROS API. ", "This class has two relevant functions for transforming from ", " to ", " or ", ". ", "Both of these functions have a final optional argument that augments the ", " which is created to include extra channels.  These channels may include intensities, distances, timestamps, the index or thew viewpoint from the original laser array. ", "There is a simple Python implementation here (", "). ", "The method ", " does the simplest possible projection of the laser.  Each ray is simply projected out along the appropriate angle according to: ", "The appropriate sine and cosine values are cached, making this a very efficient operation.  However, the generated ", " is in the same frame as the original ", ". While this has the advantage that it does not require an instance of a ", " or message notifier, it does not hold up in situations where the laser is moving and skew needs to be accounted for. ", "Please consult the ", " for full usage details. ", "The ", " method does a more advanced projection, but requires that you have set up a ", " transform listener. (If you are unfamiliar with ", ", it is recommended you go through the ", " first.) ", "Because the stamp of a ", " is the time of the ", " measurement, one cannot simply wait for a transform ", "to target_frame at this stamp. Instead one also has to wait for a transform at the ", " measurement of the scan. ", "Please consult the ", " for full usage details.  ", "The method ", " projects a single laser scan from a linear array into a 3D ", ". The generated cloud will be in the same frame as the original laser scan. "], "package_tt": ["projectLaser()", "transformLaserScanToPointCloud()", "projectLaser()", "tf::transformer", "transformLaserScanToPointCloud()", "projectLaser()"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]}
,{"url": "https://wiki.ros.org/spatial_world_model", "package": "spatial_world_model", "package_summary": ["Spatial World Model for Object Tracking"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", "\n", "\n", " ", "\n", "\n", "As a basic example for the types of end-user interfaces that can be created with the Spatial World Model, we look at the Map annotation interface. Information on this interface can be found on the ", ". Below is a video demonstrating its capabilities: ", "The following steps are written for ", " but apply to most Linux systems. ", "To begin, we must install ", " and the Python libraries that will talk to it. To do so, run the following command: ", "Finally, we are able to install the database schema. This is provided in a script found in the ", " package. This script can be used to both install a new database and to update an existing one. ", "In many cases, you will be installing the Spatial World Model database on a central server so that multiple clients (and robots) can talk to it. As of now, the ROS nodes communicate via SQL to the database; however, due to security risks this will eventually be changed. To allow remote connections, we must modify the configuration scripts on the system. Using your choice of editor, modify ", " with root privileges and add the following line: ", "Next, modify ", " with root privileges and add the following line: ", "At its core, the Spatial World Model is designed to be a persistent, multi-robot model to keep track of both the robot's working memory as well as keeping track of properties, affordances, and activities that can be associated with each object. To manage persistence, the world model is stored in a ", " database  At a high level, currently the Spatial World Model allows for two sets of entities: a ", " and a ", ". ", "A ", ", defined in the ", " message, can be thought of as a robot's working memory. At a basic level, such an entity contains a relative pose in the world with associated tags and timestamps. These entities describe a particular, specific instance of an object in the world (e.g., the cup sitting on the desk in the conference room). Each instance is linked to a single ", " which contains a set of spatial descriptors for the object (e.g., mesh, bounding box, point-cloud cluster, etc...). Below is a detailed explanation of the fields in the ", ". Note that some fields will be blank depending on the type of object or what you know about the world.  ", "The second implemented entity is the ", ". This entity, defined in the ", " message, contains spatial descriptors of objects in the world. These are shared models that are common between all instances of such an object (e.g., a 3D mesh of the object itself). Each descriptions contains a set of tags and an array of actual ", "s. The genericness of the descriptor model allows for models to come from a variety of sources (point cloud segmentation, 3D model warehouses and databases) with few-to-no restrictions. The main idea is to associate an appropriate ", " and ", " field with each descriptor to determine how the data should be treated. In a sense, the ", " field can be thought up as a non-standard MIME type (PNG, Collada, but also ", " as a type). Future goals of the project set out to create a standard set of accepted type fields. Below is a detailed description of the fields associated with a ", ". ", "The first design decision was to use a ", " database for storage. Given the highly relational components associated with the world model (e.g., ", " and ", "), it made sense to use such a database over other types of databases. For efficiency in searching and storage, the database schema itself is broken into finer grains than the APIs allow for. It is intended that developers make user of these higher-level APIs when dealing with the Spatial World Model as apposed to making raw SQL queries. ", "The current implementation includes several layers of APIs. As mentioned previously, it is not intended for a developer to use the world model by directly making SQL queries. At the lowest level, the ", " Python API should be used. This level of the API is responsible for talking SQL to the world model database and is able to make basic insertion and search queries while maintaining the correct structure. This level of the API allows for non-ROS processes to make use of the world model (another future goal of the project). By using an SQL connection between this library and the database, remote connections can be made and a central database can be used (such as one hosted in the cloud). This, of course, requires your server to allow remote SQL connections which is not ideal. Therefore, future plans hope to create a server-side API to allow for remote queries (think REST as an example but this would require polling). With such an API in place, the interface between the robot or client and the database could be made with this new service. ", "Furthermore, a ", " library is provided in ", " to allow remote web clients to interact with the world model. This API currently uses ", " and ", " to communicate with the world mode; however, as discussed above, the eventual goal is to have a standard server-side API to communicate with directly instead of using ROS. ", "Within ROS, the intended use of the APIs into the world model was to create a series of what are being called listener nodes. Such nodes listen to a set of defined topics, make the appropriate inferences on the information, and update the world model accordingly. Below are three examples included in ", ".  ", "To allow for multiple robots, a notion of namespacing must be kept. To support this feature early on, this information is currently held inside of the ", " of the instance. It is up to the developer to maintain this namespace. For example, the above listeners take an optional argument to define the namespace. If no namespace is given, it will default to the hostname of the machine the node is running on. In most cases, this is good enough since the hostname of the robot is usually a good namepsace. Then, when searching for things like a particular robot, we can do a tag search for ", ". Future improvements should be made to make this clearer and enforce unique namespacing.  ", "One improvement to the current system would be to separate the ", " array into its own separate database. The idea behind properties is to define relationships such as ", " or ", " between entities in the world model. Current thoughts are to point to entries within a graph database. By doing so, powerful search queries to can written such as \"give me all the objects inside the bedroom?\" or \"is the book on my bookshelf?\" in an efficient way.  ", "One large piece of the world model that is missing is the notice of affordances. The goal of the Spatial World Model is to not only keep track of particular instances of objects, but to also manage what types of actions can be taken on certain objects. For example, a door can be opened, a cup can be grasped, and a robot can grasp (assuming it has a gripper, of course). Furthermore, pre-conditions should also be stored here. For example, the cup must be on the table to be picked up (or any number of other conditions). This would rely on the implementation of the graph database described above. These types of attributes should be stored in a separate table in the database and linked to a particular ", ".  ", "In addition to the affordances, a notion of activities, must be stored as well. Such a structure would be used to figure out how to perform such an action on such an object. For example, if you wanted to use a ", " action on a coffee cup, the associated activity would be some action call to a grasping pipeline. Each activity can be thought of as a node with some kind of transition model incorporated to provide feedback and belief states. An updated diagram of the Spatial World Model would be the following: ", "In addition to abstracting out the ", " as defined above, several improvements are needed with respect to the instances. For one, belief states should be associated with most attributes. While the current ", " does allow for this, beliefs about things just as timestamps are just as important.  ", "A second major component is a cleanser process for the database. Currently, descriptions can be linked to multiple instances. This is the main idea behind the descriptions itself. Additionally, these descriptions can potentially contain massive amounts of data (Collada models for example). If there are no longer any instances linked to a given description, it should be removed not only from the database itself, but from the disk as well (since the large data portions are kept in ", ". Care should be taken to ensure thread safety in the removal. ", "Perhaps the largest piece needed in the project is a more robust, efficient, and flexible server-side API for the world model. Currently, the ", " Python API is used by the main ROS node and speaks SQL to the database. For many reasons, security being one, this is not ideal. Efforts should be made to create a server-side API that allows for multiple remote connections to interact with the world model. Not only would this still allow the robots to communicate with the world model, but clients could now directly connect to the world model instead of using ", " as a \"proxy\". While at first glance it may seem appropriate, this API should not be response-based such as a REST API. A more robust socket-level connection should be made to allow for bi-directional communication. By standardizing a server-side interface, we can also create a more powerful query system. The protocol between clients and the server could include things like searching descriptions or descriptors without having to return the data associated with them. This allows clients to subscribe to changes in the world model without the need of polling. A diagram of the updated API levels is shown below. ", "Discussions and contributions are welcome! To get involved, check out the ", " for current feature requests and discussions.  ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["spatial_world_model", "/etc/postgresql/9.1/main/pg_hba.conf", "/etc/postgresql/9.1/main/postgresql.conf", "WorldObjectInstance", "WorldObjectDescription", "WorldObjectInstance", "WorldObjectDescription", "WorldObjectInstance", "instance_id", "name", "creation", "update", "expected_ttl", "perceived_end", "source", "origin", "creator", "pose", "frame_id", "instance_id", "description_id", "WorldObjectDescription", "properties", "on(45)", "tags", "WorldObjectDescription", "Discriptor", "type", "ref", "type", "nav_msgs/OccupancyGrid", "WorldObjectDescription", "description_id", "name", "descriptors", "type", "data", "ref", "tags", "tags", "WorldObjectInstance", "WorldObjectDescription", "JavaScript", "map_listener", "/map", "map", "robot_pose_listener", "robot_pose_listener", "/robot_pose", "/initpose", "tags", "[\"robot\",\u00a0\"myRobotName\"]", "properties", "on", "in", "WorldObjectDescription", "pickup", "properties", "pose"], "package_code": ["sudo apt-get install git postgresql python-psycopg2", "sudo -u postgres createdb world_model", "sudo -u postgres createuser -D -A -P <username>", "\n", "\n", "\n", "\n", "\n", "\n", "host     world_model     <username>      0.0.0.0/0               md5", "listen_addresses = '*'", "sudo service postgresql restart"]}
,{"url": "https://wiki.ros.org/explore_lite", "package": "explore_lite", "package_summary": ["Lightweight frontier-based exploration."], "package_details": ["Use GitHub to ", ". [", "]", "\n ", "\n", " ", "\n", " uses ", " for navigation. You need to run properly configured ", " node. ", " ", " subscribes to a ", " and ", " messages to construct a map where it looks for frontiers. You can either use costmap published by ", " (ie. ", ") or you can use map constructed by mapping algorithm (SLAM). ", "\n", "\n", "\n", "\n", "This package provides greedy frontier-based exploration. When node is running, robot will greedily explore its environment until no frontiers could be found. Movement commands will be send to ", ". ", "Unlike similar packages, ", " does not create its own costmap, which makes it easier to configure and more efficient (lighter on resources). Node simply subscribes to ", " messages. Commands for robot movement are send to ", " node. ", "Depending on your environment you may achieve better results with either SLAM map or costmap published by ", ". Advantage of ", " costmap is the inflation which helps to deal with some very small unexplorable frontiers. When you are using a raw map produced by SLAM you should set the ", " parameter to some reasonable number to deal with the small frontiers. For details on both setups check the ", " and ", " launch files. ", "Before starting experimenting with ", " you need to have working ", " for navigation. You should be able to navigate with ", " manually through ", ". Please refer to ", " for setting up ", " and the rest of the navigation stack with your robot. ", "You should be also able to to navigate with ", " though unknown space in the map. If you set the goal to unknown place in the map, planning and navigating should work. With most planners this should work by default, refer to ", " if you need to setup this for ", " planner (but should be enabled by default). Navigation through unknown space is required for ", ". ", "If you want to use costmap provided by ", " you need to enable unknown space tracking by setting ", ". ", "If you have ", " configured correctly, you can start experimenting with ", ". Provided ", " should work out-of-the box in most cases, but as always you might need to adjust topic names and frame names according to your setup. ", "This package was developed as part of my bachelor thesis at ", " in Prague. ", "This project was initially based on ", " package by Charles DuHadway. Most of the node has been rewritten since then. The current frontier search algorithm is based on ", " by Paul Bovbel. "], "package_tt": ["explore_lite", "explore_lite", "explore_lite", "<move_base>/global_costmap/costmap", "move_base", "move_base", "min_frontier_size", "explore.launch", "explore_costmap.launch", "explore_lite", "explore_lite", "track_unknown_space:\u00a0true", "explore_lite", "explore.launch", "move_base", "explore_lite", "costmap", "track_unknown_space:\u00a0true", "costmap_updates", "~frontiers", "~robot_base_frame", "string", "base_link", "~costmap_topic", "string", "costmap", "~costmap_updates_topic", "string", "costmap_updates", "~visualize", "bool", "false", "~planner_frequency", "double", "1.0", "~progress_timeout", "double", "30.0", "progress_timeout", "~potential_scale", "double", "1e-3", "~orientation_scale", "double", "0", "~gain_scale", "double", "1.0", "~transform_tolerance", "double", "0.3", "~min_frontier_size", "double", "0.5", "global_frame", "robot_base_frame", "map", "base_link", "robot_base_frame", "global_frame", "global_frame", "costmap_topic"], "package_code": ["@masterthesis{H\u00f6rner2016,\n", "  author = {Ji\u0159\u00ed H\u00f6rner},\n", "  title = {Map-merging for multi-robot system},\n", "  address = {Prague},\n", "  year = {2016},\n", "  school = {Charles University in Prague, Faculty of Mathematics and Physics},\n", "  type = {Bachelor's thesis},\n", "  URL = {https://is.cuni.cz/webapps/zzp/detail/174125/},\n", "}"]}
,{"url": "https://wiki.ros.org/explorer", "package": "explorer", "package_summary": ["The explorer package utilizes frontier based exploration for multi-robot systems. Beside frontier detection, coordinated and uncoordinated exploration strategies are available to select goal points. Coordinated exploration enhances robot distribution and reduces redundancy in exploration reducing exploration time."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The ", " utilizes frontier based exploration to discover environments autonomously operating a distributed multi-robot system. Beside frontier detection, coordinated and uncoordinated exploration strategies are available to select goal points. Coordinated exploration enhances robot distribution and reduces redundancy in exploration which result in improvement of efficiency in terms of exploration time. ", "The ", " comprises multiple functionalities to perform frontier based exploration. Frontier detection is utilized on local and global costmaps to further select navigation goals in the environment to proceed with exploration. The assignment of robots to goals is accomplished according to coordinated and uncoordinated exploration strategies being applied for the distributed multi-robot system. ", "Auctioning thereby ensures negotiation among available goals to coordinate efficiently, distributing robots among the environment by minimizing the overall travel path. Additionally to frontier detection and selection, the ", " is concerned with navigation to goal points by incorporating a simple action client utilizing ", ". ", "You may obtain the paper from ", " or search in  ", ". "], "package_tt": ["~<name>/map_merger/global_map", "~<name>/base_scan", "~<name>/frontiers", "~<name>/visited_frontiers", "~<name>/negotiation_list", "~<name>/auction", "~<name>/all_positions", "~<name>/visitedfrontierPoints", "~<name>/goalPoint", "~<name>/frontierPoints", "~<name>/cluster_grid_~", "~<name>/adhoc_communication/send_frontier", "~<name>/adhoc_communication/send_auction", "~<name>/frontier_selection", "int", "~<name>/local_costmap/width", "int", "~<name>/number_unreachable_for_cluster", "int"], "package_code": ["@InProceedings{Andre2014,\n", "  Title                    = {Coordinated Multi-Robot Exploration: Out of the Box Packages for {ROS}},\n", "  Author                   = {Andre, T. and Neuhold, D. and Bettstetter, C.},\n", "  Booktitle                = {Proc. of IEEE GLOBECOM WiUAV Workshop},\n", "  Year                     = {2014},\n", "  Month                    = dec,\n", "}"]}
,{"url": "https://wiki.ros.org/mongodb_log", "package": "mongodb_log", "package_summary": ["The mongodb_log package"], "package_details": ["\n", "\n", "\n", " ", "\n", "\n", " ", " ", "\n", "\n", "\n", "This package provides nodes that can record any and all data transmitted via ROS topics and stores them in the document-oriented database ", " replicating the message type as document structure. Afterwards, data can be used and queried independently of a particular robot software framework using the existing MongoDB query features with indexes, data locality (sharding) and ", ". This means you can also freely mix in data acquired from other sources, for example using ", ". ", "This project is joint work of the ", " at The Robotics Institute of the Carnegie Mellon University and the ", " at the RWTH Aachen University. For more details please visit the ", ". ", "The logger regularly creates graphs based an a round-robin database (RRD) using ", ". Additionally, the ", " script can be run to create graphs showing the performance of MongoDB. Example graphs look like the following. ", "The ", " package provides two functionalities. For one there is a node to store all messags of one specific topic to the database, for another it provides a library for other nodes to interact with the database. This mongodb_log package compares to the former part. ", "The ", " node of the ", " package stores incoming messages as serialized blobs, much like rosbag does. This way, queries can only be made based on the time of the message. More powerful queries and usage of the data is only possible of a specific node has been created or modified to record data in more verbose documents. ", "The upper graphs shows CPU and memory usage of rosbag, the generic mongodb_log python logger, and the specific C++ logger mongodb_log_tf, all recording the /tf topic at the same time, with transform messages containing 5 transforms at a rate of 100 Hz. We see that the MongoDB C++ logger and rosbag perform with about the same overhead. However, MongoDB is more efficient when writing, because rosbag writes the message type specification for each recorded message (note that MongoDB was writing two topics, one for the Python and the C++ logger each, while rosbag logged only one). The generic Python logger is much more demanding in terms of both, CPU and memory usage. The problem is the inherent Python overhead for deserializing message, which we had also analyzed when developing roslua (cf. ", "). Hence, logging many unknown topics can put a considerable burden on your logging machine. ", "The data acquired can be useful for a plethora of tasks. We have used it for fault analysis and performance evaluation, as described on the ", " and in the ", ". More information will be provided at a later point in time. ", "If you want to get in touch please contact ", ". Feel free to fork the ", " and let us know about your changes. Please report issues on the ", ". "], "package_tt": ["mongodb_rrd", "record_to_db"], "package_code": ["git clone https://github.com/timn/ros-mongodb_log.git mongodb_log\n", "cd mongodb_log\n", "make", "rosrun mongodb_log mongodb_log -a", "  MongoDB document                          rostopic echo /tf\n", "------------------------------------------------------------------------------\n", "{                                        |\n", "  \"_id\" : ObjectId(\"5011...\"),           |\n", "  \"__topic\" : \"/tf\",                     |\n", "  \"__recorded\" : ISODate(\"2012-07...\"),  |\n", "  \"transforms\" : [                       |  transforms:\n", "    {                                    |  -\n", "      \"header\" : {                       |    header:\n", "        \"stamp\" : ISODate(\"2012-07...\"), |    stamp:\n", "                                         |      secs: 1343297357\n", "                                         |      nsecs: 291\n", "        \"frame_id\" : \"/from\",            |      frame_id: /from\n", "        \"seq\" : 0                        |      seq: 0\n", "      },                                 |\n", "      \"transform\" : {                    |    transform:\n", "        \"translation\" : {                |      translation:\n", "        \"x\" : 1,                         |        x: 1.0\n", "        \"y\" : 0,                         |        y: 0.0\n", "        \"z\" : 0                          |        z: 0.0\n", "      },                                 |\n", "      \"rotation\" : {                     |      rotation:\n", "        \"x\" : 0,                         |        x: 0.0\n", "        \"y\" : 0,                         |        y: 0.0\n", "        \"z\" : 0,                         |        z: 0.0\n", "        \"w\" : 1                          |        w: 1.0\n", "      },                                 |\n", "      \"child_frame_id\" : \"/some_other\"   |    child_frame_id: /some_other\n", "    }                                    |\n", "  ]                                      |\n", "}                                        |"]}
,{"url": "https://wiki.ros.org/movie_publisher", "package": "movie_publisher", "package_summary": ["Node for using a video file as video topic source."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", "The node can run with either of two backends - ", " and ", ". ", " is strongly recommended, as it uses ", ", which is quite versatile and efficient. Is you do not set the ", " param, autodetection is run. ", "It is a Bash script with ROS node-like API - you pass it parameters via ", " on commandline or via ROS param server. ", "Call this script from commandline setting the node-private parameters, and pass any other ", " arguments - these will be relayed to ", " as is. Do not pass arguments that would collide with the node-private parameters of this script (e.g. ", "). ", "It is a Bash script with ROS node-like API - you pass it parameters via ", " on commandline or via ROS param server. ", "Call this script from commandline setting the node-private parameters, and pass any other ", " arguments - these will be relayed to movie_publisher.launch as is. Do not pass arguments that would collide with the node-private parameters of this script (e.g. ", "). ", "Goes through ", " and for all messages with a ", " field sets their publication time to the time stored in their ", " plus ", ". If ", " are set, only works on messages on the listed topics. Reading timestamps from ", " is also supported. ", "It is a Python script with ROS node-like API - you pass it parameters via ", " on commandline. "], "package_tt": ["movie_publisher_node", "sensor_msgs/Image", "movie_publisher.launch", "immediate", "movie_to_bag", "add_movie_to_bag", "fix_bag_timestamps", "merge.py", "moviepy", "opencv", "moviepy", "ffmpeg", "backend", "movie\u00a0(sensor_msgs/Image)", "movie_file\u00a0(string,\u00a0required)", "fps\u00a0(float,\u00a0optional)", "start\u00a0(float|tuple|string,\u00a0optional)", "15.35", "(min,\u00a0sec)", "(hour,\u00a0min,\u00a0sec)", "'01:03:05.35'", "end", "duration", "end\u00a0(float|tuple|string,\u00a0optional)", "15.35", "(min,\u00a0sec)", "(hour,\u00a0min,\u00a0sec)", "'01:03:05.35'", "start", "duration", "duration\u00a0(float|tuple|string,\u00a0optional)", "15.35", "(min,\u00a0sec)", "(hour,\u00a0min,\u00a0sec)", "'01:03:05.35'", "start", "end", "loop\u00a0(bool,\u00a0default\u00a0False)", "immediate", "immediate\u00a0(bool,\u00a0default\u00a0False)", "fake_time_start", "loop", "playback_rate\u00a0(float,\u00a0optional)", "fake_time_start\u00a0(float,\u00a0default\u00a00.0)", "immediate", "frame_id\u00a0(string,\u00a0default\u00a0\"\")", "spin_after_end\u00a0(bool,\u00a0default\u00a0False)", "verbose\u00a0(bool,\u00a0default\u00a0False)", "wait_after_publisher_created\u00a0(float,\u00a0default\u00a01.0)", "publisher_queue_size\u00a0(int,\u00a0default\u00a01000\u00a0in\u00a0immediate\u00a0mode,\u00a010\u00a0otherwise)", "queue_size", "backend\u00a0(string,\u00a0default\u00a0\"moviepy\")", "moviepy", "opencv", "moviepy", "opencv", "ffmpeg\u00a0(string,\u00a0default\u00a0\"\")", "transport\u00a0(string,\u00a0default\u00a0'raw')", "image_transport/republish", "republished_topic_basename\u00a0(string,\u00a0default\u00a0movie_$(arg\u00a0transport))", "$(arg\u00a0republished_topic_basename)/$(arg\u00a0transport)", "$(arg\u00a0republished_topic_basename)", "raw", "movie_publisher_node", "movie", "_param:=value", "movie\u00a0(string)", "bag\u00a0(string)", "topic\u00a0(string)", "overwrite_bag\u00a0(bool,\u00a0default\u00a0false)", "bag", "bag", "tmp_bag\u00a0(string,\u00a0default\u00a0/tmp/movie.bag)", "transport\u00a0(string,\u00a0default\u00a0compressed)", "raw", "compressed", "theora", "arg:=value", "movie_publisher.launch", "movie_file", "_param:=value", "movie\u00a0(string)", "bag_in\u00a0(string)", "bag_out\u00a0(string,\u00a0default:\u00a0output.bag)", "topic\u00a0(string)", "movie_delay\u00a0(int,\u00a0default\u00a00)", "overwrite_out_bag\u00a0(bool,\u00a0default\u00a0false)", "bag_out", "bag_out", "bag_tmp\u00a0(string,\u00a0default\u00a0/tmp/movie_add_to.bag)", "transport\u00a0(string,\u00a0default\u00a0compressed)", "raw", "compressed", "theora", "arg:=value", "movie_file", "in_bag", "header", "header.stamp", "delay", "topics", "/tf", "_param:=value", "in_bag\u00a0(string)", "out_bag\u00a0(string)", "topics\u00a0(string,\u00a0default:\u00a0'')", "delay\u00a0(int,\u00a0default\u00a00)", "header", "overwrite_existing\u00a0(bool,\u00a0default\u00a0false)", "out_bag", "out_bag"], "package_code": ["sudo pip install moviepy", "rosdep install python-moviepy-pip", "rosrun movie_publisher movie_to_bag _movie:=movie.mp4 _bag:=movie.bag _topic:=\"/movie\" start:=5 fake_time_start:=1548323340.24", "rosrun movie_publisher add_movie_to_bag _movie:=movie.mp4 _bag_in:=movie_in.bag _bag_out:=movie_out.bag _topic:=\"/movie\" start:=5 movie_delay:=-1"]}
,{"url": "https://wiki.ros.org/lanelet2", "package": "lanelet2", "package_summary": ["Meta-package for lanelet2"], "package_details": ["\n", " is a C++ library for handling map data in the context of automated driving. It is designed to utilize high-definition map data in order to efficiently handle the challenges posed to a vehicle in complex traffic scenarios. Flexibility and extensibility are some of the core principles to handle the upcoming challenges of future maps. ", " ", "\n", "Use GitHub to ", ". [", "]", "\n ", "\n", " ", "Lanelet2 is the successor of the old ", " that was developed in 2013. ", "\n", "For more information, please refer to our ", ". ", "If you are using Lanelet2 for scientific research, we would be pleased if you would cite our ", ": "], "package_code": ["@inproceedings{poggenhans2018lanelet2,\n", "  title     = {Lanelet2: A High-Definition Map Framework for the Future of Automated Driving},\n", "  author    = {Poggenhans, Fabian and Pauls, Jan-Hendrik and Janosovits, Johannes and Orf, Stefan and Naumann, Maximilian and Kuhnt, Florian and Mayr, Matthias},\n", "  booktitle = {Proc.\\ IEEE Intell.\\ Trans.\\ Syst.\\ Conf.},\n", "  year      = {2018},\n", "  address   = {Hawaii, USA},\n", "  owner     = {poggenhans},\n", "  month     = {November},\n", "  Url={http://www.mrt.kit.edu/z/publ/download/2018/Poggenhans2018Lanelet2.pdf}\n", "}"]}
,{"url": "https://wiki.ros.org/retalis", "package": "retalis", "package_summary": ["Retalis Language for Information Processing and Management in Autonomous Robot Software"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " ", " ", "\n", " ", " ", " ", " ", " ", "\n", "\n", " ", " ", " ", "\n", " ", " ", "\n", "\n", " ", "Messages received by retalis from the subscribed topics are automatically converted to events. For example, the following message of type ", " ", "Events are time-stamped according to header times of ros messages. If a message does not have a header, it is time stamped with ", ".  The format of time-stampes are  ", " where ", " encodes nanoseconds since seconds (i.e. stamp.nsec in ros messages). For example, the above ", " message contains a list of ", " messages (only one here). While each  ", " message is time-stamped, the ", " itself does not have a header. Therefore, the corresponding event is stamped with the current time. ", "The following rule calls  the ", " function for every ", " event received by retalis. ", "Each ", " message from ", " contains a list of recognized objects, each represented by a  ", " message. The following rule generates a separate event for each object. ", "where ", " represents a recognized object and ", " encodes the time of recognition. This time corresponds to the time of taking the picture at which the object was recognized. This time is taken from the header file of the corresponding ", " message. The events is also time stamped with ", ". ", "Retalis integrates the '", ". ", " supports temporal and logical reasoning on flow of events. Please see ", "  for publications and for examples of rules implementing various event-processing functionalities. ", "This memory instance keeps the history of events of the form ", ", specified by the first argument. The second argument specifies a list of conditions, being empty here. A memory instance only records events that satisfy the conditions. The third argument specifies the format for recording events. The fourth argument is the Id of the memory instance. The last argument is the size. Only the last 2500 events of the given form are maintained by this memory instance. ", "The ", " event from Section 4.1.3 matches this memory instance. This events is recorded by this memory instance as ", ". ", "We saw in Section 4.1.3 that the ", " and ", " functions are implemented as Prolog clauses. The ", " file can include an arbitrary Prolog program to encode a domain knowledge. We also saw in Section 4.1.4  that how memory instances are used to maintain histories of events ", "The Prolog program in ", " together with the the dynamic knowledge maintained by memory instances represent a Prolog-based knowledge base. This knowlede base can be queries by event-processing rules, for instance, as in Section 4.1.3. It can be also queried directly by a ros service (in our ", " list). ", "An example of using ", " and ", " terms is in implementation of the ", " function, in the eventRules.txt. The input values to this function is the ", " of a memory instance, keeping the history of some ", " events, and a time point. The ", " events represent observations of the transformation between two coordinate frames over time. From these observations, this function interpolates the transformation between the frames at time ", ". This is implemented as follows. The last observation before ", " and the first observation after ", " are found using the ", " and ", " terms. Then the position is linearly interpolated by making a function call to the ", " library that has been integrated with retalis. ", "The ", " function in eventRules.txt uses the ", " function to position an object in the world reference frame. Given ", ", the position of an object relative to the camera at time ", ", this function computes ", ", the position in the world, as follows. First, it changes the time format from ros time to datime. Then, it interpolates the transformation between ", ", ", ", ", ", ", " and ", " at the time ", ". Third, it applies these transformations on the ", " by making a function call to the ", " library. It is assumed that the ", " frame is aligned with the world reference frame. ", "We saw in Section 4.1.6 that how calling ", " function interpolates the position between the ", " and ", " coordination frames at time ", ". This function uses ", " and ", " terms to access the first and the last observations after and before ", ", respectively. To interpolate the position at ", ", the position should have been observed, at least once, after ", ". The observations, ", " messages here, are received asynchronously. Therefore, the ", " function should be evaluated only after the ", " memory instance has been updated with an event occurring after ", ". This is realized in retalis using a synchronized event, as follows. ", "The ", " function, performs the ", ", when the ", " are satisfied and then generate the ", ". Consider the following clause from eventRules.txt: ", "This rule computes the position of recognized markers in the world and is read as follows.   For each ", " event, specified in line 6, the position is computed by calling the ", " function, as in line 3. After computing the position, an event of the following form is generated, specified in line 2: ", "Such a ", " event encodes the marker's name, its position in the world and the time of recogntion. The ", " are the followings, specified in line 4: ", "These conditions specify that the ", " function should be evaluated, only after all ", ", ", ", ", ", ", " and ", " memory instances have been updated, at least once, with events occurring after time ", ". The time ", " is the time of recognition of the marker. ", "Retalis performs the synchronization of events in an event-driven and efficient way. The generation of a synchronized ", " is posponed, until the ", " are satisfied. Postponing an event does not postpone the generation of other events and postponed events are generated as soon as necessary conditions are met. ", "The subscription subscribes the topic ", " to the ", " events in which ", " is ", ". Such events are generated by the synchronized rule, presented in Section 4.1.7. They contain the position of the marker ", " in the world coordination frame.  The id of the subscription is ", " which can be used to cancel the subscrition at any time. ", "The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes when running the NAO example. The retalis node calculates the position of objects in real-time. It processes about 1900 events, memorizes 130 new events and prunes 130 outdated events per second.  It also queries memory instances, 70 times per second. These tasks are performed using about 18 percent of the CPU time. In this experience, the retalis node has been directly subscribed to the ", " and ", " ros topics. The retalis-ros-converter only subscribes retalis to the ", " topic and converts and publishes events about objects' positions to ros topics. To have this setup, comments out the subscriptions to ", " and ", " topics in the pub-sub.xml file and instead, set the ", " boolean variable in the retalis_interface.cpp file to ", ". You should also recompile the package. ", "As we saw in Section 4.1.2, retalis provides an easy way to subscribe to ros topics and automatically convert ros messages to events. This is implemented by the retalis-ros-converter node. The implementation is in Python and is realized by inspecting classes and objects at runtime and therefore is expensive. The following figure shows the CPU time used by the retalis and retalis-ros-converter nodes for the NAO example, when the retalis-ros-converter is used to subscribe to ", " and ", " topics. This results show that while the automatic conversion among messages and events are desirable in a prototyping phase, the final application should implement it in C++ for performance reasons. We will investigate the possibility to re-implement the retalis-ros-converter node in C++. ", "The following figure shows the CPU time for a number of runs where up to 160 memory instances are added to the NAO example. These memory instances record ", " events. Among the events processed by retalis, there are no such events. The results show that the increase in CPU time is negligible. This shows that a memory instance consumes CPU time only if the input stream of events contains events whose type matches the type of events the memory instance records.  ", "In the following figure, the green and blue lines show the CPU time for cases where 20 memory instances of type ", " are added to the NAO example. These memory instances match all ", " events, about 1900 of such is processed every second. The size of memory instances for the green line is 2500. These memory instances reach their size limit in two seconds. After this time, the CPU time usage is constant over time and includes the costs of unification, assertion and retraction for updating 20 memory instances with 1900 events per second. The size of memory instances for the blue line is 150,000. It takes about 80 seconds for this memory instances to reach their size limit. Consequently, the CPU time before the time 80 only includes the costs of unification and assertion, but not the costs of retraction. After the time 100, the CPU usages of both runs are equal. This shows that the cost of a memory instance does not depend on its size. The purple line shows the CPU time for the case where similarely there are 20 memory instances of type ", ". However, these memory instances record events until their reach their size limit. We added a condition for these memory instances such that after reaching their size limit, they perform no operation when receiving new events. After the time 100, the CPU time is constant about 23 percent, being 5 percent more than the CPU time of the NAO example, represented by the red line. This 5 percent increase represents the unification cost. This also shows that the costs of about 38000 assertions and 38000 retractions per second is about 30 percent of CPU time. In other words, 2500 memory updates (i.e. assertions or retractions) are processed using one percent of CPU time. ", "The following figure shows the CPU time for a number of runs where up to 40 memory instances of type ", " and size 2500 are added to the NAO example.  The red line at the bottom shows the CPU time for the NAO example. We make the following observations. Adding first 10 memory instances to the NAO example increases the CPU time about 20 percent. After that, adding each set of 10 memory instances increases the CPU time about 13 percents. This shows that the cost grows less than linearly. The implementation of memory instances is in a way that the cost of an assertion or a retraction can be assumed constant. This means that the unification cost for the first set of memory instances is the highest. In other words, the unification cost per memory instance decreases when the number of memory instances are increased.  ", "The following figure shows the CPU time for a number of runs where up to 640 memory instances of type ", " and size 2500 are added to the NAO example. The events matching these memory instances are received with the frequency of 50 Hz. We make the following observaitons. First, it takes 50 seconds for these memory instances to reach their size limit. After 50 seconds, these memory instances reach their maximum CPU usages, as the costs of retraction is added. Second, each memory instance filters 1900 events per second recording about two percents of them. The cost of 640 memory instances is about 35 percent of CPU time. Third, the unification cost per memory instance is decreased when the number of memory instances are increased. ", "The following figure compares the costs of different types of memory instances. The purple line shows the CPU time for the case where there are 10 memory instances of type ", ". The green line shows the CPU time for the case where there are 320 memory instances of type ", ". We observe that the costs of both cases are equal. The memory instances in the former case record 19,000 events per second (i.e. 10*1900). The memory instances in the latter case filter 1900 events per seconds for ", " events, recording 16000 events per second (i.e. 320*50). The results show the efficiency of the filtering mechanism. ", "The brown line shows the CPU time for the case where there are 10 memory instances of type ", " and 320 memory instances of type ", ". ", "Comparing it with the green and purple lines shows that the CPU time usage of these memory instances is less than sum of the CPU usages by 10 ", " memory instances and 320 ", " memory instances. This shows that the  unification cost per memory instance is decreased when the number of memory instances are increased, even when the memory instances are not of the same type. ", "The green line in the following figure shows the CPU time of the NAO example adapted as follows. There is an additional ", " memory instance of size 128. This memory instance is queried by 1000 ", " terms for each recognition of an object. In average, 7000 ", " terms are evaluated per second. The blue line visualize the CPU time of a similar program in which 7000 ", " terms are evaluated per seconds. The figure shows that the costs of the evaluations of ", " and ", " terms are similar. The purple line shows the CPU time of the case where 14,000 ", " terms are evaluated per second. We observe that the cost grows linearly, as expected. ", "The blue line in the following figure visualizes the CPU time of the case where 7000 ", " terms are evaluated per second. The green line visualizes the CPU time of the case where there are 320 ", " memory instances. The purple line visualizes the CPU time of the case where 7000 ", " terms are evaluated per second and there are 320 ", " memory instances. We observe that the cost of accessing a memory instance does not depend on existance of other memory instances. ", "The green line in the following figure visualizes the CPU time of evaluating 7000 ", " terms per second on a memory instance of size 128. The blue linevisualizes the CPU time of evaluating 7000 ", " terms per second on a memory instance of size 16384. The size of the memory instance in the latter case is the power of two of the size of the memory instance in the former case. The increase in the CPU time for the latter case, with respect to the NAO example, is less than two times of the increase in the CPU time for the former case.     ", "The red line in the following figure visualized the CPU time of the NAO example where in each second, 1000 ", " queries on a memory instance of size 2500 are evaluated. In addition, for each ", " query, a new event is generated. The green line visualizes the CPU time of a similar case where the next queries are synchronized. This experiment is conducted in a way that no query needs to be delayed. Coparing these two cases shows that when queries are not delayed, the synchronization cost is negligible. ", "Information flow processing systems such as Etalis are designed for applications that require a real-time processing of a large volume of data flow. Please see ", " for the evaluation of the performance of on-flow functionalities. The evaluation results show, in terms of performance, Etalis is competitive with respect to the state-of-the-art on-flow processing systems. "], "package_tt": ["add_output_subscription", "delete_output_subscription", "add_memory", "delete_memory", "add_input_subscription", "delete_input_subscription", "__0__", "__0__", "__0__", "__0__", "'\"/odom\"','\"/base_link\"'", "'\u201c/odom\u201d',\u00a0'\u201c/base_link\u201d'", "ToDo", "Event", "RelativePos", "AbsolutePose", "RelativePos", "AbsolutePose", "CameraTop", "RelativePos", "SynchConditions", "Query", "SynchConditions", "Event", "PoseStamped", "SyncConditions", "PoseStamped", "'\"4x4_1\"'", "__0__", "__0__", "CameraTop_frame"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]}
,{"url": "https://wiki.ros.org/remote_manipulation_markers", "package": "remote_manipulation_markers", "package_summary": ["A set of interactive markers for various methods of remote teleoperation manipulation of 6-DOF robot end-effectors"], "package_details": ["\n", "\n", " ", "\n", "Newly proposed, mistyped, or obsolete package. Could not find package \"remote_manipulation_markers\" in rosdoc: /home/rosbot/docs/api/remote_manipulation_markers/manifest.yaml ", "\n", "\n", "\n", "\n", "\n", "The ", " package contains interactive marker servers for a set of remote manipulation interaction approaches.  The approaches include Free Positioning, Constrained Positioning, and Point-and-Click.  These interactive marker servers are intended for use with rviz or with Robot Web Tools interfaces. ", "This package includes three approaches:  Free Positioning (FP), Constrained Positioning (CP), and Point-and-Click (P&C).  The three approaches are shown below, with interaction points for setting initial poses shown in yellow, and interaction points for adjusting poses shown in blue. ", "Free positioning uses a ring-and-arrow marker which can be clicked and dragged to individually adjust translation along and rotation about each Cartesian axis.  Constrained positioning uses a sphere marker to first set a grasp point, followed by setting an approach angle by clicking on the surface of the sphere.  The approach angle is constrained to pass through the grasp point.  Point-and-click makes use of autonomous grasp calculation, and involves the user selecting a previously calculated grasp for execution from a list of potential grasps.  Further details on these can be found in ", ", published in HRI 2017.  The approaches are designed for both 2D and 3D visualization modes.  For full details and a comparison of the efficiency and effectiveness of each approach in both 2D and 3D visualization modes, see our IJRR 2019 article ", ". Videos of the approaches in action can be found ", " and ", ". ", "To install the ", " package, you can install from source with the following commands: ", "Note that ", " and ", " include a boolean parameter ", ".  Setting ", " to true will launch a ", " node that corresponds to the free or constrained positioning node. ", "If you use this package in your work, please cite our ", ": ", "David Kent, Carl Saldanha, and Sonia Chernova.  Leveraging Depth Data in Remote Robot Teleoperation Interfaces for General Object Manipulation. ", ", 2019. "], "package_tt": ["remote_manipulation_markers", "execute_grasp/goal", "execute_grasp/result", "execute_grasp/feedback", "grasp", "grasp_topic", "gripper_marker_pose", "reset_marker_pose", "base_link", "string", "eef_link", "string", "grasp_topic", "string", "execute_grasp/goal", "execute_grasp/result", "execute_grasp/feedback", "grasp", "grasp_topic", "gripper_marker_pose", "clear_gripper_marker", "clear_full_marker", "create_sphere", "grasp_topic", "string", "execute_grasp/goal", "execute_grasp/result", "execute_grasp/feedback", "grasp", "grasp_topic", "/grasp_sampler/sampled_grasps", "calculatedPosesTopic", "cycle_grasps", "grasp_topic", "string", "calculated_poses_topic", "string", "/free_positioning/gripper_marker_pose", "marker_node_name", "marker_node_name", "string", "remote_manipulation_markers", "free_positioning.launch", "constrained_positioning.launch", "run_separate_vis", "run_seperate_vis", "gripper_marker_vis"], "package_code": ["\n", "\n", "\n", "\n", "\n", "roslaunch remote_manipulation_markers free_positioning.launch", "roslaunch remote_manipulation_markers constrained_positioning.launch", "roslaunch remote_manipulation_markers point_and_click.launch"]}
,{"url": "https://wiki.ros.org/ecl_formatters", "package": "ecl_formatters", "package_summary": ["The formatters here simply format various input types to a specified\n   text format. They can be used with most streaming types (including both\n   ecl and stl streams)."], "package_details": ["\n", "\n", "\n", "\n", "Typically c/c++ libraries bundle streaming and formatting within the same tool (printf, iostream, ...). This tends to make them cumbersome for simple tasks. The formatter classes in this package externalise the formatting task from the io manipulation (which is usually just (u)char manipulation), This increases the efficiency of low level operations whilst also maintaining type safety. They typically do this by making use of the lower level functionality provided by ", ". ", "The formatter classes can be used standalone, with stl streams or with ", ". ", "If outside of ros, you will also need to link to ", ". ", "Each standard formatter is a template specialisation of the form ", " where the available input types are: "], "package_tt": ["Format<inputType>"], "package_code": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n"]}
,{"url": "https://wiki.ros.org/rr_openrover_driver_msgs", "package": "rr_openrover_driver_msgs", "package_summary": ["The rr_openrover_driver_msgs package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package contains the messages used to publish hardware data from the ", ". "], "package_code": ["std_msgs/Header header\n", "std_msgs/int32 left_motor\n", "std_msgs/int32 right_motor\n", "std_msgs/int32 flipper_motor", "std_msgs/Header header\n", "std_msgs/int32 reg_pwr_total_current\n", "std_msgs/int32 reg_motor_fb_rpm_left\n", "std_msgs/int32 reg_motor_fb_rpm_right\n", "std_msgs/int32 reg_flipper_fb_position_pot1\n", "std_msgs/int32 reg_flipper_fb_position_pot2\n", "std_msgs/int32 reg_motor_fb_current_left\n", "std_msgs/int32 reg_motor_fb_current_right\n", "std_msgs/int32 reg_motor_charger_state\n", "std_msgs/int32 reg_power_a_current\n", "std_msgs/int32 reg_power_b_current\n", "std_msgs/int32 reg_motor_flipper_angle\n", "std_msgs/int16 battery_current_a\n", "std_msgs/int16 battery_current_b", "std_msgs/Header header\n", "std_msgs/int32 reg_motor_fault_flag_left\n", "std_msgs/int32 reg_motor_temp_left\n", "std_msgs/int32 reg_motor_temp_right\n", "std_msgs/int32 reg_power_bat_voltage_a\n", "std_msgs/int32 reg_power_bat_voltage_b\n", "std_msgs/int32 reg_robot_rel_soc_a\n", "std_msgs/int32 reg_robot_rel_soc_b\n", "std_msgs/uint16 battery_mode_a\n", "std_msgs/uint16 battery_mode_b\n", "std_msgs/uint16 battery_temp_a\n", "std_msgs/uint16 battery_temp_b\n", "std_msgs/uint16 battery_voltage_a\n", "std_msgs/uint16 battery_voltage_b\n", "std_msgs/int32 buildno", "std_msgs/Header header\n", "\n", "std_msgs/bool over_charged_alarm\n", "std_msgs/bool terminate_charge_alarm\n", "std_msgs/bool over_temp_alarm\n", "std_msgs/bool terminate_discharge_alarm\n", "std_msgs/bool remaining_capacity_alarm\n", "std_msgs/bool remaining_time_alarm\n", "\n", "std_msgs/bool initialized\n", "std_msgs/bool discharging\n", "std_msgs/bool fully_charged\n", "std_msgs/bool fully_discharged"]}
,{"url": "https://wiki.ros.org/pr2_gazebo_plugins", "package": "pr2_gazebo_plugins", "package_summary": ["Gazebo Plugins for various PR2-specific sensors and actuators on the robot."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", " plugin provides ROS topic and service interfaces similar to those provided by the ", " on PR2. ", "\n", "\n", "\n", " plugin provides ROS topics and services similar to those provided by ", " on physical PR2. ", "\n", "\n", "\n", "\n", "\n", "\n", " plugin provides similar ROS interface as ", " on the physical PR2 robot.  This plugin is written in a way that ", " works transparently with either this simulated plugin or the ", " hardware.  For more information on using ", " or ", " with this plugin, please see ", ". ", "\n", "\n", "This package contains dynamic plugins for ", " and ", " integration with simulated hardware. ", "Please see ", " for additional supported hardware components in simulation. ", "This stack will be updated with new features as the PR2 hardware itself is updated. Future versions will also incorporate ", " options to match ORS driver functionality. "], "package_tt": ["GazeboRosControllerManager", "GazeboRosProsilica", "GazeboRosPowerMonitor", "<robotParam>", "<robotNamespace>", "GazeboRosProsilica", "<robotNamespace>", "<imageTopicName>", "<cameraInfoTopicName>", "<pollServiceName>", "<frameName>", "<CxPrime>", "<Cx>", "<Cy>", "<focal_length>", "<distortion_k1>", "<distortion_k2>", "<distortion_k3>", "<distortion_t1>", "<distortion_t2>", "<hackBaseline>", "GazeboRosPowerNode", "<robotNamespace>", "<powerStateTopic>", "<powerStateRate>", "<fullChargeCapacity>", "<chargeRate>", "<dischargeVoltage>", "<dischargeRate>", "<chargeVoltage>", "plugged_in", "<powerStateTopic>", "<imageTopicName>", "<cameraInfoTopicName>", "request_image", "GazeboRosControllerManager"], "package_code": ["    <!-- GazeboMechanismControl -->\n", "    <controller:gazebo_ros_controller_manager name=\"gazebo_ros_controller_manager\" plugin=\"libgazebo_ros_controller_manager.so\">\n", "      <alwaysOn>true</alwaysOn>\n", "      <updateRate>1000.0</updateRate>\n", "      <robotParam>robot_description</robotParam>\n", "      <robotNamespace>/</robotNamespace>\n", "    </controller:gazebo_ros_controller_manager>", "  <body:empty name=\"camera_body_name\">\n", "    <sensor:camera name=\"high_def_sensor\">\n", "      <imageFormat>R8G8B8</imageFormat>\n", "      <imageSize>2448 2050</imageSize>\n", "      <hfov>45</hfov>\n", "      <nearClip>0.1</nearClip>\n", "      <farClip>100</farClip>\n", "      <updateRate>20.0</updateRate>\n", "      <controller:gazebo_ros_prosilica name=\"high_def_controller\" plugin=\"libgazebo_ros_prosilica.so\">\n", "        <alwaysOn>true</alwaysOn>\n", "        <updateRate>20.0</updateRate>\n", "        <imageTopicName>/prosilica/image_raw</imageTopicName>\n", "        <cameraInfoTopicName>/prosilica/camera_info</cameraInfoTopicName>\n", "        <pollServiceName>/prosilica/request_image</pollServiceName>\n", "        <frameName>high_def_frame</frameName>\n", "        <CxPrime>1224.5</CxPrime>\n", "        <Cx>1224.5</Cx>\n", "        <Cy>1025.5</Cy>\n", "        <focal_length>2955</focal_length> <!-- image_width / (2*tan(hfov_radian /2)) -->\n", "        <distortion_k1>0.00000001</distortion_k1>\n", "        <distortion_k2>0.00000001</distortion_k2>\n", "        <distortion_k3>0.00000001</distortion_k3>\n", "        <distortion_t1>0.00000001</distortion_t1>\n", "        <distortion_t2>0.00000001</distortion_t2>\n", "        <interface:camera name=\"high_def_iface\"/>\n", "      </controller:gazebo_ros_prosilica>\n", "    </sensor:camera>\n", "  </body:empty>", "    <controller:gazebo_ros_power_monitor name=\"gazebo_ros_power_monitor_controller\" plugin=\"libgazebo_ros_power_monitor.so\">\n", "        <alwaysOn>true</alwaysOn>\n", "        <updateRate>1.0</updateRate>\n", "        <timeout>5</timeout>\n", "        <interface:audio name=\"power_monitor_dummy_interface\" />\n", "        <powerStateTopic>power_state</powerStateTopic>\n", "        <powerStateRate>10.0</powerStateRate>\n", "        <fullChargeCapacity>87.78</fullChargeCapacity>\n", "        <dischargeRate>-474</dischargeRate>\n", "        <chargeRate>525</chargeRate>\n", "        <dischargeVoltage>15.52</dischargeVoltage>\n", "        <chargeVoltage>16.41</chargeVoltage>\n", "    </controller:gazebo_ros_power_monitor>"]}
,{"url": "https://wiki.ros.org/wiimote", "package": "wiimote", "package_summary": ["The wiimote package allows ROS nodes to communicate with a Nintendo Wiimote\n    and its related peripherals, including the Nunchuk, Motion Plus, and\n    (experimentally) the Classic. The package implements a ROS node that uses\n    Bluetooth to communicate with the Wiimote device, obtaining accelerometer\n    and gyro data, the state of LEDs, the IR camera, rumble (vibrator),\n    buttons, joystick, and battery state. The node additionally enables ROS\n    nodes to control the Wiimote's LEDs and vibration for feedback to the human\n    Wiimote operator. LEDs and vibration may be switched on and off, or made to\n    operate according to a timed pattern."], "package_details": [" ", "\n", "\n", " The cwiid library currently only recognizes Wiimotes which report the name as \"Nintendo RVL-CNT-01\"; the latest Wiimotes will not be discovered. See ", ". ", "\n", "\n", "\n", " ", "\n", " ", "The ", " array shows which buttons are currently depressed on the ", "Wiimtoe device. The position mapping is as follows: ", "This package should be considered as ", " except for support of the Classic controller, which requires additional testing. ", "Check out the wiimote package, and ", " to ready the package for ", "operation. Plug the Bluetooth dongle into your machine's USB port. ", "The ", " message communicates all data that is available from ", "your Wiimote device. Samples are taken and broadcast at 100Hz. Here ", "are comments on some of the fields: ", "The message header's time ", " is set to reflect the time when the respective message's sample was taken from the Wiimote device. ", "The ", " shows the Motion+ gyroscope ", "reading. These values are valid only if the Motion+ attachment is ", "plugged into the Wiimote. Else they are held at constant zero, and ", "matrix entry [0,0] in message field angular_velocity_covariance is set ", "to -1. ", "The ", " are four sets of x/y/[z], and size measures, for the four ", "infrared light sources that the Wiimote device can track. When no ", "lights are detected, the respective values are set to -1. The z axis ", "is always -1, as it is not measured. ", "The ", " array are four intensity measures of the lights that ", "the camera observes. The meaning of these measures are unclear to the ", "author. ", "The ", " entry is the battery charge reading. The unit of ", "this number is unclear. Field ", " returns the remaining ", "charge as a percentage of full charge. ", "The ", " is the time of the most recent device calibration. ", "The ", " field is currently not used. "], "package_tt": ["cwiid", "rosmake", "wiimote_node.py", "set_feedback", "joy", "imu/data", "wiimote/state", "wiimote/nunchuk", "wiimote/classic", "imu/is_calibrated", "imu/calibrate", "State", "stamp", "angular_velocity_zeroed", "angular_velocity_raw", "buttons", "ir_tracking", "ir_sizes", "raw_battery", "percent_battery", "zeroing_time", "errors"], "package_code": ["Position   Button Name\n", "0         1\n", "1         2\n", "2         A\n", "3         B (toggle button on back of device)\n", "4         Plus\n", "5         Minus\n", "6         Rocker Left\n", "7         Rocker Right\n", "8         Rocker Up\n", "9         Rocker Down\n", "10        HOME"]}
,{"url": "https://wiki.ros.org/rr_openrover_driver_msgs", "package": "rr_openrover_driver_msgs", "package_summary": ["The rr_openrover_driver_msgs package"], "package_details": ["\n", "\n", "\n", "\n", "\n", "This package contains the messages used to publish hardware data from the ", ". "], "package_code": ["std_msgs/Header header\n", "std_msgs/int32 left_motor\n", "std_msgs/int32 right_motor\n", "std_msgs/int32 flipper_motor", "std_msgs/Header header\n", "std_msgs/int32 reg_pwr_total_current\n", "std_msgs/int32 reg_motor_fb_rpm_left\n", "std_msgs/int32 reg_motor_fb_rpm_right\n", "std_msgs/int32 reg_flipper_fb_position_pot1\n", "std_msgs/int32 reg_flipper_fb_position_pot2\n", "std_msgs/int32 reg_motor_fb_current_left\n", "std_msgs/int32 reg_motor_fb_current_right\n", "std_msgs/int32 reg_motor_charger_state\n", "std_msgs/int32 reg_power_a_current\n", "std_msgs/int32 reg_power_b_current\n", "std_msgs/int32 reg_motor_flipper_angle\n", "std_msgs/int16 battery_current_a\n", "std_msgs/int16 battery_current_b", "std_msgs/Header header\n", "std_msgs/int32 reg_motor_fault_flag_left\n", "std_msgs/int32 reg_motor_temp_left\n", "std_msgs/int32 reg_motor_temp_right\n", "std_msgs/int32 reg_power_bat_voltage_a\n", "std_msgs/int32 reg_power_bat_voltage_b\n", "std_msgs/int32 reg_robot_rel_soc_a\n", "std_msgs/int32 reg_robot_rel_soc_b\n", "std_msgs/uint16 battery_mode_a\n", "std_msgs/uint16 battery_mode_b\n", "std_msgs/uint16 battery_temp_a\n", "std_msgs/uint16 battery_temp_b\n", "std_msgs/uint16 battery_voltage_a\n", "std_msgs/uint16 battery_voltage_b\n", "std_msgs/int32 buildno", "std_msgs/Header header\n", "\n", "std_msgs/bool over_charged_alarm\n", "std_msgs/bool terminate_charge_alarm\n", "std_msgs/bool over_temp_alarm\n", "std_msgs/bool terminate_discharge_alarm\n", "std_msgs/bool remaining_capacity_alarm\n", "std_msgs/bool remaining_time_alarm\n", "\n", "std_msgs/bool initialized\n", "std_msgs/bool discharging\n", "std_msgs/bool fully_charged\n", "std_msgs/bool fully_discharged"]}
,{"url": "https://wiki.ros.org/mavros", "package": "mavros", "package_summary": ["MAVROS -- MAVLink extendable communication node for ROS\n    with proxy for Ground Control Station."], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", " only. ", "\n", "\n", "\n", "\n", "\n", "\n", "Main node can be extended by plugins (see ", "). See also ", " package. ", "If you unsure what firmware your FCU runs start apm.launch and see ", ". ", "Starting from 0.11 mavros knows string representation for autopilot mavlink enum. ", "For older you shall manually find autopilot type value in mavlink documentation.  ", "All utilities provides ", " and ", " information. ", "Supported custom modes listed at ", ". ", "Standard set of communication plugins loaded by ", ". ", "Note: this list for ", " version. ", "Older versions: ", ", ", ", ", ", ", ", ", ", ", ", ", ". "], "package_tt": ["mavlink/to", "mavlink/from", "diagnostics", "~system_id", "int", "~component_id", "int", "~target_system_id", "int", "~target_component_id", "int", "~startup_px4_usb_quirk", "bool", "~plugin_blacklist", "string[]", "~plugin_whitelist", "string[]", "~fcu_url", "string", "~fcu_protocol", "string", "~gcs_url", "string", "ros_udp", "mavlink/from", "mavlink/to", "~gcs_url", "string", "mavros/state", "<trigger_event>", "~<event_name>/service", "string", "~<event_handler>/event", "string[]", "~<event_handler>/action", "string[]", "~<event_handler>/shell", "string", "~<event_handler>/logfile", "string", "/path/to/serial/device[:baudrate]", "serial:///path/to/serial/device[:baudrate][/?ids=sysid,compid]", "serial-hwfc:///path/to/serial/device[:baudrate][?ids=sysid,compid]", "udp://[bind_host][:port]@[remote_host][:port][/?ids=sysid,compid]", "udp-b://[bind_host][:port]@[:port][/?ids=sysid,compid]", "tcp://[server_host][:port][/?ids=sysid,compid]", "tcp-l://[bind_host][:port][/?ids=sysid,compid]", "~system_id", "~component_id", "baudrate", "bind_host", "remote_host", "server_host", "port", "<util>\u00a0--help", "<util>\u00a0<command>\u00a0--help", "~radio_status", "~actuator_control", "~hil_controls/hil_controls", "~frame_id", "string", "~cmd/command", "~cmd/command_int", "~cmd/arming", "~cmd/set_home", "~cmd/takeoff", "~cmd/land", "~cmd/trigger_control", "~cmd/use_comp_id_system_control", "bool", "SYSTEM_CONTROL", "~ftp/open", "~ftp/close", "~ftp/read", "~ftp/write", "~ftp/list", "~ftp/truncate", "~ftp/remove", "~ftp/rename", "~ftp/mkdir", "~ftp/rmdir", "~ftp/checksum", "~ftp/reset", "~global_position/global", "~global_position/local", "~global_position/gp_vel", "~global_position/rel_alt", "~global_position/compass_hdg", "~global_position/raw/fix", "~global_position/raw/gps_vel", "~global_position/frame_id", "string", "~global_position/tf/send", "bool", "~global_position/tf/frame_id", "string", "~global_position/tf/child_frame_id", "string", "~imu/data", "~imu/data_raw", "~imu/mag", "~imu/temperature", "~imu/atm_pressure", "~imu/frame_id", "string", "~imu/linear_acceleration_stdev", "double", "~imu/angular_velocity_stdev", "double", "~imu/orientation_stdev", "double", "~imu/magnetic_stdev", "double", "~local_position/pose", "~local_position/velocity", "~local_position/frame_id", "string", "~local_position/tf/send", "bool", "~local_position/tf/frame_id", "string", "~local_position/tf/child_frame_id", "string", "~manual_control/send", "~manual_control/control", "~param/", "~param/pull", "~param/push", "~param/get", "~param/set", "~rc/override", "SYSID_MYGCS", "~rc/in", "~rc/out", "~safety_area/set", "~safety_area/p1/x", "double", "~safety_area/p1/y", "double", "~safety_area/p1/z", "double", "~safety_area/p2/x", "double", "~safety_area/p2/y", "double", "~safety_area/p2/z", "double", "~setpoint_accel/accel", "~setpoint_accel/send_force", "bool", "~setpoint_attitude/cmd_vel", "~setpoint_attitude/attitude", "~setpoint_attitude/thrust", "~setpoint_attitude/reverse_throttle", "bool", "~setpoint_attitude/use_quaternion", "bool", "~setpoint_attitude/tf/listen", "bool", "~setpoint_attutude/tf/frame_id", "string", "~setpoint_attitude/tf/child_frame_id", "string", "~setpoint_attitude/tf/rate_limit", "double", "~setpoint_position/global", "~setpoint_position/local", "~setpoint_position/tf/listen", "bool", "~setpoint_position/tf/frame_id", "string", "~setpoint_position/tf/child_frame_id", "string", "~setpoint_position/tf/rate_limit", "double", "~setpoint_raw/local", "~setpoint_raw/global", "~setpoint_raw/attitude", "~setpoint_raw/target_local", "~setpoint_raw/target_global", "~setpoint_raw/target_attitude", "~setpoint_velocity/cmd_vel_unstamped", "~state", "~battery", "~battery", "~extended_state", "~set_stream_rate", "~set_mode", "~conn/timeout", "double", "~conn/heartbeat_rate", "double", "~sys/min_voltage", "double", "~sys/disable_diag", "bool", "~time_reference", "~conn/system_time_rate", "double", "SYSTEM_TIME", "~conn/timesync_rate", "double", "~time/time_ref_source", "string", "~time/timesync_avg_alpha", "double", "~vfr_hud", "~wind_estimation", "~mission/reached", "~mission/waypoints", "~mission/pull", "~mission/push", "~mission/clear", "~mission/set_current", "~mission/pull_after_gcs", "bool", "tf/"], "package_code": ["roslaunch mavros px4.launch", "roslaunch mavros apm.launch", "usage: mavcmd [-h] [-n MAVROS_NS] [-v] [--wait]\n", "              {long,int,sethome,takeoff,land,takeoffcur,landcur,trigger_control}\n", "              ...\n", "\n", "Commad line tool for sending commands to MAVLink device.\n", "\n", "positional arguments:\n", "  {long,int,sethome,takeoff,land,takeoffcur,landcur,trigger_control}\n", "    long                Send any command (COMMAND_LONG)\n", "    int                 Send any command (COMMAND_INT)\n", "    sethome             Request change home position\n", "    takeoff             Request takeoff\n", "    land                Request land\n", "    takeoffcur          Request takeoff from current GPS coordinates\n", "    landcur             Request land on current GPS coordinates\n", "    trigger_control     Control onboard camera trigerring system (PX4)\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output\n", "  --wait                Wait for establishing FCU connection", "usage: mavftp [-h] [-n MAVROS_NS] [-v]\n", "              {cd,list,cat,remove,mkdir,rmdir,download,upload,verify,reset}\n", "              ...\n", "\n", "File manipulation tool for MAVLink-FTP.\n", "\n", "positional arguments:\n", "  {cd,list,cat,remove,mkdir,rmdir,download,upload,verify,reset}\n", "    cd                  change directory\n", "    list                list files and dirs\n", "    cat                 cat file\n", "    remove              remove file\n", "    mkdir               create direcotory\n", "    rmdir               remove directory\n", "    download            download file\n", "    upload              upload file\n", "    verify              verify files\n", "    reset               reset\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavparam [-h] [-n MAVROS_NS] [-v] {load,dump,get,set} ...\n", "\n", "Commad line tool for getting, setting, parameters from MAVLink device.\n", "\n", "positional arguments:\n", "  {load,dump,get,set}\n", "    load                load parameters from file\n", "    dump                dump parameters to file\n", "    get                 get parameter\n", "    set                 set parameter\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavsafety [-h] [-n MAVROS_NS] [-v] {arm,disarm,safetyarea} ...\n", "\n", "Commad line tool for manipulating safty on MAVLink device.\n", "\n", "positional arguments:\n", "  {arm,disarm,safetyarea}\n", "    arm                 Arm motors\n", "    disarm              Disarm motors\n", "    safetyarea          Send safety area\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output", "usage: mavsetp [-h] [-n MAVROS_NS] [-V] {local} ...\n", "\n", "Commad line tool for control the device by setpoints.\n", "\n", "positional arguments:\n", "  {local}\n", "    local               Send local setpoint\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -V, --verbose         verbose output", "usage: mavsys [-h] [-n MAVROS_NS] [-v] [--wait] {mode,rate} ...\n", "\n", "Change mode and rate on MAVLink device.\n", "\n", "positional arguments:\n", "  {mode,rate}\n", "    mode                Set mode\n", "    rate                Set stream rate\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output\n", "  --wait                Wait for establishing FCU connection", "usage: mavwp [-h] [-n MAVROS_NS] [-v]\n", "             {show,load,pull,dump,clear,setcur,goto} ...\n", "\n", "Commad line tool for manipulating mission on MAVLink device.\n", "\n", "positional arguments:\n", "  {show,load,pull,dump,clear,setcur,goto}\n", "    show                Show waypoints\n", "    load                load waypoints from file\n", "    pull                pull waypoints from FCU\n", "    dump                dump waypoints to file\n", "    clear               clear waypoints on device\n", "    setcur              set current waypoints on device\n", "    goto                send goto waypoint (APM only)\n", "\n", "optional arguments:\n", "  -h, --help            show this help message and exit\n", "  -n MAVROS_NS, --mavros-ns MAVROS_NS\n", "                        ROS node namespace\n", "  -v, --verbose         verbose output"]}
,{"url": "https://wiki.ros.org/m4atx_battery_monitor", "package": "m4atx_battery_monitor", "package_summary": ["Battery Monitor for the M4-ATX Power Module"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "The ", " package will read the information from a m4atx battery supply and publish it as a ros message. ", "Locate the bus and device number of the device called \"", " Technology, Inc.\". ", "To install the ", " package, you can choose to either install from source, or from the Ubuntu package: ", "The ", " package contains a ", " file. This file launches an instance of the ", ". To launch these nodes the following command can be used: ", "Please send bug reports to the ", ". Feel free to contact me at any point with questions and comments.  "], "package_tt": ["m4atx_battery_monitor", "m4atx_battery_monitor_node", "battery_status_m4atx", "~diag_frequency", "~input_nominal", "~battery_dead_voltage", "m4atx_battery_monitor", "ros_ethernet_rmp", "m4atx-battery-monitor.launch", "m4atx_battery_monitor_node"], "package_code": ["lsusb ", "sudo chmod a+rw /dev/bus/usb/<bus_num>/<device_num>", "\n", "\n", "\n", "\n", "\n", "sudo apt-get install ros-indigo-m4atx-battery-monitor", "roslaunch m4atx_battery_monitor_node m4atx_battery_monitor_node.launch "]}
,{"url": "https://wiki.ros.org/maggie_labjack", "package": "maggie_labjack", "package_summary": ["labjack node"], "package_details": ["\n", "\n", "\n", "\n", "\n", "\n", "This device supports all the drivers implemented in the ", " package. "], "package_tt": ["get_touch_sensors", "get_voltage", "is_plugged", "get_state", "set_state"], "package_code": [" $ roslaunch maggie_labjack labjack.launch robot:=maggie"]}
,{"url": "https://wiki.ros.org/ridgeback_msgs", "package": "ridgeback_msgs", "package_summary": ["Messages exclusive to Ridgeback, especially for representing low-level motor commands and sensors."], "package_details": ["\n", "\n", "These messages are the low-level interface between ", "'s ARM MCU and integrated PC. Most users of Ridgeback should be able to use standard ROS interfaces (eg. ", ", ", ") to command and monitor the robot. A possible exception is to programmatically monitor system state such as voltage, current, battery, faults, etc. "]}
,{"url": "https://wiki.ros.org/simple_arm", "package": "simple_arm", "package_summary": ["Simple velocity controlled arm. Teleoperation software and firmware."], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "\n", " ", "\n", " Caution! This software does not stop moving the robot if no messages are received for certain period of time. A pull request for this is very welcome. ", "\n", " We like PlatformIO: \"Single source code. Multiple platforms.\" PlatformIO supports approximately 200", " and all major", ". Learn more on", ". ", "\n", " ", " ", " ", " ", " ", " ", " ", "\n", "A simple arm system. ", ": ", "This package ", ": ", "This diagram is also available in ", ". ", "Package created by Ryerson University students for the ", ", summer 2017. ", "3. Install the ", " onto a microcontroller connected to the arm joint motors by PWM. The microcontroller must also be connected to the computer running the simple_arm ROS node by a serial connection (ex. USB). ", "This node converts ", " messages from the ", " node into a variety of commands that are sent over serial to a microcontroller to drive the robot arm. ", "This node communicates with the ", " using a simple serial protocol. Each serial motion command is a list of floats, one for each joint. ", "The ", " microcontroller code does the minimum amount of work possible to receive motor commands from a USB serial connection and output voltages to digital PWM output to be received by motor controllers. ", "We deploy the ", " to an Arduino microcontroller using PlatformIO. ", "More PlatformIO install info: ", " ", "More PlatformIO info: ", " ", "Feature requests, bug reports, and contributions are welcome at ", ". "], "package_tt": ["joy_arm", "~microcontroller_serial_device", "string", "~baudrate", "int", "arm_firmware", "arm_firmware"], "package_code": ["$ sudo apt-get install ros-kinetic-simple-arm", "$ roslaunch simple_arm simple_arm.launch joystick_serial_dev:=/dev/input/js0 microcontroller_serial_dev:=/dev/ttyACM0", "(FLOAT) GRIP,\n", "(FLOAT) WRIST_ROLL,\n", "(FLOAT) WRIST_PITCH,\n", "(FLOAT) UPPER_ELBOW,\n", "(FLOAT) LOWER_ELBOW,\n", "(FLOAT) BASE_YAW,\n", "(FLOAT) CAMERA", "$ sudo python -c \"$(curl -fsSL https://raw.githubusercontent.com/platformio/platformio/master/scripts/get-platformio.py)\"\n", "\n", "# Enable Access to Serial Ports (USB/UART)\n", "$ sudo usermod -a -G dialout <your username here>\n", "$ curl\u00a0https://raw.githubusercontent.com/platformio/platformio/develop/scripts/99-platformio-udev.rules\u00a0\u00a0> /etc/udev/rules.d/99-platformio-udev.rules\n", "# After this file is installed, physically unplug and reconnect your board.\n", "$ sudo service udev restart", "$ roscd simple_arm\n", "$ cd ./arm_firmware/\n", "# Find the microcontroller that you have in the list of PlatformIO boards\n", "$ pio boards | grep -i mega2560\n", "# Use the name of your board to initialize your project\n", "$ pio init --board megaatmega2560", "$ vim src/main.cpp +9", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "$ vim src/main.cpp +4", "\n", "\n", "\n", "\n", "\n", "$ pio run --target upload"]}
,{"url": "https://wiki.ros.org/simple_drive", "package": "simple_drive", "package_summary": ["A simple robot drive system that includes skid steering joystick teleoperation, control of a panning servo to look around the robot, and Arduino firmware."], "package_details": ["\n", " ", "\n ", " ", "\n", "\n", "\n", " ", "\n", "\n", "\n", "\n", "\n", " If your microcontroller supports subscribing to ROS ", " messages (Arduinos can use ", ") then it would be simpler to do that and skip this node. However, this node is written in python so you could more easily add complex functionality in python and then in your microcontroller do the minimum amount of work necessary. ", "\n", "\n", " Caution! This software does not stop moving the robot if no messages are received for certain period of time. A pull request for this is very welcome. ", "\n", " We like PlatformIO: \"Single source code. Multiple platforms.\" PlatformIO supports approximately 200", " and all major", ". Learn more on", ". ", "\n", " ", " ", " ", " ", " ", " ", " ", "\n", "\n", "\n", "\n", " ", " - Differential drive software with support for a velocity PID target, a small GUI to control the robot, and more. ", " - Differential drive software that is real-time safe, integrates with ", ", and more. ", " ", " - This teleop node converts joy messages to twist messages. ", " - This teleop node takes joy messages and publishes topics or calls actions according a configuration file. ", " ", " - Multiplex several velocity command topics with prioritization or disabling according to a configuration file. ", "\n", "A simple robot drive system. ", ": ", "This package ", ": ", "Package created by Ryerson University students for the ", ", summer 2017. ", "3. Install the ", " onto a microcontroller connected to motors and wheels by PWM. The microcontroller must also be connected to the computer running the simple_drive ROS node by a serial connection (ex. USB). ", "This diagram is also available in ", ". ", "This node converts ", " messages from the ", " node into a variety of commands to drive the robot at low, medium, and high speed, look around with a servo, and cancel move_base goals at any moment. This node simply sends commands to other nodes. Typically the servo is used to move a camera so that the teleoperator can look around the robot. ", "The ", " node receives movement commands on two ", " topics, one for teleoperation and one for autonomous control, typically ", ". Movement commands are multiplexed to a final topic for robot consumption. If any teleoperation command is received autonomous commands are blocked for a set time defined by the ", " parameter. ", "This node communicates with the ", " using a custom serial protocol described below. An example serial data packet could be 0,0.5,0.5 which would mean drive motors forward at half speed and rotate at half speed.   ", "The ", " microcontroller code does the minimum amount of work possible to receive motor commands from a USB serial connection and output voltages to digital PWM output to be received by motor controllers.  ", "We deploy the ", " to an Arduino microcontroller using PlatformIO. ", "More PlatformIO install info: ", " ", "More PlatformIO info: ", " ", "When a left and right joystick inputs are received by the ", " node, representing left and right wheel velocities (ie. skid steering or differential drive), a ", " with linear and rotational velocities is calculated as: ", "When a ", " containing linear and rotational velocities is received by the ", ", wheel velocities are calculated as: ", "Feature requests, bug reports, and contributions are welcome at ", ". "], "package_tt": ["joy", "teleop/cmd_vel", "servo_pos", "~servo_pan_speed", "int", "~servo_pan_max", "int", "~servo_pan_min", "int", "cmd_vel_mux", "block_duration", "teleop/cmd_vel", "move_base/cmd_vel", "cmd_vel", "block_duration", "~block_duration", "int", "(BYTE)\u00a00,\u00a0(FLOAT)\u00a0LINEAR_VELOCITY,\u00a0(FLOAT)\u00a0ANGULAR_VELOCITY", "(BYTE)\u00a02,\u00a0(FLOAT)\u00a0SERVO_ANGLE", "twist", "cmd_vel", "servo_pos", "~serial_dev", "string", "~baudrate", "int", "drive_firmware", "drive_firmware", "(left_speed\u00a0+\u00a0right_speed)\u00a0/\u00a02.0", "(right_speed\u00a0-\u00a0left_speed)\u00a0/\u00a02.0", "linear_speed\u00a0+\u00a0angular_speed", "linear_speed\u00a0-\u00a0angular_speed"], "package_code": ["$ sudo apt-get install ros-kinetic-simple-drive", "$ roslaunch simple_drive drive_teleop.launch joy_dev:=/dev/input/js0\n", "$ roslaunch simple_drive cmd_vel_mux.launch\n", "$ roslaunch simple_drive simple_drive.launch serial_dev:=/dev/ttyACM0\n", "\n", "OR all-in-one launch:\n", "$ roslaunch simple_drive drive.launch", "$ roslaunch simple_drive drive_teleop.launch joy_dev:=/dev/input/js0", "$ roslaunch simple_drive cmd_vel_mux.launch", "$ roslaunch simple_drive simple_drive.launch serial_dev:=/dev/ttyACM0", "$ sudo python -c \"$(curl -fsSL https://raw.githubusercontent.com/platformio/platformio/master/scripts/get-platformio.py)\"\n", "\n", "# Enable Access to Serial Ports (USB/UART)\n", "$ sudo usermod -a -G dialout <your username here>\n", "$ curl\u00a0https://raw.githubusercontent.com/platformio/platformio/develop/scripts/99-platformio-udev.rules\u00a0\u00a0> /etc/udev/rules.d/99-platformio-udev.rules\n", "# After this file is installed, physically unplug and reconnect your board.\n", "$ sudo service udev restart", "$ roscd simple_drive\n", "$ cd ./drive_firmware/\n", "# Find the microcontroller that you have in the list of PlatformIO boards\n", "$ pio boards | grep -i mega2560\n", "# Use the name of your board to initialize your project\n", "$ pio init --board megaatmega2560", "$ vim src/main.cpp +4", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "$ vim src/main.cpp +17", "\n", "\n", "\n", "\n", "\n", "$ pio run --target upload"]}
,{"url": "https://wiki.ros.org/naoqi_pose", "package": "naoqi_pose", "package_summary": ["\n          This package contains nodes for managing Nao's poses.\n    "], "package_details": ["\n", "\n"], "package_tt": ["body_pose", "joint_trajectory", "~xap", "string", "~poses", "list", "joint_angles_action/goal", "joint_trajectory/goal", "joint_stiffness_trajectory/goal", "body_pose_naoqi/goal", "joint_angles", "joint_stiffness", "body_stiffness/disable", "body_stiffness/enable", "rest", "wakeup", "~poll_rate", "float", "~init_stiffness"]}
,{"url": "https://wiki.ros.org/rosserial_embeddedlinux", "package": "rosserial_embeddedlinux", "package_summary": ["rosserial for embedded Linux enviroments"], "package_details": ["\n", " ", "\n", "\n", "\n", "\n", "There are a variety of great embedded linux systems on the market today which enable quickly and easily programming hardware. Some, like the ", " support an entire electro-mechanical robotics platform. Others, like the Chumby alarm clock or WRT54-class routers provide just an inexpensive linux controller. This class of device typically supports USB and wifi, has USB drivers for webcam and USB-serial dongles, is physically small, and consumes under 10 watts of electrical power. This makes them expandable and interesting for use on smaller robots, especially when vision is desired.  ", "Using the ", " package, you can use ROS directly with the these systems. ", " provides a ROS communication protocol that works over your embedded linux system's serial UART, or its wifi or network connection. It allows your embedded linux system to run linux processes that are full fledged ROS nodes that can directly publish and subscribe to ROS topics, advertise services and request services, publish TF transforms, and get the ROS system time over any of the supported connection types. ", "The ", " package supports the following major connection types and capabilities: ", "This package contains embedded-linux-specific extensions required to run ", " on a small embedded linux system such as the VEXPro controller, Chumby alarm clock, WRT54GL router, Raspberry Pi, or many similar devices. It is meant to demonstrate how easy it is to integrate custom hardware and cheap sensors including USB cameras into your ROS project using an embedded linux system. The Tutorials of this package will walk you through setting up your run environment and creating a few example programs.  ", "Go to the ", " to learn how to install and use the package to connect your embedded linux system to ROS. ", "Please file new bugs on the project's ", ". The bugs listed below are the most serious, which you would want to be aware of when considering use of this technology. You are encouraged to contribute fixes. "]}]
