[{"title": "GNU C Compiler Warnings jenkis build.ros.org", "time": "2020-02-14 04:20:26 -0600", "post_content": [" ", " ", "I have a Warning when our package is build in Jenkins\n", "but the information about the warning is not helpful", "Please add a verbatim copy-paste of the warning to your question text."], "answer": [" ", " ", "resolve by adding this in CmakeList"], "answer_code": ["remove_definitions(-DDISABLE_LIBUSB-1.0)"], "url": "https://answers.ros.org/question/344125/gnu-c-compiler-warnings-jenkis-buildrosorg/"}
,{"title": "odometry dose not show in rviz", "time": "2020-02-13 21:49:01 -0600", "post_content": [" ", " ", "hello,", "I have a differential-drive robot, and sending odometry to ubuntu is done yesterday. I tried to have a look with rviz but failed and don't know why.\nIt simply follows the example codes and I choose \"odom\" as the fixed frame in rviz and add an odometry and attach \"odom\" as well as its topic but nothing comes out on the grid.\nOdometry info can be seen via rostopic echo /odom"], "answer": [" ", " ", "As you can see here (", ") odometry information is usually published as a transformation between the ", " and the ", " frame. So. when you set odom as fixed-frame, you should see the base_link frame moving, if your odometry info (dead-reckoning) changes. ", "Generally, I would suggest setting the fixed frame either to ", " (if your localization works) or to ", " (if you want to take the perspective of the robot, or your localization is not running)", "See also ", " for an explanation."], "answer_code": ["odom", "base_link", "map", "base_link"], "url": "https://answers.ros.org/question/344094/odometry-dose-not-show-in-rviz/"}
,{"title": "How can i use ROS_INFO to show \"graph\" and \"initialEstimate\"?", "time": "2020-02-13 16:48:12 -0600", "post_content": [" ", " ", " ", " ", "the c++ code like this.", "Values initial;", "if i use print", "the result looks like this", "Factor Graph: size: 3", "Factor 0: PriorFactor on 1   prior\n  mean: (0, 0, 0)   noise model:\n  diagonal sigmas[0.3; 0.3; 0.1];", "Factor 1: BetweenFactor(1,2) ", "\n  measured: (2, 0, 0)   noise model:\n  diagonal sigmas[0.2; 0.2; 0.1];", "Factor 2: BetweenFactor(2,3) ", "\n  measured: (2, 0, 0)   noise model:\n  diagonal sigmas[0.2; 0.2; 0.1];", "Initial Estimate: Values with 3\n  values: Value 1: (N5gtsam5Pose2E)\n  (0.5, 0, 0.2)", "Value 2: (N5gtsam5Pose2E) (2.3, 0.1,\n  -0.2)", "Value 3: (N5gtsam5Pose2E) (4.1, 0.1,\n  0.1)", "Final Result: Values with 3 values:\n  Value 1: (N5gtsam5Pose2E)\n  (7.46978322e-16, -5.34409103e-16,\n  -1.78381865e-16)", "Value 2: (N5gtsam5Pose2E) (2,\n  -1.09236637e-15, -2.48671183e-16)", "Value 3: (N5gtsam5Pose2E) (4,\n  -1.70076058e-15, -2.50943867e-16)", "How can i use ROS_INFO show the same things as mentioned above which was printed."], "answer": [], "question_code": ["NonlinearFactorGraph graph;\n\ngraph.emplace_shared<BetweenFactor<Pose2> >(1, 2, odometry, odometryNoise);\ngraph.emplace_shared<BetweenFactor<Pose2> >(2, 3, odometry, odometryNoise);\ngraph.print(\"\\nFactor Graph:\\n\");\n", " initial.insert(1, Pose2(0.5, 0.0, 0.2));\n initial.insert(2, Pose2(2.3, 0.1, -0.2));\n initial.insert(3, Pose2(4.1, 0.1, 0.1));\n initial.print(\"\\nInitial Estimate:\\n\");\n"], "url": "https://answers.ros.org/question/344079/how-can-i-use-ros_info-to-show-graph-and-initialestimate/"}
,{"title": "rosidl default generators CMake error", "time": "2020-02-14 05:09:56 -0600", "post_content": [" ", " ", " ", " ", "Hi,", "I want to build custom messages and services in ROS2 by using rosidl_generator", "However I get following CMake error", "I tried to install ROS2 by Debian Packages and by Source.\nI also checked if rosidl_default_generators is installed:", "What could be the problem ?", "Thanks", "package:", "CMakeList:", "A few things to clarify:"], "answer": [], "question_details": [" ", " ", " ", " ", " ", " ", " ", " ", "Can you please provide the full CMake output and not only the error message line", "You say your installed ROS from debian packages AND from source. Which one are you using for this build ? and how did you install it exactly (a link to a tutorials or a list of commands would be useful)?", "It looks like your packages are outdated, is there a reason for you not to upgrade all your ROS packages?", "You seem to be using CLion, do you have the same behavior if you try to build from the command line?", "Are you able to build official packages with custom messages, for example ", ", (make sure to use the dashing branch for the repositories you clone) or does that fail as well ?"], "question_code": [" find_package(rosidl_default_generators REQUIRED)\n", " CMake Error at /opt/clion-2019.2.4/bin/cmake/linux/share/cmake-3.15/Modules/FindPackageHandleStandardArgs.cmake:137 (message):\n Could NOT find FastRTPS (missing: FastRTPS_INCLUDE_DIR FastRTPS_LIBRARIES)\n", " apt list--installed | grep rosidl-default-generators\n\n ros-dashing-rosidl-default-generators/now 0.7.0-1bionic.20191016.185016 amd64 [installed,upgradable to: 0.7.0-1bionic.20191210.230356]\n", "<?xml version=\"1.0\"?>\n<?xml-model href=\"http://download.ros.org/schema/package_format3.xsd\" schematypens=\"http://www.w3.org/2001/XMLSchema\"?>\n<package format=\"3\">\n  <name>canopen</name>\n  <version>0.0.0</version>\n  <description>TODO: Package description</description>\n  <maintainer email=\"jens@todo.todo\">jens</maintainer>\n  <license>TODO: License declaration</license>\n\n  <buildtool_depend>ament_cmake</buildtool_depend>\n\n  <depend>rclcpp</depend>\n  <depend>std_srvs</depend>\n  <depend>std_msgs</depend>\n  <depend>canopen_msgs</depend>\n\n  <build_depend>builtin_interfaces</build_depend>\n  <build_depend>rosidl_default_generators</build_depend>\n  <exec_depend>builtin_interfaces</exec_depend>\n  <exec_depend>rosidl_default_runtime</exec_depend>\n\n  <member_of_group>rosidl_interface_packages</member_of_group>\n\n  <test_depend>ament_lint_auto</test_depend>\n  <test_depend>ament_lint_common</test_depend>\n\n  <export>\n    <build_type>ament_cmake</build_type>\n  </export>\n</package>\n", "cmake_minimum_required(VERSION 3.5)\nproject(canopen)\n\n# Default to C99\nif(NOT CMAKE_C_STANDARD)\n  set(CMAKE_C_STANDARD 99)\nendif()\n\n# Default to C++14\nif(NOT CMAKE_CXX_STANDARD)\n  set(CMAKE_CXX_STANDARD 14)\nendif()\n\nif(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\n  add_compile_options(-Wall -Wextra -Wpedantic)\nendif()\n\n\n# find dependencies\nfind_package(ament_cmake REQUIRED)\nfind_package(rclcpp REQUIRED)\nfind_package(std_msgs REQUIRED)\nfind_package(std_srvs REQUIRED)\nfind_package(builtin_interfaces REQUIRED)\nfind_package(rosidl_default_generators REQUIRED)\n\nrosidl_generate_interfaces(new_msg\n\"include/can_msgs/msg/Frame.msg\"\nDEPENDENCIES builtin_interfaces)\n\n\ninclude_directories(include)\nament_export_include_directories(include)\n\nadd_executable(pub src/main_pub.cpp)\nament_target_dependencies(pub rclcpp std_msgs std_srvs)\n\n\ninstall(TARGETS\n        pub\n        DESTINATION lib/${PROJECT_NAME}\n        )\n\nament_package()\n"], "url": "https://answers.ros.org/question/344133/rosidl-default-generators-cmake-error/"}
,{"title": "rospy unload to reconnect python node", "time": "2016-06-29 16:42:24 -0600", "post_content": [" ", " ", " ", " ", "Essentially what I need here is to reconnect a python node without restarting the process.\nIdeally this should work:", "It does not work, until the moment the only solution I found is restarting the process.\nMy current idea is that I could \"clean\" the internal state of rospy to \"mimic\" that \"process restarting\".", "However I do not find the way to execute the rospy.init_node a second time like it were a clean node initialization.", "I have tested several approaches:", "Using the rospy.shutdown_signal method", "using the python imp.reload method to reload the rospy package", "With these approaches I am able to execute again the rospy.init_node method without any error, however when I use some other method from rospy I get errors. For instance using rospy.set_param method I get this error:", "This is not supported. I've seen one or two other questions asking the same thing, and they've generally gone un-answered.", "I see. :-(", "Perhaps if you tell us why you think you \"have to relaunch a node without killing the whole process\", we could see whether there is an alternative approach that could work (just to avoid an xy-problem).", "Some years after, again with the same issue :-) the idea is essentially being able to reconnect without restarting the python process. I edited the question so the goals may be now clear.", "It would still help if you could tell us ", " you want to do this. You've only clarified ", " you want to do.", "In this case I have a graphic interface developed in pyside that is the main interface of the whole robotic system. It is GUI is designed to be used by non-expert people and it should be able to work standalone (ie: even without the rosmaster working or any network issue)", "Ignoring the question whether this is possible or not: ROS 1's networking code was (initially, and mostly) written with \"perfect networks\" in mind. Whether that is a valid assumption or not is a different question, but this means that dealing with lost connections is not something which is built-in at every level.", "There is also an (implicit) assumption about ", " and that restarting the node means restarting the process. In ROS 2, this is all different, but you appear to be using ROS 1.", "As such, I'm afraid this (ie: reinitialising a node) is simply not supported at the moment (or at least not with the regular ", ", ", " over the TCPROS and UDPROS transports).", "Using a transport or client library that does know how to deal with this may be a lot easier than trying to shoe-horn a solution on-top of ", ". One of the ...", "You could of course also try to track down where this error is being thrown. Could be it's a simple fix."], "answer": [], "question_code": ["#!/usr/bin/python\nimport rosgraph\nimport time\nimport os\nimport rospy\nimport std_msgs\n\nm = os.environ['ROS_MASTER_URI']\nfirstime = True\ndef msg_callback(msg):\n    rospy.loginfo(msg)\n\nwhile True:\n    connected = rosgraph.is_master_online(m)\n    time.sleep(1)\n    print(\"waiting master ...\")\n\n    if connected:\n        rospy.init_node(\"test_node\")\n        sub = rospy.Subscriber(\"/chatter\", std_msgs.msg.String, msg_callback)\n        r = rospy.Rate(1)\n        while not rospy.is_shutdown() and rosgraph.is_master_online(m):\n            rospy.loginfo(\"alive\")\n            r.sleep()\n\n    print(\"master lost ...\")\n", " rospy.set_param(\"myparamname\", myparamvalue)\n File \"/opt/ros/indigo/lib/python2.7/dist-packages/rospy/client.py\", line 502, in set_param\n_param_server[param_name] = param_value #MasterProxy does all the magic for us\nFile \"/opt/ros/indigo/lib/python2.7/dist-packages/rospy/msproxy.py\", line 148, in __setitem__\nself.target.setParam(rospy.names.get_caller_id(), rospy.names.resolve_name(key), val)\nFile \"/usr/lib/python2.7/xmlrpclib.py\", line 1224, in __call__\nreturn self.__send(self.__name, args)\nFile \"/usr/lib/python2.7/xmlrpclib.py\", line 1578, in __request\nverbose=self.__verbose\nFile \"/usr/lib/python2.7/xmlrpclib.py\", line 1264, in request\nreturn self.single_request(host, handler, request_body, verbose)\nFile \"/usr/lib/python2.7/xmlrpclib.py\", line 1292, in single_request\nself.send_content(h, request_body)\nFile \"/usr/lib/python2.7/xmlrpclib.py\", line 1439, in send_content\nconnection.endheaders(request_body)\nFile \"/usr/lib/python2.7/httplib.py\", line 958, in endheaders\nself._send_output(message_body)\nFile \"/usr/lib/python2.7/httplib.py\", line 818, in _send_output\nself.send(msg)\nFile \"/usr/lib/python2.7/httplib.py\", line 780, in send\nself.connect()\nFile \"/usr/lib/python2.7/httplib.py\", line 761, in connect\nself.timeout, self.source_address)\nFile \"/usr/lib/python2.7/socket.py\", line 571, in create_connection\nraise err\nerror: [Errno 97] Address family not supported by protocol\n", "process==single node", "rospy", "roscpp", "rospy"], "url": "https://answers.ros.org/question/238463/rospy-unload-to-reconnect-python-node/"}
,{"title": "Instructions to get traffic light detection working", "time": "2020-02-14 08:23:23 -0600", "post_content": [" ", " ", "Hi everyone, \nI'm using Autoware (version 1.12.0) with LGSVL (version 2020.01) on Ubuntu 16.04. I'm doing a set of tests to assure that I can stimulate the main functionalities of autoware, testing on the BorregasAve map (from LGSVL), downloaded from the ", " (commit 05658fee453454af1f9290e0a0f76d4f19d1bb89)", "Right now, I'm trying to make the traffic light detection work, but with no success so far. In fact, I'm not really aware of how does the traffic light works, or how should I set it up. By looking on available .launch files, I understood that I need to launch both:", "Which is within the my_detection.launch file I'm using. I thought with that we should start the appropriate modules for traffic light recognition. However, it (apparently) does not.  Camera data from LGSVL seems to be working properly, as I could set up the object detection with SSD. ", "As you can see in the image above, there is a traffic light in sight, but none is detected with the TrafficLightPlugin (RViz panel), neither tlr_result (or any other tlr topic) contains updated messages. Even though I manually drive the car nearer to the traffic light, there is still no detection. Was that expected?", "I went to the ", " after the README file, but there is only an explanation on using feat_proj_lanelet2 (which does not exist in my Autoware project, perhaps because it is version 1.12.0).", "Given that, I'd like to kindly ask you where can I find some sort of tutorial on setting up the traffic light detection. I know that there is also some detection based on neural networks, which is nice, but I'd like to have the vanilla version properly working before adding more complexity to the task.", "I thank you all in advance.\nCheers!"], "answer": [], "question_code": ["  <!-- traffic light recognition -->\n  <!-- feat_proj -->\n  <include file=\"$(find trafficlight_recognizer)/launch/feat_proj.launch\" />\n\n\n  <!-- region_tlr -->\n  <include file=\"$(find trafficlight_recognizer)/launch/traffic_light_recognition.launch\">\n    <arg name=\"light_src\" value=\"/traffic_signal_info\" />\n  </include>\n"], "url": "https://answers.ros.org/question/344145/instructions-to-get-traffic-light-detection-working/"}
,{"title": "How can I fix \"install joint_state_publisher\" error (it is installed already)?", "time": "2020-02-14 06:17:10 -0600", "post_content": [" ", " ", "I am new to ROS and learning URDF from ", " , I am at this ", " tutorial and facing an error that says \"you should install \"joint_state_publisher\" \" which is installed", "Please don't paraphrase or summarise errors.", "Add a verbatim copy of the entire error message (including a few lines before and after it) to your question.", "You can use the ", " button/link for that."], "answer": [" ", " ", "thanks, but I was making the mistake. joint_state_publisher_gui was not installed (I installed it now), and I was confusing it with joint_state_publisher.\nthanks again."], "question_code": ["edit"], "url": "https://answers.ros.org/question/344142/how-can-i-fix-install-joint_state_publisher-error-it-is-installed-already/"}
,{"title": "ros2 launch creates two nodes of same type", "time": "2020-02-14 06:11:18 -0600", "post_content": [" ", " ", "Hi,\nI am experiencing a weird behavior of the ", " command.", "Using following example launch file from the robot_localization packge:", "creates following output:", "Listing running nodes with ", " also shows me two ekf_nodes.", "The same happens with ros2 cartographer_ros node. ", "Any Idea why this is happening? I am able to launch other nodes without any problem."], "answer": [], "question_code": ["ros2 launch", "from launch import LaunchDescription\nfrom ament_index_python.packages import get_package_share_directory\nimport launch_ros.actions\nimport os\nimport yaml\nfrom launch.substitutions import EnvironmentVariable\nimport pathlib\nimport launch.actions\nfrom launch.actions import DeclareLaunchArgument\n\ndef generate_launch_description():\n    return LaunchDescription([\n        launch_ros.actions.Node(\n            package='robot_localization',\n            node_executable='ekf_node',\n            node_name='ekf_filter_node',\n            output='screen',\n            parameters=[os.path.join(get_package_share_directory(\"robot_localization\"), 'params', 'ekf.yaml')],\n           ),\n])\n", "$ ros2 launch robot_localization ekf.launch.py \n[INFO] [launch]: All log files can be found below /home/xxx/.ros/log/2020-02-14-12-59-00-118313-xxx-22388\n[INFO] [launch]: Default logging verbosity is set to INFO\n[INFO] [ekf_node-1]: process started with pid [22398]\n[ekf_node-1] [WARN] [rcl.logging_rosout]: Publisher already registered for provided node name. If this is due to multiple nodes with the same name then all logs for that logger name will go out over the existing publisher. As soon as any node with that name is destructed it will unregister the publisher, preventing any further logs for that name from being published on the rosout topic.\n[ekf_node-1] X acceleration is being measured from IMU; X velocity control input is disabled\n", "ros2 node list"], "url": "https://answers.ros.org/question/344141/ros2-launch-creates-two-nodes-of-same-type/"}
,{"title": "How to use robot_localization correctly?", "time": "2020-02-14 10:43:22 -0600", "post_content": [" ", " ", "Hi All,", "I would like to ask you opinions and best practices of using the ", " package for the following use case:", "I'm planning to fuse these two odometry sources with one ", " and use its output for the waypoint finding. I'm wondering if this is a viable approach to do this or there would be a better way?", "Many thanks,\nTam\u00e1s"], "answer": [], "question_details": [" ", " ", " ", " ", "The vehicle has two wheels (left and right), more accurately two tracks (a robotic vehicle for agriculture).", "Eventually I will have to achieve automatic GPS waypoint finding.", "The wheels have fairly accurate encoders, so I can measure travelled distance and speed of both left and right tracks, calculate and publish ", " messages from that with at least 10Hz.", "The vehicle is equipped with a navigational device which provides me GPS latitude, longitude and orientation (roll, pith, yaw) and speed. I can use these data to calculate and publish another ", " message. Latitude and longitude is updated with 1Hz, orientation is updated with 10Hz."], "question_code": ["robot_localization", "Odometry", "Odometry", "ekf_localization_node"], "url": "https://answers.ros.org/question/344152/how-to-use-robot_localization-correctly/"}
,{"title": "Anyone who've ever used openai_ros with gym?", "time": "2020-02-10 01:12:44 -0600", "post_content": [" ", " ", "Hello, I'm working with ROS kinetic on Ubuntu 16.04.", "I've finished installing Tensorflow and Keras with the Openai_ros package for the DRL frameworks.", "But it seems openai_ros needs the appropriate ", " module for a learning environment.", "I've simply thought that openai_ros package also includes the ", " module, but it was not; every time I declare gym like", "it brought  ", ".", "Is it necessary to install ", " module once more? ", "Honesty, I'm afraid I would make some mistake in installing it for some reason; whether it might spoil my work env, so I'm hesitating to install...", "If anyone who've ever used openai ", " with ROS, would you please give me helpful advice?", "Thanks in advance.\nThanks in advance."], "answer": [], "question_code": ["gym", "from gym import spaces\n", "ImportError", "gym", "gym"], "url": "https://answers.ros.org/question/343698/anyone-whove-ever-used-openai_ros-with-gym/"}
,{"title": "nav2_bt_navigator exception in callback", "time": "2020-02-13 09:33:20 -0600", "post_content": [" ", " ", "I'm trying to run bt_navigator but it is searching for a library that does not exist:", "The node is triggered by:", "Both ROS2 and navigation2 are installed via debian packages.", "That library doesn't exist anymore. It has been replaced by a number of other libraries - one per node. I expect you have a mismatch between the version of the nav2_bt_navigator and the version of the nav2_behavior_tree package.", "Can you provide the versions of the nav2 packages you have installed and your LD_LIBRARY_PATH?", "For the versions, provide the output of:", "dpkg -l | grep nav2", "And for LD_LIBRARY_PATH, just", "echo $LD_LIBRARY_PATH", "Version:", "LD_LIBRARY_PATH:", "The library in the error message (libnav2_behavior_tree_nodes.so) hasn't existed for a while. It shouldn't be possible to get that error message. Is it possible an older version of bt_navigator is actually running? After you run ", "Run", "This should show the path to the executable. It should be somewhere under /opt/ros/eloquent.", "Here the running processes:"], "answer": [" ", " ", " ", " ", "I just remembered where I'd seen this before. ", ".", "I think your problem is you aren't providing the plugin names as a parameter to bt_navigator. You need to set the plugin_lib_names parameter as is done here: ", "The simplest way to get this to work is to create a file (/tmp/bt_parms.yaml) that contains:", "And then run:", "I filed an issue against nav2 because this is pretty unwieldy for your use case, IMHO. The issue is ", "I followed exactly the instructions, but I got the same error.", "EDIT:", "It works.", "Thanks. I fixed the command line above.", "When you say \"It works\" do you mean your problem is solved now?", "Yes Carl! With this command and configuration runs correctly."], "question_code": ["lorenzoteo@lorenzoteo-HP-ZBook-15v-G5:~$ ros2 run nav2_bt_navigator bt_navigator bt_navigator.xml\n[INFO] [bt_navigator]: Creating\n[INFO] [bt_navigator]: Configuring\n[ERROR] []: Caught exception in callback for transition 10\n[ERROR] []: Original error: Could not load library: libnav2_behavior_tree_nodes.so: cannot open shared object file: No such file or directory\n[WARN] []: Error occurred while doing error handling.\n[FATAL] [bt_navigator]: Lifecycle node entered error state\n[WARN] [rcl_lifecycle]: No transition matching 3 found for current state unconfigured\n[ERROR] []: Unable to start transition 3 from current state unconfigured: Transition is not registered., at /tmp/binarydeb/ros-eloquent-rcl-lifecycle-0.8.4/src/rcl_lifecycle.c:327\n", "lorenzoteo@lorenzoteo-HP-ZBook-15v-G5:~$ ros2 run nav2_util lifecycle_bringup bt_navigator\n", "lorenzoteo@lorenzoteo-HP-ZBook-15v-G5:~$ dpkg -l | grep nav2\n....\nii  ros-eloquent-nav2-bt-navigator                      0.3.2-1bionic.20200121.234559                   amd64        TODO\n....\n", "lorenzoteo@lorenzoteo-HP-ZBook-15v-G5:~$ echo $LD_LIBRARY_PATH\n/opt/ros/eloquent/opt/yaml_cpp_vendor/lib:/opt/ros/eloquent/opt/rviz_ogre_vendor/lib:/opt/ros/eloquent/lib\n", "> ros2 run nav2_bt_navigator bt_navigator bt_navigator.xml\n", "> ps | grep bt_navigator\n", "lorenzoteo@lorenzoteo-HP-ZBook-15v-G5:~$ ps aux | grep bt_navigator\nlorenzo+ 24228  0.1  0.3 278148 61364 pts/1    S+   10:51   0:00 /usr/bin/python3 /opt/ros/eloquent/bin/ros2 run nav2_bt_navigator bt_navigator bt_navigator.xml\nlorenzo+ 24233  5.7  0.1 984248 24068 pts/1    Sl+  10:51   0:14 /opt/ros/eloquent/lib/nav2_bt_navigator/bt_navigator bt_navigator.xml\nlorenzo+ 24765  0.0  0.0  22132  1000 pts/0    S+   10:55   0:00 grep --color=auto bt_navigator\n"], "answer_code": ["bt_navigator:\n  ros__parameters:\n    bt_xml_filename: \"navigate_w_replanning_and_recovery.xml\"\n    plugin_lib_names:\n    - nav2_compute_path_to_pose_action_bt_node\n    - nav2_follow_path_action_bt_node\n    - nav2_back_up_action_bt_node\n    - nav2_spin_action_bt_node\n    - nav2_wait_action_bt_node\n    - nav2_clear_costmap_service_bt_node\n    - nav2_is_stuck_condition_bt_node\n    - nav2_goal_reached_condition_bt_node\n    - nav2_initial_pose_received_condition_bt_node\n    - nav2_reinitialize_global_localization_service_bt_node\n    - nav2_rate_controller_bt_node\n    - nav2_recovery_node_bt_node\n    - nav2_pipeline_sequence_bt_node\n    - nav2_round_robin_node_bt_node\n", "> ros2 run nav2_bt_navigator bt_navigator --ros-args --params-file /tmp/bt_params.yaml\n", "ros2 run nav2_bt_navigator bt_navigator --ros-args --params-file /tmp/bt_params.yaml\n"], "url": "https://answers.ros.org/question/344030/nav2_bt_navigator-exception-in-callback/"}
,{"title": "How can I publish I420 image data as sensor_msgs/Image? (Image transport plugin)", "time": "2020-02-11 14:18:54 -0600", "post_content": [" ", " ", "From gstreamer v4l2src plugin, I get gstreamer buffer data(I420).", "How can I publish it as sensor_msgs/Image? (Image transport plugin)", "So I have a pointer to data. I know Height and width of final image.\n", " (Just to indicate pixel arrangements, whole post in not important).", "Is it the correct way? Or first I have to convert image from I420 to BGR?"], "answer": [], "question_code": ["image_transport::Publisher pub = it.advertise(\"out_image_base_topic\", 1);\nmat = cv::Mat((height*3)/2, width, CV_8UC1, map.data);\nsensor_msgs::ImagePtr msg = cv_bridge::CvImage(std_msgs::Header(), \"i420\", mat).toImageMsg();\npub.publish(msg);\n", "cvtColor(mat, mat, CV_YUV2BGR_I420, 3);\n"], "url": "https://answers.ros.org/question/343864/how-can-i-publish-i420-image-data-as-sensor_msgsimage-image-transport-plugin/"}
,{"title": "Fixed frame [map] does not exist when using multiple physical Turtlebots", "time": "2020-02-13 13:00:43 -0600", "post_content": [" ", " ", " ", " ", "I have been trying to get 2 physical Turtlebot's using SLAM simultaneously. Working individually and with namespaces they work fine. However, when trying to get them to work at the same time, I am greeted with \"Fixed frame [map] does not exist' errors.", "I've been following these instructions in 15.5 except I am using TBOTA and TBOTB for the naming convention.\nI'm also not using the rviz command listed and am simply launching it and manually adding the items seen in the image.\n", "Here is the tf_tree", "Here is the node graph:", "Is there anything that stands out as far as not being configured correctly?", "Both the master PC and Turtlebots are running ROS 1 Kinetic", "Here is the tf_tree", "Actually, that is a ", " (ie: multiple, disconnected trees).", "And that is most likely your problem.", "I have fixed the tf graph, there are only 2 trees this time. The error remains the same and the node graph also remained the same. I can update the images on a bit.", "I have fixed the tf graph, there are only 2 trees this time.", "that's great, but RViz is most likely going to need only a single one. Otherwise it will not be able to calculate the relative transform between all the relevant frames (or actually: TF will not be able to do, which makes RViz unhappy).", "If you want to visualise data coming from multiple robots, you'll need to make sure the relative transform between all robots is known, or it will be impossible to determine ", " that data should be visualised.", "In the official instructions, they showed this being the tf_tree: ", "We also seem to have a similar use case outlined in the ROS FAQ: ", "We have tried launching all the required nodes without adding the prefixes before, but that had similar problems. Do you know the proper way we should approach this?", "Updated graphs are in the original post.", "It's perfectly fine to have several trees in a forest, but it will mean that RViz will not be able to visualise ", " data in your node graph, as that would depend on having a complete, single tree.", "Without checking the TB3 documentation, I believe there are two options:", "Yes, this is the part we are having trouble with. We don't care about it being visualized on the same window, just that it is receiving valid data. These errors prevent that.", "Edit: we can launch two instances of Rviz and set the map data to whichever namespace and prefixes we want, but following the instructions, the physical turtlebots don't work properly."], "answer": [], "question_details": [" ", " ", " ", " ", " ", " ", " ", " ", "accept you cannot visualise everything at the same time (ie: select one or the other ", " frame)", "add a second instance of the relevant RViz displays and make it listen to the topics for \"the other\" robot, while making sure to configure them to use the correct ", " as well"], "question_code": ["map", "tf_prefix", "while making sure to configure them to use the correct tf_prefix as well"], "url": "https://answers.ros.org/question/344055/fixed-frame-map-does-not-exist-when-using-multiple-physical-turtlebots/"}
,{"title": "Autoware runtime manager lidar_euclidean_cluster_detect clip_min_height parameter unable to take float values", "time": "2020-02-02 21:24:00 -0600", "post_content": [" ", " ", "In this commit: ", "\nthe value of v is changed from -1.3 to -5.", "In the Runtime Manager Dialog: ", "\nthe way a parameter is determined to be a float instead of an int is by checking whether one of the min, max, or v values is a float. If at least one of them is a float, then it'll be a float param which can receive float values from the user in the dialog box. Before the above commit, this would have worked, but now it's not working and I can't change the clip_min_height value without changing these files manually and rebuilding. In addition, even if I do change these values, they just reset every time I exit the docker container and re-enter. Is there a way to permanently fix these values on my end, or do I need to go in and change them and rebuild every time I re-enter the container?", "Either way, I just wanted to let you guys know of this issue. Thanks for your help."], "answer": [" ", " ", " Thanks for looking into the cause of this issue! This sounds like a great opportunity for your first contribution to a major open-source project! As for saving the files while exiting/entering the Docker container, I suggest using the \"base\" docker container for Autoware (which just has the Linux environment and all dependencies installed) instead of the \"full\" docker container for Autoware (which also includes the pre-built source code). Here are some instructions which I will add to the Docker section of the Wiki for using the \"base\" container:", "Create a workspace on your machine for working with the code.", "a. ", "b. ", "Clone the Docker repository.", "a. ", "b. ", "Use the ", " script to enter the ", " Docker container without Autoware.ai included, mounting the provided folder into the Docker container in the ", " folder.", "a. ", "Download and build the Autoware.ai source code inside the container.", "a. ", "b. ", " ", ": If you want to use a different version of Autoware than ", ", replace ", " in the URL above with the version (e.g. 1.13.0).", "c. ", "d. ", "After you have completed the above instructions, you will have a workspace on your host machine in ", " which has been built by ", " and can be modified without losing your changes. Using the above ", " command will also make that workspace available in the Docker container.", "If you want to make a Merge Request to fix this issue, ", " of the ", " repository on Gitlab. After that, delete the ", " folder in your workspace, edit ", " to have the ", " repository point to your fork, then run the ", " command again inside Docker. This will use your fork instead of the official one for the ", " repository. Once you have fixed the file and committed it to your fork, ", " back to the Autoware repository and the maintainers will review and merge it!", "Thank you so much for your detailed response. I just submitted a pull request, and I also set up Autoware using the base docker container and it all works perfectly. Thank you so much for your help!"], "answer_code": ["cd ~", "mkdir -p autoware.ai/src", "git clone https://gitlab.com/autowarefoundation/autoware.ai/docker", "cd docker/generic", "run.sh", "base", "/home/autoware/Autoware", "./run.sh -b $HOME/autoware.ai", "cd Autoware", "wget -O autoware.ai.repos \"https://gitlab.com/autowarefoundation/autoware.ai/autoware/raw/master/autoware.ai.repos?inline=false\"", "master", "master", "vcs import src < autoware.ai.repos", "colcon build", "$HOME/autoware.ai", "colcon", "./run.sh", "utilities", "autoware.ai/src/autoware/utilities", "autoware.ai.repos", "utilities", "vcs import", "utilities"], "url": "https://answers.ros.org/question/343129/autoware-runtime-manager-lidar_euclidean_cluster_detect-clip_min_height-parameter-unable-to-take-float-values/"}
,{"title": "QXcb connection XCB error 170", "time": "2018-05-25 04:04:25 -0600", "post_content": [" ", " ", " ", " ", "I'm running ROS Kinetic on unbuntu 16.04 on a windows 10 machine along with Xming.\nI've been trying the Moveit! tutorials but when i type: ", "the rviz logo flashes for less than a second then the window disappears.", "I'm getting an error which says ", ", but then it says you can start planning now! but no window appears.", "Please help.", "The ros beginner tutorials and turtlesim worked perfectly. So it's not a problem with Xming."], "answer": [" ", " ", " ", " ", "I found one possible cause/solution to this problem in this blog post: ", ". The problem was that the LIBGL_ALWAYS_INDIRECT flag was set to 1. As per the blog post:", "it is not possible to launch rviz when this indirection is active", "Setting it to 0 fixed the problem for me and allowed me to run rviz properly:", "You can check what it is currently set to using:", "It seems that every new WSL (I assume you are using WSL to run Linux/ROS on Windows) shell defaults this flag to 1. So you may need to add the export command to your ", " file.", "I should also mention that I do still see the error. The only difference is that with it set to 0, Rviz will actually launch.", " ", " ", "May not answer to the question directly though,"], "answer_details": [" ", " ", " ", " ", "I see ", " error, meaning the problem is related ", ". RViz is graphic instensive much more than other simpler GUI tools.\n", "I see you're on Windows. For Windows + X, ", " gives a good list of things to look at.", "Took a brief look at ", " (as I've seen multiple questions reporting similar issue with this package). So far I don't see anything particularly concerning regarding RViz operation.\n", "I've struggled a lot in using RViz over ", " in our product development. My conclusion so far is unfortunately I moved away from X and use something else (Remote Desktop etc.) to guarantee a consistent behavior.", " ", " ", " ", " "], "question_code": ["roslaunch panda_moveit_config demo.launch rviz_tutorial:=true\n", "QXcb connection XCB error 170"], "answer_code": ["export LIBGL_ALWAYS_INDIRECT=0\n", "echo $LIBGL_ALWAYS_INDIRECT\n", ".bashrc", "Qxcb", "X", "X"], "url": "https://answers.ros.org/question/292272/qxcb-connection-xcb-error-170/"}
,{"title": "Sensor fusion after intrinsic and extrinsic calibration - Autoware", "time": "2020-02-10 17:16:30 -0600", "post_content": [" ", " ", "Hello!  I am runing autoware v1.12 on nvidia jetson agx with jetpack 4.2. Currently am using live sensors VLP-16 lidar and FLIR ADK thermal camera. \nI was able to get the intrinsic and extrinsic calibration by following directions at: ", "However now, I do not know how to overlay data and get fusion. ", "I run the calibration publisher using the extrinsic yaml file and generic fields that autoware already has in target_frame, camera_frame, camera_info_topic_name etc  and it runs and exits out of the node - is that how it is supposed to be?", "I used Pixel-Cloud Fusion node (", ")  but it keeps on saying waiting for intrinsic file and the target frame does not exist. Am I supposed to do something else also? The Directions ask for \"rectified_image\" how am i to do that? ", "Following the steps from ", " at time 8:20, does not allow me to view both lidar and camera data, it only shows one or the other depending on which frame I pick i.e. velodyne or boson-camera, and then the camera feed does not have any overlay data either. ", "I would really appreciate if you could direct me of the next steps I could take in order to overlay the data of each sensor and get \"sensor fusion\". I am very new to this, but am trying to learn and properly document.", "Thank you!!"], "answer": [" ", " ", " The ", " node is the correct node for this function. You first need to use the ", " package to publish the camera calibration based on the lidar/camera calibration file that you created. Here is an example command to run the ", " using a launch file from ", ":", "In the above command, replace ", " with the TF frame that your camera publishes images in, replace ", " with the topic name of the raw image from your camera, replace ", " with the full path to your lidar/camera calibration file produced from the ", " YAML file, and replace ", " with the topic that you would like the ", " to publish the calibration info on.", "Once this is running, you can use the ", " file to launch both an ", " node (which will generate the rectified image topic) and the ", " node. You'll have to remap the topics in this launch file to the appropriate topics for your camera and calibration.", "Thanks alot!!!", " ", " ", " ", " ", "you need to follow traditional point-to pixel transform to project LIDAR points onto your RGB image. From there you may assign RGB values to point cloud and have point cloud with XYZRGB fields. After you are able to do this projection you can pretty much get all of the \"fusion\" tasks staright forward. Assuming the calibration parameters you got are right first you need to transform your point from LIDAR frame to Camera frame using extrinsic parameters and finally project this point in camera frame to image plane using intrinsic parameters. Now in code it will look something like below first know the sizes and types of you matrices, and then feed your calibration parameters into them", "And a function that takes in point cloud from your Lidar and results of matric multplication above; ", "You may use a function that look like in above to do the transform, I also listed the matrices that are going to be involved. so you can just feed your calibration results to them  and call the function. \nThe return of that function is a matrix of points with pixel coordinates of whole point cloud.  Remember that since you have 360 degrees cloud, not all projected points will make sense you may get some negative values as well, so you need to do a few checks to get the points that actually corresponds to image coordinates.  Assuming you used the above function somewhere in your code and now you have ", " returned,  you may use a for loop as below to do fusion; ", "I thought autoware would already have node that could do sensor fusion", "well they might but I am not sure", "even if they do, must be something that looks similar to what I just wrote :)", "Thank you!"], "answer_code": ["pixel_cloud_fusion", "calibration_publisher", "calibration_publisher", "runtime_manager", "\nroslaunch runtime_manager calibration_publisher.launch camera_frame:=/camera_frame image_topic_src:=/camera/image_raw file:=/path/to/your/lidar_camera_cal.yaml camera_info_topic:=/camera/camera_info\n", "/camera_frame", "/camera/image_raw", "/path/to/your/lidar_camera_cal.yaml", "autoware_camera_lidar_calibration", "/camera/camera_info", "calibration_publisher", "pixel_cloud_fusion.launch", "image_rectifier", "pixel_cloud_fusion", " //  camera projection matrix P\nEigen::MatrixXf TRANS_CAM_TO_IMAGE;\n//  lidar to cam transform matrix\nEigen::MatrixXf TRANS_LIDAR_TO_CAM;\nEigen::MatrixXf TRANS_LIDAR_TO_IMAGE;\n\nTRANS_CAM_TO_IMAGE = Eigen::MatrixXf::Zero(3, 4);\nTRANS_LIDAR_TO_CAM = Eigen::MatrixXf::Zero(4, 4);\n\nTRANS_CAM_TO_IMAGE << 612.3624267578125, 0.0, 422.271484375, 0.0, 0.0, 610.940185546875, 241.3871612548828,\n    0.0, 0.0, 0.0, 1.0, 0.0;\n\nTRANS_LIDAR_TO_CAM << 0.9999990463256836, -0.0005898026865907013, 0.0012526829959824681,\n    0.015111126005649567, 0.0005937033565714955, 0.9999949932098389, -0.003115807892754674, 0.00044604094000533223,\n    -0.0012508389772847295, 0.003116548527032137, 0.9999943375587463, -0.000181241164682433, 0, 0, 0, 1;\n\nTRANS_LIDAR_TO_IMAGE = TRANS_CAM_TO_IMAGE * TRANS_LIDAR_TO_CAM;\n", "Eigen::MatrixXf transformLidarToImage(pcl::PointCloud<pcl::PointXYZRGB>::Ptr in_cloud, Eigen::MatrixXf TRANS_LIDAR_TO_IMAGE)\n{\n    Eigen::MatrixXf matrix_lidar_points_in_lidar_frame = Eigen::MatrixXf::Zero(4, in_cloud->size());\n   // feed cloud points into a matrice\n    for (int i = 0; i < in_cloud->size(); ++i) {\n        matrix_lidar_points_in_lidar_frame(0, i) = in_cloud->points[i].x;\n        matrix_lidar_points_in_lidar_frame(1, i) = in_cloud->points[i].y;\n        matrix_lidar_points_in_lidar_frame(2, i) = in_cloud->points[i].z;\n        matrix_lidar_points_in_lidar_frame(3, i) = 1;\n    }\n\n    /*************** PROJECT POINT CLOUD TO IMAGE PPLANE  ****************/\n\n    Eigen::MatrixXf image_points = TRANS_LIDAR_TO_IMAGE * matrix_lidar_points_in_lidar_frame;\n    Eigen::MatrixXf uv = Eigen::MatrixXf::Zero(3, matrix_lidar_points_in_lidar_frame.cols());\n    uv.row(0) = image_points.row(0).array() / image_points.row(2).array();\n    uv.row(1) = image_points.row(1).array() / image_points.row(2).array();\n    uv.row(2) = image_points.row(2);\n    return uv;\n}\n", "uv", "pcl::PointCloud<pcl::PointXYZRGB>::Ptr fused_cloud(new pcl::PointCloud<pcl::PointXYZRGB>);\nfor (int m = 0; m < uv.cols(); m++) {\n    cv::Point point;\n    point.x = uv(0, m);\n    point.y = uv(1, m);\n\n    // Store corners in pixels only of they are on image plane\n    if (point.x > 0 && ..."], "url": "https://answers.ros.org/question/343755/sensor-fusion-after-intrinsic-and-extrinsic-calibration-autoware/"}
,{"title": "What is the proper way to call clear rosservice in rospy? [closed]", "time": "2020-02-11 22:45:28 -0600", "post_content": [" ", " ", "I have tried", "as well as what was posted here ", " but still cannot get it to work. The clear rosservice works fine from terminal."], "answer": [], "question_code": ["rospy.wait_for_service('clear')\nclear = rospy.ServiceProxy('clear', std_srvs/Empty)\n"], "url": "https://answers.ros.org/question/343875/what-is-the-proper-way-to-call-clear-rosservice-in-rospy/"}
,{"title": "use services defined in own package from outside catkin workplace", "time": "2020-02-11 23:19:29 -0600", "post_content": [" ", " ", "Hello everyone,", "I'm faced with CMake build/header include issue. I'm currently working in a code base that uses ROS, but not ROS exclusively but also other libraries and modules. The code is build using CMake, so the code structure looks like below:", "What I'm trying to do is to use the srv defined in", " in the code ", " outside catkin_ws. It also uses other libraries from outside the catkin workplace, and that's the reason it is outside catkin_ws. ", "I'm still a novice when it comes to CMake, and I've managed to make it work by using ", " after executing a ", ", but I'm aware that this is just a dirty trick and not a viable (long term) solution. So I was wondering If there's a better practice, or the correct way of doing it.", "Thanks in advance, and if the question need more detail I'll append it asap!"], "answer": [], "question_code": ["project/\n    catkin_ws/\n        src/\n            myPackage/\n                src/\n                    myServiceNode.cpp\n                srv/\n                    mysrv.srv\n                package.xml\n                CMakeLists.txt\n        CMakeLists.txt\n    src/ \n        myClientNodeOutside.cpp\n    CMakeLists.txt  \n    include/\n    other_libraries/\n", "mysrv.srv", "myClientNodeOutside.cpp", "target_include_directories(myClientNodeOutside PUBLIC ${CMAKE_CURRENT_SOURCE_DIR}/catkin_ws/install/include/)", "catkin_make install"], "url": "https://answers.ros.org/question/343876/use-services-defined-in-own-package-from-outside-catkin-workplace/"}
,{"title": "How to add external libraries to ROS cpp file?", "time": "2020-01-15 08:58:58 -0600", "post_content": [" ", " ", " ", " ", "Hello,", "Could someone explain the proper way how to link external libraries to ros cpp node in the cmake. For example I want to use libserial in my node to control the driver. Fro that I have installed the lib by using this commands:", "sudo apt install libserial-dev", "And now I have to link that lib in the cmake", "Thanks in advance!", "Maybe it's outdated but you could try this "], "answer": [" ", " ", " ", " ", "I want to answer my own question, to clarify which way I found and what is the proper as I consider. ", "Basically, you have to add folder with header files and the library itself. You can do it with find_package, or manually. ", "The header files you have to include in \"include_libraries\" like I did:", "include_directories(\n  ${catkin_INCLUDE_DIRS}\n  ${Qt5Core_INCLUDE_DIRS}\n  ${Qt5WebSockets_INCLUDE_DIRS}\n  /usr/include\n)", "And the library itself, you can add with \"target_link_libraries\", like this:", "add_executable(driver src/driver_node.cpp)\ntarget_link_libraries(driver ${catkin_LIBRARIES} ${CMAKE_THREAD_LIBS_INIT} /usr/lib/aarch64-linux-gnu/libserial.so)"], "url": "https://answers.ros.org/question/341788/how-to-add-external-libraries-to-ros-cpp-file/"}
,{"title": "TEB planner tuning help to follow a path strictly", "time": "2020-02-14 04:56:18 -0600", "post_content": [" ", " ", "So what I am trying to do, is let the robot follow a global path very strictly. ", "\nI know this path doesn't make sense, as it's not taking the shortest route, etc, but let's just say it's like a street the robot has to follow.  ", "My question is, if it is even possible to limit the planner in such a way, that it follows the path and doesn't take a shortcut. ", "\nI tried to enable via points and decreased the global plan lookahead but it doesn't affect planning at all.  ", "Also when looking at the second gif, the robot moves back to the beginning of the path. ", "\nBut for this case, I thought the planner is pruning the already passed global path with calling this function ", ", similar to dwb is doing it.", " ", " "], "answer": [" ", " ", "I think TEB is fundamentally the incorrect technology choice if you want exact waypoint following. Implementing something like a pure pursuit (or \"carrot\") controller would be your better bet. ", "Well that\u2018s true. Maybe strict and exact is too heavy, it should prefer aligning to the plan. We also have a pure pursuit controller, but next step was to take some constraints into account and thought about an mpc controller. And the teb planner feels a bit like a mpc controller, with added planner and obstacle avoidance which would also be a nice feature.\nReplanning the global plan will be difficult, as it\u2018s coming from a remote server.", "I don't think you're going to get that here. You should look at DWB for something like that. Just a note though, if you tune any controller to be a nearly exact path follower, its not going to be able to handle dynamic obstacles well (or at all in some cases) since you've trained it not to deviate from the path.", "I wouldn't consider that to be good behavior unless youre in a static environment, have a fast replanning rate, or need to navigate in very narrow places.", "Thanks, I get your point. Not exactly sure about the DWB, cause I think it\u2018s also a \u201ecost optimizer\u201c which is then tuned to follow the path. \nBut to some this up, it looks like I need two local controllers. A \u201edumb\u201c controller which just follows the path and just stops if there is an obstacle on the path. And a planning controller to drive around obstacles if the road is blocked or in complete autonomous situations.", "that sounds reasonable.", "If I've answered your question, can you hit the checkmark so its removed from our unanswered questions queue?"], "question_code": ["controller_frequency: 10.\ncontroller_plugin_ids: [\"FollowPath\"]\ncontroller_plugin_types: [\"teb_local_planner::TebLocalPlannerROS\"]\nmin_theta_velocity_threshold: 0.0001\nmin_x_velocity_threshold: 0.0001\nmin_y_velocity_threshold: 0.0001\nFollowPath.acc_lim_theta: 3.\nFollowPath.acc_lim_x: 2.\nFollowPath.acc_lim_y: 0.\nFollowPath.allow_init_with_backwards_motion: False\nFollowPath.cmd_angle_instead_rotvel: False\nFollowPath.complete_global_plan: True # true prevents the robot from ending the path early when it cross the end goal\nFollowPath.costmap_converter_plugin: \"costmap_converter::CostmapToPolygonsDBSMCCH\"\nFollowPath.costmap_converter_spin_thread: True\nFollowPath.costmap_obstacles_behind_robot_dist: 1.0\nFollowPath.delete_detours_backwards: True\nFollowPath.detours_orientation_tolerance: 1.5708\nFollowPath.dt_hysteresis: 0.05\nFollowPath.dt_ref: 0.3\nFollowPath.dynamic_obstacle_inflation_dist: 0.6\nFollowPath.enable_homotopy_class_planning: True\nFollowPath.enable_multithreading: True\nFollowPath.exact_arc_length: False\nFollowPath.feasibility_check_no_poses: 5\nFollowPath.footprint_model.radius: 0.6\nFollowPath.footprint_model.type: \"circular\"\nFollowPath.force_reinit_new_goal_dist: 1.\nFollowPath.free_goal_vel: False\nFollowPath.global_plan_overwrite_orientation: True\nFollowPath.global_plan_prune_distance: 2.0\nFollowPath.h_signature_prescaler: 1.\nFollowPath.h_signature_threshold: 0.1\nFollowPath.include_costmap_obstacles: True\nFollowPath.include_dynamic_obstacles: True\nFollowPath.inflation_dist: 0.1\nFollowPath.is_footprint_dynamic: False\nFollowPath.legacy_obstacle_association: False\nFollowPath.length_start_orientation_vector: 0.4\nFollowPath.map_frame: \"map\"\nFollowPath.max_global_plan_lookahead_dist: 0.5\nFollowPath.max_number_classes: 5\nFollowPath.max_ratio_detours_duration_best_duration: 3.\nFollowPath.max_samples: 20\nFollowPath.max_vel_theta: 1.\nFollowPath.max_vel_x: 1.3\nFollowPath.max_vel_x_backwards: 0.3\nFollowPath.max_vel_y: 0.0\nFollowPath.min_obstacle_dist: 0.1\nFollowPath.min_resolution_collision_check_angular: 3.14159\nFollowPath.min_samples: 3\nFollowPath.min_turning_radius: 0.0\nFollowPath.no_inner_iterations: 5\nFollowPath.no_outer_iterations: 4\nFollowPath.obstacle_association_cutoff_factor: 5.\nFollowPath.obstacle_association_force_inclusion_factor: 1.5\nFollowPath.obstacle_cost_exponent: 1.\nFollowPath.obstacle_heading_threshold: 0.45\nFollowPath.obstacle_keypoint_offset: 0.1\nFollowPath.obstacle_poses_affected: 25\nFollowPath.odom_topic: \"odom\"\nFollowPath.optimization_activate: True\nFollowPath.optimization_verbose: True\nFollowPath.oscillation_filter_duration: 10.\nFollowPath.oscillation_omega_eps: 0.1\nFollowPath.oscillation_recovery: True\nFollowPath.oscillation_recovery_min_duration: 10.\nFollowPath.oscillation_v_eps: 0.1\nFollowPath.penalty_epsilon: 0.1\nFollowPath.publish_feedback: False\nFollowPath.roadmap_graph_area_length_scale: 1.\nFollowPath.roadmap_graph_area_width: 2.\nFollowPath.roadmap_graph_samples: 15\nFollowPath.selection_alternative_time_cost: False\nFollowPath.selection_cost_hysteresis: 1.\nFollowPath.selection_obst_cost_scale: 100.\nFollowPath.selection_prefer_initial_plan: 0.95\nFollowPath.selection_viapoint_cost_scale: 1.\nFollowPath.shrink_horizon_backup: True\nFollowPath.shrink_horizon_min_duration: 10.\nFollowPath.simple_exploration: False\nFollowPath.switching_blocking_period: 0.\nFollowPath.teb_autosize: 1.\nFollowPath.global_plan_viapoint_sep: 1. # If positive, via-points are extracted from the global plan (path-following mode). The value determines the resolution of the reference path (min. separation between each two consecutive via-points along the global plan, if negative: disabled). Refer to parameter weight_viapoint for adjusting the intensity.\nFollowPath.via_points_ordered: True # If true, the planner adheres to the order of via-points in the storage container\nFollowPath.viapoints_all_candidates: True\nFollowPath.visualize_hc_graph: True\nFollowPath.visualize_with_time_as_z_axis_scale: 0.\nFollowPath.weight_acc_lim_theta: 1.\nFollowPath ..."], "url": "https://answers.ros.org/question/344130/teb-planner-tuning-help-to-follow-a-path-strictly/"}
,{"title": "Follow the straight global plan", "time": "2020-02-12 01:04:58 -0600", "post_content": [" ", " ", " ", " ", "Suppose I want to go to point B from A. Global plan initially publishes a straight plan. But whenever, a dynamic obstacle is in the path, DWA will try to drive around the obstacle. ", "However, I would want to stop for some time and then follow the initial global plan after the obstacle moves away from the plan. I've tried to play with ", ", ", " and other parameters with no success. Is there some straight-forward way to classify dynamic obstacle from the cost map, so I can send zero_velocity from DWA upon detecting one?", "Or do I have to write a custom local planner? If yes, could you guys point me towards something to achieve this functionality?", " question asks a similar question with no answer but some helpful comments.", " you've answered a similar question. Could you shed some light on this?", " could you please link to that specific answer (I don't know which one that was...) and detail why this doesn't answer your question or what the difference is to that question?", " see edit. My task is to align the local planner with the initial straight global plan, and if there were any obstacles, preferably stop the robot rather than moving around."], "answer": [" ", " ", "Is there some straight-forward way to classify dynamic obstacle from the cost map, so I can send zero_velocity from DWA upon detecting one?", "As I said in the question you link to: No (not to my knowledge, at least).", "Or do I have to write a custom local planner?", "You could try the ", " (following ", ") and check if this helps.", "If only following the global plan without obstacle avoidance, only waiting, is your only goal, I'd go for a custom planner. This could have a simple PD controller for path following and a little look-ahead stopping movement once it encounters an obstacle...", "thank you so much for your help. looks like implementing a PD controller is the best way for me.", "  thanks worked like a charm. Additionally, what could be the best way to detect an obstacle without implementing move_base?"], "question_code": ["goal_distance_bias", "path_distance_bias"], "answer_code": ["teb_local_planner"], "url": "https://answers.ros.org/question/343878/follow-the-straight-global-plan/"}
,{"title": "move_base does not update local_costmap", "time": "2020-01-02 08:23:54 -0600", "post_content": [" ", " ", " ", " ", "Hello,", "I have problem with ", " stack, ", " node in particular. I have launched everything and the robot is going to the goal, which I specified on rviz. AMCL localization is working and everything is good except 1 thing, the move_base node doesn't publish any data to local_costmap topic and the robot can't avoid new obstacles. ", "this is the output from ", "rosparam get /move_base", "Check whether transform is available from laser_frame to robot's base_link frame", " I have checked everything seems to be okay, I'll post the screenshot of tf tree soon"], "answer": [" ", " ", "It seems that the problem was in: \nmin_obstacle_height: 0.1\nmax_obstacle_height: 0.4", "As ", " mentioned.", "Now it is working))", " ", " ", " ", " ", "Two things to try in your costmap configs:", "Thank you for your answer. I want to ask, instead of using footprint, I am using:", "Is is okay? Or I have to use footprint", "And another question, do I need to write topic name with slash, or without. ", "here I add my yaml files separately:", "costmap_common_para.yaml:", "global_costmap.yaml:", "local_costmap.yaml:", "base_local_param.yaml:", " do you have any other idea?", "I would also check the following parameters in the ", " observation source", "It could be that your laser is mounted outside of this height window (with respect to the map frame's z-axis origin)", " Hi! Thank you for your comment, could you explain please what does it mean: could be mounted outside of this height window??", "My Laser scan frame is not on the same height with respect to the map. But it is mentioned in the tf tree.", "What I meant was if your laser is mounted say 0.5m from the ground (where z = 0), then the laser points would be filtered out and not included in the costmap.", " Yes, it is mounted 0.4m from ground, but I mentioned it in static conversion in TF. So, I can't understand how it can be filtered out.", "Could you explain?"], "answer_details": [" ", " ", " ", " ", " -> you haven't specified the robot footprint parameter in both the global and local costmaps. A simpler way is to list it in the common_costmap only (with the  appropriate footprint dimensions added). You can add the footprint as discussed in section 2.3.1 from the ", ".", " is defined three times: twice in the global costmap and once in the local costmap. In the two global costmap definitions it's given different parameters: the first time ", " subscribes to topic ", ", while the second time ", " subscribes to topic ", ". As above, I would remove all three definitions from the global and local costmaps and instead include a single definition in the common_costmap, where the topic subscribed to is  ", ".", " ", " ", " ", " "], "question_code": ["NavfnROS: {allow_unknown: true, default_tolerance: 0.1, planner_costmap_publish_frequency: 0.5,\n  planner_window_x: 0.0, planner_window_y: 0.0, visualize_potential: true}\nTrajectoryPlannerROS: {acc_lim_th: 3.5, acc_lim_theta: 1.0, acc_lim_x: 1.0, acc_lim_y: 1.0,\n  angular_sim_granularity: 0.05, controller_frequency: 5, dwa: true, escape_reset_dist: 0.1,\n  escape_reset_theta: 1.57079632679, escape_vel: -0.1064, gdist_scale: 0.8, global_frame_id: odom,\n  goal_distance_bias: 2.5, heading_lookahead: 0.325, heading_scoring: true, heading_scoring_timestep: 0.8,\n  holonomic_robot: false, latch_xy_goal_tolerance: true, max_rotational_vel: 1.0,\n  max_vel_theta: 1.0, max_vel_x: 1.0, meter_scoring: true, min_in_place_rotational_vel: 0.05,\n  min_in_place_vel_theta: 0.55, min_vel_theta: -1.0, min_vel_x: 0.2, occdist_scale: 0.1,\n  oscillation_reset_dist: 0.1, path_distance_bias: 0.5, pdist_scale: 0.6, planner_frequency: 0,\n  prune_plan: true, publish_cost_grid_pc: false, restore_defaults: false, sim_granularity: 0.25,\n\nsim_time: 4.0, simple_attractor: false, vtheta_samples: 40, vx_samples: 20, xy_goal_tolerance: 0.2,\ny_vels: '-0.3,-0.1,0.1,-0.3', yaw_goal_tolerance: 0.2}\naggressive_reset: {reset_distance: 1.84}\nbase_global_planner: navfn/NavfnROS\nbase_local_planner: base_local_planner/TrajectoryPlannerROS\nclearing_rotation_allowed: true\nconservative_reset: {reset_distance: 3.0}\nconservative_reset_dist: 2.0\ncontroller_frequency: 5.0\ncontroller_patience: 3.0\nglobal_costmap:\n  footprint: '[]'\n  footprint_padding: 0.01\n  global_frame: map\n  height: 10\n  inflation_layer: {cost_scaling_factor: 10.0, enabled: true, inflate_unknown: false,\n    inflation_radius: 0.4}\n  inflation_radius: 0.4\n  laser_scan_sensor: {clearing: true, data_type: LaserScan, marking: true, max_obstacle_height: 0.4,\n    min_obstacle_height: 0.1, sensor_frame: laser_frame, topic: scan}\n  observation_sources: laser_scan_sensor\n  obstacle_layer:\ncombination_method: 1\nenabled: true\nfootprint_clearing_enabled: true\n    laser_scan_sensor: {clearing: true, data_type: LaserScan, marking: true, max_obstacle_height: 0.4,\n      min_obstacle_height: 0.1, sensor_frame: laser_frame, topic: /scan}\n    max_obstacle_height: 2.0\n    observation_sources: laser_scan_sensor\n    obstacle_range: 2.5\n    raytrace_range: 3.0\n  obstacle_range: 2.5\n  origin_x: 0.0\n  origin_y: 0.0\n  plugins:\n    - {name: static_layer, type: 'costmap_2d::StaticLayer'}\n    - {name: obstacle_layer, type: 'costmap_2d::ObstacleLayer'}\n    - {name: inflation_layer, type: 'costmap_2d::InflationLayer'}\n  publish_frequency: 0.0\n  raytrace_range: 3.0\n  resolution: 0.05\n  robot_base_frame: base_footprint\n  robot_radius: 0.2\n  static_layer: {enabled: true}\n  static_map: true\n  transform_tolerance: 1.0\n  update_frequency: 3.0\n  width: 10\nlocal_costmap:\n  footprint: '[]'\n  footprint_padding: 0.01\n  global_frame: odom\n  height: 3\n  inflation_layer: {cost_scaling_factor: 10.0, enabled: true, inflate_unknown: false,\n    inflation_radius: 0.4}\n  inflation_radius: 0.4\n  laser_scan_sensor: {clearing: true, data_type: LaserScan, marking: true, max_obstacle_height: 0.4,\n    min_obstacle_height: 0.1, sensor_frame: laser_frame, topic: scan}\n  map_topic: map\n  map_type: costmap\n  observation_sources: laser_scan_sensor\n  obstacle_layer: {combination_method: 1, enabled: true, footprint_clearing_enabled: true,\n    mark_threshold: 0, max_obstacle_height: 2.0, origin_z: 0.0, unknown_threshold: 15,\n    z_resolution: 0.2, z_voxels: 10}\n  obstacle_range: 2.5\n  origin_x: 0.0\n  origin_y: 0.0\n  plugins:\n  - {name: obstacle_layer, type: 'costmap_2d::VoxelLayer'}\n  - {name: inflation_layer, type: 'costmap_2d::InflationLayer'}\n  publish_frequency: 2.0\n  raytrace_range: 3.0\n  resolution: 0.05\n  robot_base_frame: base_footprint\n  robot_radius: 0.2\n  rolling_window: true\n  static_map: false\n  transform_tolerance: 1.0\n  update_frequency: 5.0\n  width: 3\nmax_planning_retries: -1\noscillation_distance: 0.5\noscillation_timeout: 0.0\nplanner_frequency: 3.0\nplanner_patience: 5.0\nrecovery_behavior_enabled: true\nrecovery_behaviors:\n- {name: conservative_reset, type: clear_costmap_recovery/ClearCostmapRecovery}\n- {name: rotate_recovery1, type: rotate_recovery/RotateRecovery}\n- {name: aggressive_reset, type ..."], "answer_code": ["footprint: '[]'", "laser_scan_sensor", "sensor_frame", "scan", "sensor_frame", "\\scan", "\\scan", "robot_radius: 0.2\n", "/map or map\n", "obstacle_range: 2.0\nraytrace_range: 3.0\n#footprint: [[x0, y0], [x1, y1], ... [xn, yn]]\nrobot_radius: 0.2\n#ir_of_robot\ninflation_radius: 0.40\ntransform_tolerance: 1.0\n\nobservation_sources: laser_scan_sensor \n#point_cloud_sensor\n\n#laser_scan_sensor: {sensor_frame: laser_frame, data_type: LaserScan, topic: scan, marking: true, clearing: true}\n\nlaser_scan_sensor:\n  sensor_frame: laser_frame\n  data_type: LaserScan\n  topic: /scan\n  marking: true\n  clearing: true\n  marking: true\n  min_obstacle_height: 0.1\n  max_obstacle_height: 0.4\n\n#point_cloud_sensor: {sensor_frame: frame_name, data_type: PointCloud, topic: topic_name, marking: true, clearing: true}\n", "global_costmap:\n  global_frame: map\n  robot_base_frame: base_footprint\n  update_frequency: 5.0\n  static_map: true\n", "local_costmap:\n  global_frame: map\n  robot_base_frame: base_footprint\n  update_frequency: 1\n  publish_frequency: 2.0\n  static_map: false\n  rolling_window: true\n  width: 3.0\n  height: 3.0\n  resolution: 0.1\n  plugins:\n   - {name: obstacle_layer,      type: \"costmap_2d::VoxelLayer\"}\n   - {name: inflation_layer,     type: \"costmap_2d::InflationLayer\"}\n", "TrajectoryPlannerROS:\n  max_vel_x: 1.0\n  min_vel_x: 0.3\n  max_vel_theta: 1.0\n  min_in_place_vel_theta: 0.7\n\n  acc_lim_theta: 3.2\n  acc_lim_x: 2.5\n  acc_lim_y: 2.5\n\n# Goal Tolerance Parameters\n  xy_goal_tolerance: 0.5\n  yaw_goal_tolerance: 0.5\n\n  holonomic_robot: false\n", "laser_scan_sensor", "min_obstacle_height: 0.1\nmax_obstacle_height: 0.4\n"], "url": "https://answers.ros.org/question/340908/move_base-does-not-update-local_costmap/"}
,{"title": "laserscan_multi_merge", "time": "2020-02-12 03:01:23 -0600", "post_content": [" ", " ", "i want to know the two laser pointcloud how to fusing"], "answer": [], "url": "https://answers.ros.org/question/343894/laserscan_multi_merge/"}
,{"title": "MOVEIT GRASP COMPILATION ERROR", "time": "2020-02-14 14:28:23 -0600", "post_content": [" ", " ", "Hi everyone i'm traying to use this MOVEIT GRASP package ", ", but i have a compilation problem , i'm using kinetic branch and i followed all the steps to install it , but i had the below problem "], "answer": [], "question_code": ["Errors     << moveit_grasps:make /home/ixmatix-manuel/openDog_arm/logs/moveit_grasps/build.make.002.log\n/home/ixmatix-manuel/openDog_arm/src/moveit_grasps/src/grasp_data.cpp: In member function \u2018virtual bool moveit_grasps::GraspData::loadGraspData(const ros::NodeHandle&, const string&)\u2019:\n/home/ixmatix-manuel/openDog_arm/src/moveit_grasps/src/grasp_data.cpp:114:92: error: invalid initialization of non-const reference of type \u2018Eigen::Affine3d& {aka Eigen::Transform<double, 3, 2>&}\u2019 from an rvalue of type \u2018Eigen::Affine3d {aka Eigen::Transform<double, 3, 2>}\u2019\n     error += !rosparam_shortcuts::get(parent_name, child_nh, \"tcp_to_eef_mount_transform\", tcp_to_eef_mount_);\n                                                                                            ^\nIn file included from /usr/include/eigen3/Eigen/Geometry:44:0,\n             from /opt/ros/kinetic/include/moveit/robot_model/joint_model.h:47,\n             from /opt/ros/kinetic/include/moveit/robot_model/joint_model_group.h:41,\n             from /opt/ros/kinetic/include/moveit/robot_model/robot_model.h:47,\n             from /opt/ros/kinetic/include/moveit/robot_state/robot_state.h:41,\n             from /home/ixmatix-manuel/openDog_arm/src/moveit_grasps/include/moveit_grasps/grasp_data.h:52,\n             from /home/ixmatix-manuel/openDog_arm/src/moveit_grasps/src/grasp_data.cpp:40:\n/usr/include/eigen3/Eigen/src/Geometry/Transform.h:320:10: note:   after user-defined conversion: Eigen::Transform<Scalar, Dim, Mode, _Options>::Transform(const Eigen::Transform<_Scalar, Dim, OtherMode, OtherOptions>&) [with int OtherMode = 1; int OtherOptions = 0; _Scalar = double; int _Dim = 3; int _Mode = 2; int _Options = 0]\n\n   inline Transform(const Transform<Scalar,Dim,OtherMode,OtherOptions>& other)\n          ^\nIn file included from /home/ixmatix-manuel/openDog_arm/src/moveit_grasps/src/grasp_data.cpp:51:0:\n/opt/ros/kinetic/include/rosparam_shortcuts/rosparam_shortcuts.h:93:6: note:   initializing argument 4 of \u2018bool rosparam_shortcuts::get(const string&, const ros::NodeHandle&, const string&, Eigen::Affine3d&)\u2019\n bool get(const std::string &parent_name, const ros::NodeHandle &nh, const std::string &param_name,\n      ^\nIn file included from /usr/include/eigen3/Eigen/Core:297:0,\n             from /usr/include/eigen3/Eigen/Geometry:11,\n             from /opt/ros/kinetic/include/moveit/robot_model/joint_model.h:47,\n             from /opt/ros/kinetic/include/moveit/robot_model/joint_model_group.h:41,\n             from /opt/ros/kinetic/include/moveit/robot_model/robot_model.h:47,\n             from /opt/ros/kinetic/include/moveit/robot_state/robot_state.h:41,\n             from /home/ixmatix-manuel/openDog_arm/src/moveit_grasps/include/moveit_grasps/grasp_data.h:52,\n             from /home/ixmatix-manuel/openDog_arm/src/moveit_grasps/src/grasp_data.cpp:40:\n/usr/include/eigen3/Eigen/src/Geometry/Transform.h: In instantiation of \u2018Eigen::Transform<Scalar, Dim, Mode, _Options>::Transform(const Eigen::Transform<_Scalar, Dim, OtherMode, OtherOptions>&) [with int OtherMode = 2; int OtherOptions = 0; _Scalar = double; int _Dim = 3; int _Mode = 1; int _Options = 0]\u2019:\n/home/ixmatix-manuel/openDog_arm/src/moveit_grasps/src/grasp_data.cpp:163:81:   required from here\n/usr/include/eigen3/Eigen/src/Core/util/StaticAssert.h:32:40: error: static assertion failed: \n\nYOU_PERFORMED_AN_INVALID_TRANSFORMATION_CONVERSION\n     #define EIGEN_STATIC_ASSERT(X,MSG) static_assert(X,#MSG);\n                                        ^\n/usr/include/eigen3/Eigen/src/Geometry/Transform.h:330:5: note: in expansion of macro \u2018EIGEN_STATIC_ASSERT\u2019\n     EIGEN_STATIC_ASSERT(EIGEN_IMPLIES(OtherMode==int(Affine)||OtherMode==int(AffineCompact), Mode!=int(Isometry)),\n     ^\nmake[2]: *** [CMakeFiles/moveit_grasps.dir/src/grasp_data.cpp.o] Error 1\nmake[2]: *** Waiting for unfinished jobs....\nmake[1 ..."], "url": "https://answers.ros.org/question/344179/moveit-grasp-compilation-error/"}
,{"title": "How do i use /compute_fk services offered by moveit_group in ROS?", "time": "2020-02-03 00:46:42 -0600", "post_content": [" ", " ", "I want to get the value of joints for a given end effector position and I saw /compute_IK being listed under ros service . can any give synatx on how to call the service ?"], "answer": [], "url": "https://answers.ros.org/question/343134/how-do-i-use-compute_fk-services-offered-by-moveit_group-in-ros/"}
,{"title": "depth from Intel realsense t265 as ROS topic", "time": "2020-02-03 01:15:35 -0600", "post_content": [" ", " ", "Is there any code that publishes depth from t265 with using only two fisheyes's images?", "I found ", " python script without ROS. ", "Maybe someone already wrote script that adds ROS in that script?", "It should be trivial to just modify that script to publish in the ", " loop and remove the openCV viewer code.", "what's better, using that script, or running rtabmap for stereo cameras?"], "answer": [], "question_code": ["while"], "url": "https://answers.ros.org/question/343136/depth-from-intel-realsense-t265-as-ros-topic/"}
,{"title": "Communication occurs only one way between devices", "time": "2019-08-26 05:08:38 -0600", "post_content": [" ", " ", " ", " ", "Hello,", "I am using the talker and listener nodes to check that the communication occurs between my raspberry pi and my system. I am running Kinetic in the system and using ubiquity robotics image in the RPi which has ROS pre-installed. I am only able to send data from the RPi to the system but not vice-versa. ", "Here are the setup lines in my .bashrc files:", "In System", "In RPi (Master)", "Here are my etc/hosts files", "In System", "In RPi", "I have also included the rqt_graphs.\nWhen i run talker on the Pi and listener on the system, i can echo the /chatter topic. But when I do the reverse, i cannot observe anything in the topic.", "This are the errors I get when i run roswtf", "When trying to communicate from the system to your raspberry, do you have a ", " running on the raspberry ?", "Yes, I do have a roscore running on the raspberry"], "answer": [" ", " ", "It was a firewall problem.", "Thanks guys.", " ", " ", " ", " ", "the ROS_HOSTNAME should not be the IP address. Use ROS_IP. The HOSTNAME would be the output from /etc/hostname of the machine. you would then set that in the /etc/hosts file on your laptop such as ", "172.20.10.9  \"whatever the RPi hostname is\"", "Hi, I have followed what you suggested. I found out the hostname of both the devices in /etc/hostname and changed the ROS_HOSTNAME in both. I have also edited the /etc/hosts file in both, RPi IP and hostname in system and system IP and hostname in RPI.", "There still seems to be the same problem, only one way communication.", "are you running the roscaore via a startup service or from a terminal launch file? You shouldn't have to use both ROS_HOSTNAME and ROS_IP; ", "What is showing for the server for \"started roslaunch server ", "\" ?", "I am using the roscore command in the terminal to run roscore. \nIt shows \"started roslaunch server ", "\"", "did you run sudo systemctl disable magni-base on the Pi image as per Ubiquity's site?  I have often found upstart ros jobs have different network settings than what is in your bashrc profile. You could run journalctl -u magni-base to see if it is still running. At the top of the output would show what network settings it is using if it is still running. If it is still running then you could modify its startup setup or use robot_upstart to setup your own job with the network settings you describe. To test you can run sudo killall -9 roscore \"or rosmaster\" I forget which one and then manually launch on the Pi and then your system to verify your network settings."], "question_code": ["export ROS_IP=172.20.10.8\nexport ROS_HOSTNAME=172.20.10.8\nexport ROS_MASTER_URI=http://172.20.10.9:11311/\n", "export ROS_IP=172.20.10.9\nexport ROS_HOSTNAME=172.20.10.9\nexport ROS_MASTER_URI=http://172.20.10.9:11311/\n", "127.0.0.1   localhost\n127.0.1.1   01HW822483\n172.20.10.9     172.20.10.9\n172.20.10.8     172.20.10.8\n\n::1     ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\n172.20.10.9 172.20.10.9\n", "127.0.0.1         localhost\n::1                  localhost ip6-localhost ip6-lookback\nff02::1            ip6-allnodes\nff02::2            ip6-allrouters\n\n172.20.10.9   172.20.10.9\n172.20.10.8   172.20.10.8\n", "analyzing graph...\n... done analyzing graph\nrunning graph rules...\nERROR: Unknown host [my_robot.local] for node [/rosbridge_ws/rosbridge_websocket]\nERROR: Unknown host [my_robot.local] for node [/rosbridge_wss/rosbridge_websocket]\nERROR: Unknown host [my_robot.local] for node [/rosout]\nERROR: Unknown host [my_robot.local] for node [/teleop_twist_joy]\nERROR: connection refused to [http://172.20.10.9:45169/]\nERROR: Unknown host [my_robot.local] for node [/joint_state_publisher]\nERROR: Unknown host [my_robot.local] for node [/motor_node]\nERROR: Unknown host [my_robot.local] for node [/joy_node]\nERROR: Unknown host [my_robot.local] for node [/robot_state_publisher]\nERROR: Unknown host [my_robot.local] for node [/tf2_web_republisher]\nERROR: Unknown host [my_robot.local] for node [/rosbridge_wss/rosapi]\n", "roscore"], "url": "https://answers.ros.org/question/331574/communication-occurs-only-one-way-between-devices/"}
,{"title": "Callback of Subscriber as a Function of a Class isn't Called", "time": "2020-02-10 14:01:56 -0600", "post_content": [" ", " ", " ", " ", "Hi all, I was trying to make a class for my program handler including subscriber and publisher.\nBut I'm stuck since 2 weeks without no progress. Somehow the callback function isn't called...", "my ", "Some small detail:", "The output I get with rosrun is: ", "So, as I debuged the code and also with print message, I noticed that the function is called which prints", "but not the message ", "it jumps directly to publish topic. Means the callback function is not called.", "Please if anyone can help. Thank you guys.", "EDIT: header file", "Can you please publish content of ", " ? This will help debugging. I hit this sitation a few times in the past so I can take a quick look and try to run your example", "I include the header in the edited question.", "So I have solved the error in pointer. I used a variable in other class to store lidar points and with sensor_msgs::PointCloud2ConstPtr I couldn't just use ( new Pointcloud2).", "But it should be:", "But it still doesn't subscribe to the given topic.", "it jumps directly to publish topic. Means the callback function is not called.", "It is actually expected to have the message ", " right after ", ", when you define the subscriber you don't call the callback function so you don't have to expect ", ".", "Your question might be unclear about your issue : Do you have an issue because you expect to see ", " right after the definition of the subscriber or your callback is never called while data is published on ", " (meaning you have an output when using ", ") ?", "I have an input of the lidar running from other package and expect for the callback to be executed while the input is received.", "I have an input of the lidar running from other package", "Just to be sure : Do you actually have data received with ", " ?\nAlso, where do you set all the topic names ? And to which value ? Particularly ", ", are you sure  it's the same as the actual lidar topic ?"], "answer": [" ", " ", "The reason why your callback is not called is topic names mismatch. Let me explain. ", "Let's say your variable ", " contains value ", ". You probably expect to subscribe to the topic name ", ". However, in reality ROS subscribes to ", " because you pass ", " into ", " variable of the class constructor.", "This causes all subscriptions to have your node name in front of topic names.  See ", " for explanation", "So minimal way to fix it is to change ", " ", "to ", ";", "I just tested on my machine and it works.", "P.S. By the way, my usual practice is to pass two ", " variables into my constructors - one regular (i.e. without ", ") and one private", "Then I use regular handle for all of my publishers, subscribers and global parameters and I use private handle to get node's private parameters with ", " function"], "question_details": [" ", " ", " ", " ", " ", " ", "There is no error in compiling. ", "The topic that I want to subscribe is there", "The lidarSubscriber_ is declared (private/public, both doesnt work) in the class."], "question_code": ["#include <ros/ros.h>\n#include \"pointcloud_reader_handler.h\"\n\nint main(int argc, char **argv) {\n\nros::init(argc, argv, \"pointcloud_reader\");\nros::NodeHandle private_node_handle_(\"~\");\n// class object which handle the package\npointcloud_reader_handler myReaderHandle(private_node_handle_);\n\n// ros spin with the rate time\nros::Rate naptime(myReaderHandle.getNodeRate());\n\n// Main Loop\nwhile(ros::ok())\n{\n    myReaderHandle.run();\n    // sleep for given rate(time)\n    ros::spinOnce();\n    naptime.sleep();\n}\nreturn 0;\n }\n", "#include <ros/ros.h>\n#include \"pointcloud_reader_handler.h\"\n\n// Constructor\npointcloud_reader_handler::pointcloud_reader_handler(ros::NodeHandle &nodeHandle):\nnodeHandle_(nodeHandle) {\n    ROS_INFO(\"Construction Handle\");\n    loadParameters();\n    ROS_INFO(\"Subscribing topic starting\");\n    subscribeToTopics();\n    publishToTopics();\n}\n\n// Getters\nint pointcloud_reader_handler::getNodeRate() const {return node_rate_;}\n\n// Methods\nvoid pointcloud_reader_handler::loadParameters() {\n// add parameters from cfg file here\n}\n\nvoid pointcloud_reader_handler::subscribeToTopics() {\n    ROS_INFO(\"Subscribing topic\");\n    pointcloud_reader_handler::lidarSubscriber_ = nodeHandle_.subscribe<sensor_msgs::PointCloud2>\n    (lidar_input_topic_name_, input_message_queue_, \n    &pointcloud_reader_handler::lidarReadingCallback, this);\n    }\n\nvoid pointcloud_reader_handler::publishToTopics() {\n    ROS_INFO(\"publish to topics\");\n    lidarPublisher_ = nodeHandle_.advertise<sensor_msgs::PointCloud2>(lidar_cone_filter_topic_name_, output_filter_message_queue_);\n    detectionPublisher_ = nodeHandle_.advertise<fsd_common_msgs::Detection>(lidar_cone_detection_topic_name_, output_detection_message_queue_);\n    detectionLidarPublisher_ = nodeHandle_.advertise<sensor_msgs::PointCloud2>(lidar_cone_detection_pointcloud_topic_name_, output_detection_pointcloud_message_queue_);\n}\n\nvoid pointcloud_reader_handler::run() {\n     // do stuff here\n}\n\nvoid pointcloud_reader_handler::lidarReadingCallback(const sensor_msgs::PointCloud2ConstPtr& pointCloudMsg) {\n    ROS_INFO(\"Filtering Lidar Point Cloud\");\n    pointCloudPreProcessing_.updateInputCloud(pointCloudMsg);\n}\n", "[ INFO] [1581362020.241452441]: Construction Handle\n[ INFO] [1581362020.244867156]: Subscribing topic starting\n[ INFO] [1581362020.244876716]: Subscribing topic\n[ INFO] [1581362020.245867283]: publish to topics\nperception_lidar: /usr/include/boost/smart_ptr/shared_ptr.hpp:728: typename boost::detail::sp_dereference<T>::type boost::shared_ptr<T>::operator*() const [with T = const sensor_msgs::PointCloud2_<std::allocator<void> >; typename boost::detail::sp_dereference<T>::type = const sensor_msgs::PointCloud2_<std::allocator<void> >&]: Assertion `px != 0' failed.\n", "[ INFO] [1581362020.244876716]:0 Subscribing topic\n", "Filtering Lidar Point Cloud\n", "#ifndef SRC_POINTCLOUD_READER_HANDLER_H\n#define SRC_POINTCLOUD_READER_HANDLER_H\n\n#include \"PointCloudPreProcessing.h\"\n#include \"ObjectDetection.h\"\n#include <sensor_msgs/PointCloud2.h>\n\nclass pointcloud_reader_handler {\npublic:\n\n    // Constructor\n    pointcloud_reader_handler(ros::NodeHandle &nodeHandle);\n\n    // Getters\n    int getNodeRate() const;\n\n    // Methods\n    void loadParameters();\n    void subscribeToTopics();\n    void publishToTopics();\n    void run();\n    ros::Publisher lidarPublisher_;\n    ros::Subscriber lidarSubscriber_;\n\nprivate:\n    ros::NodeHandle nodeHandle_;\n    ros::Publisher detectionPublisher_;\n    ros::Publisher detectionLidarPublisher_;\n\n    void lidarReadingCallback(const sensor_msgs::PointCloud2ConstPtr& pointCloudMsg);\n\n    std::string lidar_input_topic_name_;\n    std::string lidar_cone_filter_topic_name_;\n    std::string lidar_cone_detection_topic_name_;\n    std::string lidar_cone_detection_pointcloud_topic_name_;\n    std::string frame_id_;\n\n   // some other variables\n\n    PointCloudPreProcessing pointCloudPreProcessing_;\n    sensor_msgs::PointCloud2Ptr points_filtered_;\n};\n\n#endif //SRC_POINTCLOUD_READER_HANDLER_H\n", "pointcloud_reader_handler.h", "sensor_msgs::PointCloud2ConstPtr point_cloud_input_ = boost::make_shared<const sensor_msgs::PointCloud2>();\n", "publish to topics", "Subscribing topic", "Filtering Lidar Point Cloud", "Filtering Lidar Point Cloud", "lidar_input_topic_name_", "rostopic echo", "rostopic echo", "lidar_input_topic_name_"], "answer_code": ["lidar_input_topic_name_", "echo", "/echo", "<your node name>/echo", "private_node_handle_(\"~\")", "nodeHandle_", "ros::NodeHandle private_node_handle_(\"~\");", "ros::NodeHandle private_node_handle_", "NodeHandle", "~", "<private nh>.param()"], "url": "https://answers.ros.org/question/343750/callback-of-subscriber-as-a-function-of-a-class-isnt-called/"}
,{"title": "how to stop publishing a specific topic", "time": "2020-02-03 02:26:46 -0600", "post_content": [" ", " ", "Hi, I'm new to ROS and c++, I'm using ROS kinetic running on ubuntu 16.04, I want to stop a topic completely in run time, I don't want the topic to be advertised. im using roscpp, Is there any API to do so? please help me", "Just to avoid an ", ", could you please add a sentence or two explaining why you want to do this?", "There could be a perfectly valid reason, but it would be good if you could tell us about your motivation.", "I'm writing a publisher node to publish camera image data on a topic, now if i unplug the camera, i want to stop that topic from being advertised."], "answer": [], "url": "https://answers.ros.org/question/343141/how-to-stop-publishing-a-specific-topic/"}
,{"title": "robot_localization imu only not publishing odometry/filtered", "time": "2020-02-03 02:51:38 -0600", "post_content": [" ", " ", "So I'm using Dr Robot's Jaguar 4x4 robot on Ubuntu 16.04 and Ros Kinetic.\nI want to use the robot for autonomous navigation.\nI'm currently using robot_localization package of ROS for localization. \nBut I've encountered into a problem. The robot only publishes IMU data so I'm using that ekf_localization_node using only imu to give odometry/filtered but it's not working. I have gps data and I want to use navsat_transform with the robot to work path planners.\nBoth the gps and imu data are in REP-103 and REP-105 format.", "I'm not getting any messages from either odometry/filtered and odometry/gps. Any help would be greatly appreciated for this.\nI have tried going through the documentation and couldn't find anything else. I want to just use my IMU and GPS for localization. ", "Here's my file ekf.yaml for the ekf parameters", "And here's my nav.yaml for navsat parameters:", "Any help in it would be greatly appreciated.", "I would suggest to look at some example projects that use robot_localization like ", " for example. Also read the documentation of ", ".  ", "if you configure an imu0 in your config it expects a ", " type topic as input. I doubt that ", " in your config points to the right topic, it would more likely be something like ", " . Same for the gps0, which expects ", " and would usually be something like ", ". ", "Also there is no apparent good reason to have these two sensor configs in separate files. ", "If you want more help add the output of ", ", ", " and ", " while everything is launched to the question. Also add rosnode info from the node that is publishing your imu data and gps.", "Hey I wrote all of the messages from the robot as it didn't follow standard REP conventions. So it points to the right topic . I'm enclosing the output of rosnode and rostopic in a text file."], "answer": [], "question_code": ["frequency: 50\nsensor_timeout: 0.1\ntwo_d_mode: true\ntransform_time_offset: 0.0\ntransform_timeout: 0.0\nprint_diagnostics: true\ndebug: false\n\nmap_frame: map\nbase_link_frame: base_link\n\nimu0: /imu\nimu0_config: [false, false, false,\n              false,  false,  true,\n              false, false, false,\n              false,  false,  false]\nimu0_nodelay: false\nimu0_differential: false\nimu0_relative: false\nimu0_queue_size: 10\nuse_control: false\n", "frequency: 50\ndelay: 0\nzero_altitude: 0\npublish_filtered_gps: true\nbroadcast_utm_transform: true\nimu0: /imu\nodom0: /odometry/filtered\ngps0: /gpu\n", "sensor_msgs/Imu", "imu0: /imu", "imu0: /imu/data", "sensor_msgs/NavSatFix", "gps0: /imu/fix", "rosnode list", "rosnode info ekf_localization", "rostopic list"], "url": "https://answers.ros.org/question/343147/robot_localization-imu-only-not-publishing-odometryfiltered/"}
,{"title": "Is ROS only for Computer Scientists?", "time": "2011-02-15 11:12:45 -0600", "post_content": [" ", " ", " ", " ", "I see ROS is being used by several top-level universities.", "Do I have to be a computer scientist to use ROS?", "I'm a mechanical engineer and I use ROS everyday at work and even use it at home for hobbies. I think I learned C++ because of ROS! (I use to only use Matlab)."], "answer": [" ", " ", "While ROS is used in many research laboratories and universities, you don't have to be an academic to use it.", "I would say as a general guide, you will want to have some background in the following.", "If you have some basic working knowledge of these things, then you should have no trouble using ROS.  Some of the higher level concepts are more mathematically rigorous (or rely more heavily on computer science and control systems knowledge), but most of these things can be learned from Wikipedia or other sources of information on the web. I am currently mentoring a group of undergraduates on a robotics project, and they have had no trouble attaining the skills necessary to work in ROS.", " ", " ", "No. Even electrical engineers can use it! :-)", " ", " ", "No, in fact, I'd say it's especially useful for non-CS types.  I'm an electrical engineer, so instead of networking, my classes focused on signal processing.  ROS takes care of all the networking and allows me to get straight to processing data without having to create packets and struct up everything or share memory.  The publisher/subscriber foundation of ROS is extremely useful and I would use it even if none of the existing libraries existed or were useful!", " ", " ", "No you don't need to be a computer scientist to use ROS.  Although ROS does seem to be quite popular in academic research there are also a growing number of robotics hobbyists using it, of which I am one.  If its popularity continues then it should eventually be quite easy for non-experts to assemble working robot software from pre-written modules (stacks).", " ", " ", "Our project is now turn on ROS, to be honestly, I like Ubuntu more than Windows.I would love ROS, when I first contact it. To key point, I major in mathematics,rather than CS(computer science)."], "answer_details": ["Linux:  You should be aware of how the Linux operating system is put together and how to navigate it's file system.  You should also be able to install and uninstall packages, as well as follow tutorials written for Linux software.", "Command Line: You will want to have a basic fluency in using the Linux command line.  Much of this can be learned as you go, but without some basic knowledge, you will struggle to get to the higher-level concepts that ROS has to offer.", "Python and C Programming: You don't have to have a degree in computer science to dabble in programming, and I would say that most hobbyists (or undergraduates) have the skill set necessary to create their own ROS nodes.  ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " ", " "], "url": "https://answers.ros.org/question/9075/is-ros-only-for-computer-scientists/"}
,{"title": "Docker never starts with run.sh", "time": "2020-01-31 17:08:53 -0600", "post_content": [" ", " ", " ", " ", "Hi.", "It is my first attempt on using the autoware project. I'm running everything on Ubuntu 16.04.6 LTS (GNU/Linux 4.4.0-62-generic x86_64).", "I'm following the steps to install/use autoware via the docker approach, following the the installation guide. I have docker-ce 19.03 installed and can successfully run both ", " and ", ". Thus, I belive that both docker and nvidia runtime settings are ok, installed accordingly to the instructions.", "However, when I proceed to start the docker, it takes 'forever' to start, as reported above.", "It stays like this for more than an hour. Even though I could wait more, I don't think it is necessary/correct to wait for such a long time to start the docker, so I'm pretty sure there is something wrong.", "Additionally, since I'm running on Ubuntu 16.04, I have also tried to run:\n", "\nBut, again, the image is downloaded but the script remains stuck in the \"This operation can take a while...\" message.", "Do anyone knows what can be the cause of this and how to solve it? There is a git ", " with a similar problem, but with no solution given.", "Thank you.", "Update:\nI tried again and waited for a few hours (2 or 3 hours) and I got in the docker container. I believe the problem is on the ", " command, inside the entrypoint.sh file (which I guess is executed on the container startup). I'm running it on a server shared with more people, which are also executing their stuff, and the find command is simply computational intense. Given that, is there any alternative for this? Since I'm working remotely, sometimes there are broken pipes in ssh ...", "I'm running it on a server shared with more people, which are also executing their stuff, and the find command is simply computational intense.", "that will certainly negatively influence performance, yes.", "Is the machine you're remotely logged into equipped with an SSD or a mechanical, rotation HDD? That would significantly influence things as well.", "Since I'm working remotely, sometimes there are broken pipes in ssh connections and I'd like to regain access to autoware without having to wait for so long. ", "Are you running things in a plain terminal session, or are you using something like ", " or ", "?", "If the former, I'd recommend using the latter.", "Note: I'm not an autoware user, so it may be that there are way to avoid running that ", " command altogether. Regardless, I'd really recommend using something like ", " or ", " when running anything remotely.", "Thank you for the input. \nYou are completely right. Using screen is more reliable to work on remote servers. I wasn't doing that yet because I just feel it's easier to use the terminal without the screen during the setup. Anyway, waiting for so long should still not happen.", "Regarding the storage media, the docker containers are mounted into a HDD partition, due to the SSD size available in the server, so yes it can also be influencing on that."], "answer": [" ", " ", " have you tried skipping the UID modification step? you can add the ", " flag to the ", " so:\n", "Just tried that now and the docker enters immediately, which is nice. However, I have to use 'sudo' to create/delete/edit data on the shared_dir folder (guess that is what the UID modifications try to avoid). \nI'll base myself on this and try a few things out, and report if I get any better than this. Thank you!", "you can change the owner of the ", " folder once inside the container to the docker user, though you'll likely need to change it again if accessing the ", " folder from outside the container", "I solved the issue by using the --base-only flag. I would need that anyway if I want to modify the source code and keeping it outside the docker container (which I want to). As a consequence the waiting time issue no longer exists. I could properly build autoware from the source, from inside the docker container through this way."], "question_code": ["run docker hello-world", "docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi", "pedro@p0server:/scratch/autoware/docker/generic$ ./run.sh \nUsing options:\n    ROS distro: melodic\n    Image name: autoware/autoware\n    Tag prefix: latest\n    Cuda support: on\n    Pre-release version: off\n    UID: <1014>\nLaunching autoware/autoware:latest-melodic-cuda\nUnable to find image 'autoware/autoware:latest-melodic-cuda' locally\nlatest-melodic-cuda: Pulling from autoware/autoware\n7ddbc47eeb70: Already exists \nc1bbdc448b72: Already exists \n8c3b70e39044: Already exists \n45d437916d57: Already exists \n2b9b01e3e432: Pulling fs layer \n04fb7e096fb1: Pulling fs layer \n516bdffd8ca2: Pulling fs layer \n60339fb0d35d: Pulling fs layer \nf443a7a7d6ca: Pulling fs layer \na8fa796f177c: Pulling fs layer \n6960f5a11411: Pull complete \na9f77b2b02e4: Pull complete \ncdc5942e3fe6: Pull complete \nc9b7baf524c9: Pull complete \n3a8eadf0d457: Pull complete \nacb09b0e5e84: Pull complete \n037448bf7e7f: Pull complete \n7c4970c95db8: Pull complete \ne3c2bd6ca232: Pull complete \nccf6832e4897: Pull complete \n0b8d377ac46d: Pull complete \n7a457cce8ed2: Pull complete \n5c0ab1da738e: Pull complete \n101bea683c7d: Pull complete \nbd53215473a0: Pull complete \na09161de1216: Pull complete \n765f6cfa1af2: Pull complete \nb209f717e1df: Pull complete \n255191677602: Pull complete \n2c6aa05ac6a7: Pull complete \n78619f8dffe5: Pull complete \nbe4812ebbd95: Pull complete \nc3171763f3be: Pull complete \n18e58ccbe414: Pull complete \n143a621b3de1: Pull complete \nDigest: sha256:f47b92e189b202e5a424fcfa21b69604333cef6edd8da30a9715b0af92da9ef3\nStatus: Downloaded newer image for autoware/autoware:latest-melodic-cuda\nChanging autoware user ID to match your host's user ID (1014).\nThis operation can take a while...\n", "./run.sh -r kinetic -t 1.12.0", "find /home/autoware -user $DEFAULT_USER_ID -exec chown -h $USER_ID {} \\;", "tmux", "screen", "find", "tmux", "screen"], "answer_code": ["-s", "run.sh", "./run.sh -s", "shared_dir", "shared_dir"], "url": "https://answers.ros.org/question/343048/docker-never-starts-with-runsh/"}
,{"title": "CoopeliaSim ros_control plugin", "time": "2020-02-03 06:15:54 -0600", "post_content": [" ", " ", "Did someone try to write a ros_control plugin, similar to gazebo ros_control for the CoopeliaSim (previously v-rep). ", "There are some examples for v-rep (", "), but since the libraries changed a bit, the code won't work without further changes."], "answer": [], "url": "https://answers.ros.org/question/343161/coopeliasim-ros_control-plugin/"}
,{"title": "Issues regarding map_server", "time": "2020-02-03 03:23:45 -0600", "post_content": [" ", " ", " ", " ", "Hello all, I am facing a startup issue with the map_server. I am trying to setup this on a Nvidia Jetson Nano board, though the same setup is working on a Raspberry Pi 3B+ board. For Jetson, it's diving into certain issues, I resolved many but unable to resolve these ones. I am attaching the relevant output from the terminal which I get when I run the project.", "The below statement:", "keeps on continually printing to the terminal until I kill the process.", "Specifications for the system am using:-", "Relevant packages :"], "answer": [], "question_details": [" ", " ", " ", " ", " ", " ", " ", " ", " ", " ", "navigation > "], "question_code": ["setting /run_id to ac921624-465e-11ea-854a-00044be541e0\nprocess[rosout-1]: started with pid [7295]\nstarted core service [/rosout]\nprocess[robot2/base_to_lidar-2]: started with pid [7302]\nprocess[robot2/base_to_sonar-3]: started with pid [7303]\nprocess[robot2/base_controller_node-4]: started with pid [7304]\nprocess[robot2/motor_driver_node-5]: started with pid [7315]\n\nprocess[robot2/tcp_server_node-7]: started with pid [7317]\nprocess[robot2/rplidarNode-8]: started with pid [7327]\nprocess[robot2/laser_filter-9]: started with pid [7334]\n[ INFO] [1580718307.096068066]: RPLIDAR running on ROS package rplidar_ros. SDK Version:1.12.0\nprocess[robot2/robot_controller_node-10]: started with pid [7339]\nprocess[robot2/nodelet_manager-11]: started with pid [7345]\nprocess[robot2/velocity_smoother-12]: started with pid [7352]\nprocess[map_server-13]: started with pid [7354]\n[ INFO] [1580718307.343979394]: BOX filter started\n[ INFO] [1580718307.346575962]: invert filter not set, assuming false\nprocess[robot2/move_base-14]: started with pid [7360]\n[ WARN] [1580718307.403541579]: Using deprecated map server interface. Please switch to new interface.\nprocess[robot2/r2amcl-15]: started with pid [7379]\n[ INFO] [1580718307.892212943]: Subscribed to map topic.\n[ INFO] [1580718308.181643986]: Received a 1984 X 1984 map @ 0.050 m/pix\n\n[ WARN] [1580718308.181778845]: Frame_id of map received:'/map' doesn't match global_frame_id:'map'. This could cause issues with reading published topics\n[ INFO] [1580718308.544700222]: Initializing likelihood field model; this can take some time on large maps...\n[ INFO] [1580718309.012177912]: Done initializing likelihood field model.\nRPLIDAR S/N: 55BC9AF2C1EA9FC0A2EB92F1C66F3C02\n[ INFO] [1580718309.609679209]: Firmware Ver: 1.25\n[ INFO] [1580718309.609777657]: Hardware Rev: 5\n[ INFO] [1580718309.611322563]: RPLidar health status : 0\n[ INFO] [1580718310.156915537]: current scan mode: Express, max_distance: 12.0 m, Point number: 4.0K , angle_compensate: 1\n[ WARN] [1580718312.843989564]: Timed out waiting for transform from base_link to = /map to become available before running costmap, tf error: canTransform: target_frame = /map does not exist. canTransform: source_frame base_link does not exist.. canTransform returned after 0.100096 timeout was 0.1.\n[ WARN] [1580718317.879287019]: Timed out waiting for transform from base_link to = /map to become available before running costmap, tf error: canTransform: target_frame = /map does not exist. canTransform: source_frame base_link does not exist.. canTransform returned after 0.10097 timeout was 0.1.\n", "[ WARN] [1580541492.073914543]: Timed out waiting for transform from base_link to = map to become available before running costmap, tf error: canTransform: target_frame = map does not exist. canTransform: source_frame base_link does not exist.. canTransform returned after 0.101147 timeout was 0.1.\n", "CPU & Processor  >  Nvidia Jetson Nano\nOS  > Ubuntu 18.04.4 LTS\nCodename  >  bionic\nros-distro  >  melodic\n"], "url": "https://answers.ros.org/question/343151/issues-regarding-map_server/"}
,{"title": "Unable to communicate with service [/rosapi/service_type] while running Rosbidge", "time": "2020-02-03 08:17:42 -0600", "post_content": [" ", " ", " ", " ", "Hello all,", "I am trying web interface \"ROS Control Center\" based on Robot Web Tools.\n", "I have also tried running rosapi_node but no luck.", "However when I run a simple web interface only implementing teleop and displaying the map. NO errors appear related to WebSocket and able to interact with robot from web commands.", "Thanks"], "answer": [], "question_code": ["I am getting following errors from WebSocket node-\nUnable to communicate with service [/rosapi/service_type]\nUnable to communicate with service [/rosapi/get_param]\n"], "url": "https://answers.ros.org/question/343171/unable-to-communicate-with-service-rosapiservice_type-while-running-rosbidge/"}
,{"title": "how to add this below service in launch file:  rosservice call /enable_motors \"enable: true\"", "time": "2020-02-03 10:54:22 -0600", "post_content": [" ", " ", "how to add this below service in launch file?\n rosservice call /enable_motors \"enable: true\"\nI am using kinetic dist"], "answer": [], "url": "https://answers.ros.org/question/343176/how-to-add-this-below-service-in-launch-file-rosservice-call-enable_motors-enable-true/"}
,{"title": "Error viewing map in RVIZ", "time": "2020-02-01 23:57:51 -0600", "post_content": [" ", " ", " ", " ", "I have a map in one of my directories.", "I used the map server node to provide the map. But in rviz, when I set my fixed frame to: ", " (which is the odom frame of my robot) and map frame to ", " (the frame which I used to create the map), I get the error in the map display as no transform (and thus cannot see my map in rviz).", "I realize that there is no connection between the 2 in tf tree.", "I have actually created the map using ", " from the same fixed frame: ", ". How can I get the map to be displayed in rviz?", "(I guess connecting the two frames in tf would be sufficient but for using ", " I don't know the values to provide)", "The error that I get is:", "Could I ask you to please use some whitespace, punctuation and proper markup? Your question was a wall of text which made it very difficult to read.", "I've done it for you this time, but please keep it in mind for your next question.", "Sorry, I will be careful from next time, any help with the question?", "I would have no idea.", "Let's see whether other forum members can help."], "answer": [" ", " ", "The actual transform would depend on where the origin of the map frame is relative to the robot. That is something that would not really be doable in the end with a static transform, unless you always start your robot in the same place and in the same orientation.", "To verify that the map is being published you could try setting the fixed frame in rviz to ", ", if the option does not appear in the dropdown list just type it in there, if the map is being published and you have it visualized in the rviz config it should show up.", "Next you could try giving a static transform between the map frame and your odom frame. Without knowing anything about the map and odom frames I would just start with a transform that would set the odom frame to be in the origin of the map frame and see how it looks. You can read more about the ", " from the ros wiki. With the frames you have given the command would be something like this:", "To verify that this transform is published you could run  ", " and the previous command and run ", " from another terminal. There are various other tools to debug tfs like ", "For debugging you could figure out the correct transform based on some fixed heading and location in your testing area to your map and always start your robot there.", "In the end the transform between map and odom would be published by some node that would calculate the transform based on some logic. One option for such a node is ", " . Getting the robot localization node running properly requires quite a bit of work and trial and error. The documentation for the mentioned node is ", ".", "Thanks a lot, I now could figure out what exactly happens during localization"], "question_code": ["summit_xl_a_odom", "/map", "gmapping", "summit_xl_a_odom", "static_transform_publisher", "No transform from [map] to [summit_xl_a_odom]\n"], "answer_code": ["map", "rosrun tf static_transform_publisher 0.0 0.0 0.0 0.0 0.0 0.0 map summit_xl_a_odom 100", "roscore", "rosrun rqt_tf_tree rqt_tf_tree", "rosrun tf tf_echo /frame_id /other_frame_id"], "url": "https://answers.ros.org/question/343070/error-viewing-map-in-rviz/"}
,{"title": "Error when I install Catkin_make after I update my CmakeLists.txf", "time": "2020-02-03 06:39:36 -0600", "post_content": [" ", " ", " ", " ", "Straight dump of the error:"], "answer": [], "question_code": ["Base path: /home/kasi/catkin_ws\nSource space: /home/kasi/catkin_ws/src\nBuild space: /home/kasi/catkin_ws/build\nDevel space: /home/kasi/catkin_ws/devel\nInstall space: /home/kasi/catkin_ws/install\n####\n#### Running command: \"make cmake_check_build_system\" in \"/home/kasi/catkin_ws/build\"\n####\n####\n#### Running command: \"make install -j4 -l4\" in \"/home/kasi/catkin_ws/build\"\n####\n[  0%] Built target std_msgs_generate_messages_lisp\n[  0%] Built target std_msgs_generate_messages_cpp\n[  0%] Built target std_msgs_generate_messages_nodejs\n[  0%] Built target std_msgs_generate_messages_py\n[  0%] Built target _beginner_tutorials_generate_messages_check_deps_AddTwoInts\n[  0%] Built target std_msgs_generate_messages_eus\n[  0%] Built target _beginner_tutorials_generate_messages_check_deps_Num\n[ 30%] Built target beginner_tutorials_generate_messages_py\n[ 46%] Built target beginner_tutorials_generate_messages_lisp\n[ 53%] Generating C++ code from beginner_tutorials/Num.msg\n[ 61%] Generating C++ code from beginner_tutorials/AddTwoInts.srv\n[ 76%] Built target beginner_tutorials_generate_messages_nodejs\n[100%] Built target beginner_tutorials_generate_messages_eus\nTraceback (most recent call last):\nTraceback (most recent call last):\n  File \"/opt/ros/melodic/share/gencpp/cmake/../../../lib/gencpp/gen_cpp.py\", line 41, in <module>\n  File \"/opt/ros/melodic/share/gencpp/cmake/../../../lib/gencpp/gen_cpp.py\", line 41, in <module>\n    import genmsg.template_tools\n    import genmsg.template_tools\n  File \"/opt/ros/melodic/lib/python2.7/dist-packages/genmsg/template_tools.py\", line 39, in <module>\n  File \"/opt/ros/melodic/lib/python2.7/dist-packages/genmsg/template_tools.py\", line 39, in <module>\n    import em\n    import em\nModuleNotFoundError: No module named 'em'\nModuleNotFoundError: No module named 'em'\nbeginner_tutorials/CMakeFiles/beginner_tutorials_generate_messages_cpp.dir/build.make:63: recipe for target '/home/kasi/catkin_ws/devel/include/beginner_tutorials/Num.h' failed\nmake[2]: *** [/home/kasi/catkin_ws/devel/include/beginner_tutorials/Num.h] Error 1\nmake[2]: *** Waiting for unfinished jobs....\nbeginner_tutorials/CMakeFiles/beginner_tutorials_generate_messages_cpp.dir/build.make:70: recipe for target '/home/kasi/catkin_ws/devel/include/beginner_tutorials/AddTwoInts.h' failed\nmake[2]: *** [/home/kasi/catkin_ws/devel/include/beginner_tutorials/AddTwoInts.h] Error 1\nCMakeFiles/Makefile2:691: recipe for target 'beginner_tutorials/CMakeFiles/beginner_tutorials_generate_messages_cpp.dir/all' failed\nmake[1]: *** [beginner_tutorials/CMakeFiles/beginner_tutorials_generate_messages_cpp.dir/all] Error 2\nMakefile:140: recipe for target 'all' failed\nmake: *** [all] Error 2\nInvoking \"make install -j4 -l4\" failed\n"], "url": "https://answers.ros.org/question/343163/error-when-i-install-catkin_make-after-i-update-my-cmakeliststxf/"}
,{"title": "How does ROS relocate nodes at runtime?", "time": "2020-01-30 12:48:06 -0600", "post_content": [" ", " ", "I came across the following statement in the tutorial:", "A well-written node makes no assumptions about where in the network it runs, allowing computation to be relocated at run-time to match the available resources", "Link: ", "It seems that ROS is able to move software components across systems at run-time. Alas, I couldn't find any more information on that. Can you tell me where I can find more information about that? I'm interested in how ROS manages to move a software component from one machine to the next. Given that C++ is a compiled language and the binary is specific to the target machine (which might not have access to a compiler) that seems impressive to me. Can you tell me the names of the function calls / ROS commands that I can look into to learn more about this relocation?"], "answer": [" ", " ", " ", " ", "I believe there is a misunderstanding here: the \"relocation at run-time\" is attempting to say that ", " (ie: the act of computing something) could be relocated. Not the entity that performs it. Or at least, not the ", " entity.", "So because of location independence and by avoiding \"assumptions in nodes about where in the network it runs\" (and of course also in the rest of the application/nodegraph), it would be possible to start a node anywhere, and by bringing down one node and starting it somewhere else, the ", " itself may be relocated (as in: it was at X, but is now running on host Y).", "There is no support for migrating on-line nodes (ie: processes) from one machine to another.", "I would also say that should probably not even be the responsibility of ROS (ie: the middleware), but of more appropriate (sub)systems of the OS and/or orchestration layer.", "The idea described in the tutorial you link would be similar to how stateless applications running in (Docker) containers can be easily migrated to run wherever computing resources are available: that is not the same as migrating live processes, but in a similar sense one could state that \"the computation\" (ie: the functionality) is being migrated to other machines.", "Thank you for your response. So if I understood you correctly, because ROS provides some form of MQTT broker, it doesn't really matter on which system a software component runs. But it is not possible to move software from one system to the next. When I read that sentence in the tutorial, I was hoping to find something like the functionality offered by deploying an AWS Lambda function to an AWS Greengrass device but with C++ (for resource-constraint devices). Anyway, thank you for your answer!", "So if I understood you correctly, because ROS provides some form of MQTT broker", "No, ROS 1 does not work that way (and neither does ROS 2). The broker in MQTT is actually involved in message exchange. In ROS, message exchange is peer-to-peer. There is no broker. There is only a ", ", but that is essentially a DNS.", "it doesn't really matter on which system a software component runs", "this is the consequence of node decoupling. Not of some intermediate entity like a broker. See ", " for some more discussion about this.", "When I read that sentence in the tutorial, I was hoping to find something like the functionality offered by deploying an AWS Lambda function to an AWS Greengrass device but with C++ (for resource-constraint devices)", "I'm not entirely sure whether running instances can be migrated by Greengrass.", "Thank you for the clarification!"], "url": "https://answers.ros.org/question/342950/how-does-ros-relocate-nodes-at-runtime/"}
,{"title": "How to combine HectorSLAM and RGB-D camera data to achieve 3D mapping?", "time": "2020-02-03 05:18:20 -0600", "post_content": [" ", " ", " ", " ", "I represent a team of engineers from Lancaster University. We are attempting to combine 2D LIDAR data (preferably using HectorSLAM) and RGB-D camera data (as done by Technische Universit\u00e4t Darmstadt ", ") for an autonomous UAV mapping application. We are using AND RPLIDAR A2 scanner and a Realsense Depth Camera D415. The ROS distro is Kinetic. \nHow could we achieve this and could it be performed using ROS on an Nvidia Jetson Nano? Can we run two SLAM algorithms concurrently (e.g HectorSLAM and ORB-SLAM), or do we need to combine the sensor data before applying SLAM?\nIs there any open-source code available to achieve this?", "Many Thanks."], "answer": [" ", " ", "There are many ways to approach this problem. I'll outline the simplest one, but your comment about:", "to combine the sensor data before applying SLAM", "will probably give you a better result. Or approaching this from a tightly-coupled approach, if that's terminology you're familiar with. ", "The only way to my knowledge that's fully-open source and relatively plug and play is as follows:", "1) Use the 2D laser scanner to build a map. This can be done with Hector like you mention, but also slam toolbox, karto, or gmapping. ", "2) Look at Octomap. Use the positioning provided by the slam algorithm and odometry to project your points of your depth sensor into the  global frame provided by the 2D slam", "3) Rejoice! ", "Obvious asterisks:", "While this is a popular method for junior developers and folks that don't want to actually create a SLAM solution, there are clear downsides.", "If you're working with a 2D laser scanner, then you're throwing out a ton of data that could be used to build a better map and position yourself, and only just using that 3D information to build the global model. Calling this 3D SLAM is a bit of a misnomer, but again, its a popular method.", "To increase fidelity, you may need to continuously post the graph to octomap to update the positioning of individual measurements if they shift around. This is necessary for loop closure and reduction of residual error operations. Hector doesn't do loop closures, so that may not be an issue you have the ability to resolve if you're married to Hector. ", "Thank you for your fast and comprehensive response. This gives us everything we need to get started.", "Can I clarify what you mean by \"Use the positioning provided by the slam algorithm and odometry to project your points of your depth sensor into the global frame provided by the 2D slam\".", "How do you specifically suggest we combine the Odometry data with the Octomap and then combine this with the global frame provided by the 2D SLAM? Is this just a case of finding appropriate open-source code on Github? Thanks again for your help!", "Awesome, please mark the answer as correct to get it off the unanswered questions queue.", "Basically Hector / SLAM will give you a pose estimation in TF. You should use octomap to take in sensor readings in their current frame (camera_frame, or something) and transform into the global frame (map, or something) to insert into the octomap occupancy grid."], "url": "https://answers.ros.org/question/343158/how-to-combine-hectorslam-and-rgb-d-camera-data-to-achieve-3d-mapping/"}
,{"title": "Issues regarding nodelet_manager and map_server", "time": "2020-02-01 02:19:46 -0600", "post_content": [" ", " ", " ", " ", "Hello all,\nI am facing a startup issue with the nodelet_manager and also with the map_server. \nI am trying to setup this on a Nvidia Jetson Nano board, though the same setup is working on a Raspberry Pi 3B+ board. For Jetson, it's diving into certain issues, I resolved many but unable to resolve these ones.\nI am attaching the relevant output from the terminal which I get when I run the project.", "Failed to load nodelet [/robot2/velocity_smoother] of type [yocs_velocity_smoother/VelocitySmootherNodelet]", "do you have the ", " package installed?", "What is the output of ", "?", " Thanks for the suggestion, I had already solved the problem by installing the concerned package, I've now edited the scenario of the problem with the current problems am facing.", "Please don't do this.", "This is not a forum, but a Q&A site, which works best with a 1-to-1 ratio of problems-to-answers.", "Revert your edit, post how you solved your initial problem as an answer, accept your own answer.", " post a new question with your current problem -- after having made sure you're not posting a duplicate (use Google to search, append ", " to your query).", "Oh, and:", "I tried all the solutions available but didn't made any difference", "this sentence does not give any information. We don't know ", " you've tried, so we cannot avoid giving you the same advice/help.", "Please always describe what you've already read and done, and why that didn't (seem to) help.", " Thanks for the suggestions regarding the usage of the site. I've done the relevant changes and asked for another question regarding the problems currently. Am new to this site so mistakes, apologies for the same, I'll make sure to follow the ethics in the future.", "No need to apologise.", "Thanks for reverting."], "answer": [" ", " ", "I have solved the problem by installing the yocs_velocity_smoother. I used the following command to do the same", "Completing this operation the nodes, nodelet_manager and velocity_smoother have been started and started communicating as defined (publishing/subscribing to the topics)."], "question_code": ["process[robot2/tcp_server_node-7]: started with pid [17321]\nprocess[robot2/rplidarNode-8]: started with pid [17326]\nprocess[robot2/laser_filter-9]: started with pid [17333]\nprocess[robot2/robot_controller_node-10]: started with pid [17339]\n[ INFO] [1580541481.569816769]: RPLIDAR running on ROS package rplidar_ros. SDK Version:1.12.0\nprocess[robot2/nodelet_manager-11]: started with pid [17341]\nprocess[robot2/velocity_smoother-12]: started with pid [17350]\nprocess[map_server-13]: started with pid [17353]\nprocess[robot2/move_base-14]: started with pid [17354]\n[ INFO] [1580541481.688089922]: BOX filter started\n[ INFO] [1580541481.692382390]: invert filter not set, assuming false\nprocess[robot2/r2amcl-15]: started with pid [17361]\n[ WARN] [1580541481.725805073]: Using deprecated map server interface. Please switch to new interface.\n[ERROR] [1580541481.845865565]: Failed to load nodelet [/robot2/velocity_smoother] of type [yocs_velocity_smoother/VelocitySmootherNodelet] even after refreshing the cache: According to the loaded plugin descriptions the class yocs_velocity_smoother/VelocitySmootherNodelet with base class type nodelet::Nodelet does not exist. Declared types are  SlamGMappingNodelet nodelet_tutorial_math/Plus pcl/BAGReader pcl/BoundaryEstimation pcl/ConvexHull2D pcl/CropBox pcl/EuclideanClusterExtraction pcl/ExtractIndices pcl/ExtractPolygonalPrismData pcl/FPFHEstimation pcl/FPFHEstimationOMP pcl/MomentInvariantsEstimation pcl/MovingLeastSquares pcl/NodeletDEMUX pcl/NodeletMUX pcl/NormalEstimation pcl/NormalEstimationOMP pcl/NormalEstimationTBB pcl/PCDReader pcl/PCDWriter pcl/PFHEstimation pcl/PassThrough pcl/PointCloudConcatenateDataSynchronizer pcl/PointCloudConcatenateFieldsSynchronizer pcl/PrincipalCurvaturesEstimation pcl/ProjectInliers pcl/RadiusOutlierRemoval pcl/SACSegmentation pcl/SACSegmentationFromNormals pcl/SHOTEstimation pcl/SHOTEstimationOMP pcl/SegmentDifferences pcl/StatisticalOutlierRemoval pcl/VFHEstimation pcl/VoxelGrid test_nodelet/ConsoleTest test_nodelet/FailingNodelet test_nodelet/NodehandleTest test_nodelet/Plus test_nodelet_topic_tools/NodeletLazyString test_nodelet_topic_tools/NodeletThrottleString\n[ERROR] [1580541481.847912635]: The error before refreshing the cache was: According to the loaded plugin descriptions the class yocs_velocity_smoother/VelocitySmootherNodelet with base class type nodelet::Nodelet does not exist. Declared types are  SlamGMappingNodelet nodelet_tutorial_math/Plus pcl/BAGReader pcl/BoundaryEstimation pcl/ConvexHull2D pcl/CropBox pcl/EuclideanClusterExtraction pcl/ExtractIndices pcl/ExtractPolygonalPrismData pcl/FPFHEstimation pcl/FPFHEstimationOMP pcl/MomentInvariantsEstimation pcl/MovingLeastSquares pcl/NodeletDEMUX pcl/NodeletMUX pcl/NormalEstimation pcl/NormalEstimationOMP pcl/NormalEstimationTBB pcl/PCDReader pcl/PCDWriter pcl/PFHEstimation pcl/PassThrough pcl/PointCloudConcatenateDataSynchronizer pcl/PointCloudConcatenateFieldsSynchronizer pcl/PrincipalCurvaturesEstimation pcl/ProjectInliers pcl/RadiusOutlierRemoval pcl/SACSegmentation pcl/SACSegmentationFromNormals pcl/SHOTEstimation pcl/SHOTEstimationOMP pcl/SegmentDifferences pcl/StatisticalOutlierRemoval pcl/VFHEstimation pcl/VoxelGrid test_nodelet/ConsoleTest test_nodelet/FailingNodelet test_nodelet/NodehandleTest test_nodelet/Plus test_nodelet_topic_tools/NodeletLazyString test_nodelet_topic_tools/NodeletThrottleString\n[FATAL] [1580541481.869766677]: Failed to load nodelet '/robot2/velocity_smoother` of type `yocs_velocity_smoother/VelocitySmootherNodelet` to manager `nodelet_manager'\n[ INFO] [1580541481.947580235]: Subscribed to map topic.\n[robot2/velocity_smoother-12] process has died [pid 17350, exit code 255, cmd /home/xena/catkin_ws/devel/lib/nodelet/nodelet `load yocs_velocity_smoother/VelocitySmootherNodelet nodelet_manager velocity_smoother/raw_cmd_vel:=cmd_vel/in velocity_smoother/smooth_cmd_vel:=cmd_vel/out velocity_smoother/robot_cmd_vel:=cmd_vel/out velocity_smoother/odometry:=odom __name:=velocity_smoother __log:=/tmp/f8f13060-44c2-11ea-b35d-00044be541e0/robot2-velocity_smoother-12.log].`\nlog file: /tmp/f8f13060-44c2-11ea-b35d-00044be541e0/robot2-velocity_smoother-12*.log\n[ INFO] [1580541482.391220727]: Received a 1984 X 1984 map @ 0.050 m/pix\n[ INFO] [1580541482 ...", "yocs_velocity_smoother", "rospack find yocs_velocity_smoother", "site:answers.ros.org"], "answer_code": ["sudo apt install ros-melodic-yocs-velocity-smoother\n"], "url": "https://answers.ros.org/question/343056/issues-regarding-nodelet_manager-and-map_server/"}
,{"title": "How can i pass values from one callback function to another.", "time": "2020-01-30 17:53:51 -0600", "post_content": [" ", " ", "How can i combine arguments of one callback function with another.", "I have pose (x,y,z) coordinate from a topic and waypoints(x,y,z) from different topic. i need to use these two coordinates to find the distance between two coordinate points.", "What have you tried so far? Can you add a copy and paste of your code?"], "answer": [], "url": "https://answers.ros.org/question/342968/how-can-i-pass-values-from-one-callback-function-to-another/"}
,{"title": "catkin how to search source install include directory before debian include directory?", "time": "2020-01-30 21:51:49 -0600", "post_content": [" ", " ", "I have a problem where I want to depend on a newer interface than what is in the debain install.  To do this I am building the library I'm depending on (moveit) from source in an upstream workspace.  However for some reason catkin/cmake is creating an include list that is always including the debian based includes first.  This is from the compile step:", "Here is the documentation from the man page of ", " (-isystem is always searched after -I):", "How can I instruct catkin/cmake to include my upstream include path first (by changing the -isystem to -I or something similar)?"], "answer": [], "question_code": ["-isystem /home/tyler/workspace/ws_upstream/install/include\n-I/opt/ros/melodic/include", "g++", "       The lookup order is as follows:\n   1.  For the quote form of the include directive, the directory of the current file is searched first.\n   2.  For the quote form of the include directive, the directories specified by -iquote options are searched in left-to-right\n       order, as they appear on the command line.\n   3.  Directories specified with -I options are scanned in left-to-right order.\n   4.  Directories specified with -isystem options are scanned in left-to-right order.\n   5.  Standard system directories are scanned.\n   6.  Directories specified with -idirafter options are scanned in left-to-right order.\n"], "url": "https://answers.ros.org/question/342974/catkin-how-to-search-source-install-include-directory-before-debian-include-directory/"}
,{"title": "Gazebo not working in ros kinetic singularity image", "time": "2019-04-10 03:48:28 -0600", "post_content": [" ", " ", " ", " ", "I am trying to create an emika_franka_panda robot simulator using the ", " docker image as explained in ", ". To do this i created the following definition file:", "I then tried to create the image by using the following command:", "Following when running the container using:", "and trying to launch gazebo using:", "I run into troubles. The gazebo interface tries to launch but crashes with the following errors after 1 second.", "Now the gazebo simulator launches without any problems.", "In this case I tried to first bootstrap from the ubuntu 16.04 repository and following trying to install ros kinetic by using the ", ". This gave me the following errors when trying to run the gazebo simulator.", " ", "Your image doesn't contain any graphics drivers (or at least: not the level of 3D support that Gazebo requires).", " is the right approach, but with versions of Singularity newer than ", "/", " you'll need to take additional steps, as not all required files (notably: OpenGL related) are injected into your container.", "It's not trivial, but I believe the Singularity user documentation should document this.", "Also:", "If you're using ", " here (and ", " with ", ") because you have included your workspace in your image, then don't. Build your image to include the necessary dependencies, but keep your workspace out of the image. You can use ", " to install all required dependencies (after having copied the workspace temporarily into your image build dir, then remove after ", " has finished).", "Thanks a lot for your answer ", "! And the tip about the --sandbox and --writable options. I review the documentation again and I now better understand their usage. Based on the documentation I indeed thought the --nv option solved the driver problems I encountered previously. After your suggestion, I tried to install 2 OpenGL packages that were missing to my images but this did unfortunately not work either. ", "Do you maybe know what the best way is to solve this problem? I have a hard time finding a good guide on how to do this. Do I need to use the old ", ", use the ", " image instead of the ros-kinetic-image, use the ", " package or copy the needed nvidia .run files from my host system to my image container.", "Thanks a lot in advance", "Question: do you actually have NVIDIA hardware in your system?", "If so: can you show the output of ", "?", "Thanks a lot for looking into it my problem. For clarity, I added my system specifications and the singularity shell output to the question above.", "Which version of Singularity is that? And can you show the command line you used to start it (unless it was exactly the command I suggested)?", "I would've at least expected to see some ", " lines in there.", "Yea that is strange it is singularity 3.0.3 with the ", " command in the /bin/bash/ command line.", "I solved my issue with the tips of ", ". The problem was caused by my Nvidia-driver after having purged the driver according to this guide ", " and reinstalling a ", " my issue disappeared."], "answer": [" ", " ", " ", " ", "With the comments made by ", " I managed to solve the issue by reinstalling my driver. In my case I needed the ", " driver instead of the ", ". ", "Although I'm not totally sure what the exact issue was this might solve the issue for other people as well. To find the right driver for your video card run the ", " command to get the name of your video card. Following you can find which driver you need on the ", ". The new driver can then be installed according to "], "question_details": [" ", " ", " ", " ", " ", " ", " ", " ", " ", " ", "PC: Hp Zbook G3", "Root linux system: Ubuntu 18.04", "Graphics driver: Quadro M1000M", "Cuda versions: 10.0 (cudnn 7.4.2) and 9.0 (cudnn 7.5.0)", "Singularity version 3.0.3"], "question_code": ["osrf/ros:kinetic-desktop-full", "Bootstrap: docker\nFrom: osrf/ros:kinetic-desktop-full\n\n%post  \n    # Initiation commands\n    apt-get update\n\n    # Setup ros dependency tool\n    rosdep update\n", "sudo singularity build --sandbox ros_kinetic_panda ros_kinetic_panda.def\n", "sudo singularity shell --nv --writable ros_kinetic_panda\n", "gazebo\n", "Singularity panda_kinetic:~/singularity/containers> gazebo\nlibGL error: libGL error: No matching fbConfigs or visuals found\nNo matching fbConfigs or visuals found\nlibGL error: failed to load driver: swrast\nlibGL error: failed to load driver: swrast\nGtk-Message: Failed to load module \"appmenu-gtk-module\"\nGtk-Message: Failed to load module \"gail\"\nGtk-Message: Failed to load module \"atk-bridge\"\nGtk-Message: Failed to load module \"canberra-gtk-module\"\n", "Bootstrap: docker\nFrom: osrf/ros:melodic-desktop-full\n\n%post\n    echo \"Setting up ros melodic emika franka container.\"\n\n    # Initiation commands\n    apt-get update\n\n    # Setup ros dependency tool\n    rosdep update\n", "libGL error: No matching fbConfigs or visuals found\nlibGL error: No matching fbConfigs or visuals found\nlibGL error: failed to load driver: swrast\nlibGL error: failed to load driver: swrast\nterminate called after throwing an instance of 'std::runtime_error'\n  what():  locale::facet::_S_create_c_locale name not valid\nSingularity ros_test:~> gazebo\nlibGL error: No matching fbConfigs or visuals found\nlibGL error: failed to load driver: swrast\nlibGL error: No matching fbConfigs or visuals found\nlibGL error: failed to load driver: swrast\nterminate called after throwing an instance of 'std::runtime_error'\n  what():  locale::facet::_S_create_c_locale name not valid\n", "VERBOSE: Set messagelevel to: 4\nVERBOSE: Container runtime\nVERBOSE: Check if we are running as setuid\nVERBOSE: Spawn scontainer stage 1\nVERBOSE: Get root privileges\nVERBOSE: Execute scontainer stage 1\nVERBOSE: Get root privileges\nVERBOSE: Create mount namespace\nVERBOSE: Spawn smaster process\nVERBOSE: Spawn scontainer stage 2\nVERBOSE: Create mount namespace\nVERBOSE: Spawn RPC server\nVERBOSE: Execute smaster process\nVERBOSE: Serve RPC requests\nVERBOSE: Found 'bind path' = /etc/localtime, /etc/localtime\nVERBOSE: Found 'bind path' = /etc/hosts, /etc/hosts\nVERBOSE: Checking for template passwd file: /usr/local/var/singularity/mnt/session/rootfs/etc/passwd\nVERBOSE: Creating passwd content\nVERBOSE: Creating template passwd file and appending user data: /usr ...", "--nv", "2.5.x", "2.6", "sudo singularity build --sandbox ros_kinetic_panda ros_kinetic_panda.def\n", "--sandbox", "--writable", "shell", "rosdep", "rosdep", "singularity -v shell --nv /path/to/your/image", "Found NV library: ..", "singularity -v shell --nv ros_kinetic_panda"], "answer_code": ["NVIDIA driver metapackage from nvidia-driver-418 (opensource)", "NVIDIA driver metapackage from nvidia-driver-415 (opensource)", "nvdia-smi"], "url": "https://answers.ros.org/question/320755/gazebo-not-working-in-ros-kinetic-singularity-image/"}
,{"title": "Controlling Aubo i5 using Joint velocities", "time": "2020-01-30 23:25:25 -0600", "post_content": [" ", " ", " ", " ", "Hi, ", "I am doing a visual servoing project in Aubo i5 robot. I need to control the robot based on visual servoing outputs from the camera. Using visual servoing i have computed the linear and angular velocity. Is there any way to control the real robot like controlling turtlesim using twist message using cmd_vel topic. ", "Also using jacobian matrix i have calculated the joint velocities of 6 joints from the linear and angular velocities. I came to know that in ur5 driver there is option to control the robot using joint speed. but in aubo there is no option like that. is it possible to find the joint positions from joint velocity so that i can control the robot using followJointTrajectory/goal topic of the controller. ", "Any suggestion is highly appreciated.", "This may not be what you came here to hear, but: have you asked Aubo about this? It's not entirely clear which repository now contains the official drivers, but they appear to be supporting ROS themselves, so they should be able to answer your question.", "  Their git hub repository is currently inactive. We have posted several issues in that repository. But there is no response. Is there any way that we can create our own node code to perform this action. ie, convert the twist message into pose or jointtrajectory using a small step time (converting linear velocity into position using the step time until the goal is reached) or any other option. Any tip or information would be really helpful.", "You could take a look at ", ". No guarantees it will work with your robot though.", "Their git hub repository is currently inactive. ", "I believe ", " is the currently active repository. Last commits from December 2019.", "We have posted several issues in that repository. But there is no response. ", "I see only ", ".", " i think jog_arm also needs position controller or velocity controller to control the robot. i could see in aubo controller there is only trajectory controller. in the package aubo_controller there is only one excecutable \"aubo_joint_trajectory_action\". the rosnode info for this gives below ", "does this mean aubo have no velocity controller ??? ", "We have posted several other queries also in their github repository.  lg609/aubo_robot #44 which was posted on oct last year. We are not getting any response on the issues.", "I have no experience with Aubo robots, their controllers nor their ROS driver(s).", "If those are the only topics you have, it would appear there is only a ", " action server and a topic which accepts ", " messages. That does not seem like something that would accept velocities, no.", "You may want to take a look at the driver itself. Perhaps the controller does support velocity control, but it's just not exposed by the ROS driver they provide you with."], "answer": [], "question_code": ["Publications: \n * /aubo_i5_controller/follow_joint_trajectory/feedback [control_msgs/FollowJointTrajectoryActionFeedback]\n * /aubo_i5_controller/follow_joint_trajectory/result [control_msgs/FollowJointTrajectoryActionResult]\n * /aubo_i5_controller/follow_joint_trajectory/status [actionlib_msgs/GoalStatusArray]\n * /joint_path_command [trajectory_msgs/JointTrajectory]\n * /rosout [rosgraph_msgs/Log]\n\nSubscriptions: \n * /aubo_i5_controller/follow_joint_trajectory/cancel [actionlib_msgs/GoalID]\n * /aubo_i5_controller/follow_joint_trajectory/goal [control_msgs/FollowJointTrajectoryActionGoal]\n * /feedback_states [control_msgs/FollowJointTrajectoryFeed\n", "FollowJointTrajectory", "JointTrajectory"], "url": "https://answers.ros.org/question/342977/controlling-aubo-i5-using-joint-velocities/"}
,{"title": "Subscriber failed Deserialization Error : Rosserial", "time": "2020-01-31 00:11:38 -0600", "post_content": [" ", " ", " ", " ", "HI,\nI'm trying to  create a subscriber but I'm getting the following error", "The code im using is as follows ", "Any idea on what i'm doing wrong here?", "Just as in ", ", you appear to have a very short ", ". Would be worth checking whether increasing that helps.", "Naah didn't work. It is not setting up the subscriber.", "Try removing the Serial.begin statement as that is setting the Serial speed to 115200; but your terminal output from your serial_node says it is reading data at 57600. A mismatch in speed will mean it cannot decode the data correctly.", "That was my inital guess as well. However no it didn't work.", "Regardless of whether it fixed your issue: it needs to go, as what ", " writes is true. It will never work this way.", "The next thing I would try would be to change ", "to ", "as you are using t to set one of the fields in msg in the main loop and then publishing the message, but t  will not be initialised to a known value until you receive a message on the topic you subscribe to."], "answer": [], "question_code": ["rosrun rosserial_python serial_node.py /dev/ttyACM0\n[INFO] [1580450261.541002]: ROS Serial Python Node\n[INFO] [1580450261.554769]: Connecting to /dev/ttyACM0 at 57600 baud\n[INFO] [1580450263.710550]: Note: publish buffer size is 280 bytes\n[INFO] [1580450263.711406]: Setup publisher on my_topic [dbw_mkz_msgs/SteeringCmd]\n[INFO] [1580450263.720098]: Note: subscribe buffer size is 280 bytes\n[INFO] [1580450263.721023]: Setup subscriber on /vehicle/steering_cmd [dbw_mkz_msgs/SteeringCmd]\nTraceback (most recent call last):\n  File \"/opt/ros/kinetic/lib/rosserial_python/serial_node.py\", line 89, in <module>\n    client.run()\n  File \"/opt/ros/kinetic/lib/python2.7/dist-packages/rosserial_python/SerialClient.py\", line 504, in run\n    self.callbacks[topic_id](msg)\n  File \"/opt/ros/kinetic/lib/python2.7/dist-packages/rosserial_python/SerialClient.py\", line 107, in handlePacket\n    m.deserialize(data)\n  File \"/opt/ros/kinetic/lib/python2.7/dist-packages/dbw_mkz_msgs/msg/_SteeringCmd.py\", line 133, in deserialize\n    raise genpy.DeserializationError(e) #most likely buffer underfill\ngenpy.message.DeserializationError: unpack requires a string argument of length 18\n", "#include <ros.h>\n#include <dbw_mkz_msgs/SteeringCmd.h>\n#include <std_msgs/Float64.h>\n#include <std_msgs/Float32.h>\n\nfloat t;\n\nros::NodeHandle nh;\n\ndbw_mkz_msgs::SteeringCmd msg;\n\nvoid messageCb(const dbw_mkz_msgs::SteeringCmd& msg1)\n{\n    msg.count = msg1.count;\n    digitalWrite(13, HIGH - digitalRead(13));\n}\n\nros::Subscriber<dbw_mkz_msgs::SteeringCmd> sub(\"/vehicle/steering_cmd\", &messageCb);\n\nros::Publisher p(\"my_topic\", &msg);\n\nvoid setup()\n{\n    Serial.begin(115200);\n\n    pinMode(13, OUTPUT);\n    nh.initNode();\n\n    nh.subscribe(sub);\n    nh.advertise(p);\n}\n\nvoid loop()\n{\n    t = msg.count;\n    p.publish(&msg);\n    nh.spinOnce();\n    delay(1);\n}\n", "delay(1)", "float t;\n", "float t=0.0;\n"], "url": "https://answers.ros.org/question/342981/subscriber-failed-deserialization-error-rosserial/"}
,{"title": "Install ROS2 Dependent Packages", "time": "2020-01-31 01:42:05 -0600", "post_content": [" ", " ", "Hi.", "I am trying to install ROS 2 Dependent Packages on Ubuntu 18.04.3 LTS.", "When I write \" curl -sSL ", " | sh\", \"sh: 2: Syntax error: newline unexpected\" appear. ", "Do you know how to solve this error?", "I am trying to install ROS 2 Dependent Packages on Ubuntu 18.04.3 LTS.", "please always link to whichever instructions or tutorial(s) you are trying to follow.", "We don't know everything by heart, which makes it difficult to figure out what you're attempting/supposed to be doing."], "answer": [" ", " ", "Looks like there's something wrong with the server hosting that page:", "I'd suggest contacting the Gazebo folks over at ", ".", "If/when you post at ", ", please post a comment here with a link to your new question, so we can keep things connected."], "answer_code": ["answers.gazebosim.org", "answers.gazebosim.org"], "url": "https://answers.ros.org/question/342985/install-ros2-dependent-packages/"}
,{"title": "What will happen if I run 'rosclean purge'?", "time": "2020-01-30 23:34:15 -0600", "post_content": [" ", " ", " ", " ", "Hello, I'm using ROS kinetic on ununtu 16.04.", "This question might not be serious, and it does not bring up any other problems.", "I got the following warning every time when my roscore runs:", "I also referenced to ", ", but I just afraid this command might spoil my ROS system in some ways.", "The above instruction says maybe ", " can remove that warning, but I'm not still sure.\nWould it truely going to be ok if I run ", "?"], "answer": [" ", " ", "Yes, what that's going to do is remove the ROS logs from your ", " directory. When packages print to screen or have debug messages, they also get logged in that directory.", "Over time if nothing empties them, it'll keep piling up. This warning is to let you know that there are alot of logs laying around, and you may want to get rid of them so they don't keep growing. ", "All that ", " does is remove those files. ", "Thank you, it works without any issues!"], "question_code": ["WARNING: disk usage in log directory [/home/robotics/.ros/log] is over 1GB.\nIt's recommended that you use the 'rosclean' command.\n", "rosclean purge", "rosclean purge"], "answer_code": [".ros/log", "rosclean purge"], "url": "https://answers.ros.org/question/342978/what-will-happen-if-i-run-rosclean-purge/"}
,{"title": "In the gazebo environment, once dynamic parameters are added to the urdf model, the connecting rod will be fixed at the origin.", "time": "2020-01-31 02:26:40 -0600", "post_content": [" ", " ", "In the gazebo environment, once dynamic parameters are added to the urdf model, the link will be fixed at the origin.", "After adding the dynamics damping,the showed link will be fixed at the origin(or maybe world).", "before adding the dynamics damping:\n", "after adding the dynamics damping:\n", "All urde files :", "I would perhaps recommend to ask this over at ", ", seeing as you're attempting to make this work in Gazebo."], "answer": [], "question_code": ["    <dynamics damping=\"0.7\"/>\n", "    <?xml version=\"1.0\" encoding=\"utf-8\"?>\n\n\n       <!-- This URDF was automatically created by SolidWorks to URDF Exporter! Originally created by Stephen Brawner (brawner@gmail.com) \n             Commit Version: 1.5.1-0-g916b5db  Build Version: 1.5.7152.31018\n             For more information, please see http://wiki.ros.org/sw_urdf_exporter -->\n\n\n        <!-- Revolute-Revolute Manipulator -->\n            <robot name=\"link\" xmlns:xacro=\"http://www.ros.org/wiki/xacro\">\n\n              <!-- Import all Gazebo-customization elem\n\n        ents, including Gazebo colors -->\n\n\n       <xacro:include filename=\"$(find link)/urdf/link.gazebo\" />\n\n          <!-- Used for fixing robot to Gazebo 'base_link' -->\n          <link name=\"world\"/>\n\n      <joint name=\"fixed\" type=\"fixed\">\n        <parent link=\"world\"/>\n        <child link=\"base_link\"/>\n      </joint>\n\n      <link\n        name=\"base_link\">\n    <inertial>\n      <origin\n        xyz=\"5.41431391044674E-19 -3.81599768090245E-18 0.0119651355617924\"\n        rpy=\"0 0 0\" />\n      <mass\n        value=\"0.317346214028947\" />\n      <inertia\n        ixx=\"0.000400193890599361\"\n        ixy=\"-3.73238496454284E-22\"\n        ixz=\"-4.8058493695367E-21\"\n        iyy=\"0.000399358915837397\"\n        iyz=\"-4.57713225377642E-20\"\n        izz=\"0.000705715767674914\" />\n    </inertial>\n    <visual>\n      <origin\n        xyz=\"0 0 0\"\n        rpy=\"0 0 0\" />\n      <geometry>\n        <mesh\n          filename=\"package://link/meshes/base_link.STL\" />\n      </geometry>\n      <material\n        name=\"\">\n        <color\n          rgba=\"1 1 1 1\" />\n      </material>\n    </visual>\n    <collision>\n      <origin\n        xyz=\"0 0 0\"\n        rpy=\"0 0 0\" />\n      <geometry>\n        <mesh\n          filename=\"package://link/meshes/base_link.STL\" />\n      </geometry>\n    </collision>\n  </link>\n  <link\n    name=\"link1\">\n    <inertial>\n      <origin\n        xyz=\"0.05 1.04083408558608E-17 0\"\n        rpy=\"0 0 0\" />\n      <mass\n        value=\"0.0335342917352885\" />\n      <inertia\n        ixx=\"2.87735927381987E-06\"\n        ixy=\"2.32934060494933E-21\"\n        ixz=\"2.30346855521167E-22\"\n        iyy=\"3.89630886120412E-05\"\n        iyz=\"1.52906451041926E-23\"\n        izz=\"4.12815430236062E-05\" />\n    </inertial>\n    <visual>\n      <origin\n        xyz=\"0 0 0\"\n        rpy=\"0 0 0\" />\n      <geometry>\n        <mesh\n          filename=\"package://link/meshes/link1.STL\" />\n      </geometry>\n      <material\n\n\nname=\"\">\n    <color\n      rgba=\"1 1 1 1\" />\n  </material>\n</visual>\n<collision>\n  <origin\n    xyz=\"0 0 0\"\n    rpy=\"0 0 0\" />\n  <geometry>\n    <mesh\n      filename=\"package://link/meshes/link1.STL\" />\n  </geometry>\n    </collision>\n  </link>\n  <joint\n    name=\"joint1\"\n    type=\"continuous\">\n    <origin\n      xyz=\"0 0 0.06\"\n      rpy=\"-1.5708 -1.033 0\" />\n    <parent\n      link=\"base_link\" />\n    <child\n      link=\"link1\" />\n    <axis\n      xyz=\"0 0 -1\" />\n    <dynamics damping=\"0.7\"/>\n  </joint>\n  <link\n    name=\"link2\">\n    <inertial>\n      <origin\n        xyz=\"0.0847185207825683 -7.7715611723761E-16 -5.85317276699049E-18\"\n        rpy=\"0 0 0\" />\n      <mass\n        value=\"0.0777109513774519\" />\n      <inertia\n        ixx=\"9.11722126446958E-06\"\n        ixy=\"6.56450534122083E-21\"\n        ixz=\"2.83871210352196E-21\"\n        iyy=\"0.0003324057043755\"\n        iyz=\"7.17448377804427E-22\"\n        izz=\"0.000335193630705286\" />\n    </inertial>\n    <visual>\n      <origin\n        xyz=\"0 0 0\"\n        rpy=\"0 0 0\" />\n      <geometry>\n        <mesh\n          filename=\"package://link/meshes/link2.STL\" />\n      </geometry>\n      <material\n        name=\"\">\n        <color\n          rgba=\"1 1 1 1\" />\n      < ...", "answers.gazebosim.org"], "url": "https://answers.ros.org/question/342991/in-the-gazebo-environment-once-dynamic-parameters-are-added-to-the-urdf-model-the-connecting-rod-will-be-fixed-at-the-origin/"}
,{"title": "Failed to running bebop Driver as Node", "time": "2020-01-31 03:59:04 -0600", "post_content": [" ", " ", " ", " ", "I am trying to run the bebop_autonomy driver as a node in ROS Kinetic on Ubuntu 16.04.\nWhen trying to launch the node it first seems fine but at the end it says the the process has died.\nI sourced the workspace beforehand."], "answer": [], "question_code": ["... logging to /home/student/.ros/log/d8a39020-440c-11ea-ada6-48a4727f27d1/roslaunch-student-GL73-8SE-3972.log\nChecking log directory for disk usage. This may take awhile.\nPress Ctrl-C to interrupt\nDone checking log file disk usage. Usage is <1GB.\n\nxacro: Traditional processing is deprecated. Switch to --inorder processing!\nTo check for compatibility of your document, use option --check-order.\nFor more infos, see http://wiki.ros.org/xacro#Processing_Order\nstarted roslaunch server http://student-GL73-8SE:32827/\n\nSUMMARY\n========\n\nPARAMETERS\n * /bebop/bebop_driver/bebop_ip: 192.168.42.1\n * /bebop/bebop_driver/camera_info_url: package://bebop_d...\n * /bebop/bebop_driver/cmd_vel_timeout: 0.2\n * /bebop/bebop_driver/odom_frame_id: odom\n * /bebop/bebop_driver/publish_odom_tf: True\n * /bebop/bebop_driver/reset_settings: True\n * /bebop/bebop_driver/states/enable_altitudechanged: True\n * /bebop/bebop_driver/states/enable_autotakeoffmodechanged: True\n * /bebop/bebop_driver/states/enable_camerastate_orientation: True\n * /bebop/bebop_driver/states/enable_commonstate_batterystatechanged: True\n * /bebop/bebop_driver/states/enable_commonstate_wifisignalchanged: True\n * /bebop/bebop_driver/states/enable_controllerstate_ispilotingchanged: True\n * /bebop/bebop_driver/states/enable_flightplanstate_availabilitystatechanged: True\n * /bebop/bebop_driver/states/enable_flightplanstate_componentstatelistchanged: True\n * /bebop/bebop_driver/states/enable_gpsstate_numberofsatellitechanged: True\n * /bebop/bebop_driver/states/enable_mavlinkstate_mavlinkfileplayingstatechanged: True\n * /bebop/bebop_driver/states/enable_mavlinkstate_mavlinkplayerrorstatechanged: True\n * /bebop/bebop_driver/states/enable_mediastreamingstate_videoenablechanged: True\n * /bebop/bebop_driver/states/enable_numberofsatellitechanged: True\n * /bebop/bebop_driver/states/enable_overheatstate_overheatchanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_altitudechanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_attitudechanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_flattrimchanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_flyingstatechanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_navigatehomestatechanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_positionchanged: True\n * /bebop/bebop_driver/states/enable_pilotingstate_speedchanged: True\n * /bebop/robot_description: <?xml version=\"1....\n * /rosdistro: kinetic\n * /rosversion: 1.12.14\n\nNODES\n  /bebop/\n    bebop_driver (bebop_driver/bebop_driver_node)\n    robot_state_publisher (robot_state_publisher/robot_state_publisher)\n\nROS_MASTER_URI=http://localhost:11311\n\nprocess[bebop/bebop_driver-1]: started with pid [3992]\nWARNING: Package name \"psTutorial\" does not follow the naming conventions. It should start with a lower case letter and only contain lower case letters, digits, underscores, and dashes.\nprocess[bebop/robot_state_publisher-2]: started with pid [3993]\n[ INFO] [1580464041.385539237]: Initializing nodelet with 12 worker threads.\n[ INFO] [1580464041.407180478]: [BebopSDK] 10:47:21:407 | Bebop:225 - Bebop Cnstr()\n[ INFO] [1580464041.407252542]: Nodelet Cstr\n[ INFO] [1580464041.412047723]: Connecting to Bebop ...\n[ INFO] [1580464041.414171485]: [CB] 10:47:21:414 | Ardrone3PilotingStateFlatTrimChanged:388 - [STATES] Enabling states/ardrone3/PilotingState/FlatTrimChanged\n[ INFO] [1580464041.415212966]: [CB] 10:47:21:415 | Ardrone3PilotingStateFlyingStateChanged:432 - [STATES] Enabling states/ardrone3/PilotingState/FlyingStateChanged\n[ INFO] [1580464041.416371767]: [CB] 10:47:21:416 | Ardrone3PilotingStateNavigateHomeStateChanged:534 - [STATES] Enabling states/ardrone3/PilotingState/NavigateHomeStateChanged\n[ INFO] [1580464041.417154537]: [CB] 10:47:21:417 | Ardrone3PilotingStatePositionChanged:592 - [STATES] Enabling states/ardrone3/PilotingState/PositionChanged\n[ INFO] [1580464041.417855382]: [CB] 10:47:21:417 | Ardrone3PilotingStateSpeedChanged:657 - [STATES] Enabling states/ardrone3/PilotingState/SpeedChanged\n[ INFO] [1580464041.418641658]: [CB] 10:47:21:418 | Ardrone3PilotingStateAttitudeChanged:722 - [STATES] Enabling states/ardrone3/PilotingState/AttitudeChanged\n[ INFO] [1580464041.419815576]: [CB] 10:47:21:419 | Ardrone3PilotingStateAltitudeChanged:838 - [STATES] Enabling states/ardrone3/PilotingState/AltitudeChanged\n[ INFO] [1580464041.423148610]: [CB] 10:47:21:423 | Ardrone3MediaStreamingStateVideoEnableChanged:1388 - [STATES] Enabling states/ardrone3/MediaStreamingState/VideoEnableChanged\n[ INFO] [1580464041.424286957]: [CB] 10:47:21:424 | Ardrone3CameraStateOrientation:1490 - [STATES] Enabling states/ardrone3/CameraState/Orientation\n[ INFO] [1580464041.426868449]: [CB] 10:47:21:426 | Ardrone3GPSStateNumberOfSatelliteChanged:1882 - [STATES ..."], "url": "https://answers.ros.org/question/343000/failed-to-running-bebop-driver-as-node/"}
,{"title": "cmake: \"/usr/bin/c++\" is not a full path to an existing compiler tool. [closed]", "time": "2020-01-30 23:41:12 -0600", "post_content": [" ", " ", " ", " ", "INSTALLED ROS VERSION IS 16.04.6 AS BELOW:", "TO EXECUTE NAVIGATION FILE, I FOLLOWED THE PROCESS BELLOW.", "<sending goals=\"\" to=\"\" the=\"\" navigation=\"\" stack=\"\">\n(1) build package", "(2) move to the pkg.", "(3) make a source file and enter the below code.", "Contents of  ", ":", "(4) modify- add below code at the end of ", " in pkg ", "(5) build", "AT HERE, ERROR OCCURS:", "HOW CAN I FIX IT?\nI'LL ATTACH MY CMakeOutput.log.", "This doesn't appear to be a ROS problem, but a pure CMake problem. A ", " shows many generic results. ", "From reading those it looks like you have set some environment variables to override the compiler selection and they may be outdated or slightly malformed. I saw several references to having extra whitespace etc that might get stripped in the debug outputs. Or the removal of distcc or updates to an alternative compiler as the contents of /usr/bin/cc if a link generated by setting your system compiler.\n", "Since this is off topic for this form ..."], "answer": [], "question_details": [" ", " ", "[remote PC]  $roscore", "[turtlebot PC] $ roslaunch turtlebot3_bringup turtlebot3_robot.launch\n3.[Remote PC] $ export TURTLEBOT3_MODEL=waffle_pi\n                     $ roslaunch turtlebot3_navigation turtlebot3_navigation.launch map_file:=$HOME/map.yaml\nand set the initial position of turtlebot by teleopkey. ($ roslaunch turtlebot3_teleop turtlebot3_teleop_key.launch)"], "question_code": ["leejeongmin@leejeongmin-940X5N:~$ cat /etc/issue\nUbuntu 16.04.6 LTS \\n \\l\n", "$ cd ~/catkin_ws/src\n$ catkin_create_pkg simple_navigation_goals move_base_msgs actionlib roscpp\n", "$ roscd simple_navigation_goals\n", "$ cd src\n$ gedit simple_navigation_goals.cpp\n", "simple_navigation_goals.cpp", "#include <ros/ros.h>\n#include <move_base_msgs/MoveBaseAction.h>\n#include <actionlib/client/simple_action_client.h>\n\ntypedef actionlib::SimpleActionClient<move_base_msgs::MoveBaseAction> MoveBaseClient;\n\nint main(int argc, char** argv){\n  ros::init(argc, argv, \"simple_navigation_goals\");\n\n  //tell the action client that we want to spin a thread by default\n  MoveBaseClient ac(\"move_base\", true);\n\n  //wait for the action server to come up\n  while(!ac.waitForServer(ros::Duration(5.0))){\n    ROS_INFO(\"Waiting for the move_base action server to come up\");\n  }\n\n  move_base_msgs::MoveBaseGoal goal;\n\n  //we'll send a goal to the robot to move 1 meter forward\n  goal.target_pose.header.frame_id = \"base_link\";\n  goal.target_pose.header.stamp = ros::Time::now();\n\n  goal.target_pose.pose.position.x = 1.0;\n  goal.target_pose.pose.orientation.w = 1.0;\n\n  ROS_INFO(\"Sending goal\");\n  ac.sendGoal(goal);\n\n  ac.waitForResult();\n\n  if(ac.getState() == actionlib::SimpleClientGoalState::SUCCEEDED)\n    ROS_INFO(\"Hooray, the base moved 1 meter forward\");\n  else\n    ROS_INFO(\"The base failed to move forward 1 meter for some reason\");\n\n  return 0;\n}\n", "CMakeLsists.txt", "simple_navigation_goals", "add_executable(simple_navigation_goals src/simple_navigation_goals.cpp)\ntarget_link_libraries(simple_navigation_goals ${catkin_LIBRARIES}\n", "$ catkin_make\n", "leejeongmin@leejeongmin-940X5N:~/catkin_ws$ catkin_make\nBase path: /home/leejeongmin/catkin_ws\nSource space: /home/leejeongmin/catkin_ws/src\nBuild space: /home/leejeongmin/catkin_ws/build\nDevel space: /home/leejeongmin/catkin_ws/devel\nInstall space: /home/leejeongmin/catkin_ws/install\n####\n#### Running command: \"make cmake_check_build_system\" in \"/home/leejeongmin/catkin_ws/build\"\n####\nCMake Error in CMakeLists.txt:\n  The CMAKE_C_COMPILER:\n\n    /usr/bin/cc\n\n  is not a full path to an existing compiler tool.\n\n  Tell CMake where to find the compiler by setting either the environment\n  variable \"CC\" or the CMake cache entry CMAKE_C_COMPILER to the full path to\n  the compiler, or to the compiler name if it is in the PATH.\n\n\nCMake Error in CMakeLists.txt:\n  The CMAKE_CXX_COMPILER:\n\n    /usr/bin/c++\n\n  is not a full path to an existing compiler tool.\n\n  Tell CMake where to find the compiler by setting either the environment\n  variable \"CXX\" or the CMake cache entry CMAKE_CXX_COMPILER to the full path\n  to the compiler, or to the compiler name if it is in the PATH.\n\n\n-- Configuring incomplete, errors occurred!\nSee also \"/home/leejeongmin/catkin_ws/build/CMakeFiles/CMakeOutput.log\".\nSee also \"/home/leejeongmin/catkin_ws/build/CMakeFiles/CMakeError.log\".\nMakefile:2866: recipe for target 'cmake_check_build_system' failed\nmake: *** [cmake_check_build_system] Error 1\nInvoking \"make cmake_check_build_system\" failed\n", "The system is: Linux - 4 ...", "\ntfoote@snowman4:~/work Last: [1] (0s Seconds)\n$ ll /usr/bin/c++\nlrwxrwxrwx 1 root root 21 Jul 12  2019 /usr/bin/c++ -> /etc/alternatives/c++*\ntfoote@snowman4:~/work Last: [0] (0s Seconds)\n$ ll /usr/bin/cc\nlrwxrwxrwx 1 root root 20 Jul 12  2019 /usr/bin/cc -> /etc/alternatives/cc*\n"], "url": "https://answers.ros.org/question/342979/cmake-usrbinc-is-not-a-full-path-to-an-existing-compiler-tool/"}
,{"title": "Output rosconsole log messages on terminal from remote machine", "time": "2020-01-31 03:27:00 -0600", "post_content": [" ", " ", "Hello,", "I'm having some trouble setting up the rosconsole when used on a remote machine using the \"machine\" tag in my roslaunch file. ", "On both machines I setup the rosconsole.config file so that it shows rosconsole message up to the level \"INFO\" in my terminal (as shown in ", " section2). When I run my roslaunch file locally on each machine everything works fine. However, when I try to run the same launch file on the remote machine using the \"machine\" tag, only the message up to level \"Warning\" are being printed in my terminal. I also noticed that the  $ROSCONSOLE_FORMAT that I set up is not taken into account when using the \"machine\" tag.", "I tried the solutions proposed in ", " (Section 2. and 5.) but none of them are working.", "What am I missing?", "Thanks !"], "answer": [], "url": "https://answers.ros.org/question/342999/output-rosconsole-log-messages-on-terminal-from-remote-machine/"}
,{"title": "MavRos Override conditions ?", "time": "2020-01-21 10:10:31 -0600", "post_content": [" ", " ", " ", " ", "Hi everyone,", "On the Raspberry4 equipped with NAVIO2+,  I try to force the RC output using mavros and a simple \"rostopic pub\".", "I  would like to control 3 servos as channels 3, 4 and 5.", "I'm using ROS Kinetic and sometimes ROS Melodic for ground station. The mavros node is launched directly on the RPI4 but doesn't connect to the shield, I send it an udp stream from APM.", "I also set correctly the id with the cmd :", "What are the conditions on APM and MAVROS to enable correctly an override ?", "I also try the same behavior with APMROVER2 and MavProxy and ended up with this message :"], "answer": [], "question_code": ["rosrun mavparam set SYSID_MYGCS 1\n", "RC override not supported by this FCU!\n"], "url": "https://answers.ros.org/question/342210/mavros-override-conditions/"}
,{"title": "uvc_camera node on Ubuntu 18.04.3 on Oracle Virtual box delivers terrible image.", "time": "2020-01-23 02:00:12 -0600", "post_content": [" ", " ", "some environment info:", "The Ubuntu guvcview works fine, so there should be no problems with the uvc driver and my web cam.", "For your reference to driver environment, I ran:", "I executed:", "But I did it without the launch file, because I have no idea on what to do, also because successful examples I refered to seemed not to use the launch file.", "The output message below:", "Topic lists are:", "Then I tried to run image_view:", "THe image is like 20 ..."], "answer": [], "question_code": ["rosdistro: melodic\nrosversion: 1.14.3\nOracle VM: 6.1\n", "v4l2-ctl -d /dev/video0 \u2013all\nthe result below:\nDriver Info (not using libv4l2):\n        Driver name   : uvcvideo\n        Card type     : VirtualBox Webcam - USB Camera:\n        Bus info      : usb-0000:00:06.0-1\n        Driver version: 5.0.15\n        Capabilities  : 0x84A00001\n                Video Capture\n                Metadata Capture\n                Streaming\n                Extended Pix Format\n                Device Capabilities\n        Device Caps   : 0x04200001\n                Video Capture\n                Streaming\n                Extended Pix Format\nPriority: 2\nVideo input : 0 (Camera 1: ok)\nFormat Video Capture:\n        Width/Height      : 1920/1080\n        Pixel Format      : 'MJPG'\n        Field             : None\n        Bytes per Line    : 0\n        Size Image        : 1228800\n        Colorspace        : sRGB\n        Transfer Function : Default (maps to sRGB)\n        YCbCr/HSV Encoding: Default (maps to ITU-R 601)\n        Quantization      : Default (maps to Full Range)\n        Flags             :\nCrop Capability Video Capture:\n        Bounds      : Left 0, Top 0, Width 1920, Height 1080\n        Default     : Left 0, Top 0, Width 1920, Height 1080\n        Pixel Aspect: 1/1\nSelection: crop_default, Left 0, Top 0, Width 1920, Height 1080\nSelection: crop_bounds, Left 0, Top 0, Width 1920, Height 1080\nStreaming Parameters Video Capture:\n        Capabilities     : timeperframe\n        Frames per second: 25.000 (25/1)\n        Read buffers     : 0\n                     brightness 0x00980900 (int)    : min=0 max=100 step=1 default=50 value=50\n", "rosrun uvc_camera uvc_camera_node\n", "[ INFO] [1579760001.246181062]: using default calibration URL\n[ INFO] [1579760001.247002639]: camera calibration URL: file:///home/comas/.ros/camera_info/camera.yaml\n[ INFO] [1579760001.247141319]: Unable to open camera calibration file [/home/comas/.ros/camera_info/camera.yaml]\n[ WARN] [1579760001.247232595]: Camera calibration file /home/comas/.ros/camera_info/camera.yaml not found.\nopening /dev/video0\npixfmt 0 = 'MJPG' desc = 'Motion-JPEG'\n  discrete: 1920x1080:   1/30 1/25 1/20 1/15 1/10 1/5 \n  discrete: 800x600:   1/30 1/25 1/20 1/15 1/10 1/5 \n  discrete: 1024x768:   1/30 1/25 1/20 1/15 1/10 1/5 \n  discrete: 1280x720:   1/30 1/25 1/20 1/15 1/10 1/5 \n  discrete: 1280x960:   1/30 1/25 1/20 1/15 1/10 1/5 \n  discrete: 1600x900:   1/30 1/25 1/20 1/15 1/10 1/5 \n  discrete: 1600x1200:   1/30 1/25 1/20 1/15 1/10 1/5 \n  discrete: 640x480:   1/30 1/25 1/20 1/15 1/10 1/5 \n  discrete: 2592x1944:   1/15 1/10 1/5 \n  discrete: 3264x2448:   1/15 1/10 1/5 \n  int (Brightness, 0, id = 980900): 0 to 100 (1)\n", "/camera_info\n/image_raw\n/image_raw/compressed\n/image_raw/compressed/parameter_descriptions\n/image_raw/compressed/parameter_updates\n/image_raw/compressedDepth\n/image_raw/compressedDepth/parameter_descriptions\n/image_raw/compressedDepth/parameter_updates\n/image_raw/theora\n/image_raw/theora/parameter_descriptions\n/image_raw/theora/parameter_updates\n/rosout\n/rosout_agg\n", "$rosrun image_view image_view image:=/image_raw\n"], "url": "https://answers.ros.org/question/342369/uvc_camera-node-on-ubuntu-18043-on-oracle-virtual-box-delivers-terrible-image/"}
,{"title": "ERROR: can't locate node in package  [gazebo_ros]", "time": "2017-05-31 07:17:57 -0600", "post_content": [" ", " ", " ", " ", "Hello~ I'm new in ROS and am learning it by the tutorials.However,there were some errors when I followed the  ", ".\nEverthing is normal until I ran the the command:", "However, it seems I can start gazebo  by command line.\n", "I have tried ", ",but it didn't work.", "This is all the files I have in ", ".Is there anything wrong?", "Thanks a lot for your help!", "How did you install ", " -- from source or from apt-get? What does ", " return?", "It returns this:\n/opt/ros/indigo/share/gazebo_ros", "Should I reinstall Gazebo?", "You could certainly try ", " although, that wouldn't explain what went wrong in the first place. Do you have the missing executables in ", " (that's where they should get installed)?", "I tried   ", ".However,the same problem still exist.\nI have attached a screenshot of all the files I got in /opt/ros/indigo/lib/ga zebo_ros/. Is there any problem?\nThanks for your help!", "If that works, then there is likely something wrong with your workspace. Try deleting the build/ and devel/ directories and then re-running ", "Also, as a side note, please stop posting images to show information that is fundamentally text (list files in a directory, error messages, terminal commands, etc.). Images are not searchable nor are they copy/paste-able. Please post this type of thing using the preformatted text button.", "It works just as you said.Thanks a lot. It seems that I have installed gazebo twice.I'm not very familiar with the editor of this website, learning and improving. Thanks for you advice.", "Is your original question resolved? Can you now run your rrobt launch file?"], "answer": [" ", " ", " ", " ", "Do you maybe have an additional copy of ", " in your workspace? Try using rosrun to manually start one of the missing nodes: (i) start ", " (ii) ", " to use just the base install (deactivates your workspace)  (iii) ", " ", " ", "This worked for me:-", "sudo chmod +x /file path*(gzserver)", "sudo chmod +x /file path*(gzclient)", "sudo chmod +x /file path*(spawn_model)", "*means location where the files are present", "for eg:/home/tom/project_ws/src/gazebo_ros/gazebo_ros/scripts/gzclient", " ", " ", "I solved this issue by these steps:\n1. delete build and devel folders.\n2. catkin_make."], "question_code": ["roslaunch rrbot_gazebo rrbot_world.launch\n", "sudo apt-get install --reinstall ros-indigo-gazebo-ros", "/opt/ros/indigo/lib/gazebo_ros/", "gazebo_ros", "rospack find gazebo_ros", "sudo apt-get install --reinstall ros-indigo-gazebo-ros", "/opt/ros/indigo/lib/gazebo_ros/", "sudo apt-get install --reinstall ros-indigo-gazebo-ros", "catkin_make"], "answer_code": ["gazebo_ros", "roscore", "source /opt/ros/indigo/setup.bash", "rosrun gazebo_ros gzserver"], "url": "https://answers.ros.org/question/262907/error-cant-locate-node-in-package-gazebo_ros/"}
,{"title": "ros2 how to implement subscription using RCL", "time": "2020-01-31 05:29:57 -0600", "post_content": [" ", " ", "I am studying RCL.\nI wrote this code and made a simple subscriber.\nI'd like a subscriber to take a message when any message is published.\nHow do I edit it ?", "Thanks.", "Any particular reason to use rcl instead of rclcpp? Could you also clarify what you mean by any message?", "You could have a look here ", " . For the implementation of the LET executor made by Bosch for micro-ROS. It uses most aspects of the RCL layer in a simple to follow way using C. Hope this helps you ^^", "Thank you so much for a comment.\nActually, I try to make client library in other language by wrapping RCL, so I submitted this question.\nI also checked micro-ROS implementation, and it seems that functions related to rcl_wait_set_t are suitable for my purpose.\nThanks.", "There was also some talk about work on RCLC, so a C layer sitting on top of RCL, in the RealTime working group on ROS discourse. I'm not sure if work on this has already started/continued or not. I believe this is also an effort by Bosch. They are looking at C, because they are dealing with micro-controllers/-processors. Depending on what language you want to wrap you could maybe seek contact with the RT WG people. They do a lot of things with RCL and helped me a lot when I was looking at the C++ executor. Make sure to not post straight up questions on Discourse though (that's what ROS answers is for) and please don't derail the working group with off topic discussions :P. Just saying there are some smart people there that could have useful info in case you get stuck."], "answer": [], "question_code": ["int main(int argc,const* argv[]){    \nrcl_init_options_t initOptions = rcl_get_zero_initialized_init_options();\nrcl_init_options_init(&initOptions, rcutils_get_default_allocator());\nrcl_context_t context = rcl_get_zero_initialized_context();\nrcl_init(argc, argv, &initOptions, &context);\nrcl_init_options_fini(&initOptions);\n\nrcl_node_t node = rcl_get_zero_initialized_node();\nrcl_node_options_t nodeOptions = rcl_node_get_default_options();\nrcl_node_init(&node, \"node_name\", \"node_namespace\", &context, &nodeOptions);\nconst rosidl_message_type_support_t * typeSupport = ROSIDL_GET_MSG_TYPE_SUPPORT(std_msgs, msg, String);\nrcl_subscription_t subscription = rcl_get_zero_initialized_subscription();\nrcl_subscription_options_t subscriptionOptions = rcl_subscription_get_default_options();\nrcl_subscription_init(&subscription, &node, typeSupport, \"test_topic\", &subscriptionOptions);\nstd_msgs__msg__String msg;\nrmw_message_info_t messageInfo;\nrcl_take(&subscription, &msg, &messageInfo);\nrcl_subscription_fini(&subscription, &node);\nrcl_node_fini(&node);\nreturn 0;\n}\n"], "url": "https://answers.ros.org/question/343008/ros2-how-to-implement-subscription-using-rcl/"}
,{"title": "What is the /odom topic?", "time": "2020-01-22 22:38:53 -0600", "post_content": [" ", " ", " ", " ", "Hello, I'm working on ROS kinetic in Ubuntu 16.04.", "I have a simple question; what is the ", " topic?", "Of course I know it represents the pose of mobile robot at every time, but", "is ", " topic the result of localization?", "When I launch ", " node with my robot, in this case, ", "is it ok if i adopt ", " as the robot's localized state by like ", " or ", "?"], "answer": [" ", " ", "The ", " topic represents more then just the \"pose\" of the mobile robot. If you check the ", " (which is usually used for this kind of message), you see that it also contains the current velocity, as well as the respective uncertainties.", "Typically, the odometry describes the \"internal\" state of the robot, i.e. the integrated position using wheel encoders and, potentially with fused IMU or other sensors measuring internal state. Often it is also used when you fuse a GNSS sensor. Obviously, then you get more in the direction of a localization system then only tracking internal state (see the ", ").", "About ", ", though...\n", " ", " the ", " topic (as per the wiki). So the answer to ", "is it ok if i adopt /odom as the robot's localized state ", "would be no. Seems the ", " topic comes from somewhere else. You can use the ", " topic for that, or use the published transform."], "question_code": ["/odom", "/odom", "amcl", "/odom", "EKF", "UKF"], "answer_code": ["odom", "nav_msgs/Odometry", "amcl", "amcl", "odom", "odom", "amcl_pose"], "url": "https://answers.ros.org/question/342361/what-is-the-odom-topic/"}
,{"title": "Resource not found", "time": "2019-12-10 07:03:01 -0600", "post_content": [" ", " ", " ", " ", "Hi, ", "I am working within a simple ROS workspace where I have two packages. ", "I have included in my workspace (as a new package, \"", "\") a configuration generated by ", ". My question is about this particular package.  The configuration generated by ", " already creates different launch files. ", "I can build the workspace correctly, and then using ", "  I can successfully run, for example. ", "roslaunch  robotic_moveit_config demo.launch", "and so I can test simple planning scenarios in ", ". ", "At the same time, I am trying to write some simple motion planning programs. ", "zahid_test_workspace", "Here, when I try to issue ", "I receive the following error.\nResource not found: ur_description", "Although before running roslaunch, I do the following", "The strange thing is that, other day, I was able to launch my program.\nHere is the launch file that I am using. ", "thanks, ", "Zahid", "Did you build your workspace before calling ", "? Can you please add the output of ", "?", "I build the package using, \n", " \nfollowed by \n", "\n then I issued \n", "The complete error is follows", "and the output from echo $ROS_PACKAGE_PATH", "I explicitly added the following path ", "to the ", ". Then, to confirm I issue ", " and I receive the following output", "The directory ", " is found under ", ", and therefore I added this path. Following this, I issue ", "  and ", "  and still see the following", "i tried the following", "adding the following line to the ", " file. ", "export ROS_PACKAGE_PATH=~/catkin_ws/src/universal_robot:${ROS_PACKAGE_PATH}", "copying the directory ", " under ", "But, still the same problem persists. ", "thanks for your time.", "It would be wonderful if anyone could answer this question, as I am receiving the same results regardless of the ROS paths I indicated."], "answer": [" ", " ", " ", " "], "answer_details": ["The package ", " is not released for meldoic, yet.\n", "You can get the source code from ", " .", "Clone it from github into a folder in your workspaces src folder ", "Please never manually edit the ", "Try to work with ONE workspace only. In it:\n", "you have one src folder with multiple subfolders, e.g.: \n", " (from the repo above) and also ", " (from the MoveIt setup assistant)", "There should also be a file ", ", that was generated by ", "Remove ", " and ", " folder, ", "in a clean terminal source only ", "build the workspace", "after this, ", " is sufficient.", " ", " ", " ", " "], "question_code": ["src  \n--  my_test_pkg\n--   ur5_moveit_config \n\n      -- include\n      -- src\n      -- launch    \n         -- smp.launch\n", "roslaunch ur5_moveit_config smp.launch\n", "source /opt/ros/melodic/setup.bash\nsource ~/catkin_ws/devel/setup.bash\nsource devel/setup.bash\n", "<launch>\n<include file=\"$(find ur5_moveit_config)/launch/demo.launch\"/>\n<node name=\"ur5\" pkg=\"ur5_moveit_config\" type=\"ur5\" respawn=\"false\" output=\"screen\"/>\n</launch>\n", "source devel/setup.bash", "echo $ROS_PACKAGE_PATH", "catkin clean", "catkin build", "source devel/setup.bash", "Resource not found: ur_description\nROS path [0]=/opt/ros/melodic/share/ros\nROS path [1]=/home/zahid/Desktop/IMPLEMENTATIONS/zahid_test_ws/src\nROS path [2]=/opt/ros/melodic/share\nThe traceback for the exception was written to the log file\n", "/home/zahid/ws_moveit/src/ros-moveit-arm/moveit_plugin:/home/zahid/ws_moveit/src/moveit_tutorials:/home/zahid/ws_moveit/src/ros-moveit-arm/my_arm_xacro:/home/zahid/ws_moveit/src/panda_moveit_config:/opt/ros/melodic/share\n", "export ROS_PACKAGE_PATH=/home/zahid/catkin_ws/src/universal_robot:$ROS_PACKAGE_PATH\n", "ROS_PACKAGE_PATH", "echo $ROS_PACKAGE_PATH", "/home/zahid/catkin_ws/src/universal_robot:/home/zahid/Desktop/IMPLEMENTATIONS/zahid_test_ws/src/my_test_pkg:/home/zahid/Desktop/IMPLEMENTATIONS/zahid_test_ws/src/ur5_moveit_config:/opt/ros/melodic/share\n", "ur_description", "/home/zahid/catkin_ws/src/universal_robot", "source devel/setup.bash", "roslaunch robotic_moveit_config smp.launch", "Resource not found: ur_description\nROS path [0]=/opt/ros/melodic/share/ros\nROS path [1]=/home/zahid/Desktop/IMPLEMENTATIONS/zahid_test_ws/src/my_test_pkg\nROS path [2]=/home/zahid/Desktop/IMPLEMENTATIONS/zahid_test_ws/src/ur5_moveit_config\nROS path [3]=/opt/ros/melodic/\n", "~/.bashrc", "ur_description", "/home/zahid/Desktop/IMPLEMENTATIONS/zahid_test_ws/src/ur5_moveit_config/"], "answer_code": ["ur_description", "ROS_PACKAGE_PATH", "universal_robot", "my_test_pkg", "CMakeLists.txt", "catkin_init_workspace", "devel", "build", "source /opt/ros/melodic/setup.bash", "source ~/catkin_ws/devel/setup.bash"], "url": "https://answers.ros.org/question/339600/resource-not-found/"}
,{"title": "rclpy commend crushed in ROS2", "time": "2018-10-31 08:32:31 -0600", "post_content": [" ", " ", " ", " ", "what is the mean of SYntaxError: invalid syntax ini rclpy/__init__.py?\nPlease help this question ", "We're gonna need a lot more information to be of use here... What is ", "?"], "answer": [" ", " ", "You're using Python 2 (", ") but rclpy and all of ROS 2 supports only Python 3 so you should run the following "], "question_code": ["python db_reader.py\nTraceback (most recent call last):\n  File db_reader.py\", line 3, in <module>\n    import rclpy\n  File \"/opt/ros/bouncy/lib/python3.6/site-packages/rclpy/__init__.py\", line 23\n    def init(*, args=None):\n              ^\nSyntaxError: invalid syntax\n", "db_reader.py"], "answer_code": ["python db_reader.py", "python3 db_reader.py"], "url": "https://answers.ros.org/question/307323/rclpy-commend-crushed-in-ros2/"}
,{"title": "Calculate Joint Effort", "time": "2020-01-23 04:52:46 -0600", "post_content": [" ", " ", "Hi, I am building currently my URDF data for my own robot. The whole inertia parameter is already calculated through the CAD Software. I just imagine how could I calculate the limit effort of my joint? I think it is necessary to do the simulation with PyBullet or Gazebo. Otherwise the model will collapse, right?", "Any suggestion for it? Or has somebody done it before? "], "answer": [], "url": "https://answers.ros.org/question/342384/calculate-joint-effort/"}
]
