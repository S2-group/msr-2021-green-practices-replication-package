,{"git_repo_name": "pandora_ros_pkgs", "code_comments_file_names": ["pose_estimation_node", "pose_estimation", "pandora_slam_2d", "pandora_slam_2d_node", "laser_scan_to_point_cloud_converter", "laser_scan_to_point_cloud_converter_node", "pandora_icp_slam_3d_kinect", "pandora_icp_slam_3d_kinect_node", "pandora_icp_slam_3d_laser", "pandora_icp_slam_3d_laser_node", "pandora_icp_slam_3d_kinect_map_node", "pandora_icp_slam_3d_kinect_map", "pandora_icp_slam_3d_laser_map_node", "pandora_icp_slam_3d_laser_map", "setup", "test_flow", "test_move_end_effector_server", "test_effector_clients", "test_move_end_effector_server", "test_client_factory", "command_mapping_dict", "client_factory", "__init__", "effector_clients", "move_end_effector_server", "move_eef_script", "topics", "client_dict", "client_list", "end_effector_controller_node", "states", "mock_end_effector_planner", "__init__", "goal_maker", "action_servers", "setup", "stabilizer_control_node", "stabilizer_control", "test_pandora_stabilizer_node", "setup", "sensor_orientation_controller", "__init__", "__init__", "move_kinect_script", "move_head_script", "setup", "linear_actuator_controller", "__init__", "__init__", "move_linear_actuator_script", "motors_keyop", "motors_keyop_node", "motors_joyop", "keyop", "joyop", "setup", "__init__", "__init__", "dataset_utils", "motion_reward", "experiment", "kinodynamic_control", "params", "navigation_environment", "navigation_task", "utils", "__init__", "linear_fusion", "goal_cost", "trajectory_cost", "fuse_cost_node", "__init__", "fusion_strategy", "cost_node", "move_base", "move_base_node", "mock_local_patcher", "static_patch", "setup", "__init__", "__init__", "move_base", "setup", "range_to_point_cloud_converter", "point_cloud_cropper", "mock_data_fusion", "hard_obstacle_patcher", "tururu", "mock_params", "obstacle_test", "map_utils_test", "__init__", "obstacle", "map_utils", "map_patch_params", "map_patch", "setup", "co2_widget", "widget_info", "message_data_model", "__init__", "battery_widget", "pandora_gui", "console", "save_mission_client", "probability_info", "rpc_client", "console_widget", "sonars_widget", "temp_widget", "standar_widget", "main_widget", "gui_state_client", "victim_found_server", "__init__", "rqt_gui", "listener", "victim_action_client", "talker", "victim_propabilities", "pandora_rqt_gui", "pointcloud_to_image_converter", "discrete_wavelet_transform", "discrete_wavelet_transform_test", "victim_hole_preprocessor", "victim_hole_processor", "victim_node", "victim_handler", "victim_parameters", "victim_vj_detector", "victim_image_processor", "victim_image_preprocessor", "victim_postprocessor", "rgb_feature_extraction", "edge_orientation_extractor", "channels_statistics_extractor", "depth_feature_extraction", "sift_extractor", "histogram_extractor", "feature_extraction", "haralickfeature_extractor", "hog_extractor", "color_angles_extractor", "mean_std_dev_extractor", "dft_coeffs_extractor", "dominant_color_extractor", "neural_network_validator", "random_forests_validator", "validator_factory", "neural_network_classifier", "abstract_validator", "victim_training_node", "rgbd_svm_validator", "svm_classifier", "abstract_classifier", "random_forests_classifier", "classifier_factory", "rgb_random_forests_classifier", "rgbd_svm_classifier", "svm_validator", "feature_extraction_utilities", "principal_component_analysis", "bag_of_words_trainer", "file_utilities", "platt_scaling", "accuracy_test", "victim_benchmark_test", "haralickfeature_extractor_test", "sift_extractor_test", "histogram_extractor_test", "edge_orientation_extractor_test", "dominant_color_test", "mean_std_dev_test", "color_angles_test", "random_dataset_creator", "check_annotations_file", "transform_annotations_to_full_frame", "benchmark_tests_automation", "rename_dataset", "training_automation", "qrcode_detector", "qrcode_processor", "qrcode_preprocessor", "qrcode_node", "qrcode_handler", "qrcode_postprocessor", "accuracy_test", "qrcode_benchmark_test", "qrCode_detector_test", "obstacle_postprocessor", "obstacle_preprocessor", "hard_obstacle_handler", "hard_obstacle_postprocessor", "dummy_processor", "hard_obstacle_node", "hard_obstacle_preprocessor", "traversability_mask", "dummy_main", "hard_obstacle_detector", "hard_obstacle_processor", "barrel_handler", "barrel_processor", "barrel_node", "fast_symmetry_detector", "barrel_detector", "parameters", "soft_obstacle_handler", "soft_obstacle_detector", "soft_obstacle_processor", "soft_obstacle_node", "barrel_benchmark_test", "rename_bag_topic", "barrel_detector_test", "fast_symmetry_detector_test", "traversability_mask_test", "soft_obstacle_detector_test", "setup", "image_saver_by_topic", "enhanced_image_shower", "rgb_to_enhanced", "__init__", "__init__", "vision_benchmark_test_base", "pkg.develspace.context.pc", "pkg.installspace.context.pc", "setup", "annotator_controller", "annotator_connector", "annotator_node", "annotator_loader", "annotator_application", "annotator_tools", "__init__", "images_to_bag", "split_bag", "motion_preprocessor", "motion_postprocessor", "motion_handler", "motion_processor", "motion_node", "motion_detector", "dbscan", "motion_detector_test", "landoltc_postprocessor", "landoltc_preprocessor", "landoltc_node", "landoltc_handler", "landoltc_detector", "landoltc_parameters", "landoltc3d_parameters", "landoltc3d_detection", "landoltc3d_node", "landoltc3d_detector", "accuracy_test", "landoltc_benchmark_test", "landoltc_detector_test", "landoltc3d_detector_test", "datamatrix_node", "datamatrix_detector", "datamatrix_preprocessor", "datamatrix_postprocessor", "datamatrix_handler", "datamatrix_processor", "datamatrix_detector_test", "color_processor", "color_handler", "color_preprocessor", "color_node", "color_postprocessor", "color_detector", "color_detector_test", "predator_node", "predator", "orb_detector", "feature_matching_detector", "hazmat_postprocessor", "sift_detector", "hazmat_handler", "planar_object_detector", "hazmat_processor", "detector_factory", "hazmat_node", "hazmat_preprocessor", "surf_detector", "image_signature", "surf_trainer", "factory", "sift_trainer", "hazmat_trainer_node", "planar_pattern_trainer", "orb_trainer", "accuracy_test", "hazmat_benchmark_test", "feature_matching_test", "trainer_test", "image_signature_test", "thermal_node", "thermal_hole_detector", "thermal_cropper", "thermal", "thermal_cropper_node", "noise_elimination", "holes_conveyor", "histogram", "blob_vector", "outline_discovery", "image_matching", "wavelets", "visualization", "bounding_box_detection", "edge_detection", "blob_detection", "morphological_operators", "message_conversions", "parameters", "hole_filters", "rgb", "rgb_hole_detector", "noise_elimination", "holes_conveyor", "histogram", "blob_vector", "outline_discovery", "image_matching", "wavelets", "visualization", "bounding_box_detection", "edge_detection", "blob_detection", "morphological_operators", "message_conversions", "parameters", "hole_filters", "timer", "filters", "planes_detection", "hole_fusion", "hole_merger", "hole_validation", "rgb_filters", "filters_resources", "depth_filters", "hole_uniqueness", "noise_elimination", "holes_conveyor", "histogram", "blob_vector", "outline_discovery", "image_matching", "wavelets", "visualization", "bounding_box_detection", "edge_detection", "blob_detection", "morphological_operators", "message_conversions", "parameters", "hole_filters", "depth_hole_detector", "depth", "noise_elimination", "holes_conveyor", "histogram", "blob_vector", "outline_discovery", "image_matching", "wavelets", "visualization", "bounding_box_detection", "edge_detection", "blob_detection", "morphological_operators", "message_conversions", "parameters", "hole_filters", "pc_thermal_synchronizer", "hole_detector_test", "hole_benchmark_test", "hole_detector_test", "holes_conveyor_test", "message_conversions_test", "morphological_operators_test", "noise_elimination_test", "wavelets_test", "outline_discovery_test", "edge_detection_test", "blob_vector_test", "visualization_test", "hole_filters_test", "bounding_box_detection_test", "hole_merger_test", "rgb_filters_test", "hole_validation_test", "hole_uniqueness_test", "filters_test", "filters_resources_test", "depth_filters_test", "planes_detection_test", "hole_detector_test", "rgb_depth_thermal_synchronizer", "interface_tester", "tf_monitor", "interfaces_xml_parser", "node_diagnostics", "generic_diagnostic", "interface_diagnostics_node", "interface_diagnostics", "bounds_check", "bounds_check_subscriber", "overall_main_motor_control_checker", "main_motor_state_checker", "butterfly_checker", "irs_checker", "mlx_checker", "sonars_checker", "co2_checker", "tpa_checker", "compass_checker", "overall_controllers_checker", "xmega_hardware_interface", "xmega_hardware_interface_node", "battery_controller", "range_sensor_controller", "encoder_sensor", "test", "range_sensor", "battery_sensor", "xmega_serial_interface", "linear_actuator_hardware_interface_node", "linear_actuator_hardware_interface", "firgelli_com_interface", "jrk_com_interface", "jrk_communicator", "thermal_sensor_controller", "battery_controller", "co2_sensor_controller", "range_sensor_controller", "arm_hardware_interface_node", "arm_hardware_interface", "arm_usb_interface", "arm_usb_interface_demo", "imu_hardware_interface", "imu_hardware_interface_node", "imu_rpy_controller", "ahrs_com_interface", "trax_ahrs_configuration_node", "imu_com_interface", "cpu_temperature_monitor", "battery_monitor", "state_indicator", "serial_epos2_handler", "epos2_test", "epos_serial_gateway", "Utils", "serial_epos_handler", "test", "abstract_epos_handler", "error_codes_test", "epos2_gateway", "motor_hardware_interface", "motor_hardware_interface_node", "skid_steer_velocity_controller", "skid_steer_torque_controller", "leddar_hardware_interface", "leddar_hardware_interface_node", "Leddar", "leddar_serial_interface_demo", "OS", "leddar_serial_interface", "Modbus", "leddar_usb_interface_demo", "leddar_usb_interface", "leddar_sensor_controller", "joint_states_wrapper", "gio_gazebo_interface", "pandora_wheel_physics_plugin", "pandora_fdir_plugin", "pandora_differential_plugin", "pandora_microphone_plugin", "pandora_co2_plugin", "pandora_sonar_plugin", "pandora_thermal_plugin", "pandora_p3d_plugin", "pandora_imu_stabilizer_plugin", "setup", "end", "init", "sensor_hold", "identification", "fusion_validation", "victim_deletion", "operator_validation", "exploration", "fsm_framework", "utilities", "world_model", "navigator", "effector", "explorer", "data_fusion", "gui", "victim_validator", "mocks", "agent_standalone", "__init__", "topics", "target", "agent", "config", "utils", "__init__", "navigator", "effector", "explorer", "data_fusion", "gui", "__init__", "msgs", "action_servers", "publishers", "__init__", "transition", "machine", "state", "event", "agent_end_effector_test", "data_fusion_agent_test", "agent_explorer_test", "hole_data_fusion_test", "setup", "__init__", "processing", "setup", "__init__", "capture", "monitor", "record", "transport_image_topics", "setup", "state_server", "state_client", "state_client_nodelet", "state_changer", "state_manager_test", "__init__", "state_client", "test_client", "sensor_processor_test", "dummy_handler", "dummy_processor", "dummy_preprocessor", "dummy_processor_node", "dummy_postprocessor", "setup", "bag_player_for_tests", "customized_player", "map_loader", "__init__", "dummy_node", "test_dummy_node", "__init__", "bcolors", "mocksubscriber", "moxcomparators", "messageInfoParser", "generic_mock", "__init__", "dummy_node", "test_dummy_node", "__init__", "test_base", "alert_delivery", "integration_tester", "utils", "watchdog", "watchdog_monitor", "mutex_guard", "standalone_mutex", "remote_mutex", "kinect_movement_filter", "parse_extra_files", "download_checkmd5", "exploration_controller", "exploration_controller_node", "navfn_frontier_path_generator", "navfn_service_frontier_path_generator", "map_frontier_search", "frontier_goal_selector", "distance_cost_function", "visited_cost_function", "alignment_cost_function", "size_cost_function", "frontier_selector_test", "exploration_caller", "map_frontier_search_test", "costmap_tools_test", "setup", "__init__", "__init__", "explorer", "surface_checker", "sensor_coverage", "main", "sensor", "utils", "coverage_checker", "sensor_planner", "sensor_planner_node", "interactive_command_publisher_marker", "interactive_tf_publisher_marker", "temprature_visualization", "data_fusion_object_visualization", "pandora_qr_csv_node", "qr_csv_creator", "objects_srv", "save_csv", "server", "creator", "pandora_geotiff_node", "objects_srv", "utilities", "geotiff_creator_test", "save_mission_client", "talker", "utils", "ros_tf_listener", "utils_test", "pandora_alert_handler_node", "object_factory", "alert_handler", "landoltc", "motion", "obstacle", "visual_victim", "qr", "sound", "co2", "soft_obstacle", "hard_obstacle", "hole", "hazmat", "thermal", "victim", "barrel", "data_matrix", "filter_model", "victim_handler", "victim_clusterer", "object_handler", "victim_list", "obstacle_list", "subscriber_test", "mass_alert_publisher", "alert_handler_test", "test_base", "alert_handler_static_test", "object_list_test", "object_factory_test", "victim_clusterer_test", "victim_test", "objects_test", "victim_list_test", "clusterer", "thermal_node", "co2_processor", "co2_node", "utils", "thermal_processor", "co2_processor_test", "test_base", "thermal_processor_test", "clusterer_test", "utils_test", "pose_finder", "pose_finder_test", "keypoint_transformer", "view_pose_finder", "roi_transformer", "frame_matcher_node", "frame_matcher", "matcher_processor", "enhanced_image_postprocessor", "candidate_hole_postprocessor", "enhanced_image_preprocessor", "frame_matcher_functional"], "md_file_names": ["README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README"], "md_contents": {"README": ["pandora_data_fusion [![Build Status](http://jenkins.pandora.ee.auth.gr/buildStatus/icon?job=test-pandora_data_fusion/hydro-devel)](http://jenkins.pandora.ee.auth.gr/job/test-pandora_data_fusion/branch/hydro-devel/)\n", "===================\n", "\n", "Data and victim fusion implementation for pandora UGV.\n"]}, "code_comments_c++": {"pose_estimation_node": ["*******************************************************************"], "pose_estimation": ["*******************************************************************", " Initialize exponential decay filter", " Maybe it's something else relatively to /map frame", "DEBUG z", "DEBUG z --> Publish IMU RPY", "MultiArrayDimension", "float", "float", "float", " Get frame flat", " Get difference in x and y", " Find difference in z", " TODO(lynx): interpolation steps as parameter", " Update previousOrigin", " Broadcast updated footprint transform", "tf::Vector3 translationZ(0, 0, final_z);", " For testing purposes: keep z in internal state without affecting others", "DEBUG z", "MultiArrayDimension", "float", "float", "float", "float", "float", " Broadcast updated base stabilized", " base_stabilized -> base_link", "Measure exec time and INFO rate", "", " Newest measurements at the front of the queue!", " Accumulators", "Leave 1 element in queue as starting point for next loop", "TODO(lynx): exp filter IMU", "", "", "the 0.9 factor might help reduce quantization error?", " namespace pandora_pose_estimation"], "pandora_slam_2d": ["*******************************************************************", "", "", " namespace pandora_slam_2d"], "pandora_slam_2d_node": ["*******************************************************************", "!< Main function of the node"], "pandora_icp_slam_3d_kinect": ["Inverse"], "pandora_icp_slam_3d_kinect_node": [" Use 4 threads", " spin() will not return until the node has been shutdown"], "pandora_icp_slam_3d_laser": ["Inverse"], "pandora_icp_slam_3d_laser_node": [" Use 4 threads", " spin() will not return until the node has been shutdown"], "pandora_icp_slam_3d_kinect_map_node": [" Use 4 threads", " spin() will not return until the node has been shutdown"], "pandora_icp_slam_3d_kinect_map": ["Inverse"], "pandora_icp_slam_3d_laser_map_node": [" Use 4 threads", " spin() will not return until the node has been shutdown"], "pandora_icp_slam_3d_laser_map": ["Inverse"], "stabilizer_control_node": ["*******************************************************************"], "stabilizer_control": ["*******************************************************************", " namespace", " Invert commands in order to stabilize", " Convert degs to rads", " Add offsets", " Check commands' limits", " Publish roll command", " Publish pitch command", " namespace pandora_control"], "sensor_orientation_controller": ["*******************************************************************", " namespace", " get params from param server", " set the action state to aborted", " Invert command in order to stabilize", " Convert degs to rads", " set the action state to succeeded", " namespace pandora_control"], "linear_actuator_controller": ["*******************************************************************", " get params from param server", " set the action state to aborted", " Parse robot description", " Get current link and its parent", " Step could be a param", " set the action state to succeeded", " set the action state to preempted", " set the action state to succeeded", " set the action state to preempted", " set the action state to succeeded", " set the action state to succeeded", " set the action state to preempted", " set the action state to preempted", " set the action state to succeeded", " set the action state to preempted", " set the action state to succeeded", " namespace pandora_control"], "motors_keyop": ["*******************************************************************", " get the console in raw mode", " Setting a new line, then end of file", " get the next event from the keyboard", " ~ linear_=angular_=0;", " namespace pandora_teleop"], "motors_keyop_node": ["*******************************************************************"], "move_base": ["*******************************************************************", "get some parameters that will be global to the move base node", "set up plan triple buffer", "set up the planner's thread", "for comanding the base", "we'll provide a mechanism for some people to send goals as PoseStamped messages over a topic", "they won't get any useful information back about its status, but this is useful for tools", "like nav_view and rviz", "we'll assume the radius of the robot to be consistent with what's specified for the costmaps", "create the ros wrapper for the planner's costmap... and initializer a pointer we'll use with the underlying map", "initialize the global planner", "check if a non fully qualified name has potentially been passed in", "if we've found a match... we'll get the fully qualified name and break out of the loop", "create the ros wrapper for the controller's costmap... and initializer a pointer we'll use with the underlying map", "create a local planner", "check if a non fully qualified name has potentially been passed in", "if we've found a match... we'll get the fully qualified name and break out of the loop", " Start actively updating costmaps based on sensor data", "advertise a service for getting a plan", "advertise a service for clearing the costmaps", "if we shutdown our costmaps when we're deactivated... we'll do that now", "load any user specified recovery behaviors, and if that fails load the defaults", "initially, we'll need to make a plan", "we'll start executing recovery behaviors at the beginning of our list", "we're all set up now so we can start the action server", "The first time we're called, we just want to make sure we have the", "original configuration", "if someone sets restore defaults on the parameter server, prevent looping", "initialize the global planner", "check if a non fully qualified name has potentially been passed in", "if we've found a match... we'll get the fully qualified name and break out of the loop", " wait for the current planner to finish planning", " Clean up before initializing the new planner", "create a local planner", "check if a non fully qualified name has potentially been passed in", "if we've found a match... we'll get the fully qualified name and break out of the loop", " Clean up before initializing the new planner", "we need to be able to publish velocity commands", "update feedback to correspond to our curent position", "push the feedback out", "check to see if we've moved far enough to reset our oscillation timeout", "if our last recovery was caused by oscillation, we want to reset the recovery index", "check that the observation buffers for the costmap are current, we don't want to drive blind", "if we have a new plan then grab it and give it to the controller", "make sure to set the new plan flag to false", "do a pointer swap under mutex", "ABORT and SHUTDOWN COSTMAPS", "disable the planner thread", "make sure to reset recovery_index_ since we were able to find a valid plan", "the move_base state machine, handles the control logic for navigation", "if we are in a planning state, then we'll attempt to make a plan", "if we're controlling, we'll attempt to find valid velocity commands", "check to see if we've reached our goal", "disable the planner thread", "check for an oscillation condition", "make sure that we send the velocity command to the base", "check if we've tried to find a valid control for longer than our time limit", "we'll move into our obstacle clearing mode", "otherwise, if we can't find a valid control, we'll go back to planning", "enable the planner thread in case it isn't running on a clock", "we'll try to clear out space with any user-provided recovery behaviors", " Fix me (tsompania)", "we'll invoke whatever recovery behavior we're currently on if they're enabled", "we at least want to give the robot some time to stop oscillating after executing the behavior", "we'll check if the recovery behavior actually worked", "update the index of the next recovery behavior that we'll try", "disable the planner thread", "disable the planner thread", "we aren't done yet", " Not used inside move_base", "clear the costmaps", " Not used inside move_base", "make sure we have a costmap for our planner", "if the user does not specify a start pose, identified by an empty frame id, then use the robot's pose", "update the copy of the costmap the planner uses", "if we have a tolerance on the goal point that is greater", "than the resolution of the map... compute the full potential function", "copy the plan into a message to send out", " This is used for nav_view and rviz", "clear the planner's costmap", "clear the controller's costmap", "make sure to set the plan to be empty initially", "since this gets called on handle activate", "get the starting pose of the robot", " planner_ is ptr to a GlobalPlanner object", "if the planner fails or returns a zero length plan, planning failed", " plan will be filled with the calculated", "first we need to check if the quaternion has nan's or infs", "next, we need to check if the length of the quaternion is close to zero", "next, we'll normalize the quaternion and check that it transforms the vertical vector correctly", " takes the goal msg pose data and set them to the goal pose", "just get the latest available transform... for accuracy they should send", "goals in the frame of the planner", " Can throw InvalidArgument if quaternion is malformed or LookupException", " (Lookup exception) The most common reason for this is that the frame is not being published,", " or a parent frame was not set correctly causing the tree to be broken.", "check if we should run the planner (the mutex is locked)", "if we should not be running the planner then suspend this thread", "time to plan! get a copy of the goal and unlock the mutex", " planner_goal_ is a poseStamped message", "run planner", " planner_plan is a ptr to a vector of poseStamped messages(each vector is a plan)", "pointer swap the plans under mutex (the controller will pull from latest_plan_)", "make sure we only start the controller if we still haven't reached the goal", "if we didn't get a plan and we are in the planning state (the robot isn't moving)", "check if we've tried to make a plan for over our time limit", "we'll move into our obstacle clearing mode", "take the mutex for the next iteration", "we will try our best to find a valid plan, by moving the given goal", "we have a goal so start the planner", "we want to make sure that we reset the last time we had a valid plan and control", "if we're active and a new goal is available, we'll accept it, but we won't shut anything down", "we will try our best to find a valid plan, by moving the given goal", "we'll make sure that we reset our state for the next execution cycle", "we have a new goal so make sure the planner is awake", "publish the goal point to the visualizer", "make sure to reset our timeouts", "if we've been preempted explicitly we need to shut things down", "notify the ActionServer that we've successfully preempted", "we'll actually return from execute after preempting", "we also want to check if we've changed global frames because we need to transform our goal pose", "we want to go back to the planning state for the next execution cycle", "we have a new goal so make sure the planner is awake", "publish the goal point to the visualizer", "make sure to reset our timeouts", "for timing that gives real time even in simulation", "the real work on pursuing a goal is done here", "if we're done, then we'll return from execute", "check if execution of the goal has completed in some way", "make sure to sleep for the remainder of our cycle time", "wake up the planner thread so that it can exit cleanly", "if the node is killed then we'll abort and return", "check for recovery behaviors with the same name", "if we've made it to this point, we know that the list is legal so we'll create all the recovery behaviors", "check if a non fully qualified name has potentially been passed in", "if we've found a match... we'll get the fully qualified name and break out of the loop", "shouldn't be possible, but it won't hurt to check", "initialize the recovery behavior with its name", "if no recovery_behaviors are specified, we'll just load the defaults", "if we've made it here... we've constructed a recovery behavior list successfully", "we'll load our default recovery behaviors here", "we need to set some parameters based on what's been passed in to us to maintain backwards compatibility", "first, we'll load a recovery behavior to clear the costmap", "next, we'll load a recovery behavior to rotate in place", "next, we'll load a recovery behavior that will do an aggressive reset of the costmap", "we'll rotate in-place one more time", "if we shutdown our costmaps when we're deactivated... we'll do that now", " converts the goal coordinates from world coordinates to map coordinates", " returns True if conversion was successful", "if cell is free, nothing to do", "try to find a valid cell, we will accept NO_INFORMATION cells also", "costmap_2d::CIRCUMSCRIBED_INFLATED_OBSTACLE", "update goal"], "move_base_node": ["ros::MultiThreadedSpinner s;"], "range_to_point_cloud_converter": ["*******************************************************************", " x", " y", " z", " namespace pandora_navigation"], "point_cloud_cropper": ["*******************************************************************", "stop pcl from spamming", "ROS_INFO(\"cb\");", " remove NaN", "ROS_INFO(\"withoutNan\");", "apply VoxelGrid filter", "ROS_INFO(\"transformed\");", " apply outlier removal (takes a lot of time)", "ROS_INFO(\"withoutOutliers\");", " filter points", "ROS_INFO(\"cropped\");", " publish final cloud", " namespace pandora_costmap"], "pointcloud_to_image_converter": ["*******************************************************************", " Prepare the output image", " For the depth image", " if element is nan make it a zero", " For the rgb image", " namespace pandora_vision"], "discrete_wavelet_transform": ["*******************************************************************", " namespace pandora_vision_common", " namespace pandora_vision"], "discrete_wavelet_transform_test": ["*******************************************************************", " namespace pandora_vision_common", " namespace pandora_vision"], "victim_hole_preprocessor": ["*******************************************************************", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_hole_processor": ["*******************************************************************", "", "  * input->getDepth() + (input->getRegions().size() > 0) + 1;", "/ Message alert creation", " if (final_victims[i]->getClassLabel() == 1)", " {", " counter_++;", "/ Debug purposes", " }", "/ Debug image", " Convert the image into a message", " Publish the image message", "", " || detectionMode == GOT_RGB", " SVM mask merging", " Combine rgb & depth probabilities", "/ Weighted mean", " Only rgb svm probabilities", " if (detectionMode == GOT_HOLES )  // || detectionMode == GOT_RGB", " {", " for (unsigned int i = 0 ; i < rgb_svm_probabilities.size(); i++)", " {", " VictimPOIPtr temp(new VictimPOI);", " if (rgb_svm_probabilities[i]->getClassLabel() == 1)", " {", " counter_++;", " temp->setProbability(rgb_svm_probabilities[i]->getProbability() *", " paramsPtr_->rgb_svm_weight);", " temp->setPoint(rgb_svm_probabilities[i]->getPoint());", " temp->setSource(RGB_SVM);", " temp->setWidth(rgb_svm_probabilities[i]->getWidth());", " temp->setHeight(rgb_svm_probabilities[i]->getHeight());", " final_probabilities.push_back(temp);", " }", " else", " counter_--;", " }", " } ", "", "/ Interpolated depth image publishing", " Convert the image into a message", " Publish the image message", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_node": ["*******************************************************************"], "victim_handler": ["*******************************************************************", "", " Escape if it is already visited", " Escape if it has only a hazmat", "", "", "", "", "//////////////////////////////////////////////////////////////////////////////", "", "", "", "", "", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_parameters": ["*******************************************************************", "!< Dynamic reconfigure parameters", "/ The dynamic reconfigure (depth) parameter's callback", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_vj_detector": ["*******************************************************************", "", " ROS_ERROR(\"%s\", cascade_path.c_str());", "", "", "/ Clear vector of faces before using it for the current frame", "", "", " Normalize probability to [-1,1]", " Normalize probability to [0,1]", "", "/ Find the faces in the frame:", "/ Process face by face:", "/ Add every element created for each frame, to the total amount of faces", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_image_processor": ["*******************************************************************", "/ Message alert creation", "/ Debug purposes", "/ Debug image", " Convert the image into a message", " Publish the image message", " VictimPOIPtr temp(new VictimPOI);", " center of frame???", " center of frame???]", " ......", " vector??", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_image_preprocessor": ["*******************************************************************", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_postprocessor": ["*******************************************************************", " namespace pandora_vision_victim", " namespace pandora_vision"], "rgb_feature_extraction": ["*******************************************************************", "", "", " TO DO(Vassilis Choutas) : Change to ROS_BREAK().", "", "", "/ Clear feature vector", "/ Extract Color Statistics features from RGB image", "/ Append Color Statistics features to RGB feature vector.", "/ Extract Edge Orientation features from RGB image", "/ Append Edge Orientation features to RGB feature vector.", "/ Extract Haralick features from RGB image", "/ Append Haralick features to RGB feature vector.", "/ Extract SIFT features from RGB image", "/ Append SIFT features to RGB feature vector.", "/ Extract HOG features from RGB image", "/ Append HOG features to RGB feature vector.", " Plot the features if the visualization flag is true.", " namespace pandora_vision_victim", " namespace pandora_vision"], "edge_orientation_extractor": ["*******************************************************************", "", " ROS_INFO(\"ENTER find edge features\");", "/ Block size", " ROS_INFO_STREAM(\"vector's size\"<< edgeFeatures->size() );", " ROS_INFO_STREAM(\"EdgeFeatures= \");", " for (int ii = 0; ii < edgeFeatures.size(); ii++)", " ROS_INFO_STREAM( \" \" << edgeFeatures[ii]);", "", " ROS_INFO(\"ENTER PARTITION\");", " std::vector<double> edgeFeatures;", "!< Do stuff with subblock here", "", " ROS_INFO(\"ENTER FIND LOCAL EDGE\");", "/ Build a vector of the same size of the image and 5 dimensions", "/ to save the gradients", "/  Define the Scharr filters for the 5 types of edges", "/ Iterate over the posible directions and apply the filters", "/ Calculate the max sobel gradient and save the type of the orientation", "/ Detect the edges", "/ multiply against the types of orientations detected by the Sobel masks", "/ Establish the number of bins", "/ Set the range", "/ save the final edgeFeatures for the 5 types of oriented gradients", " std::vector<double> edgeFeatures(5);", " (*localEdgeFeatures)[ii-1]=hist.at<float>(ii) / (data.rows *data.cols);", "", " cv::Point anchor(kernel.cols - kernel.cols / 2 - 1,", "                 kernel.rows - kernel.rows / 2 - 1);", " cv::flip(kernel,kernel, -1);", "", "/ visualize each bin", " namespace pandora_vision_victim", " namespace pandora_vision"], "channels_statistics_extractor": ["*******************************************************************", "", "/ Transform it to HSV", "/ Preprocess current image to find histograms in HSV planes.", "/ Separate the image in 3 single-channel matrices, one for each of the", "/ Hue, Saturation and Value components.", "/ Set the ranges for each color component.", "/ Compute the histograms for every color component.", "/ Find the mean value and standard deviation value of every color", "/ component.", "/ Find the dominant color component and their density values", "/ Compute the first 6 Fourier Transform coefficints of the", "/ Hue and Saturation color components.", "/ Compute the colour angles of the R, G, B color components.", "/ Append all features to the output feature vector.", "", "/ Set the histogram ranges.", "/ Compute the histograms for every color component.", "/ Find the mean and standard deviation value of the image.", "/ Find the dominant color and its density value.", "/ Compute the first 6 Fourier Transform coefficints of the image.", "/ Append all features to the output feature vector.", " namespace pandora_vision_victim", " namespace pandora_vision"], "depth_feature_extraction": ["*******************************************************************", "", "", " TO DO(Vassilis Choutas) : Change to ROS_BREAK().", "", "", "/ Clear feature vector", "/ Extract Color Statistics features from Depth image", "/ Append Color Statistics features to Depth feature vector.", "/ Extract Edge Orientation features from Depth image", "/ Append Edge Orientation features to Depth feature vector.", "/ Extract Haralick features from Depth image", "/ Append Haralick features to Depth feature vector.", "/ Extract SIFT features from Depth image", "/ Append SIFT features to Depth feature vector.", "/ Extract HOG features from Depth image", "/ Append HOG features to Depth feature vector.", " namespace pandora_vision_victim", " namespace pandora_vision"], "sift_extractor": ["*******************************************************************", "", "", "", "", "", " cv::Mat imageWithKeyPoints;", " cv::drawKeypoints(inImage, keyPoints, imageWithKeyPoints, cv::Scalar::all(-1),", " cv::DrawMatchesFlags::DEFAULT);", " cv::imshow(\"Image Keypoints\", imageWithKeyPoints);", " cvWaitKey(0);", " namespace pandora_vision_victim", " namespace pandora_vision"], "histogram_extractor": ["*******************************************************************", "", "", " Copy the channel vector.", " Get the histogram dimensions.", " Copy the histogram size in each dimension.", " Copy the range of the histogram for each channel.", " Convert the input color code to an OpenCV compliant format.", " Flag that specifies whether a joint histogram will be used.", "", " Go through the node", " Go through the node", "", " If no successful comparison was made the return a negative code", " so as to inform the feature extractor that no conversion should be", " made.", "", " The image that will be processed to produced the histogram features.", " Convert the image to another color space if necessary.", " Split the image into separate channels.", " The final vector that will contain the histograms.", " Define the ranges for the histogram.", " Calculate the histogram for the current channel.", " Normalize the histogram to convert it to a probability", " distribution.", " Store the resulting histogram.", " Concatenate the histograms so as to form a compact feature vector.", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "feature_extraction": ["*******************************************************************", "", "", "", "", "", "", "", "", "", "", "", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "haralickfeature_extractor": ["*******************************************************************", "", "", "", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(sum[0]);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(sum);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(sum);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(variance);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(corr);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(temp);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(totalSum[0]);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " double f7 = _haralickFeatures[6];", " _haralickFeatures.push_back(sum);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(sum);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(f10);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(sum);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(f12);", " _haralickFeatures.push_back(f13);", "", " ROS_INFO(\"ENTER FIND HARALICK\");", " namespace pandora_vision_victim", " namespace pandora_vision"], "hog_extractor": ["*******************************************************************", "", "", "", "", " TODO(Miltos/Vassilis) Check if HOG works with RGB image.", " TODO(Miltos/Vassilis) Check proper size.", " namespace pandora_vision_victim", " namespace pandora_vision"], "color_angles_extractor": ["*******************************************************************", "", "", "", "/ Separate the image in 3 matrices, one for each of the R, G, B channels", "/ Compute the average pixel value of each r,g,b color component", "/ Obtain zero-mean colour vectors r0, g0 and b0 by subtracting the", "/ corresponding average pixel value of each original color vector", " */", "/ Compute the dot product of the RGB color components", " */", "/ Compute the lengh of the color angle vector", " */", " */", " */", "/ Compute the color angles", " */", "/ Normalised intensity standard deviation", "/ Transform the src image to grayscale", "/ Compute the mean intensity value", "/ Find the maximum intensity value", "/ Construct the final feature vector", " namespace pandora_vision_victim", " namespace pandora_vision"], "mean_std_dev_extractor": ["*******************************************************************", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "dft_coeffs_extractor": ["*******************************************************************", "", "", "", "/ Expand input image to optimal size", "/ On the border add zero values", "/ Add to the expanded another plane with zeros", "/ This way the result may fit in the source matrix", "/ Normalize the dft coeffs", "/ Compute the magnitude", " planes[0] = Re(DFT(I), planes[1] = Im(DFT(I))", "/ planes[0] = magnitude", " namespace pandora_vision_victim", " namespace pandora_vision"], "dominant_color_extractor": ["*******************************************************************", "", "", "", " */", "/ Image contains the image histogram, not the actual image.", " namespace pandora_vision_victim", " namespace pandora_vision"], "neural_network_validator": ["*******************************************************************", "", "", "", "", " const CvMat* layerSizes = neuralNetworkValidator_.get_layer_sizes();", " std::cout << layerSizes-><int>(0,0) << std::endl;", " namespace pandora_vision_victim", " namespace pandora_vision"], "random_forests_validator": ["*******************************************************************", "", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "validator_factory": ["*******************************************************************", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "neural_network_classifier": ["*******************************************************************", "", " Iterate over the parameter YAML file to get the size for each layer", " of the ANN.", " Get the parameters of  the sigmoid function.", " Parse the learning rate parameter", " Get the maximum number of iterations for the training of the network.", " Get the maximum number of iterations for the training of the network.", " TO DO(Vassilis Choutas): Add RLProp parameters", " If the training algorithm is not the back propagation algorithm", " then we must get the rest of the parameters for RPROP algorithm.", " Initialize the training algorithm's termination criteria.", " Initialize the pointer to the Neural Network Classifier object.", " Create the Neural Network with the specified topology.", " End of NeuralNetworkClassifier Constructor", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "abstract_validator": ["*******************************************************************", "", " Make features matrix a row vector.", "/ Normalize the data", " Make features matrix a row vector.", "/ Normalize the data", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_training_node": ["*******************************************************************"], "rgbd_svm_validator": ["*******************************************************************", "", "", "", "", "", " Normalize probability to [-1,1]", " Normalize probability to [0,1]", " namespace pandora_vision_victim", " namespace pandora_vision"], "svm_classifier": ["*******************************************************************", "", "!< POLY", "!< POLY/RBF/SIGMOID", "!< POLY/SIGMOID", "!< CV_SVM_C_SVC, CV_SVM_EPS_SVR, CV_SVM_NU_SVR", "!< CV_SVM_NU_SVC, CV_SVM_ONE_CLASS, CV_SVM_NU_SVR", "!< CV_SVM_EPS_SVR", "!< CV_SVM_C_SVC", " CvParamGrid CvParamGrid_C(pow(2.0,-5), pow(2.0,15), pow(2.0,2));", " CvParamGrid CvParamGrid_gamma(pow(2.0,-20), pow(2.0,3), pow(2.0,2));", " if (!CvParamGrid_C.check() || !CvParamGrid_gamma.check())", " std::cout << \"The grid is NOT VALID.\" << std::endl;", "", "", "", " uncomment for ONE_CLASS SVM", " for (int ii = 0; ii < results.rows; ii++)", " for (int jj = 0; jj < results.cols; jj++)", " if(results.at<float>(ii, jj) == 0)", " results.at<float>(ii, jj) = -1;", " namespace pandora_vision_victim", " namespace pandora_vision"], "abstract_classifier": ["*******************************************************************", "", " + \"/Training_Images\";", " const std::string trainingDatasetPath = datasetPath_ + \"/Training_Images\";", " + \"/Test_Images\";", " const std::string testDatasetPath = datasetPath_ + \"/Test_Images\";", "", "", "", "", "", "", "", " Start Training Process", " namespace pandora_vision_victim", " namespace pandora_vision"], "random_forests_classifier": ["*******************************************************************", "", " const float priors[] = {1, 1};", " Initialize the pointer to the Random Forests Classifier object.", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "classifier_factory": ["*******************************************************************", "", " Structs for calculating elapsed time.", " Train the system", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "rgb_random_forests_classifier": ["*******************************************************************", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "rgbd_svm_classifier": ["*******************************************************************", "", "!< POLY", "!< POLY/RBF/SIGMOID", "!< POLY/SIGMOID", "!< CV_SVM_C_SVC, CV_SVM_EPS_SVR, CV_SVM_NU_SVR", "!< CV_SVM_NU_SVC, CV_SVM_ONE_CLASS, CV_SVM_NU_SVR", "!< CV_SVM_EPS_SVR", "!< CV_SVM_C_SVC", " CvParamGrid CvParamGrid_C(pow(2.0,-5), pow(2.0,15), pow(2.0,2));", " CvParamGrid CvParamGrid_gamma(pow(2.0,-20), pow(2.0,3), pow(2.0,2));", " if (!CvParamGrid_C.check() || !CvParamGrid_gamma.check())", " std::cout << \"The grid is NOT VALID.\" << std::endl;", "", "", "", "", " uncomment for ONE_CLASS SVM", " for (int ii = 0; ii < results.rows; ii++)", " for (int jj = 0; jj < results.cols; jj++)", " if(results.at<float>(ii, jj) == 0)", " results.at<float>(ii, jj) = -1;", "", " Start Training Process", " std::cout << \"results\" << results.size() << std::endl << results <<std::endl <<std::endl;", " namespace pandora_vision_victim", " namespace pandora_vision"], "svm_validator": ["*******************************************************************", "", "", "", "", "", " Normalize probability to [-1,1]", " Normalize probability to [0,1]", " namespace pandora_vision_victim", " namespace pandora_vision"], "feature_extraction_utilities": ["*******************************************************************", "", "", "", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "principal_component_analysis": ["*******************************************************************", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "bag_of_words_trainer": ["*******************************************************************", "", "", "", "", "", "", "", "", "", " Initialize the window where the histogram will be displayed.", " Initialize the window dimensions.", " Create the canvas where the descriptor/histogram of visual words", " will be drawn.", " namespace pandora_vision_victim", " namespace pandora_vision"], "file_utilities": ["*******************************************************************", "", "", "", "", "", "", "", "", " if the file was not found, then file is 0, i.e. !file=1 or true", " the file was not found", " if the file was found, then file is non-0", " the file was found", "", "", " */", "", " namespace file_utilities", " namespace pandora_vision_victim", " namespace pandora_vision"], "platt_scaling": ["*******************************************************************", " Maximal number of iterations", " Minimal step taken in line search", " For numerically strict PD of Hessian", " Initial Point and Initial Fun Value", " Update Gradient and Hessian (use H' = H + sigma I)", " numerically ensures strict PD", " Stopping Criteria", " Finding Newton direction: -inv(H') * g", " Line Search", " New function value", " Check sufficient decrease", " namespace pandora_vision_victim", " namespace pandora_vision"], "haralickfeature_extractor_test": ["*******************************************************************", "", "/ Sets up images needed for testing", " Construct a black image", " set the blackGLCM matrix", " std::cout << \"blackGLCM= \" << std::endl << \" \" << blackGLCM << std::endl << std::endl;", " Construct a white image", " std::cout << \"white= \" << std::endl << \" \" << white << std::endl << std::endl;", " set the whiteGLCM matrix", " std::cout << \"whiteGLCM= \" << std::endl << \" \" << whiteGLCM << std::endl << std::endl;", " Construct a horizontal edge image", " Construct a vertical edge image", " Image Dimensions", " Images that will be used for testing", "/ Tests HaralickFeaturesExtractor::calculateGLCM()", " The output image", " std::cout << \"out= \" << std::endl << \" \" << out << std::endl << std::endl;", " The output image", " std::cout << \"out= \" << std::endl << \" \" << out << std::endl << std::endl;", " The output feature", " std::cout << \"out= \" << std::endl << \" \" << out << std::endl << std::endl;", " compute angular second moment", " The output feature", " std::cout << \"out= \" << std::endl << \" \" << out << std::endl << std::endl;", " compute angular second moment", " namespace pandora_vision_victim", " namespace pandora_vision"], "sift_extractor_test": ["*******************************************************************", "/ The image used for testingg purposes.", "/ A pointer to the extractor siftExtractorTestFixture_ that will be tested.", "/ The pointer the keypoint detector that produces the correct results.", "/ The pointer to the feature extractor that produces the correct", "/ results.", " Create the SIFT siftExtractorTestFixture_", " Create the SIFT keypoint detector.", " Create the SIFT feature extractor.", " Check that the image was read successfully.", " Convert the image to gray scale.", " End of SiftTest", " Convert the image to gray scale.", " End of DenseSiftTest", " namespace pandora_vision_victim", " namespace pandora_vision"], "histogram_extractor_test": ["*******************************************************************", " Initialize the ranges for the BGR color space.", " Initialize the ranges for the BGR color space.", " Initialize the ranges for the BGR color space.", " Initialize the ranges for the BGR color space.", " Get all the possible channel permutations.", " Store all the possible 2-permutations of the image channels.", " Store all the possible 3-permutations of the image channels.", " outputImage->setTo(static_cast<short unsigned int>(", " (range.first + range.second) / 2));", "", "/ The width_ of the test images.", "/ The height_ of the test images.", " Iterate over all the possible channel combinations.", " For each channel in the current configuration:", " Store the number of histogram bins that correspond to the current", " permutation of the image channels.", " Do the same for the range of values of each channel of the", " current color space. The resulting vector has size equal to two", " times the number of channels we want for our histogram. The even", " values are the lower bounds and the odd values are the upper bounds", " for each channel.", " Create the correct extractor for this configuration.", " Check that the histogram feature extractor has been created.", " Set the valid channels flag to add values only to the channels that", " will be tested in this iteration.", " If only one channel is tested then set the corresponding value.", " Set all the necessary channel flags.", " Create all possible combinations for the histogram range values", " for the current channel permutation.", " Calculate the true feature vector size.", " Iterate over all the above created values.", " Create a new test image by assigning non-zero values only to the", " designated channels in the provided ranges.", " Check that the returned vector has the size we expect.", " For each channel of the image that will be included in the", " histogram:", " Check if it is included.", " Get the position of the non-zero values for the histogram", " by finding the bin that corresponds to the values we assigned", " during the image creation.", " Add an offset so as to get to the correct block of the feature", " vector(the block that corresponds to the current channel).", " Update the offset by the number of bins.", " Clear the vectors so as to use them to set up the test for", " the next iteration.", " End of BGR color histogram extractor test.", " Iterate over all the possible channel combinations.", " For each channel in the current configuration:", " Store the number of histogram bins that correspond to the current", " permutation of the image channels.", " Do the same for the range of values of each channel of the", " current color space. The resulting vector has size equal to two", " times the number of channels we want for our histogram. The even", " values are the lower bounds and the odd values are the upper bounds", " for each channel.", " Create the correct extractor for this configuration.", " Check that the histogram feature extractor has been created.", " Set the valid channels flag to add values only to the channels that", " will be tested in this iteration.", " If only one channel is tested then set the corresponding value.", " Set all the necessary channel flags.", " Create all possible combinations for the histogram range values", " for the current channel permutation.", " Calculate the true feature vector size.", " Iterate over all the above created values.", " Create a new test image by assigning non-zero values only to the", " designated channels in the provided ranges.", " Check that the returned vector has the size we expect.", " For each channel of the image that will be included in the", " histogram:", " Check if it is included.", " Get the position of the non-zero values for the histogram", " by finding the bin that corresponds to the values we assigned", " during the image creation.", " Add an offset so as to get to the correct block of the feature", " vector(the block that corresponds to the current channel).", " Update the offset by the number of bins.", " Clear the vectors so as to use them to set up the test for", " the next iteration.", " End of HSV color histogram extractor test.", " Iterate over all the possible channel combinations.", " For each channel in the current configuration:", " Store the number of histogram bins that correspond to the current", " permutation of the image channels.", " Do the same for the range of values of each channel of the", " current color space. The resulting vector has size equal to two", " times the number of channels we want for our histogram. The even", " values are the lower bounds and the odd values are the upper bounds", " for each channel.", " Create the correct extractor for this configuration.", " Check that the histogram feature extractor has been created.", " Set the valid channels flag to add values only to the channels that", " will be tested in this iteration.", " If only one channel is tested then set the corresponding value.", " Set all the necessary channel flags.", " Create all possible combinations for the histogram range values", " for the current channel permutation.", " Calculate the true feature vector size.", " Iterate over all the above created values.", " Create a new test image by assigning non-zero values only to the", " designated channels in the provided ranges.", " Check that the returned vector has the size we expect.", " For each channel of the image that will be included in the", " histogram:", " Check if it is included.", " Get the position of the non-zero values for the histogram", " by finding the bin that corresponds to the values we assigned", " during the image creation.", " Add an offset so as to get to the correct block of the feature", " vector(the block that corresponds to the current channel).", " Update the offset by the number of bins.", " Clear the vectors so as to use them to set up the test for", " the next iteration.", " End of YCrCb color histogram extractor test.", " Iterate over all the possible channel combinations.", " For each channel in the current configuration:", " Store the number of histogram bins that correspond to the current", " permutation of the image channels.", " Do the same for the range of values of each channel of the", " current color space. The resulting vector has size equal to two", " times the number of channels we want for our histogram. The even", " values are the lower bounds and the odd values are the upper bounds", " for each channel.", " Create the correct extractor for this configuration.", " Check that the histogram feature extractor has been created.", " Set the valid channels flag to add values only to the channels that", " will be tested in this iteration.", " If only one channel is tested then set the corresponding value.", " Set all the necessary channel flags.", " Create all possible combinations for the histogram range values", " for the current channel permutation.", " Calculate the true feature vector size.", " Iterate over all the above created values.", " Create a new test image by assigning non-zero values only to the", " designated channels in the provided ranges.", " Check that the returned vector has the size we expect.", " For each channel of the image that will be included in the", " histogram:", " Check if it is included.", " Get the position of the non-zero values for the histogram", " by finding the bin that corresponds to the values we assigned", " during the image creation.", " Add an offset so as to get to the correct block of the feature", " vector(the block that corresponds to the current channel)", " Update the offset by the number of bins.", " Clear the vectors so as to use them to set up the test for", " the next iteration.", " End of CIELab color histogram extractor test.", " namespace pandora_vision_victim", " namespace pandora_vision"], "edge_orientation_extractor_test": ["*******************************************************************", "", "/ Sets up images needed for testing", " Construct a black image", " Construct a white image", " Construct a horizontal edge image", " Construct a vertical edge image", " Construct a 135-degree diagonal edge image", " Construct a 45-degree diagonal edge image", " Construct an image with a circle", " Construct a noisy image", "        cv::imshow(\"noisy\", noisy);", "cv::waitKey(0);", "/ Image Dimensions", "/ Images that will be used for testing", "/ Tests EdgeOrientationExtractor::findEdgeFeatures", " The output vector", " The output vector", " uncomment to visualize", " The output vector", " uncomment to visualize", " The output vector", " uncomment to visualize", " The output vector", " uncomment to visualize", " The output vector", " uncomment to visualize", " The output vector", "uncomment to vizualize", " The output vector", "uncomment to vizualize", " namespace pandora_vision_victim", " namespace pandora_vision"], "dominant_color_test": ["*******************************************************************", "", "/ Sets up images needed for testing", " Construct a black histogram", " Construct a white histogram", " Construct an ascending histogram", " Construct a descending histogram", "/ The histograms bins", "/ Image Dimensions", "/ Images that will be used for testing", "/ Tests DominantColorExtractor::extract", " The output vector", " namespace pandora_vision_victim", " namespace pandora_vision"], "mean_std_dev_test": ["*******************************************************************", "", "/ Sets up images needed for testing", " Construct a black image", " Construct a white image", " Construct a half black - half white image", "/ The image dimensions", "/ Images that will be used for testing", "/ Tests MeanStdDevExtractor::extract", " The output vector", " namespace pandora_vision_victim", " namespace pandora_vision"], "color_angles_test": ["*******************************************************************", "", "/ Sets up images needed for testing", " Construct a blue image", " Construct a green image", " Construct a red image", "/ Tests ColorAnglesExtractor::extract", " The output vector", " std::vector<double> out;", " ColorAnglesExtractor c1(&blue);  // , c2(&green), c3(&red);", " out = c1.extract();", " EXPECT_EQ(0, out[0]);", " EXPECT_EQ(0, out[1]);", " EXPECT_EQ(0, out[2]);", " EXPECT_EQ(0, out[3]);", " out = c2.extract();", " EXPECT_EQ(255, out[0]);", " EXPECT_EQ(0, out[1]);", " out = c3.extract();", " EXPECT_EQ(127.5, out[0]);", " EXPECT_EQ(127.5, out[1]);", " namespace pandora_vision_victim", " namespace pandora_vision"], "qrcode_detector": ["*******************************************************************", "", " Initiliaze the zbar scanner", "", "", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "qrcode_processor": ["*******************************************************************", "", "", " Get the image debug view flag.", "/ Get the buffer size parameter if available", "/ Get the difference threshold parameter if available", " Initiliaze the QR code detector.", "/ The dynamic reconfigure parameter's callback", "", "", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "qrcode_preprocessor": ["*******************************************************************", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "qrcode_node": ["*******************************************************************"], "qrcode_handler": ["*******************************************************************", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "qrcode_postprocessor": ["*******************************************************************", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "qrCode_detector_test": ["*******************************************************************", "", "", "/ Tests QrCodeDetector::detectQrCode", " there shouldn't be any qrcodes", " neither when 3 channels are used", " there shouldn't be any qrcodes", " Vertically concatenated", " there shouldn't be any qrcodes", " there shouldn't be any qrcodes", " there shouldn't be any qrcodes", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "obstacle_postprocessor": ["*******************************************************************", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "obstacle_preprocessor": ["*******************************************************************", " ros::shutdown();", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "hard_obstacle_handler": ["*******************************************************************", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "hard_obstacle_postprocessor": ["*******************************************************************", "", " Get robot base footprint transform", " convert cells to meters", " transform from bottom-left corner of traversability map to base", " footprint", " transform from base footprint to map", " transform from map to bottom-left corner of slam map", " convert meters from bottom-left corner of slam map to coordinates", " obstacleDilation(output, 2, coords_map);", " That's foreground", " Check for all adjacent", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "dummy_processor": ["*******************************************************************", " namespace sensor_processor"], "hard_obstacle_node": ["*******************************************************************"], "hard_obstacle_preprocessor": ["*******************************************************************", " Convert the input Point Cloud to a local elevation map", " in the form of a occupancy Grid Map", " Find the known areas in the map.", " Normalize only the map elements that correspond to known cells.", " Set all unknown areas to 0 so that they appear as black.", "cv::imshow(\"Elevation Map Image\", colorMapImg);", "", " converting PointCloud2 msg format to pcl pointcloud format in order to read the 3d data", " Create the output Elevation Map", " Check if the current point has any NaN value.", " Check if the point is in the allowed distance range.", " Check if the z coordinate is within the specified range.", " If the current point is located higher that the higher point of the corresponding cell", " then substitute it.", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "traversability_mask": ["*******************************************************************", " Create the robot height mask.", " Calculate the values for the size of the robot parts.", " Initialize the mask of the robot.", " Assign the values for the motors of the robots.", " Top Left Barrels", " Top Right Barrels", " robotGeometryMask_->at<double>(i + wheelSize, j) = description_->barrelH;", " Top Right Barrel Height", " Bottom Left Barrels.", " Bottom Right Barrels.", " Robot sidelines.", " Robot Main body.", "", " Calculate the values for the size of the robot parts.", " Initialize the mask of the robot.", " Assign the values for the motors of the robots.", " Top Left Barrels", " Top Right Barrels", " robotGeometryMask_->at<double>(i + wheelSize, j) = description_->barrelH;", " Top Right Barrel Height", " Bottom Left Barrels.", " Bottom Right Barrels.", " Robot sidelines.", " Robot Main body.", "", " Calculate the current position of the Upper Left Wheel.", " Calculate the current position of the Lower Left Wheel.", " Calculate the current position of the Lower Right Wheel.", " Calculate the number of valid wheels.", " Get the mask for the left side of the robot", " Initialize the transformed map by creating a deep copy of the original.", " TODO(Vassilis Choutas): Check return values", " If no wheel position is know then mark the current point as unknown.", " else if (validWheelNum == 2) ", " {", " if (upperLeftWheelValid && upperRightWheelValid)", " {", " MatPtr tempMapPtr(new cv::Mat(*updatedMaskPtr,", " cv::Rect(0, 0, updatedMaskPtr->cols - 1, wheelSize)));", " // Get the mask for the top side of the robot.", " bool traversabilityFlag = findElevatedTopBottom(tempMapPtr, upperLeftWheelMeanHeight,", " upperRightWheelMeanHeight, wheelCenterDist);", " // If the return value is false then it that point is not traversible.", " if (!traversabilityFlag)", " return occupiedArea;", " validAreaWidth += updatedMaskPtr->cols - 1;", " validAreaHeight += wheelSize;", " // Get the Position of the the barrels that are located below the forward wheels.", " cv::Point leftBarrelPos(", " metersToSteps(center_.x - description_->robotD / 2 - description_->barrelD", " - description_->wheelD),", " metersToSteps(center_.y - description_->robotD / 2 - description_->barrelD));", " cv::Point rightBarrelPos(", " metersToSteps(center_.x + description_->robotD / 2 + description_->barrelD),", " metersToSteps(center_.y - description_->robotD / 2 - description_->barrelD));", " double upperLeftBarrelMeanHeight, upperLeftBarrelStdDev;", " bool upperLeftBarrelValid = findHeightOnWheel(leftBarrelPos, &upperLeftBarrelMeanHeight,", " &upperLeftBarrelStdDev);", " double upperRightBarrelMeanHeight, upperRightBarrelStdDev;", " bool upperRightBarrelValid = findHeightOnWheel(rightBarrelPos, &upperRightBarrelMeanHeight,", " &upperRightBarrelStdDev);", " if (upperLeftBarrelValid && upperRightBarrelValid)", " {", " // Update the values for the elevated mask for the barrel area.", " tempMapPtr.reset(new cv::Mat(*updatedMaskPtr,", " cv::Rect(0, wheelSize, updatedMaskPtr->cols - 1, barrelSize)));", " traversabilityFlag = findElevatedTopBottomBody(tempMapPtr, upperLeftBarrelMeanHeight,", " upperRightBarrelMeanHeight, wheelCenterDist);", " if (!traversabilityFlag)", " return occupiedArea;", " validAreaHeight += barrelSize;", " // Get the Position of the upper half of the robot body located below .", " cv::Point leftBodyPartPos(", " metersToSteps(center_.x - description_->robotD / 2 - description_->barrelD", " - description_->wheelD),", " metersToSteps(center_.y - description_->robotD / 2));", " cv::Point rightBodyPartPos(", " metersToSteps(center_.x + description_->robotD / 2 + description_->barrelD),", " metersToSteps(center_.y - description_->robotD));", " double upperLeftBodyPartMeanHeight, upperLeftBodyPartStdDev;", " bool upperLeftBodyPartValid = findHeightOnWheel(leftBodyPartPos, &upperLeftBodyPartMeanHeight,", " &upperLeftBodyPartStdDev);", " double upperRightBodyPartMeanHeight, upperRightBodyPartStdDev;", " bool upperRightBodyPartValid = findHeightOnWheel(rightBodyPartPos, &upperRightBodyPartMeanHeight,", " &upperRightBodyPartStdDev);", " // Check that the upper half parts of the robot are within a known area of the elevation map", " if (upperLeftBodyPartValid && upperRightBodyPartValid)", " {", " tempMapPtr.reset(new cv::Mat(*updatedMaskPtr,", " cv::Rect(0, wheelSize + barrelSize, updatedMaskPtr->cols - 1, robotDSize / 2)));", " traversabilityFlag = findElevatedTopBottomBody(tempMapPtr, upperRightWheelMeanHeight,", " lowerRightWheelMeanHeight, wheelCenterDist);", " // If the upper half of the main robot body is not located in a valid area", " // then mark the point as occupied.", " if (!traversabilityFlag)", " return occupiedArea;", " validAreaHeight += robotDSize / 2;", " }", " }", " // Extract the elevation map area that corresponds to the valid part of the mask.", " cv::Mat validElevationMapOverlap =", " (*elevationMapPtr_)(cv::Rect(center_.x - robotDSize / 2 - barrelSize - wheelSize,", " center_.y -  - robotDSize / 2 - barrelSize - wheelSize, validAreaWidth, validAreaHeight));", " // Create a shallow copy of the valid region of the transformed robot height mask.", " cv::Mat validMask = (*updatedMaskPtr)(cv::Rect(validAreaTopLeftX, validAreaTopLeftY,", " validAreaWidth, validAreaHeight));", " cv::Mat diff = validMask - validElevationMapOverlap;", " cv::Mat result = diff <= 0 & validElevationMapOverlap != unknownArea;", " if (cv::countNonZero(result) > 0)", " return occupiedArea;", " else", " {", " if (cv::countNonZero(validElevationMapOverlap == - std::numeric_limits<double>::max()) == 0)", " return freeArea;", " else", " return unknownArea;", " }", " }  // End_if : Only top wheels on known elevation.", " if (lowerLeftWheelValid && lowerRightWheelValid)", " {", " }", " if (upperLeftWheelValid && lowerLeftWheelValid)", " {", " }", " if (upperRightWheelValid && lowerRightWheelValid)", " {", " }", " }", " else if (validWheelNum == 3)", " {", " } ", " If all the wheels are on a known area of the elevation Map.", " Calculate the mask for the left side of the robot.", " Get the mask for the right side of the robot.", " Get the mask for the top side of the robot.", " Get the mask for the bottom side of the robot.", " Decide about binary traversability", " Extract the elevation map area that corresponds to the valid part of the mask.", " Create a shallow copy of the valid region of the transformed robot height mask.", " End of findTraversability", "", "", "", " Interpolate the mask values to get the robot's local estimated elevation.", "", " Convert the size of the wheel from distance units to the number of cells", " it corresponds using the current elevation map resolution.", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", " Find the wheel that is located higher", " Convert the size of the wheel from distance units to the number of cells", " it corresponds using the current elevation map resolution.", " Find the wheel that is located higher", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", " Convert the size of the wheel from distance units to the number of cells", " it corresponds using the current elevation map resolution.", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", " Find the wheel that is located higher", " Convert the size of the wheel from distance units to the number of cells", " it corresponds using the current elevation map resolution.", " Find the wheel that is located higher", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", "", " Copy the region of the elevation map that corresponds to the current wheel.", "if ()", "{", "  }", "else", "{", "}", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "hard_obstacle_detector": ["*******************************************************************", " Minimum acceptable value for the process to work properly", " Load the robot's description and create it's 2d Elevation Mask.", " ROS_INFO(\"Finished loading robot description and creating robot mask!\");", " Check if input type is CV_64FC1", " Show the input image", " *elevationMapPtr_ = inputImage;", " Pass the unknown areas in edges image.", " Pass the robot mask on the complete area that was made.", "", " Initialize the output traversability map", " Set all of it's cells to unknown.", " Iterate over the map", " Check that we are on a valid cell.", "", " Initialize the output traversability map", " Set all of it's cells to unknown.", " Iterate over the map", " this is y", " this is x", " for (int ii = local_radius; ii < nonTraversableRowPoints.rows - local_radius; ++ii) {", " for (int jj = local_radius; jj < nonTraversableRowPoints.cols - local_radius; ++jj) {", " if (static_cast<int8_t>(nonTraversableRowPoints.at<uchar>(ii, jj)) == occupiedArea)", " (static_cast<int8_t>(nonTraversableRowPoints.at<uchar>(ii, jj)) == freeArea))", "       { ", " double maxHeight = -std::numeric_limits<double>::max();", " double minHeight = std::numeric_limits<double>::max();", " double mean = 0.0;", " int count = 0;", " for (double theta = 0; theta < 2 * CV_PI; theta += 0.2) {", " int iic = ii + static_cast<int>(cos(theta) * local_radius);", " int jjc = jj + static_cast<int>(sin(theta) * local_radius);", " double height = inputImage.at<double>(iic, jjc);", " if (height != -std::numeric_limits<double>::max())", " {", " mean += height;", " count++;", " if (height > maxHeight) maxHeight = height;", " if (height < minHeight) minHeight = height;", " }", " }", " // Escape if information is not considered sufficient", " if (count < static_cast<int>((2 * CV_PI / 0.2) / 2))", " continue;", " mean /= count;", " double heightDiff = inputImage.at<double>(ii, jj) - mean;", " // Escape if edge point does not lie in high ground... (error)", " if (heightDiff <= 0)", " continue;", " if (heightDiff <= height_diff_)", " {", " traversabilityMap->at<int8_t>(ii, jj) = freeArea;", " continue;", " }", " // Escape if max is smaller than min", " if (maxHeight < minHeight)", " continue;", " double grad = maxHeight - minHeight;", " if (grad >= grad_diff_)", " {", " traversabilityMap->at<int8_t>(ii, jj) = freeArea;", " // continue;", " }", " // Edge is definetely a hard obstacle", " // occupiedPoints.push_back(cv::Point(jj ,ii));", " }", " }", " }", " for (int ii = local_radius; ii < nonTraversableColPoints.rows - local_radius; ++ii) {", " for (int jj = local_radius; jj < nonTraversableColPoints.cols - local_radius; ++jj) {", " if ((static_cast<int8_t>(nonTraversableColPoints.at<uchar>(ii, jj)) == rampArea) ||", " (static_cast<int8_t>(nonTraversableColPoints.at<uchar>(ii, jj)) == freeArea))", " {", " double maxHeight = -std::numeric_limits<double>::max();", " double minHeight = std::numeric_limits<double>::max();", " double mean = 0.0;", " int count = 0;", " for (double theta = 0; theta < 2 * CV_PI; theta += 0.2) {", " int iic = ii + static_cast<int>(cos(theta) * local_radius);", " int jjc = jj + static_cast<int>(sin(theta) * local_radius);", " double height = inputImage.at<double>(iic, jjc);", " if (height != -std::numeric_limits<double>::max())", " {", " mean += height;", " count++;", " if (height > maxHeight) maxHeight = height;", " if (height < minHeight) minHeight = height;", " }", " }", " // Escape if information is not considered sufficient", " if (count < static_cast<int>((2 * CV_PI / 0.2) / 2))", " continue;", " mean /= count;", " double heightDiff = inputImage.at<double>(ii, jj) - mean;", " // Escape if edge point does not lie in high ground... (error)", " if (heightDiff <= 0)", " continue;", " if (heightDiff <= height_diff_)", " continue;", " // Escape if max is smaller than min", " if (maxHeight < minHeight)", " continue;", " double grad = maxHeight - minHeight;", " if (grad >= grad_diff_)", " continue;", " // Edge is definetely a hard obstacle", " traversabilityMap->at<int8_t>(ii, jj) = occupiedArea;", " // occupiedPoints.push_back(cv::Point(jj ,ii));", " }", " }", "   } ", "***************************************************************************", " If value is negative, make it green for visualization", "cv::imshow(title, scaledImage);", " If the map value is unknown then paint it black.", " Paint the occupied Areas red", " Paint the free areas blue", "cv::imshow(\"Traversability Map\", traversabilityVisualization);", "", " Use opencv function for visualization", " Convert CV_8UC1 to CV_8UC3", " use Opencv function for visualization", " If value is negative give color", " Check the probability of the pixel and give color for visualization", " Give Red color", " Give Yellow color", " Give Blue color", "cv::imshow(title, scaledImage);", "***************************************************************************", " Pass from the input mat the negative values as our policy dictates.", " If negative values in the input image, convert them to -1.", " Visualization of unknown areas based on their optimistic probabilities", " After convolution there might be negative values, so we need", " to set them to -1.", "***************************************************************************", " Reduce the noise of the input Image", " Detect edges with canny", " Reduce the noise of the input image", " Gradient X", "        src, dst, ddepth, 1, 0, scale, delta, border_type", " Gradient Y", "        src, dst, ddepth, 1, 0, kernelSize, scale, delta, border_type", " Total Gradient (approximate)", " Reduce the noise of the input image", " Gradient X", "        src, dst, ddepth, 1, 0, kernelSize, scale, delta, border_type", " Gradient Y", "        src, dst, ddepth, 1, 0, kernelSize, scale, delta, border_type", " Total Gradient (approximate)", " Apply threshold to the edges", " Convert the type of the output image to CV_64FC1.", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "hard_obstacle_processor": ["*******************************************************************", " Debug show parameters", " Edge detection parameters", " Canny parameters", " NODELET_INFO(\"[%s] In process\", this->getName().c_str());", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "barrel_handler": ["*******************************************************************", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "barrel_processor": ["*******************************************************************", " ROS_INFO(\"Starting bag read\");", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "barrel_node": ["*******************************************************************"], "fast_symmetry_detector": ["*******************************************************************", " Pre calculate rotation matrices from -90 deg to 90 deg (actually to 89 deg) ", "", " Get the cos and sin values from our pre-calculated rotation matrices ", " Reset our row pointers to start of each row in rotated edges matrix ", " Now append the corresponding rho values of the rotated edges ot rotated edges matrix ", "", " Make sure that we reset the accumulation matrix and rotated edges matrix ", " Find all the pixels of the edges ", " Translate them in relation to center of the image ", " For each degree of rotation ", " Rotate edge to that degree ", " Ignore edges that have smaller number of pairings ", " Vote for Hough matrix ", "", "", " Make sure that we have appropriate peaks ", " Pre-set the size of the neighbors ", " Find the peak from the Hough accumulation matrix ", " Convert from Hough space back to x-y space ", " Try to zero out the peak and the neighborhood of the peak, so that ", " we can move on to find the second highest peak ", " Handles the edge case that wraps around the matrix ", "", " return pair<Point, Point> { p0, p1, };", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "barrel_detector": ["*******************************************************************", "", " Determine the shape of Hough accumulationmatrix ", " temp.convertTo(depth8UC3, CV_8UC3, 255);", " Find the edges ", " Vote for the accumulation matrix ", " Draw the symmetrical line ", " float len1 = std::sqrt(result[i].first.x * result[i].first.x + result[i].first.y * result[i].first.y);", " float len2 = std::sqrt(result[i].second.x * result[i].second.x + result[i].second.y * result[i].second.y);", " float dot = result[i].first.x * result[i].second.x + result[i].first.y * result[i].second.y;", " float a = dot / (len1 * len2);", " float angle;", " if (a >= 1.0)", "   angle = 0.0;", " else if (a <= -1.0)", "   angle = 3.14;", " else", "   angle = std::acos(a); //  0..PI", " angle = angle * 180 / 3.14;", " cv::line(depth8UC3, result[i].first, result[i].second, cv::Scalar(0, 0, 255), 2);", " cv::rectangle(depth8UC3,", "     cv::Point(result[i].second.x - maxDist / 2, result[i].second.y),", "     cv::Point(result[i].first.x + maxDist / 2, result[i].first.y),", "     cv::Scalar(255, 0, 0),", "     2);", "  cv::line(temp, s3, s2, cv::Scalar(0, 255, 0), 2);", " Visualize the Hough accum matrix ", " cv::Mat accum = detector.getAccumulationMatrix();", " accum.convertTo(accum, CV_8UC3);", " cv::applyColorMap(accum, accum, cv::COLORMAP_JET);", " cv::resize(accum, accum, cv::Size(), 2.0, 0.5);", " /* Draw lines based on cursor position */", " if (accumIndex.x != -1 && accumIndex.y != -1)", " {", "   std::pair<cv::Point, cv::Point> pointPair = detector.getLine(accumIndex.y, accumIndex.x);", "   cv::line(depth8UC3, pointPair.first, pointPair.second, CV_RGB(0, 255, 0), 2);", " }", " Show the original and edge images ", "  cv::Mat appended = cv::Mat::zeros(depth8UC3.rows + accum.rows, depth8UC3.cols * 2, CV_8UC3);", "  depth8UC3.copyTo(cv::Mat(appended, cv::Rect(0, 0, depth8UC3.cols, depth8UC3.rows)));", "  cv::cvtColor(edge, cv::Mat(appended, cv::Rect(depth8UC3.cols, 0, edge.cols, edge.rows)), CV_GRAY2BGR);", "  accum.copyTo(cv::Mat(appended, Rect(0, depth8UC3.rows, accum.cols, accum.rows)));", "  cv::imshow(\"Candidate Barrel\", appended);", "", "  Validate based on variance in RGB ROI", " (*valid) = false;", "  Validate that through the symmetry line we have almost", "  constant depth", " (*valid) = false;", "  Rotate vector 90 degrees clockwisely", "  A point on the symmetry line", " ROS_INFO(\"%f, %f\", slope.x, slope.y);", "  In order to calculate circularity place points of the perpendicular", "  line into a vector", "  Ignore values at the border", " Used to spot extreme values, in order to remove them from calculations", "  calculate differentiation of depth values, through the perpendicular", "  line(s) for the left side of the barrel and the right side of the", "  barrel. Calculate avg of differentiation for left and right side", "  separately.", " avgLeftLinePoint = sumLeftLine;", " avgRightLinePoint = sumRightLine;", "  We expect that starting from the left side of the barrel,", "  we have a decreasing depth up to the peak of the barrel", "  (negative differential avg), and then increasing depth.", " (*valid) = false;", "  We must have a symmetry between the differential avgs of the", "  left and right sides of the barrel.", " (*valid) = false;", " Check if some of the points belong to a circle curve", " Firstly get an approximation of the center of the curve, thus", " approximate radius", " s1 is the coordinates of the center (this point is located on the symmetry line)", " so approximate radius as the difference of this point (on a barrel this point", " will have the smallest depth, same as all points on the symmetry line) and the", " point of the biggest depth inside the roi, hopefully it will be a point on the", " wall, but there is no problem if it is on the barrel.", " (*valid) = false;", " Eliminate corners with Harris Corner Detector", " cv::cvtColor(rgbImage, gray, CV_BGR2GRAY);", " dst = cv::Mat::zeros(rgbImage.size(), CV_32FC1);", " Detecting corners", " Normalizing", " (*valid) = false;", " Validation based on specific barrels' color", " convert RGB image into HSV image", " cv::inRange(hImage, iLowH, iHighH, binary);", " For RED define one second threshold", " cv::inRange(hImage, iLowH, iHighH, binaryTemp);", " (*valid) = false;", " cv::inRange(hsvImage, cv::Scalar(iLowH, iLowS, iLowV), cv::Scalar(iHighH, iHighS, iHighV), binary);  // red*/", "", " Calculate unit normal vector for the circle's plane. Consider", " third coordinate zero based on the assumption that the depth", " between two points on the symmetry line remains constant", " Calculate unit vector from center to a point on the circle, consider", " this point to be at the center of the symmetry line, thus having same", " x, y coordinates as the center point", " Calculate cross product of N and U", " Check if point belongs to the circle equation", " Find the avg error between the point and the equation", "/ Find depth distance", "", "", " Find the depth distance of the soft obstacle", " ROS_INFO(\"barrel found\");", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "parameters": ["*******************************************************************", "", "////////////////// Blob detection - specific parameters ////////////////////", "/////////////////////// Debug-specific parameters //////////////////////////", " Publish the enhanced Images", " Show the depth image that arrives in the depth node", " Show the thermal image that arrives in the thermal node", " Show the rgb image that arrives in the rgb node", " Show the holes that each of the depth and RGB nodes transmit to the", " hole fusion node, on top of their respective origin images", " Show all valid holes, from either the Depth or RGB source, or", " the merges between them", " The product of this package: unique, valid holes", " In the terminal's window, show the probabilities of candidate holes", " Show the texture's watersheded backprojection", "///////////////// Parameters specific to the Depth node ////////////////////", " The interpolation method for noise removal", " 0 for averaging the pixel's neighbor values", " 1 for brushfire near", " 2 for brushfire far", "//////////////// Parameters pecific to the Thermal node ////////////////////", " The thermal detection method", " If set to 0 process the binary image acquired from temperatures MultiArray", " If set to 1 process the sensor/Image from thermal sensor", " The probability extraction method", " 0 for Gaussian function", " 1 for Logistic function", " Gausian variables", " Logistic variables", "/////////// Parameters of acceptable temperature for threshold /////////////", "//////////////////// Parameters of the thermal image ///////////////////////", "/////////////////// Edge detection specific parameters /////////////////////", " canny parameters", " The opencv edge detection method:", " 0 for the Canny edge detector", " 1 for the Scharr edge detector", " 2 for the Sobel edge detector", " 3 for the Laplacian edge detector", " 4 for mixed Scharr / Sobel edge detection", " Threshold parameters", " When mixed edge detection is selected, this toggle switch", " is needed in order to shift execution from one edge detector", " to the other.", " 1 for the Scharr edge detector,", " 2 for the Sobel edge detector", "/////////////////////  Histogram related parameters ////////////////////////", "//////////////////////// Filters-related parameters ////////////////////////", " DepthDiff", " 0 for binary probability assignment on positive depth difference", " 1 for gaussian probability assignment on positive depth difference", " The mean stardard deviation for the normal distribution", " incorporated in the depth diff filter.", " Min difference in depth between the inside and the outside of a hole", " Max difference in depth between the inside and the outside of a hole", " DepthArea", " DepthHomogeneity", " RectanglePlaneConstitution", " IntermediatePointsPlaneConstitution", " ColourHomogeneity", " LuminosityDiff", " TextureDiff", " The threshold for texture matching regarding the intermediate points", " The threshold for texture matching reagrding the points inside the hole", " TextureBackprojection", "///////////////////// HoleFusion-specific parameters ///////////////////////", "-------------------------------- Validation --------------------------------", " The holes' validation process identifier", " When depth analysis is applicable", " When depth analysis is not applicable, we can only rely", " on RGB analysis", " Plane detection parameters", " Option to enable or disable the merging of holes", " Holes connection - merger", " Merger parameters", " The inflation size of holes' bounding rectangles", "//////////////// Image representation specific parameters //////////////////", " The depth sensor's horizontal field of view in rads", " The depth sensor's vertical field of view in rads", " Fallback values. See the input point cloud callback of the", " synchronizer node", " Depth and RGB images' representation method.", " 0 if image used is used as obtained from the image sensor", " 1 through wavelet analysis", " Method to scale the CV_32F image to CV_8UC1", " Term criteria for segmentation purposes", "///////////////// Outline discovery specific parameters ////////////////////", " The detection method used to obtain the outline of a blob", " 0 for detecting by means of brushfire", " 1 for detecting by means of raycasting", " When using raycast instead of brushfire to find the (approximate here)", " outline of blobs, raycast_keypoint_partitions dictates the number of", " rays, or equivalently, the number of partitions in which the blob is", " partitioned in search of the blob's borders", " Loose ends connection parameters", "////////////////// Parameters specific to the RGB node /////////////////////", " RGB image segmentation parameters", " Selects the method for extracting a RGB image's edges.", " Choices are via segmentation and via backprojection", " The threshold applied to the backprojection of the RGB image", " captured by the image sensor", " Parameters specific to the pyrMeanShiftFiltering method", " True to posterize the product of the segmentation", " FloodFill options regarding minimum and maximum colour difference", " Watershed-specific parameters", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "soft_obstacle_handler": ["*******************************************************************", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "soft_obstacle_detector": ["*******************************************************************", " First erode image to eliminate noise and then dilate", "/ Perform Hough Transform", "/ Keep only vertical lines", "!< The point that the line intersects with the x-axis", "/ If line is almost vertical and not close to image borders", " Add each point of the line to list of Points", "/ Calculate ROI probability", " The point inside this Rect is the roi center, now it is the", " upper left point in order to visualize", " Image should be continuous in order to be reshaped", " Get one sorted row of depth values", " Remove the zero values", " X coordinate of start and end point", "/ Find the position of the line in the list with the minimum and", "/ maximum x coordinate", " Find the line closest to the middle of the bounding box", " Y coordinate of start and end point", " First and Third point", " Second and Forth point", " Split vertically ROI to four parts", " not used", " Convert rgb image to grayscale", " Apply Histogram Equalization", " Blur image using Gaussian filter", " Perform DWT", " Normalize image [0, 255]", " Convert image to binary with Otsu thresholding", " Dilate Image", " Perform Hough Transform to detect lines (keep only vertical)", " Detect bounding box that includes the vertical lines", " Examine whether the points of the bounding box have difference in depth", " distance", " Find the new depth distance of the soft obstacle", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "soft_obstacle_processor": ["*******************************************************************", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "soft_obstacle_node": ["*******************************************************************"], "barrel_detector_test": ["*******************************************************************", "", "", "", "", " The images' width and height", " The images under processing", "", " Fill the inside of the desired rectangle with the @param rgbIn provided", "", " Fill the inside of the desired rectangle with the @param depthIn provided", "", " float step = 2 * (depthUpper - depthLower) / x;", " for (int rows = upperLeft.y; rows < upperLeft.y + y; rows++)", " {", "   // First decrement depth", "   for (int cols = upperLeft.x; cols < upperLeft.x + (x / 2); cols++)", "   {", "     image->at< float >(rows, cols) = depthUpper - (cols - upperLeft.x) * step;", "   }", "   // Then increment depth", "   for (int cols = upperLeft.x + (x / 2); cols < upperLeft.x + x; cols++)", "   {", "     image->at< float >(rows, cols) = depthLower + (cols - upperLeft.x - (x / 2)) * step;", "   }", " }", " ! Tests BarrelDetector::getSymmertyObject", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the depthImage to constant value", " Construct two vertical parallel symmetrical lines", " Construct a square", " cv::Mat square = cv::Mat::zeros(HEIGHT, WIDTH, CV_32FC1);", " BarrelDetectorTest::generateDepthRectangle", "  (cv::Point2f (WIDTH - 350, HEIGHT - 350),", "    310,", "    310,", "    0.9,", "    &square);", " depthImage += square;", " It is expected that the bounding box surrounds the square", " ! Tests BarrelDetector::validateROI", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the depthImage to constant value", " Construct the rgbImage. The entire image is at a colour of", " value approximate the the colour value of the images of walls", " Red", " Green", " Blue", " Construct a symmetric square with firstly decreasing and then increasing", " depth", " Construct the homogeneous RGB square", " It is expected that this object is verified as positive", " namespace pandora_vision"], "fast_symmetry_detector_test": ["*******************************************************************", "", "", "", " The images' width and height", " The image under processing", "", " Fill the inside of the desired rectangle with the @param rgbIn provided", "", " Fill the inside of the desired rectangle with the @param depthIn provided", " ! Tests FastSymmetryDetector::rotateEdges", " ! Tests FastSymmetryDetector::getMaxDistance", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the depthImage to constant value", " Determine the shape of Hough accumulationmatrix ", " edge.copyTo(temp1);", " Find the edges ", " Vote for the accumulation matrix ", " Get the symmetrical line ", " It is expected that the maximum distance will be zero, because no", " object has been found", " And the symmetric lines are also zero", " Construct a square", " edge.copyTo(temp1);", " Find the edges ", " Vote for the accumulation matrix ", " Get the symmetrical line ", " It is expected that the maximum distance between symmetric lines will", " be equal to the square's width or height", " It is expected that points of the symmetry line are at the center of", " the square (either vertically either horizontally)", " namespace pandora_vision"], "traversability_mask_test": ["*******************************************************************", " Set the robot dimensions.", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "soft_obstacle_detector_test": ["*******************************************************************", " Considering that a pixel has width and height equal to 1", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "image_saver_by_topic": ["*******************************************************************", "", " The folder for the images to be saved", " The width for the image to be resized", " The height of the image to be resized", "! Initialization of the static members", "! Static initialization of the counter", "", " user press left button ", " user drag the mouse ", "img->copyTo(imgCopy);", " user release left button ", "! Cast counter to string", "! Produce image path", "! Resize if requested by the user", "! Save the image", "", "!< Current frame to be processed", "! Show the image", "~ cv::rectangle(current_frame, point, cv::Point(xx, yy), CV_RGB(255, 0, 0), 3, 8, 0);", "! Catch key presses in the opencv window  ", "! Saves the image", "! Cast counter to string", "! Produce image path", "! Resize if requested by the user", "! Save the image", "! Starts counting from 0", "", "! Check the arguments. If 3 no resizing is requested.", "! Argument parsing", "!< If arguments were 5 the resize operation was requested", "! Topic subscription"], "enhanced_image_shower": ["*******************************************************************", "", "!< Current frame to be processed", " cv::cvtColor(rgb_msg->image, temp, CV_BGR2RGB);", "", "! Argument parsing", "! Topic subscription"], "annotator_controller": ["****************************************************************************", "", "", "", "", "", "", "", "", "", "", "", "", " Load all messages", "", "", "", "loader_.statusLabel->setText(QString(img_name.c_str()));", "", "", "", "cv::cvtColor(in_msg->image, temp, CV_BGR2RGB); // cvtColor Makes a copt, that what i need", " enforce deep copy, see documentation", "", "", ",", "sensor_msgs::image_encodings::TYPE_8UC3);", "ROS_INFO_STREAM(\"enc\" << in_msg->encoding);", " enforce deep copy, see documentation", "", " namespace pandora_vision"], "annotator_connector": ["****************************************************************************", "", " Event filter for the image area", "loader_.scrollArea->installEventFilter(this);", "", "", "", "", "", "", "", "", "", "", "", "", " enforce deep copy, see documentation", "", "", "", "", "", " loader_.imageLabel->setScaledContents(true);", "", "", "", "", "qDebug(\"Save current Frame as: frame%d.png\",currFrame);", "do", "{", "cv::Mat temp = QImage2Mat(localImage_);", "cv::imwrite(img_name.str(),temp);", "loader_.statusLabel->setText(\"Save current Frame as:\" + QString(img_name.str().c_str() )); ", "}while(me->key() != Qt::Key_D);", "", "", "", "", "", "", "", "", "", "", "drawBox();  ", "", "", " namespace pandora_vision"], "annotator_node": ["****************************************************************************", "", " Add custom signal handlers", "", " namespace pandora_vision"], "annotator_loader": ["****************************************************************************", "", "scrollArea->setWidget(imageLabel);", "", "~ ROS_ERROR(\"Shutdown signal!\");", "~ ROS_ERROR(\"Shutting down ros...\");", "", "", "", " namespace pandora_vision"], "annotator_application": ["****************************************************************************", "", "", " namespace pandora_vision"], "annotator_tools": ["****************************************************************************", "", "", "", "", "", "", "", "", "", "", " namespace pandora_vision"], "motion_preprocessor": ["*******************************************************************", " namespace pandora_vision_motion", " namespace pandora_vision"], "motion_postprocessor": ["*******************************************************************", " namespace pandora_vision_motion", " namespace pandora_vision"], "motion_handler": ["*******************************************************************", " namespace pandora_vision_motion", " namespace pandora_vision"], "motion_processor": ["*******************************************************************", "", " Initiliaze the motion detector.", "/ The dynamic reconfigure parameter's callback", "", " namespace pandora_vision_motion", " namespace pandora_vision"], "motion_node": ["*******************************************************************"], "motion_detector": ["*******************************************************************", "/ Check that frame_ has data and that image has 3 channels", "/ Update the background model and create", "/ binary mask for foreground objects", "/ Check that the thresholded difference image has data", "/ Calculate the standard deviation", " ROS_INFO_STREAM(\"Motion stdev=\" << stdDev[0] << \" max_deviation= \" << maxDeviation_);", "/ If not to much changes then the motion is real", "/ find motion Contours", " ROS_INFO_STREAM(\"Contours found=\" << contours.size());", "/ find motion Points", " ROS_INFO_STREAM(\"motion points=\" << motionPoints.size());", "/ Start dbscan to cluster motion Points for localization", " clusters_.reset(new ClusteredPoints);", " dbscan.getClusters(clusters_);", " ROS_INFO_STREAM(\"CLUSTERS FOUND=\" << clusters_.size());", " if (clusters->size() > 0)", " {", " cohesion = dbscan.getCohesion(clusters);", " for (int i = 0; i < cohesion.size(); i++)", " {", " std::cout << cohesion[i] << std::endl;", " }", " }", " Bound clusters into a box", " ROS_INFO_STREAM(\"PROB=\" << probability << \" points=\" << points);", "/ Counts value of non zero pixels in binary image in order", "/ to find the exact number of pixels, that differ from current", "/ frame_ and background", " H component", " S component", " V component", " Convert from 8-bit integers to doubles", " Convert from HSV to RGB, using double ranges 0.0 to 1.0", " achromatic (grey)", " If Hue == 1.0, then wrap it around the circle to 0.0", " sector 0 to 5", " integer part of h (0,1,2,3,4,5 or 6)", " \" \" \" \"", " factorial part of h (0 to 1)", " case 5 (or 6):", " Convert from doubles to 8-bit integers", " Clip the values to make sure it fits within the 8bits.", " Set the RGB cvScalar with G B R, you can use this values as you want too..", " R component", " namespace pandora_vision_motion", " namespace pandora_vision"], "dbscan": ["*******************************************************************", "", " _clusteredPoints.push_back(false);", "", "", "", "", " (calculateDistanceMatrix(p, i) < _eps)// (DP[i*_data.size()+p] <= _eps)", "", "/ For each point in P' neighbor", "/ If P' is not visited", "/ Mark P' as visited", " expandCluster(neighbours[i], neighbours_p);", "", "  if(_labels[j] == -1) ", " noise.push_back(_data[j]); ", " *noisePoints = noise;", "/ calculate centroids", "/ calculate cohesion", " for (int i = 0; i < clusters.size(); i++) ", " {", " ROS_INFO_STREAM(\"d\");", " cohesion.push_back(0.0);", " for( int j = 0; j < clusters[i].size(); j++)", " for (int k = 0; k < clusters[i].size(); k++)", " {", " cohesion[i] += dist2d(clusters[i][j], clusters[i][k]);", " }", " cohesion[i] /= clusters[i].size();", " } ", " ROS_INFO_STREAM(\"DP[\"<<i<<\"][\"<<j<<\"]=\"<<x);", "/ Mark current point as visited", " ROS_INFO_STREAM(\"FIND NEIGHBORS OF POINT \" << i << \" SIZE=\"<< neighbours.size());", "  && i != 0) ", "/ Mark P as noise", " ROS_INFO_STREAM(\"POINT \"<< i <<\" is noise\");", "/ Expand cluster", " ROS_INFO_STREAM(\"EXPAND\" << _cluster_id);", " if (DP[pt1][pt2] != -1.0)  ", " {", " double x = DP[pt1][pt2];", " // ROS_INFO_STREAM(\"dist\"<< pt1 << \" \"<< pt2 <<\"=\" << x);", " return DP[pt1][pt2];", " }  ", "   cv::Rect a = _data[pt1]; ", " cv::Rect b = _data[pt2];", " cv::Point2d tla = cv::Point2d(a.x, a.y);", " cv::Point2d tra = cv::Point2d(a.x + a.width, a.y);", " cv::Point2d bla = cv::Point2d(a.x, a.y + a.height);", " cv::Point2d bra = cv::Point2d(a.x + a.width, a.y + a.height);", " cv::Point2d tlb = cv::Point2d(b.x, b.y);", " cv::Point2d trb = cv::Point2d(b.x + b.width, b.y);", " cv::Point2d blb = cv::Point2d(b.x, b.y + b.height);", " cv::Point2d brb = cv::Point2d(b.x + b.width, b.y + b.height);", " double minDist = 9999999;", " minDist = std::min(minDist, dist2d(tla, tlb));", " minDist = std::min(minDist, dist2d(tla, trb));", " minDist = std::min(minDist, dist2d(tla, blb));", " minDist = std::min(minDist, dist2d(tla, brb));", " minDist = std::min(minDist, dist2d(tra, tlb));", " minDist = std::min(minDist, dist2d(tra, trb));", " minDist = std::min(minDist, dist2d(tra, blb));", " minDist = std::min(minDist, dist2d(tra, brb));", " minDist = std::min(minDist, dist2d(bla, tlb));", " minDist = std::min(minDist, dist2d(bla, trb));", " minDist = std::min(minDist, dist2d(bla, blb));", " minDist = std::min(minDist, dist2d(bla, brb));", " minDist = std::min(minDist, dist2d(bra, tlb));", " minDist = std::min(minDist, dist2d(bra, trb));", " minDist = std::min(minDist, dist2d(bra, blb));", " minDist = std::min(minDist, dist2d(bra, brb)); ", " DP[pt1][pt2] = minDist;", " DP[pt2][pt1] = minDist;", " // ROS_INFO_STREAM(\"DIST\"<< pt1 << \" \"<< pt2 <<\"=\" << minDist);", " namespace pandora_vision_motion", " namespace pandora_vision"], "motion_detector_test": ["*******************************************************************", "", " accessors to private functions ", " Unit Tests ", " namespace pandora_vision_motion", " namespace pandora_vision"], "landoltc_postprocessor": ["*******************************************************************", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc_preprocessor": ["*******************************************************************", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc_node": ["*******************************************************************"], "landoltc_handler": ["*******************************************************************", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc_detector": ["*******************************************************************", "!< Constructor", "", "!< Get the path to the pattern used for detection", "!< Loading reference image passed as argument to main", "!< Turning to gray and binarizing ref image", "", " std::cout << \"Angle of \" << i <<\" is: \" << (angle*(180/3.14159265359)) << std::endl;", " ROS_INFO(\"Angle of %d is %lf \\n\", i, angle*(180/3.14159265359));", "", " std::cout << \"Angle of \" << i <<\" is : \" << angle*(180/3.14159265359) << std::endl;", " ROS_INFO(\"Angle of %d is %lf \\n\", i, angle*(180/3.14159265359));", "", "", "!< if line is out of frame return", "!< X major line", "!< calculation of values of line, gradient and intercept", "!< Y major line", "!< calculation of values of line, gradient and intercept", "", "!< Rasterization of lines between thresholded points", " old _minDiff* _minDiff", "!< Searching for landoltC centers", " old _threshold", "!< Search if there's a bigger center in a smaller area", " std::cout << \"Bullseye \" << bullcount++ << \" xy \" << center.x << \",\" << center.y << std::endl;", "", "", " Corners of the destination image", " Get transformation matrix", " Apply perspective transformation", "", "!< find contours and moments in frame used for shape matching later", "!< Shape matching using Hu Moments, and contour center proximity", " do stuff", "", "", "", "", "", "", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc_parameters": ["*******************************************************************", "!< The dynamic reconfigure parameter's callback", "", "!< Threshold parameters", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc3d_parameters": ["*******************************************************************", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc3d_detection": ["*******************************************************************", "", " Convert field of view from degrees to rads", " Initiliaze and preprocess reference image", " Setting Predator value ON or OFF for the 3DLandoltC Detector", " This is used for the fusion function later, in order to assign", " probabilities according to the predator state", " The dynamic reconfigure parameter's callback", "!< initialize states - robot starts in STATE_OFF", "", "", " Declare publisher and advertise topic", " where algorithm results are posted if it works alone", " Declare subscriber", " where algorithm results are posted if it works with predator", " Get the path to the pattern used for detection", " Get the PredatorOn value", " Get the camera to be used by landoltc3d node;", " Get the Height parameter if available;", " Get the Width parameter if available;", " Get the HFOV parameter if available;", " Get the VFOV parameter if available;", " Get the listener's topic;", "", " Parse robot description", " Get current link and its parent", " Set the parent frame_id to the parent of the frame_id", "", " ROS_INFO(\"Getting Frame From Camera\");", " ROS_INFO(\"Getting Frame From Predator\");", "", " Create message of Landoltc Detector", " Landoltc center's coordinates relative to the center of the frame", " Landoltc center's yaw and pitch", "", " check if datamatrix algorithm should be running now", " shutdown if the robot is switched off", "!< this needs to be called everytime a node finishes transition", "", "", " Threshold parameters", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc3d_node": ["*******************************************************************", ""], "landoltc3d_detector": ["*******************************************************************", "/ Constructor", "/ Destructor", "", " Loading reference image passed as argument to main", " std::cout << path << std::endl;", " std::cout << \"Pattern image not loaded\" << std::endl;", " Turning to gray and binarizing ref image", "", "", "", "", "", " Corners of the destination image", " Get transformation matrix", " Apply perspective transformation", "", " std::cout << \"Angle of \" << i <<\" is : \" << angle*(180/3.14159265359) << std::endl;", " ROS_INFO(\"Angle of %d is %lf \\n\", i, angle*(180/3.14159265359));", " delete[] pts;", "", " delete[] integralImg;", "", " if line is out of frame return", " X major line", " calculation of values of line, gradient and intercept", " Y major line", " calculation of values of line, gradient and intercept", "", " Rasterization of lines between thresholded points", " Searching for landoltC centers", " Search if there's a bigger center in a smaller area", " std::cout << \"Bullseye \" << bullcount++ << \" xy \" << center.x << \",\" << center.y << std::endl;", "", " find contours and moments in frame used for shape matching later", " Shape matching using Hu Moments, and contour center proximity", "", " cv::adaptiveThreshold(dst, thresholded, 255, cv::ADAPTIVE_THRESH_GAUSSIAN_C,", " cv::THRESH_BINARY_INV, 7, Landoltc3DParameters::adaptiveThresholdSubtractSize);", "", " ROS_INFO(\"Probability is %f\", confidence);", "", "", "", "", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc_detector_test": ["*******************************************************************", "", " process input and call findcenters", " returns possible center", " y=column,i=row", "* test cases *", " TEST_F(LandoltcDetectorTest, rasterizeLineTest)", " {", " cv::Point a(1,1);", " cv::Point b(2,2);", " cv::Point c(4,5);", " cv::Point d(6,3);", " cv::Point e(2,4);", " EXPECT_EQ(1,giveVotingData(a, b, 1, 1));", " EXPECT_EQ(1,giveVotingData(b, c, 2, 2));", " EXPECT_EQ(1,giveVotingData(b, c, 3, 3));", " EXPECT_EQ(1,giveVotingData(b, c, 4, 3));", " EXPECT_EQ(1,giveVotingData(d, c, 5, 4));", " EXPECT_EQ(1,giveVotingData(d, c, 4, 5));", " EXPECT_EQ(1,giveVotingData(b, e, 2, 2));", " EXPECT_EQ(1,giveVotingData(b, e, 3, 2));", " }", " namespace pandora_vision"], "landoltc3d_detector_test": ["*******************************************************************", "", " namespace pandora_vision"], "datamatrix_node": ["*******************************************************************"], "datamatrix_detector": ["*******************************************************************", "", "", "!< Deallocate memory", "", "!< creates and initializes a new DmtxImage structure using pixel", "!< data provided  by  the calling application.", "!< creates and initializes a new DmtxDecode struct, which", "!< designates the image to be scanned and initializes the scan", "!< grid pattern.", "!< add msecs to timeout", "!< searches every pixel location in a grid pattern looking", "!< for potential barcode regions. A DmtxRegion is returned", "!< whenever a potential barcode region is found, or if the final", "!< pixel location has been scanned.", "!< Find datamatrixe's center exact position", "", "", " namespace pandora_vision_datamatrix", " namespace pandora_vision"], "datamatrix_preprocessor": ["*******************************************************************", " namespace pandora_vision_datamatrix", " namespace pandora_vision"], "datamatrix_postprocessor": ["*******************************************************************", " namespace pandora_vision_datamatrix", " namespace pandora_vision"], "datamatrix_handler": ["*******************************************************************", " namespace pandora_vision_datamatrix", " namespace pandora_vision"], "datamatrix_processor": ["*******************************************************************", "", "", "", "!< Deallocate memory", "", " namespace pandora_vision_datamatrix", " namespace pandora_vision"], "datamatrix_detector_test": ["*******************************************************************", "", "", "! Tests DatamatrixDetector::detect_datamatrix", " there shouldn't be any datamatrices", " neither when 3 channels are used", " there shouldn't be any datamatrices", " Vertically concatenated", " there shouldn't be any datamatrices", " there shouldn't be any qrcodes", " there shouldn't be any qrcodes", "TEST_F (DatamatrixDetectorTest, detect_datamatrixFromImage)", "{", "  cv::Mat inputFrame;", "  inputFrame = cv::imread(\"/home/v/Documents/PANDORA/Vision/Qr_Datamatrix_Testing/datamatrix1.jpg\");", "  //cv::resize(inputFrame, inputFrame, cv::Size(WIDTH, HEIGHT));", "  std::vector<POIPtr> datamatrix_list = detectDatamatrix(inputFrame);", "  // there should be one datamatrix", "  ASSERT_EQ(1, datamatrix_list.size());", "  int* center = locateDatamatrix(datamatrix_list[0].datamatrix_center);", "  EXPECT_LE(130, center[0]);   ", "  EXPECT_GE(160, center[0]);   ", "  EXPECT_LE(263, center[1]);   ", "  EXPECT_GE(293, center[1]);   ", "  // inputFrame = cv::imread(\"\");", "  // datamatrix_list = detectDatamatrix(inputFrame);", "  // // there should be four datamatrices", "  // EXPECT_EQ(4, datamatrix_list.size());", "  // inputFrame = cv::imread(\"\");", "  // datamatrix_list = detectDatamatrix(inputFrame);", "  // // there should be one datamatrix", "  // EXPECT_EQ(1, datamatrix_list.size());", "}", " namepsace pandora_vision_datamatrix", " namespace pandora_vision"], "color_processor": ["*******************************************************************", "", " Initiliaze the Colordetector.", "!< The dynamic reconfigure parameter's callback", "", " namespace pandora_vision_color", " namespace pandora_vision"], "color_handler": ["*******************************************************************", " namespace pandora_vision_color", " namespace pandora_vision"], "color_preprocessor": ["*******************************************************************", " namespace pandora_vision_color", " namespace pandora_vision"], "color_node": ["*******************************************************************"], "color_postprocessor": ["*******************************************************************", " namespace pandora_vision_color", " namespace pandora_vision"], "color_detector": ["*******************************************************************", "", "", "", "/ Check that frame has data and that image has 3 channels", "/ blur the image using GaussianBlur", "/ convert RGB image into HSV image", "/ get binary image", " pink*/", "  inRange(hsvFrame_, cv::Scalar(110,50,50), cv::Scalar(130,255,255), binary_);  // blue", "/ morphological opening (remove small objects from the foreground)", "/ morphological closing (fill small holes in the foreground)", "", " find contours", "/ find largest contour area", "/ get index of largest contour", "  double max; ", " cv::Point maxPosition;", " minMaxLoc(cv::Mat(areas), 0, &max, 0, &maxPosition); ", "/ draw largest contour.", " ROS_INFO_STREAM(\"AREAS=\");", "/ draw bounding rectangle around largest contour", " ROS_INFO_STREAM(\"CONTOUR NO \"<< i << \" area=\"<<areas[i]);", " draw rectangle", "  bounding_box->setWidth(r.width); ", " bounding_box->setHeight(r.height); ", "", " namespace pandora_vision_color", " namespace pandora_vision"], "color_detector_test": ["*******************************************************************", "", " accessors to private functions ", " namespace pandora_vision"], "predator_node": ["www.gnu.org/licenses/."], "predator": ["www.gnu.org/licenses/.", "", "!< Set initial value of parent frame id to null", "!< The dynamic reconfigure parameter's callback", "!< Get the path to the pattern used for detection", "!<Get Model Export Path", "!< Convert field of view from degrees to rads", "!< initialize states - robot starts in STATE_OFF", "", "", " user press left button ", " user drag the mouse ", "img->copyTo(imgCopy);", " user release left button ", "", " Parse robot description", " Get current link and its parent", " Set the parent frame_id to the parent of the frame_id", "", " draw bounding box", " end drawing bounding box (Enter)", "", "", "", "!< Get value of annotations state", "! Publishers", "! Declare publisher and advertise topic", "! where algorithm results are posted if it works alone or with annotator", "! Declare publisher and advertise topic", "! where algorithm results are posted if it works in compination with landoltc3d", "! Declare subscriber", "! if it works with annotator", "!< Get value for enabling or disabling TLD learning mode", "!< Get value of current operation state", "!< Get the camera to be used by predator node;", "! Get the Height parameter if available;", "! Get the Width parameter if available;", "!< Get the HFOV parameter if available;", "!< Get the VFOV parameter if available;", "!< Get the listener's topic;", "----------------detectorCascadeParams---------------------//", "", "", " Predator's center's coordinates relative to the center of the frame", " Predator center's yaw and pitch", "", "!< check if predator algorithm should be running now", "!< shutdown if the robot is switched off", "!< this needs to be called everytime a node finishes transition", "", "", " namespace pandora_vision"], "orb_detector": ["*******************************************************************", "", " Initialize the matchers that will be used for the", " detection of the pattern.", " A temporary container for the descriptors of each pattern.", " Add the descriptors of the i-th pattern to the", " container.", " Add the descriptors to the matcher and train it.", " Clear the container for the next iteration.", " Initialize the keypoint detector and the feature extractor", " that will be used.", "", " Detect the Keypoints on the image.", " Extract descriptors for the the detected keypoints.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "feature_matching_detector": ["*******************************************************************", "", " Read the necessary data.", "", " Open the file for reading.", " Check if the file was opened succesfully.", " Go to the xml node that contains the pattern names.", " Check if the node has a sequence.", " Initialize File iterator.", " Iterate over the node and get the names.", " Check if the names of the patters where read successfully.", " Close the file with the pattern names.", " For every pattern name read the necessary training data.", " Open the training file associated with image #i .", " Check if the file was properly opened.", " Read the pattern's descriptors.", " Read the pattern's keypoints.", " Initialize node iterators.", " Iterate over the node to get the keypoints.", " Read the pattern's bounding box.", " Initialize it's iterator.", " Add the pattern to the pattern vector.", " Close the xml file.", "", " Clear the vectors containing the matched keypoints.", " Define the vector of vectors that contains the matches.", " Each element is a vector that contains the first,the second", " up to the n-th best match.", " Check if the keypoints for pattern #patternID have been loaded.", " Check if we have stored the descriptors for pattern #patternID.", " No keypoints detected in the scene so the matching cannot continue.", " No descriptors calculated for the current frame.", " Perfom the matching using the matcher of the patternID-th", " pattern and find the top 2 correspondences.", " The vector containing the best matches", " If we have found any matches.", " We filter that matches by keeping only those", " whose distance ration between the first and the second", " best match is below a certain threshold.", " TO DO : READ THE THRESHOLD FROM FILE.", " No matches found.", " Add the keypoints of the matches found to the corresponding", " vectors for the pattern and the scene.", " Pattern key points.", " Scene key points.", " If we have less than 4 matches then we cannot find the Homography", " and this is an invalid pattern.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "hazmat_postprocessor": ["*******************************************************************", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "sift_detector": ["*******************************************************************", "", " Initialize the matchers that will be used for the", " detection of the pattern.", " A temporary container for the descriptors of each pattern.", " Add the descriptors of the i-th pattern to the", " container.", " Add the descriptors to the matcher and train it.", " Clear the container for the next iteration.", " Initialize the keypoint detector and the feature extractor", " that will be used.", "", " Detect the Keypoints on the image.", " Extract descriptors for the the detected keypoints.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "hazmat_handler": ["*******************************************************************", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "planar_object_detector": ["*******************************************************************", "", " Check if the frame is not an empty matrix.", " Check if that patterns have been read succesfully.", " The matrix that contains the descriptors of the frame.", " The mask that will be applied to the frame so as to limit the", " the search space.", " The detected keypoints of the frame that will be matched to the", " input pattern so as to find the correspondence from the training", " set to the query frame.", " Create the mask that will be used to extract regions of interest", " on the image based on the Image Signature Saliency Map.", " Calculate the keypoints and extract the descriptors from the", " frame.", " Temporary variables used to store the detected center of a pattern.", " For every pattern in the list :", " Try to find key point matches between the i-th pattern", " and the descriptors and the keypoints extracted from the frame.", " If we have succesfully found the matches.", " Find the bounding box for this query pattern.", " If this flag is true then a valid match has been found and", " we have detected the pattern.", " Get the center of the detected pattern.", "", " Check if we have enough points to find the homography between", " the pattern and the scene.", " Calculate the homography matrix using RANSAC algorithm to", " eliminate outliers.", " Transform the bounding box to the frame coordinates.", " Check if every point of the bounding box is inside the image.", " If not then the correspondences are invalid and these keypoints", " are rejected.", " The bounding box has a point out of the screen so it is", " rejected.", " Check if the Bounding box is Convex", " If not the resulting homography is incorrect due to false", " matching between the descriptors.", " A convex bounding box has been found inside the frame.", " Clear the bounding box vector.", " Not enough points for the homography.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "hazmat_processor": ["*******************************************************************", " Get the path of the current package.", " Initiliaze the object detector", " Check if the detector was initialized.", " Check if the features type has changed. If yes create a new detector.", " Check if the debug message printing is enabled.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "detector_factory": ["*******************************************************************", "", " Convert the input string to upper case format.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "hazmat_node": ["*******************************************************************", ""], "hazmat_preprocessor": ["*******************************************************************", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "surf_detector": ["*******************************************************************", "", " Initialize the matchers that will be used for the", " detection of the pattern.", " A temporary container for the descriptors of each pattern.", " Add the descriptors of the i-th pattern to the", " container.", " Add the descriptors to the matcher and train it.", " Clear the container for the next iteration.", " Initialize the keypoint detector and the feature extractor", " that will be used.", "", " Detect the Keypoints on the image.", " Extract descriptors for the the detected keypoints.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "image_signature": ["*******************************************************************", "", " if (array.channels() > 1)", " {", " std::cerr <<  \"Invalid channel number!\\n\" << std::endl;", " signs->data = NULL;", " return;", " }", " Compute the discrete cosine transform of the input image.", " Calculate the signature of the image.", " Convert the frame to a 3-channel float image and scale", " it's values accordingly.", " Resize the frame so as to process it correctly.", " TO DO : read the size from file.", " Split the input frame into it's separate channels.", " The resulting mask is a 1-channel floating point image , so as to", " correctly perform forward and inverse Discrete Cosine", " Transformatios.", " Temporary container for the inverse Discrete Cosine Transform", " for the #i channel of the image.", " For every channel of the image :", " Perform the inverse DCT on the signature.", " Calculate the total map.", " Calculate the mean of the saliency values of the 3 input channels.", " Resize the mask so that it can be applied to the frame.", " Threshold the mask to decrease noise and keep only the regions", " of interest.", " Convert the mask to 1-channel 8 bit format.", " *mask = sum;", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "surf_trainer": ["*******************************************************************", "", " Calculate image keypoints.", " Extract Descriptors from image", "", " Calculate image keypoints.", " Extract Descriptors from the images.", "", " Calculate the bounding box for the current pattern", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "factory": ["*******************************************************************", "", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "sift_trainer": ["*******************************************************************", "", " Calculate image keypoints.", " Extract Descriptors from image", "", " Calculate image keypoints.", " Extract Descriptors from the images.", "", " Calculate the bounding box for the current pattern", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "hazmat_trainer_node": ["*******************************************************************"], "planar_pattern_trainer": ["*******************************************************************", "", " The number of images.", " The temporary container for the images.", " The vector of the training image set.", " Open the file with the different pattern names.", " ROS_INFO(\"Reading the names of the patterns.\");", " Initialize the path to the data that will be used to train the system.", " Create the container for all the files in the directory containing", " the input of the training module.", " Check if the provided path exists.", " Iterate over the provided directory and store all", " the files/paths it contains.", " Sort the resulting data.", " Iterate over all the files/paths in the subdirectory.", " Check if the provided path exists.", " Check if it is a file.", " Check if it is a directory.", " If true then at least the training data for one pattern was acquired", " successfully.", "", " Iterate over the provided directory and store all", " the paths it contains.", " Sort the contained paths.", " Get the path to the image that represents the frontal view of", " the pattern.", " Get the path to the frontal view.", " Find the path in the container for the current subdirectory.", " Vector that contains the training set images.", " Check if the path was found.", " Since the frontal view was not found,training cannot continue.", " Check if it is a file.", " Add the frontal view to the collection.", " Remove the frontal view from the entries.", " Get the path to the file containing the homographies that", " created all the synthetic views.", " Initialize the container for the homographies.", " Check that the provided file is indeed a file.", " Get the homography matrices.", " If we failed to read the homographies then the training cannot", " continue.", " Find the position of the path of the homography input file", " in the list of paths.", " Delete the entry of the homography matrix from the list of", " paths.", " Iterate over all the contents of the folder and read all the images", " it contains.", " Add the current view to the collection.", " Finished parsing the images.", " We will now calculate the descriptors of the pattern", " from all the generating views!", "", " The vector that contains all the keypoints found in the training set.", " The array of all the descriptors detected in the training set.", " Calculate the features for the frontal view of the pattern.", " Find the features for all the images except the front view.", " Insert the frontal view keypoints.", " Perform the inverse transformations on the keypoints and store the", " result.", " For every image multiViewKeypoints.", " Get the homography that corresponds to the current view.", " Copy the keypoints detected in the i-th view.", " Apply the inverse homography transform to get points in the original", " coordinate frame.", " Add the transformed points to the vector containing all the", " keypoints.", " Concatenate the descriptors matrices.", " if(matches[i][0].distance < ratio*matches[i][1].distance)", " saveDataToFile(dirPath, multiViewDescriptors, multiViewKeypoints,", " boundingBox);", " saveDataToFile(dirPath, centroids, multiViewKeypoints,", " boundingBox);", "", " Calculate the image features.", " Save the training data for the i-th image.", "", " Create the file name where the results will be stored.", " Remove the file extension.", " Properly choose the name of the data file.", " TO DO : Change hard coded strings to yaml params.", " fileName = path + fileName;", " ROS_INFO(\"DEBUG MESSAGE : Saving fileName %s\", fileName.c_str());", " Opening the xml file for writing .", " Enter the name of the pattern.", " Save the descriptors.", " Calculate the number of keypoints found.", " Store the detected keypoints.", " Store the bounding box for the pattern.", " Close the xml file .", "", " Create the file name where the results will be stored.", " Remove the file extension.", " Properly choose the name of the data file.", " TO DO : Change hard coded strings to yaml params.", " fileName = path + fileName;", " ROS_INFO(\"DEBUG MESSAGE : Saving fileName %s\", fileName.c_str());", " Opening the xml file for writing .", " Enter the name of the pattern.", " Save the descriptors.", " Calculate the number of keypoints found.", " Store the detected keypoints.", " Store the bounding box for the pattern.", " Close the xml file .", "", " A container for each line.", " Open the file.", " The vector for the tokens.", " The vector used to parse to separate the float values.", " The vector containing the actual numerical values of the coefficients", " of the homography matrix.", " The OpenCV matrix that will be stored.", " Iterate over each line of the file.", " Split the line to get the name of the file.", " Insert the current value in the map and check if it is present.", " Check if any homography was read.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "orb_trainer": ["*******************************************************************", "", " Calculate image keypoints.", " Extract Descriptors from image", "", " Calculate image keypoints.", " Extract Descriptors from the images.", "", " Calculate the bounding box for the current pattern", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "feature_matching_test": ["*******************************************************************", " Check that if the array containing the descriptors calculated", " from the frame is empty then the function returns false.", " This time an empty array of the pattern descriptors is passed to the", " function.", " Pass an empty vector of pattern keypoint. The function must return", " false and not perform any calculations.", " Pass an empty vector of scene keypoints. The function must not do any", " computation and return a false flag.", " The function must return false since there are not enough points for", " the RANSAC algorithm to estimate the homography matrix.", " The function must return false since an empty vector is provided", " as a bounding box.", " Second rotation test.", " Scale test", " Scale and clockwise Rotation test.", " Scale and counter - clockwise Rotation test.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "trainer_test": ["*******************************************************************", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "image_signature_test": ["*******************************************************************", " Create a small image with positive elements .", " Create a matrix with positive elements.", " Create a matrix with positive elements.", " Check that every value is positive.", " Create a matrix with negative elements.", " Check that every value is negative.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "thermal_node": ["*******************************************************************"], "thermal_hole_detector": ["*******************************************************************", "", "", " Debug", " Detect edges in the thermal image", " Debug", " Find blobs in the edges image. Each blob is represented as", " a keypoint which is the center of the blob found", " Debug", " The final vectors of keypoints, rectangles and blobs' outlines.", "", " Debug", " Debug", " A vector of keypoints", " namespace thermal", " namespace pandora_vision_hole", " namespace pandora_vision"], "thermal_cropper": ["*******************************************************************", "", "", "", " Take NodeHandlers from nodelet manager", " Acquire the names of topics which the thermal_cropper node will be having", " transactionary affairs with", " Subscribe to the thermal poi published by thermal node", " Subscribe to rgb and depth images published by synchronizer node.", " Set the initial on/off state of the Hole Detector package to off", " Advertise enhanced message to victim node", " Advertise empty message to synchronizer node so the thermal process", " circle will start again", " Advertise the topic where any external node(e.g. a functional test node)", " will be subscribed to know that the hole node has finished processing", " the current candidate holes as well as the result of the procedure.", "", "", "", "", " The new on/off state of the Hole Detector package", " off -> on", " The on/off state of the Hole Detector Package is off, so the", " synchronizer must be unlocked to start the thermal procedure", " on -> off", " Shutdown or open publisher of enhanced images", "", " Send message to synchronizer in order for thermal procedure to start.", " namespace thermal", " namespace pandora_vision_hole", " namespace pandora_vision"], "thermal": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "thermal_cropper_node": ["*******************************************************************", ""], "noise_elimination": ["*******************************************************************", "", "", " Found black", "", " Boundaries check.", " If a neighboring points goes out of bounds, discard it", " Find the lowest non-zero value outside this concentration of", " zero-value pixels", " Because we will check for the value of neighboring points,", " if a point happens to be on the edges, it probably won't have any", " non-zero neighbors; discard it", " Scan all the neigbors of point (x, y)", " If the whole of the image is not black", " Now that the lowest value of non-zero neighboring pixels of", " this black concentration of pixels has been found,", " assign it to the whole of the concentration", "", " The number of zero value pixels", " The mean distance of the non-noisy points from the depth sensor", " The percentage of noise in the depth image", " Choose close", "", " interpolate the pixels at the edges of the inImage", " interpolate the rows", " interpolate the columns", " interpolate the corners", " top left", " top right", " bottom left", " bottom right", "", " The non-zero value neighbors' sum of values", " The number of non-zero value neighbors", " Up", " Upper right", " Right", " Lower right", " Down", " Lower left", " Left", " Upper left", "", " in the end, only pixels adjacent to the edge of the", " image are left black", "", "", " Thinning-like interpolation", " Produce the near brushfire image", " Produce the white noise image", "", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "holes_conveyor": ["*******************************************************************", "", "", "", " A conveyor of a single hole", " Assign the keypoint", " Assign the rectangle points", " Assign the outline points", " Append hole into conveyor", "", "", " If the dst is not empty, clear it", " Append the src to the dst", "", " The vector of the rectangle's vertices", " The four vertices of the rectangle", " Push them back into the vector", " Outline construction", "", " The conveyor that will be returned", " Push back the index-th hole of the conveyor into temp", "", " Clear the destination conveyor if not empty", " Append the first source to dst", " Append the second source to dst", "", " Delete the respective keypoint", "", " Clear the dst", " Fill it with the src", "", " Replace the dst's dstIndex-th hole's keypoint", " Replace the dst's dstIndex-th hole's rectangle points", " Replace the dst's dstIndex-th hole's outline points", "", " Keep the original holes' arrangement", " Hollow-out the src", " The vector of holes' indices", " Shuffle the indices", " Fill the src conveyor with the shuffled holes", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "histogram": ["*******************************************************************", "", "", " The vector of backprojection images corresponding to each", " discrete model histogram", " Convert the inImage image from RGB to HSV", " hue varies from 0 to 180", " saturation or value varies from 0 to 256", " Use the 0-th (Hue) and secondaryChannel channels", " Calculate the backproject of the input image depending on the", " i-th histogram", " Combine all backprojections into one. The value of each pixel of the", " overall backprojection shall be the maximum value of the", " sub-backprojections for that pixel", "", " The path to the package where the wall pictures directory lies in", " The actual wall pictures directory", " The number of textures inside the wallsDirectory directory", " The walls directory should exist; otherwise abort.", " Find how many texture directories there are inside the walls directory.", " The name of each directory shall be \"texture_X\" where X denotes an", " integer starting from 0.", " The name of each listing in the walls directory in string format", " The position of the \"_\" separator", " Traverse all textures and create a histogram for each one", " The actual wall pictures directory", " The number of wall picture files inside the textures directory", " Find out how many images there are in each texture_X directory", " If no images are found in the \"texture_X\" directory, shutdown.", " Read the pictures inside the wallPicturesPath, convert them to HSV", " and calculate their histogram", " The first value will always be with regard to Hue", " hue varies from 0 to 179, saturation and value from 0 to 255", " Use the 0-th and secondaryChannel-st channels", " A temporary histogram where the computed histogram will be put", " Calculate the histogram for the walls", " Append the histogram of this collection of texture images to", " the overall vector of histograms", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "blob_vector": ["*******************************************************************", "", " A single hole", " Recreate conveyor.keypoints", " Recreate conveyor.rectangles", " Recreate conveyor.outlines", " Because the outline points do not constitute a coherent shape,", " we need to draw them, connect them linearly and then the", " points that are drawn will be the hole's outline points", " The easiest and most efficient way to obtain the same result as", " if image_representation_method was 0 is to apply the raycast", " algorithm", " Push hole back into the conveyor", " Assign area of interest", " Assign the outline points", " Append hole into conveyor", " Clear the destination conveyor if not empty", " Extend with the first source", " Extend with the second source", " Clear the destination conveyor if not empty", " Extend with the first source", " Extend with the second source", " Clear the destination conveyor if not empty", " Extend with the first source", " Extend with the second source", " Clear the destination conveyor if not empty", " Extend with the first source", " Extend with the second source", " Delete the respective keypoint", " Clear the dst", " Fill it with the src", " Clear the dst", " Fill it with the src", " Replace the dst's dstIndex-th hole's keypoint", " Replace the dst's dstIndex-th hole's keypoint", " Keep the original holes' arrangement", " Hollow-out the src", " The vector of holes' indices", " Shuffle the indices", " Fill the src conveyor with the shuffled holes", " The vector of the rectangle's vertices", " The four vertices of the rectangle", " Push them back into the vector", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "outline_discovery": ["*******************************************************************", "", "", " Get a pointer on the edges image", " The sets needed by the brushfire implementation", " The indices of the blob's outline points stored in a set.", " If the blobOutlineVector was used, in it there would be redundant copies", " of each outline point", " Sweep the neighbors of the current point", " This check is needed because it is possible to access", " a point diagonal to the current one", " that goes out of the image's borders (value == 0),", " while it shouldn't.", " E.g. this happens when there are \"cracks\" to the border of a", " 1-pixel border", " Column-wise coordinate", " Row-wise coordinate", " The index of this neighbor inside image edgesImage", " If this neighbor is not within the image's borders,", " discard it and move on", " The value of the point with index ind in edgesImage", " If this neighbor is a blank pixel and", " it has not been visited, put it in set \"next\"", " If this neighbor has a non-zero value, it is an outline point", " Whatever the condition, this neighbor has been visited", " The set of all future points becomes the one with which the", " brushfire will begin", " Clear set \"next\" for the next iteration", " Fill the blobOutlineVector with the", " transformed content of the blobOutlineSet", " The area of the blob is essentialy the number of points visited", "", " The outline points of the current blob", " The area of the current blob", " Apply the brushfire algorithm for the current keypoint", " Push back the blobOutlineVector to the overall outline points vector", " Push back the area of the blob to the overall areas vector", "", " Get a pointer on the input image", " The sets needed by the brushfire implementation", " sweep the neighbors of the current point", " This check is needed because it is possible to access", " a point diagonal to the current one", " that goes out of the image's borders (value == 0),", " while it shouldn't.", " E.g. this happens when there are \"cracks\" to the border of a", " 1-pixel border", " Column-wise coordinate", " Row-wise coordinate", " The index of this neighbor inside image inImage", " If this neighbor is not within the image's borders,", " discard it and move on", " The value of the point with index ind in edgesImage", " If this neighbor is a blank pixel and", " it has not been visited, put it in set \"next\"", " Whatever the condition, this neighbor has been visited", " The set of all future points becomes the one with which the", " brushfire will begin", " Clear set \"next\" for the next iteration", "", " In order to obtain the outline of the mask quickly,", " the input image is eroded once. The outline is acquired from the", " difference between the input image and the eroded one.", "", " Debug", " Kernels for obtaining boundary pixels", " Invert the image to facilitate floodfill's operation", " A vector that holds floodfill images needed for the final output", " First floodfill operation", " Push the first floodfill operation's result", " back into the floodfillsVector", " Termination flag", " The total number of images needed to obtain a clear result", " Invert the image to facilitate floodfill's operation", " Second floodfill operation", " The prunedFloodFill image will act as termination check", " If it is filled with zeros, that means that there are no", " closed shapes in the floodfill's image.", " If not, we need to iterate the floodfill procedure", " Check the prunedFloodFill image for the numerosity of zeros", " If there are non-zero pixels, reiterate", " Push the second floodfill operation's result", " back into the floodfillsVector", " The final floodfill-ed image", " Dilate twice:", " once to (a) get rid of pesky borders", " and once (b) for the blob's outline to approximate the original's outline", " The floodfill's edges - region borders", " Debug", " Debug", "", " Debug", " Flood the original image from (0, 0) with a value of 255", " The pixels affected by the above floodfill operation are", " backgroung pixels. The ones that remain unaffected are interior to the", " shapes whose outline we wish to identify.", " Store these pixels in the tempImage image", " Kernels for obtaining boundary pixels", " The image whose non-zero pixels indicate the outlines of shapes", " Debug", " Debug", "", " Get a pointer on edgesImage", " A vector storing the non-zero pixels surrounding the keypoint", " The angle of a ray relative to the horizontal axis", " The increment of a ray's angle", " Make a complete revolution", " Indicates whether this ray has hit a non-zero value point", " Variable responsible for advancing the tip of the ray until it", " finds a non-zero value point", " A ray can hit up to 5 outline points, but only one must be chosen.", " Store these points as potential outline points.", " We will select only the first one found", " Advance the tip of the ray forwards", " Has the ray gone out of the image's bounds?", " If yes, impose limits", " The index of the neighbor of the ray's tip", " .. and its value in the edgesImage image", " If the neighbor has a non-zero value, or it is a boundary", " pixel (hence there is no valid value,", " and one has to be imposed), this point is an outline point", " End {while outline not found} loop", " From the, at most 5, outline points found,", " regard only one of them as an outline point, so that, in total,", " their number equals the number of partitions", " (Needed to approximate fairly accurately the blob's area)", " Increase the angle of the ray", " If the area of the blob needs to be returned", " Calculate each blob's approximate area by heron's formula", " https://en.wikipedia.org/wiki/Heron's_formula", " calculate the area of each triangle found", " O is the keypoint and A, B two successive outline points", " Instead of keeping the sparce points that are the product of", " the raycast algorithm, connect them linearly in order to", " have a coherent set of points as the hole's outline", " Draw the connected outline of the i-th hole onto canvas", " Clear the outline vector. It will be filled with the points", " drawn on the canvas image", " Every non-zero point is a point drawn; it is a point that", " belongs to the outline of the hole", " The final outline points vector", "", " The current blob's outline", " The current blob's area", " Find the outline and the area of the current keypoint", " Push the blob's area back into the vector of areas", " Push the blob's outline back into the vector of blobs' outline points", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "image_matching": ["*******************************************************************", "", "", " Counter of holes deleted", " Match the keypoint of each Hole found", " If the keypoint is out of or on rbg image borders reject", " that hole immediately.", " Continue the process", " Match the bounding box and check if it is outside rgb image, if so", " reject that hole. Bounding box check is enough, we dont need to check", " outlines, because they reside entirely inside it.", " If hole rejected skip next process step", " Match the blobs outline points", " The easiest and most efficient way to obtain the new outline is to", " apply the raycast algorithm", " cv::Mat canvas = cv::Mat::zeros(Parameters::Image::HEIGHT,", " Parameters::Image::WIDTH, CV_8UC1);", " unsigned char* ptr = canvas.ptr();", " for (unsigned int a = 0; a < conveyor->holes[i].outline.size(); a++)", " {", " unsigned int ind =", " conveyor->holes[i].outline[a].x + canvas.cols * conveyor->holes[i].outline[a].y;", " ptr[ind] = 255;", " }", " float area = 0.0;", " OutlineDiscovery::raycastKeypoint(conveyor->holes[i].keypoint,", " &canvas,", " Parameters::Outline::raycast_keypoint_partitions,", " false,", " &conveyor->holes[i].outline,", " &area);", " Second method to connect the new outlines", " Put the outline points in order for each hole", " Connect the points in order to have a coherent set of points", " as the hole's outline. For each hole.", "", " The value of thermal image point.x or point.y in Rgb image after", " linear transformation.", " Rotational transformation", "", " Draw the outline of the new ordered points for each hole", " Clear the outline vector so it can be filled with the new outline", " points from the outlineImage image.", " Every non-zero point is a point drawn so pass it to the vector.", "", " Vector of points that will contain the points in order.", " For each hole found.", " Push the first point in the new vector and erase it from the old vector", " Set as starting minimum value width*2, a value that can never", " been surpassed by any distance between points", " Index that shows the place of the new closest point found in", " the old vector.", " Find the x distance between two points and square it.", " Find the y distance between two points and square it.", " Find the euclidean distance between two points.", " Pass the point found to the new vector.", " The new initial point that we check distances changes.", " Erase that point from the starting vector.", " Pass the points found in order to the holesconveyor struct", " Clear the newVector so it can be used for the next hole", "", " Read values of each variable.", " x_thermal variable.", " y_thermal variable.", " C factor on x directions.", " C factor on y directions.", " The angle that thermal image been rotated.", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "wavelets": ["*******************************************************************", "", "", " LowLow contains the inImage's low low frequencies, in CV_32FC1 format", " What we will return will be this image scaled to the actual proportions", " of values of the inImage (also in CV_32FC1 format).", " After obtaining the low-low, reverse the scale operation, in an", " attempt to approximate the initial depth image's values", "", " LowLow contains the inImage's low low frequencies, in CV_32FC1 format", " What we will return will be this image scaled to the actual", " proportions of values of the inImage (also in CV_32FC1 format).", " The outImage. out has to be assigned to *outImage but cannot be done", " in the following loops immediately", " Copy out to the output image", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "visualization": ["*******************************************************************", "", "", " Draw images", " Final resize", "", "", "", " Construct a keypoints vector to feed into the cv::drawKeypoints method", "", "", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "bounding_box_detection": ["*******************************************************************", "", "", " Find the rotated rectangles for each blob based on its outline", " The area of the blob should be greater than a threshold,", " so that tiny formations of pixels are not identified as blobs", " For each rotated rectangle whose corresponding blob exceeds the minimum", " area threshold, if its vertices reside within the image's boundaries,", " store its vertices", " The for vertices of the rotated rectangle", " Check if the vertices reside in the image's boundaries", " If the rotated rectangle's edges reside outside the image's edges,", " discard this rotated rectangle", " If all four vertices reside within the image's boundaries,", " store them in their respective position", " Same as rect_points array, but vector", " Push back the 4 vertices of rectangle i", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "edge_detection": ["*******************************************************************", "", "", " Reduce noise with a kernel with size", " Parameters::Edge::canny_blur_noise_kernel_size ^ 2", " Canny detector", "", " appropriate values for scale, delta and ddepth", " the value for the non-edges", " Generate grad_x and grad_y", " Gradient X", " Gradient Y", " Total Gradient (approximate)", "", " appropriate values for scale, delta and ddepth", " the value for the non-edges", " Generate grad_x and grad_y", " Gradient X", " Gradient Y", " Total Gradient (approximate)", "", " appropriate values for scale, delta and ddepth", " the value for the non-edges", "", " Make the vertical borders of the image black", " Make the horizontal borders of the image black", " Vertically, find the outer white borders", " Horizontally, find the outer white borders", " Iterative contamination.", " Find all the pixels that are iteratively neighboring non-zero value", " pixels that lie next to the borders of the image", "", " The input depth image, in CV_8UC1 format", " The image of edges of the denoised depth image, in CV_32FC1 format", " Detect edges in the visualizableDepthImage", " Apply a threshold to the image of edges", " to get rid of low value - insignificant - edges", " Make all non zero pixels have a value of 255", " Denoise the edges found", "", " The input thermal image, in CV_8UC1 format", " The image of edges of the denoised thermal image, in CV_8UC1 format", " Detect edges in the visualizableDepthImage", " Apply a threshold to the image of edges", " to get rid of low value - insignificant - edges", " The next two steps are insignificant when we process the Temperature", " image extracted from thermal camera", " Make all non zero pixels have a value of 255", " Denoise the edges found", "", " The edges are detected on the segmented RGB image", " The edges are produced directly as a result of the watersheding", " of the rgb image with its backprojection", " Apply a threshold so as to get rid of, what we perceive to be, noise", " Make all non zero pixels have a value of 255", " Denoise the edges image", "", " Debug", " Connects each pair of points via a line", " Connects each pair of points via an arc", " The input image. On it the elliptical arcs will be drawn", " The image on which only the elliptical arcs will be drawn", " The euclidean distance of the pair", " The middle point of the segment connecting the pair points", " The angle that the line connecting the two pair points", " forms with the horizontal axis", " Given the line that is perpendicular to the line that connects", " the pair points, move on it one point at a time, in opposite", " directions. The first non-zero point found will be one of the", " curve that the pair lies on.", " Indicator that a non-zero value point has been found", " The outline point found", " Since there are two rays leaving the bisector point,", " in opposite directions,", " these two variables indicate the presence of the tip of the each ray", " within the image's borders", " Has the tip of the first ray gone out of bounds?", " Has the tip of the second ray gone out of bounds?", " Sweep the neighbors of the tip of the ray in order to find", " a valid non-zero value point, aka the outline point", " that is being sought", " Sweep the neighbors of the tip of the ray in order to find", " a valid non-zero value point, aka the outline point", " that is being sought", " An outline point could not be found", " The distance between the outline point found, and the middle point", " of the segment that connects the pair points", " If the curve that the pair points lie on approximates", " a straight line, do not connect the two pair points", " The major axis of the elliptical curve connecting the pair points", " The minor axis of the elliptical curve connecting the pair points", " The angle that the line that connects the first pair point and the", " outline point found forms with the horizontal axis", " The angle that the line that connects the second pair point and the", " outline point found forms with the horizontal axis", " Map the angles to the standard polar system", " The angle between the line that connects the two pair points", " and the horizontal axis", " The angle between the line that connects the two pair points", " and the horizontal axis. In order for the arc to accurately", " connect the two pair points, we need to know its orientation.", " It's one thing connecting point A to point B with an arc,", " and another connecting point B to point A with an arc.", " In other words, the arc has to have a starting point and an ending", " point in order for the total connected curve to have the same", " curvature orientation", " Both pair points are above the X axis", " Both pair points are below the X axis", " Pair point 2 is above the X axis while pair point 1 below it", " Pair point 1 is above the X axis while pair point 2 below it", " Draw the elliptical curve on the inImageDrawnOnce image", " size arg 1: length of the major axis. always pairsDistance / 2", " size arg 2: length of the minor axis.", " Debug", " Debug", "", " Debug", " Perform edge contamination:", " remove all non-zero pixels iteratively adjacent to the image's borders", " Debug", " Eliminate closed shapes", " Apply thinning to the contaminated original edges", " Debug", " By pruning the thinned image,", " all pixels that are open-ended are eliminated,", " leaving thus behind only shapes whose ends are connected, aka the", " closed shapes", " Debug", " The thinnedOpenLines image now features only the thinned,", " open-ended shapes", " We want to preserve the original (unthinned) outline of the closed shapes", " and connect the ends of open-ended shapes which are thinned to this point.", " So, first, we need to identify the closed shapes in the edge contaminated", " image. These will be stored in the closedLines image.", " The operation has finished when all the original closed shapes have", " been found", " Debug", " Debug", " In the image that features only open-ended shapes, find their end points.", " if they are eligible for connection,", " these points will be connected with each other", " Because the thinnedOpenLines image was wiped clean via the execution", " of the identifyCurvesAndEndpoints method, re-paint the lines found on it", " Connect the end points of open shapes", " Since what could be connected was connected, the rest of the open-ended", " shapes are not needed.", " Debug", " Re-enable the closed shapes", " Debug", " Extract only the outer border of closed shapes", " Debug", " Debug", "", "", "docs.opencv.org/modules/imgproc/doc/", " Get a pointer on mask to speed-up execution", " Fill this segment with a random colour", "", " This is edge", " This is joint", " Find larger dist between nodes", " Delete pointers inside nodes", "", " A point is potentially located along a curve only if its value", " is non-zero; otherwise it is not a point!", " Locate the indices of the points that constitute the curve on", " which point (i, j) is located, along with the end points of it.", " Push the indices of the points constituting the curve on which", " point (i, j) is located, into the overall curves' indices vector.", " Push the end-points of the curve into the overall vector of", " end-points", "", " Backprojection of the RGB inImage", " Get the backprojected image of the frame, based on the precalculated", " vector of histograms", " Locate the inImage's edges by watersheding it based on its", " backprojection", "", " Debug", " Copy the input image to the segmentedHoleFrame one", " Segment the input image.", " Posterize the product of the segmentation", " Fill the various segments with colour", " Convert the posterized image to grayscale", " In order to find the edges of the posterized image,", " first, turn it to grayscale", " Apply edge detection to the grayscale posterized input RGB image", "", " Termination criteria for the segmentation below", " Segment the image", "", " Threshold the backprojection", " The foreground image needed by the watershed algorithm", " Copy the backprojection to the foreground image", " Dilate", " All non-zero pixels have now a value of 255", " Erode. The erosion factor should be greater", " than the dilation factor used above", " The background image needed by the watershed algorithm", " Copy the backprojection to the background image", " Dilate", " All non-zero pixels have now a value of 255", " All zero value pixels turn to white, all white to black", " Erode. The erosion factor should be greater", " than the dilation factor used above. This erosion happens so that", " the background pixels belong surely to the background", " All zero value pixels' values are elevated to 128.", " These belong neither to foreground, nor to background:", " they are labeled as so-called \"unknown\"", " Create the markers image, needed by the watershed algorighm", " The markers array is composed by the foreground, background and", " unknown pixels", " Convert the marker image of type CV_8UC1, to CV_32S", " Watershed the input image, with regard to the markers constructed", " Each pixel p is transformed into", " 255p + 255 before conversion", " Convert the markers image to back to type CV_8UC1.", " This image identifies whole areas that the backprojection partially", " recognizes to be matching the histogram on which it is based", " Convert image markers32S into an edges image", " All zero value pixels turn to white, all white to black.", " In essence, this is the edges of the area whose histogram", " matches inHistogram", " Convert image markers32S into a depth of 8U", " All non-white pixels turn to black", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "blob_detection": ["*******************************************************************", "", "", " 40;", " 60;", " 0.6;", " 0.5;", " 0.3;", " detect blobs. store their center point", " if the keypoint is out of image limits, discard it", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "morphological_operators": ["*******************************************************************", "", "", "", " That's foreground", " Check for all adjacent", " The image's borders where left untouched.", " Dilate them here", " Left-most and right-most columns", " The image's left-most pixels", " The image's right-most pixels", " Upper-most and lower-most rows", " The image's upper-most pixels", " The image's lower-most pixels", " Finally, the 4 edges of the image", " Upper left", " Upper right", " Lower right", " Lower left", "", " That's foreground", " Check for all adjacent", " The image's borders where left untouched.", " Dilate them here", " Left-most and right-most columns", " The image's left-most pixels", " The image's right-most pixels", " Upper-most and lower-most rows", " The image's upper-most pixels", " The image's lower-most pixels", " Finally, the 4 edges of the image", " Upper left", " Upper right", " Lower right", " Lower left", "", " That's foreground", " Check for all adjacent", " The image's borders where left untouched.", " Erode them here", " Left-most and right-most columns", " The image's left-most pixels", " The image's right-most pixels", " Upper-most and lower-most rows", " The image's upper-most pixels", " The image's lower-most pixels", " Finally, the 4 edges of the image", " Upper left", " Upper right", " Lower right", " Lower left", "", "", "", " Check for initial stuff", "", "homepages.inf.ed.ac.uk/rbf/HIPR2/thin.htm)", " if the image is saturated by the thinning operator,", " cease its operation", " Delete pointer pts", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "message_conversions": ["*******************************************************************", "", "", "", " Prepare the output image", " For the depth image", " if element is nan make it a zero", " For the rgb image", " Get the index we need", " CV_32FC1", " it was int", "", " Fill the pandora_vision_msgs::CandidateHolesVectorMsg's", " candidateHoles vector", " Push back the keypoint", " Push back the bounding rectangle's vertices", " Push back the blob's outline points", " Push back one hole to the holes vector message", "", " Fill the ::::pandora_vision_hole::CandidateHolesVectorMsg's", " candidateHoles vector", " Fill the pandora_vision_msgs::CandidateHolesVectorMsg's", " image", " Fill the pandora_vision_msgs::CandidateHolesVectorMsg's", " header", "", "", "", " Normal mode", " A single hole", " Recreate the hole's keypoint", " Recreate the hole's rectangle points", " Recreate the hole's outline points", " Push hole back into the conveyor", " Wavelet mode", " A single hole", " Recreate conveyor.keypoints", " Recreate conveyor.rectangles", " Recreate conveyor.outlines", " Because the outline points do not constitute a coherent shape,", " we need to draw them, connect them linearly and then the", " points that are drawn will be the hole's outline points", " The easiest and most efficient way to obtain the same result as", " if image_representation_method was 0 is to apply the raycast", " algorithm", " Push hole back into the conveyor", "", " Unpack the image", " Recreate the conveyor", "", " The width and height of the input temperature multiarray", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_filters": ["*******************************************************************", "", "", " Locate the outline of blobs via brushfiring", " Find the outline points of each keypoint", " For each outline found, find the rotated rectangle", " with the least area that encloses it.", " Given the outline of the blob, find the least area", " rotated bounding box that encloses it", " Correlate each keypoint with each rectangle found.", " Keep in mind that for a blob to be a potential hole, its area", " must be greater than Parameters::bounding_box_min_area_threshold", " Locate the outline of blobs via raycasting", " Find the (approximate) outline points of each keypoint", " For each outline found, find the rotated rectangle", " with the least area that encloses it.", " Given the outline of the blob, find the least area", " rotated bounding box that encloses it", " Correlate each keypoint with each rectangle found.", " Keep in mind that for a blob to be a potential hole, its area", " must be greater than Parameters::bounding_box_min_area_threshold", " The end product here is a struct (conveyor) of keypoints,", " a set of rectangles that enclose them  and the outline of", " each blob found.", "", " Test to see where (in which rectangle(s)) the keypoint resides.", " If the keypoint resides in exactly one rectangle.", " A single hole", " Accumulate keypoint, rectangle and outline properties onto hole", " Push hole back into the conveyor", " If the keypoint resides in multiple rectangles,", " choose the one with the least area.", " The minimum area of all rectangles", " The index of the rectangle with the least area", " A single hole", " Accumulate keypoint, rectangle and outline properties onto hole", " Push hole back into the conveyor", " If the keypoint has no rectangle attached to it,", " do not insert the hole it corresponds to in struct hole", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "rgb": ["*******************************************************************", "", "", "", " Acquire the names of topics which the rgb node will be having", " transactionary affairs with", " Calculate the vector of histograms of images of wooden walls:", " the rgb node, depending on the procedure of edges extraction of", " rgb image, is going to need it", " Subscribe to the RGB image published by the", " rgb_depth_synchronizer node", " Advertise the candidate holes found by the rgb node", " The dynamic reconfigure (RGB) parameter's callback", "", "", " Obtain the rgb image. Since the image is in a format of", " sensor_msgs::Image, it has to be transformed into a cv format in order", " to be processed. Its cv format will be CV_8UC3.", " Regardless of the image representation method, the RGB node", " will publish the RGB image of original size to the Hole Fusion node", " A value of 1 means that the rgb image is subtituted by its", " low-low, wavelet analysis driven, part", " Obtain the low-low part of the rgb image via wavelet analysis", " Locate potential holes in the rgb image", " Create the candidate holes message", " Pack information about holes found and the rgb image inside a message.", " This message will be published to and received by the hole fusion node", " Publish the candidate holes message", "", " Read the name of the topic from where the rgb node acquires the", " rgb image and store it in a private member variable", " Read the name of the topic to which the rgb node will be publishing", " information about the candidate holes found and store it in a private", " member variable", "", "////////////////// Blob detection - specific parameters //////////////////", " In wavelet mode, the image shrinks by a factor of 4", "//////////////////////////// Debug parameters ////////////////////////////", " Show the rgb image that arrives in the rgb node", "////////////////// Parameters specific to the RGB node ///////////////////", "------------------- Edge detection specific parameters -------------------", " The opencv edge detection method:", " 0 for the Canny edge detector", " 1 for the Scharr edge detector", " 2 for the Sobel edge detector", " 3 for the Laplacian edge detector", " 4 for mixed Scharr / Sobel edge detection", " Canny parameters", "------------- Parameters needed for histogram calculation ----------------", "----------------- Outline discovery specific parameters ------------------", " The detection method used to obtain the outline of a blob", " 0 for detecting by means of brushfire", " 1 for detecting by means of raycasting", " When using raycast instead of brushfire to find the (approximate here)", " outline of blobs, raycast_keypoint_partitions dictates the number of", " rays, or equivalently, the number of partitions in which the blob is", " partitioned in search of the blob's borders", "------------------- Loose ends connection parameters ---------------------", " In wavelet mode, the image shrinks by a factor of 4", " Selects the method for extracting a RGB image's edges.", " Choices are via segmentation and via backprojection", "------------------- RGB image segmentation parameters --------------------", " Parameters specific to the pyrMeanShiftFiltering method", " Term criteria for the pyrMeanShiftFiltering method", " True to posterize the product of the segmentation", " FloodFill options regarding minimum and maximum colour difference", "------------ RGB image edges via backprojection parameters ---------------", " The threshold applied to the backprojection of the RGB image", " captured by the image sensor", " Watershed-specific parameters", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "rgb_hole_detector": ["*******************************************************************", "", "", " Debug", " Detect edges in rgbImage", " Debug", " Find blobs in the edges image. Each blob is represented as", " a keypoint which is the center of the blob found", " Debug", " The final vectors of keypoints, rectangles and blobs' outlines.", "", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "timer": ["*******************************************************************", " Mins", " Sec", " Ms"], "filters": ["*******************************************************************", "", " Initialize structures", " Filter #1 (Color homogeneity inside blob)------------------------------", " Filter #2 (Luminosity difference)------------------------------------", " Check for luminosity difference between the points that constitute", " the blob's bounding box and the points inside the blob's outline", " Filter #3 (Texture difference)---------------------------------------", " Filter #4 (Back project model histogram)-----------------------------", " Filter #5 (through difference of depth)--------------------------------", " Filter #6------------------------------------------------------------", " Inflate the bounding boxes by an inflation size.", " For a blob to be at least a potential hole, all the points that", " constitute the inflated rectangle should lie on exactly one plane.", " Filter #7 (depth & area comparison)----------------------------------", " Filter #8------------------------------------------------------------", " Brushfire from blob outline to blob bounding box", " with an inflation size (inflates the rectangle by x pixels).", " If the points between the blob's outline and the inflated rectangle", " lie on one plane, this blob is a hole.", " Filter #9 (Depth homogeneity)----------------------------------------", " All holes are considered valid except for those that are edgeless", " inside the area denoted by the conveyor->outlines points", " Debug", "", " A mapping of the filters' execution order to an identifier for each", " filter", " The filtering mode permission to application of depth analysis", " condition.", " Active Depth and RGB filters will both be applied", " Depth filtering cannot be applied, hence only RGB filters will", " be utilized", " Debugging images and messages of validity probabilities", " per candidate hole", " Apply each active filter, depending on the interpolation method", " o_it iterator ends", " Debug", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "planes_detection": ["*******************************************************************", "", "", "pointclouds.org/documentation/tutorials/voxel_grid.php)", " The output filtered cloud", "", " Apply voxel filtering", " The vector of planar point clouds", " The coefficients of the planes", " Locate planes", "", "www.pointclouds.org/documentation/tutorials/", " Create the segmentation object", " Optional", " Mandatory", " Maybe a value needs to be set dynamically here, depending on", " the distance of the kinect to the plane.", " Copy the input cloud to a point cloud that we will be processing", " While 100 x num_points_to_exclude % of the original", " cloud is still there", " The plane's coefficients", " The plane's inliers", " Segment the largest planar component from the remaining cloud", " Add the coefficients and inliers to their respective vectors", " Create the filtering object", " Extract the inliers", " Remove the plane found from pointCloudProcessed and place it in", " cloud_p. pointCloudProcessed goes unaffected.", " The inliers of the largest planar component create cloud_p", " Push back the point cloud of the plane found", " We want to extract the rest of the points that were found to lie on", " a plane", " In short: cloud_f = pointCloudProcessed - cloud_p", " pointCloudProcessed is now without cloud_p, that is,", " without the points that were", " found to lie on the largest planar component of pointCloudProcessed", " Increment the number of planes found", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_fusion": ["*******************************************************************", "", "", "", " Initialize the parent frame_id to an empty string", " Acquire the names of topics which the Hole Fusion node will be having", " transactionary affairs with", " Check if Thermal is enabled to run with hole-detection Package", " Thermal is enabled", " Thermal is disabled", " Initialize the numNodesReady variable.", " It acts as a counter of nodes that have published their output to the", " hole fusion node in each execution cycle.", " Advertise the topic that the rgb_depth_synchronizer will be", " subscribed to in order for the hole_fusion_node to unlock it", " Advertise the topic where any external node(e.g. a functional test node)", " will be subscribed to know that the hole node has finished processing", " the current candidate holes as well as the result of the procedure.", " Advertise the topic that the yaw and pitch of the keypoints of the final,", " valid holes will be published to", " Advertise the topic that information about the final holes,", " will be published to", " Command line usage:", " image_view /pandora_vision/hole_detector/debug_valid_holes_image", " _image_transport:=compressed", " Advertise the topic that information about holes found by the Depth", " and RGB nodes will be published to", " Command line usage:", " image_view /pandora_vision/hole_detector/debug_respective_holes_image", " _image_transport:=compressed", " Advertise the topic that the enhanced image", " will be published to", " enhancedImagesPublisher_ = nodeHandle_.advertise", "   <pandora_vision_msgs::EnhancedImage>(", "     enhancedImagesTopic_, 1, true);", " Advertise the topic that the image of the final holes,", " will be published to", " Advertise the topic that the image of the final holes,", " will be published to", " InterpolatedDepthImagePublisher_ = nodeHandle_.advertise", "   <sensor_msgs::Image>(", "     InterpolatedDepthImageTopic_, 1);", " Advertise the topic where the Hole Fusion node requests from the", " synchronizer node to subscribe to the input point cloud topic", " Advertise the topic where the Hole Fusion node requests from the", " synchronizer node to leave its subscription to the", " input point cloud topic", " Subscribe to the topic where the depth node publishes", " candidate holes", " Subscribe to the topic where the rgb node publishes", " candidate holes", " Subscribe to the topic where the synchronizer node publishes", " the point cloud", " Subscribe to the topic where the thermal node publishes", " candidate holes", " The dynamic reconfigure server for debugging parameters", " The dynamic reconfigure server for parameters pertaining to the", " priority of filters' execution:w", "", " The dynamic reconfigure server for parameters pertaining to", " thresholds of filters", " The dynamic reconfigure server for general parameters", " The dynamic reconfigure server for parameters pertaining to", " the validity of holes", " Set the initial on/off state of the Hole Detector package to off", " Initialize the filtering mode variable to an invalid value", " Calculate the collective histogram of images of walls needed", " for comparing against the one of images of the material surrounding", " candidate holes", "", "", " Clear the current depthHolesConveyor struct", " (or else keyPoints, rectangles and outlines accumulate)", " Unpack the message", " The candidate holes acquired from the depth node and the interpolated", " depth image are set", " If the RGB candidate holes and the RGB image are set", " and the point cloud has been delivered and interpolated,", " unlock the synchronizer and process the candidate holes from both sources", "", " Clear the current depthHolesConveyor struct", " (or else keyPoints, rectangles and outlines accumulate)", " Unpack the message", " The candidate holes acquired from the thermal node and the", " thermal image are set", " If the RGB candidate holes and the RGB image are set", " and the point cloud has been delivered and interpolated,", " unlock the synchronizer and process the candidate holes from both sources", "", " A vector of images that each one of them represents the corresponding", " hole's mask: non-zero value pixels are within a hole's outline points", " A vector of sets that each one of them contains indices of points", " inside the hole's outline", " A vector of vertices of each inflated bounding rectangle.", " Since inflated rectangle's vertices may go outside the image's bounds,", " this vector stores the indices of the keypoints whose corresponding", " inflated rectangle is in totality within the image's bounds", " A vector of sets that each one of them contains indices of points", " between the hole's outline and its respective bounding box", " A vector of images that each one of them contains points", " between the hole's outline and its respective bounding box", " Construct the necessary vectors, depending on which filters", " are to run in runtime and on the interpolation method", " Initialize the probabilities 2D vector.", " But first we need to know how many rows the vector will accomodate.", " If a Parameters::HoleFusion::run_checker_* variable is greater than zero,", " the respective filter is set to run", " The number of active RGB filters, regardless of the interpolation method", " The number of active depth filters", " If depth analysis is possible", " Depth analysis is not possible. Reserve positions in the probabilities", " vector only for the amount of RGB filters active.", " The 2D vector that contains the probabilities from the rgb filtering", " regime.", " Each column is a specific hole.", " In each row there are values of probabilities by a specific filter", " Apply all active filters, depending on the interpolation method", " All filters have been applied, all probabilities produced", "", " Parse robot description", " The parameter was not found.", " Set the parent of the frame_id to a default value.", " Get current link and its parent", " Set the parent frame_id to the parent of the frame_id_", "", " Read the name of the topic from where the Hole Fusion node acquires the", " input point cloud", " Read the name of the topic from where the Hole Fusion node acquires the", " candidate holes originated from the Depth node", " Read the name of the topic from where the Hole Fusion node acquires the", " candidate holes originated from the Rgb node", " Read the name of the topic from where the Hole Fusion node acquires the", " candidate holes originated from the Thermal node", " Read the name of the topic that the Hole Fusion node uses to unlock", " the synchronizer node", " Get the topic where the result of the hole processing will be", " published.", " Read the name of the topic that the Hole Fusion node uses to publish", " information about the valid holes found by the Hole Detector package", " Read the name of the topic that the Hole Fusion node uses to publish", " the EnhancedImage msg", " if (!privateNodeHandle_.getParam(\"published_topics/enhanced_images_topic\",", "     enhancedImagesTopic_))", " {", "   NODELET_FATAL(", "     \"[%s] Could not find topic enhanced_images_topic\", nodeName_.c_str());", "   ROS_BREAK();", " }", " Read the name of the topic that the Hole Fusion node uses to publish", " additional information about the valid holes found by the", " Hole Detector package", " Read the name of the topic that the Hole Fusion node uses to publish", " the InterpolatedDepthImage found by the", " Hole Detector package", " if (!privateNodeHandle_.getParam(\"published_topics/interpolated_depth_topic\",", "     InterpolatedDepthImageTopic_))", " {", "   NODELET_FATAL(", "     \"[%s] Could not find topic interpolated_depth_topic\", nodeName_.c_str());", "   ROS_BREAK();", " }", " Read the name of the topic that the Hole Fusion node uses to publish", " messages so that the synchronizer node subscribes to the", " input point cloud", " Read the name of the topic that the Hole Fusion node uses to publish", " messages so that the synchronizer node leaves its subscription to the", " input point cloud", " Read the name of the topic that the Hole Fusion node uses to publish", " an image of holes found by the Depth and RGB nodes", " Read the name of the topic that the Hole Fusion node uses to publish", " an image of the valid holes found", "", "", "//////////////////////////// Debug parameters ////////////////////////////", " Publish the enhancedImage", " Show the holes that each of the depth and RGB nodes transmit to the", " hole fusion node, on top of their respective origin images", " Show all valid holes, from either the Depth or RGB source, or", " the merges between them", " The product of this package: unique, valid holes", " In the terminal's window, show the probabilities of candidate holes", " Show the texture's watersheded backprojection", "", " Depth / Area", " Depth diff", " Outline of rectangle plane constitution", " Intermediate points plane constitution", " Depth homogeneity", " Color homogeneity", " Luminosity diff", " Texture diff", " Texture backproject", "", " Depth / Area", " Depth diff", " Outline of rectangle plane constitution", " Intermediate points plane constitution", " Depth homogeneity", " Colour homogeneity", " Luminosity diff", " Texture diff", " Texture backproject", "", " Threshold parameters", " Histogram parameters", " Backprojection parameters", " The inflation size of the bounding box's vertices", " Depth diff parameters", " 0 for binary probability assignment on positive depth difference", " 1 for gaussian probability assignment on positive depth difference", " The mean expected difference in distance between a hole's keypoint", " and the mean distance of its bounding box's vertices", " from the depth sensor", " The standard deviation expected", " Min difference in depth between the inside and the outside of a hole", " Max difference in depth between the inside and the outside of a hole", " Plane detection parameters", "--------------------------- Merger parameters ----------------------------", " Option to enable or disable the merging of holes", " Holes connection - merger parameters", "--------------------------- Texture parameters ---------------------------", " The threshold for texture matching", " The threshold for texture mismatching", " Method to scale the CV_32FC1 image to CV_8UC1", "----------------- Outline discovery specific parameters ------------------", " The detection method used to obtain the outline of a blob", " 0 for detecting by means of brushfire", " 1 for detecting by means of raycasting", " When using raycast instead of brushfire to find the (approximate here)", " outline of blobs, raycast_keypoint_partitions dictates the number of", " rays, or equivalently, the number of partitions in which the blob is", " partitioned in search of the blob's borders", "------------ RGB image edges via backprojection parameters ---------------", " Backprojection parameters", " Watershed-specific parameters", "", " The validation process", " config.validation_process;", " When depth analysis is applicable", " When depth analysis is not applicable, we can only rely", " on RGB analysis", "", " Convert the header of the point cloud message", " Store the frame_id and timestamp of the point cloud under processing.", " The respective variables in the headers of the published messages will", " be set to these values.", " Because the frame_id will be used to retrieve its parent frame_id from", " the robot's description, and the frame_id starts with a forward slash,", " remove it, in order for the search to be successful.", " The parent frame_id cannot be set in the constructor because the", " frame_id is not known until the first point cloud message arrives.", " In order not to parse the urdf file every time,", " set the parent frame_id string once", " Because the input point cloud is marked as const,", " and we need to interpolate the noise in it,", " copy the input point cloud to a local one.", " Extract the depth image from the point cloud message", " Interpolate the depthImage", " The noise elimination method above defines the interpolation method.", " Only in interpolation_method of zero can the depth filters through which", " each candidate hole is passed be utilized: there is no valid depth", " information available if the value of interpolation_method is set to", " other than zero.", " Set the interpolatedDepthImage's values as the depth values", " of the point cloud", " The interpolated point cloud, frame_id and timestamp are set", " If the depth and RGB candidate holes, the interpolated depth image", " and the RGB image are set,", " unlock the synchronizer and process the candidate holes from both sources", "", " if (Parameters::Debug::publish_enhanced_Images)", " {", "   publishEnhancedImage();", "   publishInterpolatedDepthImage();", " }", " Holes originated from analysis on the depth image,", " on top of the depth image", " Holes originated from analysis on the RGB image,", " on top of the RGB image", " Holes originated from analysis on the depth image,", " on top of the RGB image", " Holes originated from analysis on the RGB image,", " on top of the Depth image", " The four images", " The titles of the images", " If mode is enabled add the information from thermal procedure", " Holes originated from analysis on the thermal image,", " on top of the depth image", " Holes originated from analysis on the thermal image,", " on top of the rgb image", " Holes originated from analysis on the thermal image,", " on top of the resized Thermal image", " Publish an image depicting the holes found by the Depth RGB and Thermal nodes", " Merge the conveyors from the RGB Depth and Thermal sources into one conveyor", " The container in which holes will be assembled before validation", " Check if merging is enabled", " Keep a backup of the original holes found from both the", " RGB and Depth nodes", " Apply the {assimilation, amalgamation, connection} processes", " The original holes and the merged ones now reside under the", " preValidatedHoles conveyor", " Because mergers may have not been deemed valid, the preValidatedHoles", " container may include duplicate holes. Delete them, so that resources", " are not generated for them, and time is not wastefully consumed.", " Apply all active filters and obtain a 2D vector containing the", " probabilities of validity of each candidate hole, produced by all", " active filters", " Write the extracted probabilities to a file. These will be used to", " produce a dataset of values that need to be minimized in order for a", " sound validation procedure to be employed", " produceDataset(rgbdHolesConveyor, probabilitiesVector2D);", " Which candidate holes are actually holes?", " The probabilities obtained above need to be evaluated", " A vector containing images, one per valid hole found.", " A vector of validity probabilities per valid hole found.", " Iterate over the map of valid holes to their validity probabilities", " A vector containing one entry: the validity probability of the", " it->first-th hole", " The it->first-th valid hole", " Project this valid hole onto the rgb image", " Show all valid holes in one window", " In general, the preValidatedHoles conveyor will contain", " merged and um-merged holes, potentially resulting in multiple entries", " inside the conveyor for the same physical hole. The method below", " picks the most probable valid hole among the ones referring to the same", " physical hole.", " Rename the preValidatedHoles to uniqueValidHoles", " Contains the validity probability for each hole considered valid", " Valid holes on top of the interpolated depth image", " Valid holes on top of the RGB image", " The two images", " The titles of the images", " If there are valid holes, publish them", " Publish the enhanced holes message", " regardless of the amount of valid holes", " Open the dataset", " True holes", " << probabilities[4][i] << \", \"", " << probabilities[5][i] << \", \"", " << probabilities[6][i] << \", \"", " << probabilities[7][i] << \", \"", " << probabilities[4][i] << \", \"", " << probabilities[5][i] << \", \"", " << probabilities[6][i] << \", \"", " << probabilities[7][i] << \", \"", "", " void HoleFusion::publishInterpolatedDepthImage()", " {", "   // TO DO changed to ImagePtr", "   sensor_msgs::Image depthMsg;", "   depthMsg = MessageConversions::convertImageToMessage(", "   Visualization::scaleImageForVisualization(interpolatedDepthImage_,", "       Parameters::Image::scale_method),", "       sensor_msgs::image_encodings::TYPE_8UC1,", "       depthMsg);", "   InterpolatedDepthImagePublisher_.publish(depthMsg);", " }", "", " void HoleFusion::publishEnhancedImage()", " {", "   // The overall message of enhanced holes that will be published", "   pandora_vision_msgs::EnhancedImagePtr enhancedImagesMsgPtr(new pandora_vision_msgs::EnhancedImage);", "   // Set the rgbImage in the enhancedImagesMsg message to the rgb image", "   enhancedImagesMsgPtr->rgbImage = MessageConversions::convertImageToMessage(", "   rgbImage_,", "   sensor_msgs::image_encodings::TYPE_8UC3,", "   enhancedImagesMsgPtr->rgbImage);", "   // Set the depthImage in the enhancedImagesMsg message to the depth image", "   enhancedImagesMsgPtr->depthImage = MessageConversions::convertImageToMessage(", "   Visualization::scaleImageForVisualization(interpolatedDepthImage_,", "       Parameters::Image::scale_method),", "       sensor_msgs::image_encodings::TYPE_8UC1,", "       enhancedImagesMsgPtr->depthImage);", "   // Set whether depth analysis is applicable", "   enhancedImagesMsgPtr->isDepth = (filteringMode_ == RGBD_MODE);", "   // Set the message's header", "   enhancedImagesMsgPtr->header.stamp = timestamp_;", "   enhancedImagesMsgPtr->header.frame_id = frame_id_;", "   enhancedImagesPublisher_.publish(enhancedImagesMsgPtr);", " }", "", " The overall message of enhanced holes that will be published", " Set the rgbImage in the enhancedHolesMsg message to the rgb image", " Set the depthImage in the enhancedHolesMsg message to the depth image", " enhancedHolesMsgPtr->depthImage = MessageConversions::convertImageToMessage(", "   interpolatedDepthImage_,", "   sensor_msgs::image_encodings::TYPE_8UC1,", "   enhancedHolesMsgPtr->depthImage);", " Set the thermalImage in the enhancedHolesMsg message to the thermal image", " Set whether depth analysis is applicable", " Set the message's header", " The enhanced hole message. Used for one hole only", " Set the hole's keypoint", " Set the hole's bounding box width and height", " Push back into the enhancedHolesMsg message", " Publish the overall message", "", " Holes originated from analysis on the depth image,", " on top of the depth image", " Holes originated from analysis on the RGB image,", " on top of the RGB image", " The four images", " The titles of the images", " Convert the image into a message", " Publish the image message", "", " The depth sensor's horizontal and vertical field of view", " The frame's height and width", " The overall valid holes found message", " Counter for the holes' identifiers", " A single hole's message", " The hole's keypoint coordinates relative to the center of the frame", " The keypoint's yaw and pitch", " Setup everything needed by the single hole's message", " Fill the overall holes found message with the current hole message", " Publish the message containing the information about all holes found", " Publish an image with the valid holes found", " The holes conveyor containing only the valid holes", " Contains the validity probability for each hole considered valid", " Valid holes on top of the RGB image", " Convert the image into a message", " Publish the image message", "", " Clear the current rgbHolesConveyor struct", " (or else keyPoints, rectangles and outlines accumulate)", " Unpack the message", " The candidate holes acquired from the rgb node and the rgb image are set", " If the depth candidate holes and the interpolated depth image are set", " and the point cloud has been delivered and interpolated,", " unlock the synchronizer and process the candidate holes from both sources", "", " If the inImage is not of type CV_32FC1, return", "", " The new on/off state of the Hole Detector package", " off -> on", " The on/off state of the Hole Detector Package is off, so the", " synchronizer is not subscribed to the input point cloud.", " Make him subscribe to it now", " Set the Hole Detector's on/off state to the new one.", " In this case, it has to be before the call to unlockSynchronizer", " If all three callbacks have finished execution and they are waiting", " a new input while the state changed, the synchronizer needs to be", " unclocked manually here.", " By contrast, if the number of nodes ready is non-zero,", " while maybe impossible due to the halted state of the Hole Detector,", " the last callback that finishes execution will attempt to unlock the", " synchonizer, thus a manual unlock is not needed.", " on -> off", " The on/off state of the Hole Detector package is on and is to be off.", " The synchronizer node is subscribed to the input point cloud and now", " it should leave its subscription to it so that the processing", " resources of the robot's computer pertaining to the Hole Detector", " package are minimized", " Shutdown or open publisher of enhanced images", "", " The Hole Fusion node can request from the synchronizer node to process", " a new point cloud only if the on/off state of the Hole Detector package", " is set to on", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_merger": ["*******************************************************************", "", "", " Now, we need to find the combined outline points", " On an image, draw the holes' masks.", " Invert the image and brushfire in the black space in order to", " obtain the new outline points", " Draw the amalgamator's mask onto canvas", " Draw the amalgamatable's mask onto canvas", " In the meantime, construct the amalgamator's new hole set", " Locate the outline of the combined hole", " Set the discovered outline as the outline of the combined hole", " The amalgamator's new least area rotated bounding box will be the", " one that encloses the new (merged) outline points", " Obtain the four vertices of the new rotated rectangle", " Same as substituteVerticesArray array, but vector", " Store the four vertices to the substituteVerticesVector", " Replace the amalgamator's vertices with the new vertices", " Set the overall candidate hole's keypoint to the center of the", " newly created bounding rectangle", "", " If there are no candidate holes,", " or there is only one candidate hole,", " there is no meaning to this operation", " A vector that indicates when a specific hole has finished", " examining all the other holes in the conveyor for merging.", " Initialized at 0 for all conveyor entries, the specific hole", " that corresponds to a vector's entry is given a 1 when it has", " finished examining all other holes.", " The index of the candidate hole that will", " {assimilate, amalgamate, connect} the passiveId-th candidate hole.", " The activeId always has a value of 0 due to the implementation's", " rationale: The candidate hole that examines each hole in the", " rgbdHolesConveyor is always the first one. When it has finished,", " it goes back into the rgbdHolesConveyor, at the last position", " The index of the candidate hole that will be", " {assimilated, amalgamated, connected} by / with", " the activeId-th candidate hole", " Is the activeId-th candidate hole able to", " {assimilate, amalgamate, connect to} the passiveId-th candidate hole?", " The holesMaskSetVector vector is used in the merging processes", " Indicates the end of the merging process", " If a(n) {assimilation, amalgamation, connection} did happen,", " regenerate the mask sets in order for them to reflect the new", " state of holes", " Is the activeId-th candidate hole able to assimilate the", " passiveId-th candidate hole?", " Is the activeId-th candidate hole able to amalgamate the", " passiveId-th candidate hole?", " Is the passiveId-th candidate hole able to be connected with the", " activeId-th candidate hole?", " Copy the original holes conveyor to a temp one.", " The temp one will be tested through the hole filters", " On success, temp will replace rgbdHolesConveyor,", " on failure, rgbdHolesConveyor will remain unchanged", " Copy the original holes masks set to a temp one.", " If the temp conveyor is tested successfully through the hole", " filters, temp will replace the original.", " On failure, the original will remain unchanged", " Delete the passiveId-th candidate hole", " Delete the passiveId-th candidate hole,", " alter the activeId-th candidate hole so that it has amalgamated", " the passiveId-th candidate hole", " Delete the passiveId-th candidate hole,", " alter the activeId-th candidate hole so that it has been", " connected with the passiveId -th candidate hole", " Since the {assimilator, amalgamator, connector} is able,", " delete the assimilable's entries in the vectors needed", " for filtering and merging", " Obtain the activeId-th candidate hole in order for it", " to be checked against the selected filters", " Create the necessary vectors for each hole checker and", " merger used", " The inflated rectangles vector is used in the", " checkHolesDepthDiff and checkHolesRectangleEdgesPlaneConstitution", " checkers", " The vector of depth-filters-derived probabilities", " Check the difference between the mean depth of the", " vertices of the merged hole's bounding box and the depth of the", " merged hole's keypoint", " The probability that the merged hole is valid by the above filter", " Check the depth / area proportion for the ithHole", " The probability that the merged hole is valid by the above filter", " Probabilities threshold for merge acceptance.", " In the assimilation operation, the temp conveyor unconditionally", " replaces the original conveyor", " Since the tempHolesConveyor's ithHole has been positively tested,", " the tempHolesConveyor is now the new rgbdHolesConveyor", " ..and the new holesMasksSetVector is the positively tested", " temp one", " Delete the passiveId-th entry of the finishVector since the", " passiveId-th hole has been absorbed by the activeId-th hole", " Because of the merge happening, the activeId-th", " candidate hole must re-examine all the other holes", " rgbdHolesConveyor remains unchanged", " passiveId-th hole not merged. let's see about the next one", " isAble == false", " passiveId-th hole not merged. let's see about the next one", " If the passiveId-th hole was the last one to be checked for merge,", " the one doing the merge is rendered obsolete, so go to the next one", " by moving the current activeId-th candidate hole to the back", " of the rgbdHolesConveyor. This way the new activeId-th candidate", " hole still has a value of 0, but now points to the candidate hole", " next to the one that was moved back", " No meaning moving to the back of the rgbdHolesConveyor if", " there is only one candidate hole", " activeId-th hole candidate finished examining the rest of the", " hole candidates. move it to the back of the rgbdHolesConveyor", " Remove the activeId-th candidate hole from its former position", " Remove the activeId-th set from its position and append it", " Since the candidate hole was appended at the end of the", " rgbdHolesConveyor, the finish vector needs to be shifted", " once to the left because the value 1 is always set at the end", " of the finishVector vector. See below.", " Return the passive's candidate hole identifier to the", " next of the active's candidate hole identifier, which is 0", " Since the ith candidate hole was appended at the end of the", " rgbdHolesConveyor, the position to which it corresponds in the", " finishVector is at the end of the vector.", " Place the value of 1 in the last position, indicating that the", " previously activeId-th candidate hole has finished examining all", " other candidate holes for merging", " Count how many aces there are in the finishVector", " If they amount to the size of the vector, that means that", " each hole has finished examining the others, and the current", " operation is complete", "", " If there are no candidate holes,", " or there is only one candidate hole,", " there is no meaning to this operation", " A vector that indicates when a specific hole has finished", " examining all the other holes in the conveyor for merging.", " Initialized at 0 for all conveyor entries, the specific hole", " that corresponds to a vector's entry is given a 1 when it has", " finished examining all other holes.", " The index of the candidate hole that will", " {assimilate, amalgamate} the passiveId-th candidate hole.", " The activeId always has a value of 0 due to the implementation's", " rationale: The candidate hole that examines each hole in the", " rgbdHolesConveyor is always the first one. When it has finished,", " it goes back into the rgbdHolesConveyor, at the last position", " The index of the candidate hole that will be", " {assimilated, amalgamated} by / with", " the activeId-th candidate hole", " The holesMaskSetVector vector is used in the merging processes", " Is the activeId-th candidate hole able to", " {assimilate, amalgamate} the passiveId-th candidate hole?", " Is the activeId-th candidate hole able to assimilate the", " passiveId-th candidate hole?", " Is the activeId-th candidate hole able to amalgamate the", " passiveId-th candidate hole?", " Copy the original holes conveyor to a temp one.", " The temp one will be tested through the hole filters", " On success, temp will replace rgbdHolesConveyor,", " on failure, rgbdHolesConveyor will remain unchanged", " Copy the original holes masks set to a temp one.", " If the temp conveyor is tested successfully through the hole", " filters, temp will replace the original.", " On failure, the original will remain unchanged", " Delete the passiveId-th candidate hole", " Delete the passiveId-th candidate hole,", " alter the activeId-th candidate hole so that it has amalgamated", " the passiveId-th candidate hole", " Since the {assimilator, amalgamator} is able,", " delete the assimilable's entries in the vectors needed", " for filtering and merging", " Since the merge has been uncondionally happened,", " the tempHolesConveyor is now the new rgbdHolesConveyor", " ..and the new holesMasksSetVector is the positively tested", " temp one", " Delete the passiveId-th entry of the finishVector since the", " passiveId-th hole has been absorbed by the activeId-th hole", " Because of the merge happening, the activeId-th", " candidate hole must re-examine all the other holes", " isAble == false", " passiveId-th hole not merged. let's see about the next one", " If the passiveId-th hole was the last one to be checked for merge,", " the one doing the merge is rendered obsolete, so go to the next one", " by moving the current activeId-th candidate hole to the back", " of the rgbdHolesConveyor. This way the new activeId-th candidate", " hole still has a value of 0, but now points to the candidate hole", " next to the one that was moved back", " No meaning moving to the back of the rgbdHolesConveyor if", " there is only one candidate hole", " activeId-th hole candidate finished examining the rest of the", " hole candidates. move it to the back of the rgbdHolesConveyor", " Remove the activeId-th candidate hole from its former position", " Remove the activeId-th set from its position and append it", " Since the candidate hole was appended at the end of the", " rgbdHolesConveyor, the finish vector needs to be shifted", " once to the left because the value 1 is always set at the end", " of the finishVector vector. See below.", " Return the passive's candidate hole identifier to the", " next of the active's candidate hole identifier, which is 0", " Since the ith candidate hole was appended at the end of the", " rgbdHolesConveyor, the position to which it corresponds in the", " finishVector is at the end of the vector.", " Place the value of 1 in the last position, indicating that the", " previously activeId-th candidate hole has finished examining all", " other candidate holes for merging", " Count how many aces there are in the finishVector", " If they amount to the size of the vector, that means that", " each hole has finished examining the others, and the current", " operation is complete", "", " The connection rationale is as follows:", " Since the two holes are not overlapping each other,", " some sort of connection regime has to be established.", " The idea is that the points that consist the outline of each hole", " are connected via a cv::line so that the overall connector's outline", " is the overall shape's outline", " The image on which the hole's outline connection will be drawn", " Construct the connector's new hole mask", " First, clear the former one", " Locate the outline of the combined hole", " Set the discovered outline as the outline of the combined hole", " The connectable's new least area rotated bounding box will be the", " one that encloses the new (merged) outline points", " Obtain the four vertices of the new rotated rectangle", " Same as substituteVerticesArray array, but vector", " Store the four vertices to the substituteVerticesVector", " Replace the connector's vertices with the new vertices", " Replace the connector's vertices with the new vertices", " Set the overall candidate hole's keypoint to the mean of the keypoints", " of the connector and the connectable", "", " If the amalgatamable's area is larger than the amalgamator's,", " this amalgamator is not capable of amalgamating the amalgamatable", " Keep the size of the input assimilatorHoleMaskSet for", " comparing against it", " Clone the amalgamator's hole mask set.", " Try to insert every element of the amalgamatable hole mask set into", " the amalgamator's set.", " This amalgamator can amalgamate the amalgamatable if and only if the", " amalgamatable is not entirely inside the amalgamator or", " the amalgamatable and the amalgamator are not not connected", "", " If the assimilable's area is larger than the assimilator's,", " this assimilator is not capable of assimilating the assimilatable", " Keep the size of the input assimilatorHoleMaskSet for", " comparing against it", " Clone the assimilator's hole mask set.", " Try to insert every element of the assimilable hole mask set into", " the assimilator's set.", " This assimilator can assimilate the assimilable if and only if the", " assimilable is inside the assimilator, in other words, if the", " assimilator's hole mask set size remains unchanged after the", " insertion of the assimilable's elements into it", "", " If the connectable's area is greater than the connector's,", " this connectable is not capable of being connected with the connector", " Keep the size of the input assimilatorHoleMaskSet for", " comparing against it", " Clone the connector's hole mask set.", " Try to insert every element of the assimilable hole mask set into", " the connector's set.", " This connectable can be connected with the connector if and only if the", " connectable is outside of the connector", " The real min distance (in meters) between two points of the", " connector's and connectable's outlines", " The real max distance (in meters) between two points of the", " connector's and connectable's outlines", " The connectable's current outline point x,y,z coordinates", " measured by the depth sensor", " The connector's current outline point x,y,z coordinates", " measured by the depth sensor", " The current outline points distance", " If the minimum distance between the connector's and connectable's", " outlines is greater than a distance thrshold,", " this connectable is not a candidate to be connected with", " the connector", " If the maximum distance between the connector's and connectable's", " outlines is greater than a distance thrshold,", " this connectable is not a candidate to be connected with", " the connector", "", " Keep a copy of the initial (not merged) candidate holes for", " debugging and exibition purposes", " Push back the identifier of each keypoint", " Try to merge holes that can be assimilated, amalgamated or connected.", " If Depth analysis is applicable, {assimilate, amalgamate, connect}", " conditionally, based on depth filters. In the opposite case,", " {assimilate, amalgamate} unconditionally.", " Push back the identifier of each keypoint", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_validation": ["*******************************************************************", "", "", " The map of holes' indices that are valid and", " their respective validity probability that will be returned", "", " The map of holes' indices that are valid and", " their respective validity probability that will be returned", " Commence setting of priorities given to hole checkers.", " Each priority given is not fixed,", " but there is an apparent hierarchy witnessed here.", " In order to reach a valid conclusion, an analytical method had to be", " used, which is one analogous to the one presented in", " {insert link of Manos Tsardoulias's PHD thesis}", " Apply a weight to each probability according to its weight order.", " If depth analysis was not possible, use the urgent weight order.", " Color homogeneity", " Depth / area", " Luminosity diff", " Outline of rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Color homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " The total validity probability of the i-th hole", " The validity acceptance threshold", " If the total validity probability of the i-th hole exceeds a", " pre-determined threshold, we consider the i-th hole to be valid", "", " The map of holes' indices that are valid and", " their respective validity probability that will be returned", " RGB + Depth mode. All RGB and Depth active filters produce", " probabilities that will have to be checked on a per-filter basis,", " against individually-set thresholds.", " Color homogeneity", " Depth / area", " Luminosity diff", " Outline of rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Color homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " If the i-th candidate hole has passed the above checks,", " it surely is valid. Its validity probability will amount to the", " mean value of its separate validity probabilities.", " Return the valid set", "", " The map of holes' indices that are valid and", " their respective validity probability that will be returned", " Commence setting of priorities given to hole checkers.", " Each priority given is not fixed,", " but there is an apparent hierarchy witnessed here.", " In order to reach a valid conclusion, an analytical method had to be", " used, which is one analogous to the one presented in", " {insert link of Manos Tsardoulias's PHD thesis}", " Apply a weight to each probability according to its weight order.", " If depth analysis was not possible, use the urgent weight order.", " Color homogeneity", " Depth / area", " Luminosity diff", " Outline of rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Color homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " The total validity probability of the i-th hole", " The validity acceptance threshold", " If the total validity probability of the i-th hole exceeds a", " pre-determined threshold, we consider the i-th hole to be valid", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "rgb_filters": ["*******************************************************************", "", "", " Copy the input image to inImage_ so as to get a pointer on it", " Reduce the colours of inImage_.", " For a value of 16 for div, the maximum possible number of colours", " is 2^12. For every duplication of div, the number of possible colours", " is divided by a factor of 2^3", " Get the address of row i", " Process each pixel", " Sets featuring all the different colours found inside each image mask", " Collect the different values of colour components for the", " points of the current mask", " The number of distinct colours inside the mask", " Threshold the number of colours", "", " In order to find the luminosity", " convert the input RGB image to YCrCb format.", " Split the image to its three components", " The luminosity of the image is expressed by the Y channel.", " For each inflated rectangle, calculate the luminosity of", " (1) the points between the blob's outline and the edges of the", " inflated rectangle and", " (2) the points inside the blob's outline", " The current hole's inside points luminosity sum", " The current hole's intermediate points luminosity sum", " Mean luminosity of the inside points of the current hole", " Mean luminosity of the intermediate points", " If the luminosity of the inside of the candidate hole is greater", " than the luminosity of the points beyond it and restricted by the", " edges of its bounding box, it surely is not a hole", "", " Obtain the backprojection of the inImage, according to the inHistogram", " Obtain a homogenous backprojection image", " Obtain a pointer on watersheded", " For each inflated rectangle, calculate the probabilities of", " (1) the points between the blob's outline and the edges of the", " inflated rectangle and", " (2) the points inside the blob's outline", " based on the watersheded image", " The average probability of the points consisting the inflated", " rectangle matching the histograms in the inHistogram", " The average probability of the points inside the blob's outline", " matching the histograms in the inHistogram", " This blob is considered valid, with a non zero validity probability,", " if the points consisting the inflated rectangle have a greater", " resemblance (through the probability-expressing values of the", " back project cv::MatND) to the inHistogram than the one of the points", " inside the blob's outline", "", " Since not all rectangles may make it, store the indices", " of the original keypoints that correspond to valid inflated rectangles", " in the validKeyPointsIndices vector", " inImage transformed from BGR format to HSV", " The first value will always be with regard to Hue", " Histogram-related parameters", " hue varies from 0 to 179, saturation or value from 0 to 255", " Use the 0-th and secondaryChannel-st channels", " Produce the histogram for the points in between the blob's outline", " and the inflated rectangle's edges", " Produce the histogram for the points inside the outline of the blob", " For each input histogram compute the largest probability", " Find the correlation between the model histogram and the histogram", " of the inflated rectangle", " Find the correlation between the model histogram and the histogram", " of the points inside the blob", " This blob is considered valid if there is a correlation between", " the histogram of the external to the hole's outline points", " and the model histogram (inHistogram) greater than a threshold and,", " simultaneously, the correlation between the histogram of the points", " inside the hole's outline points and the model histogram is lower", " than a threshold.", " CAUTION: The use of the CV_COMP_HELLINGER for histogram comparison", " inverts the inequality checks", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "filters_resources": ["*******************************************************************", "", "", " Indicate the necessity of creating particular resources", " If the conditions permit for the depth filters to be applied,", " create their resources", " The depth diff filter requires only the contruction of the vectors", " that have to do with the inflation of holes' rectangles", " The depth/area filter requires only the construction of sets that", " hold the indices of points inside holes' outlines", " The intermediate points plane constitution filter requires exactly", " the construction of vectors pertaining to holes' inflation and", " and a vector of sets of indices of points between holes' outline and", " their respective (inflated) bounding rectangle", " The outline of rectangle plane constitution filter requires", " the construction of vectors pertaining to holes' inflation", " The depth homogeneity filter requires the construction of sets of", " points' indices; these points are the ones inside holes' outlines", " The color homogeneity filter requires a vector of holes' masks", " that will be used to extract their histograms", " The luminosity diff filter requires the set of points' indices", " that are inside a hole's outline,", " the set of points' indices that are outside a hole's outline", " but inside its (inflated) bounding rectangle", " and the inflated rectangles and indices of the respective", " valid keypoints", " The texture diff filter requires the construction of an image mask", " vector for the points inside holes' outline and of image and set", " masks for the points outside holes' outline but inside their (inflated)", " bounding box", " as it checks for texture metrics difference between the", " histograms of the points inside a hole's outline and outside", " the hole's outline but inside its (inflated) bounding rectangle", " The texture backproject filter uses two sets: they respectively contain", " the indices of points inside holes' outlines and the indices of points", " outside holes' outlines but inside their (inflated) bounding rectangle.", " Hence, we also need the construction of inflated rectangles' vectors", " Depth-based filters cannot be applied. Create only the necessary", " resources needed by the RGB-based filters, according to the *_urgent", " order", " The color homogeneity filter requires a vector of holes' masks", " that will be used to extract their histograms", " The luminosity diff filter requires the set of points' indices", " that are inside a hole's outline,", " the set of points' indices that are outside a hole's outline", " but inside its (inflated) bounding rectangle", " and the inflated rectangles and indices of the respective", " valid keypoints", " The texture diff filter requires the construction of an image mask", " vector for the points inside holes' outline and of image and set", " masks for the points outside holes' outline but inside their (inflated)", " bounding box", " as it checks for texture metrics difference between the", " histograms of the points inside a hole's outline and outside", " the hole's outline but inside its (inflated) bounding rectangle", " The texture backproject filter uses two sets: they respectively contain", " the indices of points inside holes' outlines and the indices of points", " outside holes' outlines but inside their (inflated) bounding rectangle.", " Hence, we also need the construction of inflated rectangles' vectors", " Create the necessary resources", " The generation of image masks presupposes the generation of set masks", " within method createHolesMasksImageVector", " Generate both types of masks", " The generation of image masks presupposes the generation of set masks", " within method createIntermediateHolesPointsImageVector", " The intermediate points images vector depends on the", " inflated rectangles vectors, which has been created previously", " The intermediate points set vector depends on the", " inflated rectangles vectors, which has been created previously", " The intermediate points set vector depends on the", " inflated rectangles vectors, which has been created previously", "", " Create the masks' set initially", " Draw each mask set onto an image", " The current hole's image mask", " A pointer to the hole mask image", " Draw the current hole's mask", "", " Create the masks' set initially", " Draw each mask set onto an image", " The current hole's image mask", " A pointer to the hole mask image", " Draw the current hole's mask", "", " The image on which the i-th hole's outline will be drawn", " Draw the outline points of the i-th hole onto holeMask", " The set of indices of points inside the i-th hole's outline", " The point from which the floodfill will begin", " Fill the inside of the i-th hole", " Take a pointer on the mask image", " The points with non-zero value are the ones inside the i-th hole.", " Insert them into the desired set.", "", " Store the vertices of the inside-of-image-bounds inflated bounding", " rectangles in the inflatedRectangles vector", " check if the inflated vertex has gone out of bounds", " end for rectangle's points", " If one or more vertices are out of bounds discard the whole", " inflated rectangle", " end for each hole", "", " Create the masks' set initially", " The current hole's intermediate points mask", " A pointer to the hole mask image", " Draw the intermediate points' mask", "", " Create the masks' set initially", " The current hole's intermediate points mask", " A pointer to the hole mask image", " Draw the intermediate points' mask", "", " The current hole's mask", " An image whose non-zero value pixels are the ones inside the", " hole's outline", " Draw the outline of the i-th hole onto holeOutlineFilledImage", " The set of indices of points inside the i-th hole's outline", " The brushfire start point is the hole's seedPoint", " floodFill from the seedPoint to the hole's outline", " to obtain the points inside it", " Take a pointer on the hole's mask image", " The points with non-zero value are the ones inside the i-th hole.", " Insert them into the desired set.", " holeOutlineFilledSet is now constructed", " An image whose non-zero value pixels are the ones inside the", " hole's bounding rectangle", " Draw the bounding rectangle of the i-th hole onto", " rectangleOutlineFilledImage", " The set of indices of points inside the i-th hole's", " bounding rectangle", " floodFill from the seedPoint to the hole's bounding rectangle", " to obtain the points inside it", " Take a pointer on the rectangle's mask image", " The points with non-zero value are the ones inside the i-th hole.", " Insert them into the desired set.", " rectangleOutlineFilledSet is now constructed", " The final set of points' indices", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "depth_filters": ["*******************************************************************", "", "", " The mean depth value of the points inside the i-th hole", " The number of points inside the i-th hole, or else, its area", " area = f(mean) for one circular hole", " Upper-most curve, plus an increase in height", " At most, one complete hole contains three circular ones", " Lower-most curve minus a reduction in height", " At least, one complete hole is one circular hole", "", " The mean distance of this hole's bounding box vertices", " The difference between the distance of this hole's keypoint and", " the mean distance of the vertices of its bounding box", " The keypoint's distance from the depth sensor should be greater than", " that of the mean distance of the vertices of the candidate hole's", " bounding box by at a minimum of depth_diff_cutoff_min_depth cm and at", " maximum of depth_diff_cutoff_max_depth cm.", " The probability is binary. If there is a valid depth difference,", " this hole is marked as valid.", " The probability is gaussian-based. The validity of a hole is a", " continuous function based on a normal distribution", " The gaussian mean", " The gaussian standard deviation", " The gaussian probability of this hole being valid", "", " Facilitate the edge detection by converting the 32FC1 image", " values to a range of 0-255", " From now onwards every image is in the range of 0-255", " Apply a threshold and make all non zero pixels have a value of 255", " Take a pointer on the interpolatedDepthImageEdges image", " The number of non-zero value pixels in the", " interpolatedDepthImageEdges image, inside mask i", "", " From each set of intermediate points, construct the point cloud", " that will be checked for plane constitution", " Check if the intermediatePointsPointCloud's points are on a plane", " The probability (in all probability) of the current hole lying on", " one plane will be the ratio of the number of intermediate points", " that lie on one plane over all the intermediate points", " (max points on one plane) / (all intermediate points)", "", " For each inflated rectangle, store in visitedPoints", " the points that constitute the rectangle.", " We will test if these points all lie on one plane.", " The canvas image will hold the rectangles.", " Draw the rectangle that corresponds to it", " From each set of points lying on the edges of the rectangle,", " construct the point cloud that will be checked for plane constitution", " Check if the edgePointsPointCloud points are on a plane", " The probability (in all probability) of an inflated rectangle", " residing on one plane will be the ratio of", " (max points on one plane) / (all inflated rectangle points)", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_uniqueness": ["*******************************************************************", "", "", " A container in which one of every duplicate hole will be inserted", " A set of sets containing the indices of duplicate holes.", " Each internal set points to one unique hole", " This set is comprised by indices of holes that are identical to the", " i-th hole", " First off, the two holes' keypoints must be identical.", " Second off, it is sufficient to check the identicalness of", " the vertices of the two holes' bounding boxes.", " The i-th hole is part of the overall set", " Populate the uniqueDuplicates container with a copy of each duplicate", " hole. All the duplicate holes will be deleted from the input conveyor,", " and then merged with the uniqueDuplicates conveyor.", " Now, all the duplicate holes must be deleted from the input conveyor.", " Construct ONE set of indices of all holes that need to be deleted.", " Perform the actual deletion of duplicate holes.", " Add one copy of each duplicate hole deleted to the conveyor container", "", " Each set inside the map refers a valid hole inside the conveyor conveyor.", " The entries of each set are indices to valid holes inside", " the conveyor conveyor.", " Each map.first refers to a specific valid hole inside the conveyor", " conveyor.", " map.first-> map.second means the residence of the keypoint of the", " hole with index map.first within the bounding box of holes with", " indices in map.second", " Find the indices of holes that the keypoint of each valid hole", " is located in.", " The keypoint of the i-th hole in cv::Point2f format", " A set of the identifiers of holes inside the conveyor conveyor,", " whose bounding box the i-th hole is inside, recursively.", " The outcome is a map of ints to sets, one per valid hole.", " Each set contains the indices of parent holes", " that have been deemed valid.", " What we want now is to locate which holes need to be", " compared against one another.", " Each set inside the groupSet contains holes whose overall validity", " probability needs to be compared against all the others within that set.", " The largest of them corresponds to a unique hole, whose keypoint,", " outline and bounding rectangle are considered most accurate between", " the holes in its respective set.", " Traverse the parents (the hole_it->second set)", " of this hole (its id is hole_it->first)", " For each parent of the hole_id->first-th hole,", " check the set of its corresponding parent holes", " and add them to the set of the hole_id->first-th hole's parents.", " The grandfathers added are the hole_id->first-th hole's recursive", " parents.", " A parent to the parent of hole hole_it->first is also its parent.", " Insert the set of indices of holes with which the", " hole_it->first-th hole will be compared to inside the overall", " set of sets.", " The conveyor of unique and valid holes", " Maps a unique, valid hole to its validity probability", " A hole counter", " Iterate over the set of sets within which the validity probability", " of holes needs to be compared with one another. We will locate the", " hole in a set within groupSet that has the highest probability among", " the holes inside the set", " The maximum probability of the cluser of nearby holes", " The index of the hole with maximum probability inside the cluster", " of nearby holes", " Iterate over the current set inside the groupSet", " An iterator over the input validHolesMap.", " It points to the index and probability of the *g_it-th hole", " The index-th hole inside this cluster of nearby holes is the most", " accurate one, since its probability is the highest among its rearby", " holes. Append it to the uniqueHoles conveyor.", " Map the most accurate hole to its probability.", " All unique holes have been found.", " Replace the uniqueHoles conveyor with the one containing", " clusters of holes and the input map with the one corresponding to the", " unique holes found.", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "depth_hole_detector": ["*******************************************************************", "", "", " Debug", " Detect edges in the interpolatedDepth image", " Debug", " Find blobs in the edges image. Each blob is represented as", " a keypoint which is the center of the blob found", " Debug", " The final vectors of keypoints, rectangles and blobs' outlines.", "", " Debug", " Debug", " A vector of keypoints", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "depth": ["*******************************************************************", "", "", "", " Acquire the names of topics which the depth node will be having", " transactionary affairs with", " Subscribe to the depth image published by the", " rgb_depth_synchronizer node", " Advertise the candidate holes found by the depth node", " The dynamic reconfigure (depth) parameter's callback", "", " Obtain the depth image. Since the image is in a format of", " sensor_msgs::Image, it has to be transformed into a cv format in order", " to be processed. Its cv format will be CV_32FC1.", " Regardless of the image representation method, the depth node", " will publish the interpolated depth image of original size", " to the Hole Fusion node", " A value of 1 means that the depth image is subtituted by its", " low-low, wavelet analysis driven, part", " Find the minimum and maximum values in depth distance in the", " interpolated depth image", " Obtain the low-low part of the interpolated depth image via", " wavelet analysis", " Locate potential holes in the interpolated depth image", " Create the candidate holes message", " Pack information about holes found and the interpolated depth image", " inside a message.", " This message will be published to and received by the hole fusion node", " Publish the candidate holes message", "", " Read the name of the topic from where the depth node acquires the", " unadulterated depth image and store it in a private member variable", " Read the name of the topic to which the depth node will be publishing", " information about the candidate holes found and store it in a private", " member variable", "", "////////////////// Blob detection - specific parameters //////////////////", " In wavelet mode, the image shrinks by a factor of 4", "//////////////////////////// Debug parameters ////////////////////////////", " Show the depth image that arrives in the depth node", "------------------- Edge detection specific parameters -------------------", " Canny parameters", " Threshold parameters", " Method to scale the CV_32FC1 image to CV_8UC1", "----------------- Outline discovery specific parameters ------------------", " The detection method used to obtain the outline of a blob", " 0 for detecting by means of brushfire", " 1 for detecting by means of raycasting", " When using raycast instead of brushfire to find the (approximate here)", " outline of blobs, raycast_keypoint_partitions dictates the number of", " rays, or equivalently, the number of partitions in which the blob is", " partitioned in search of the blob's borders", "-------------------- Loose ends connection parameters --------------------", " In wavelet mode, the image shrinks by a factor of 4", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "pc_thermal_synchronizer": ["*******************************************************************", "", "", " Take NodeHandlers from nodelet manager", " The synchronizer node starts off in life locked, waiting for the", " hole fusion node to unlock him", " The synchronizer node starts off in life locked for thermal standalone", " procedure , waiting for the thermal cropper node to unlock him.", " Acquire the names of topics which the synchronizer node will be having", " transactionary affairs with", " Acquire the information about the input point cloud that cannot be", " acquired from the point cloud message.", " The parameters concerned are needed only if in simulation mode", "****************************************************************************", " If thermal mode is enabled in launch file message filters is on and", " the two input messages are synchronized packed and sent.", " If not only the pointcloud is sent for further usage", "if (rgbdtMode_ || thermalMode_)", "{", "  syncPointCloudSubscriberPtr_.reset( new PcSubscriber(nh_,", "        inputPointCloudTopic_, queue_) );", "  syncThermalCameraSubscriberPtr_.reset( new ThermalSubscriber(nh_,", "        syncThermalCameraTopic_, queue_) );", "  synchronizerPtr_.reset( new ApprTimePcThermalSynchronizer(", "        ApprTimePcThermalPolicy(queue_),", "        *syncPointCloudSubscriberPtr_,", "        *syncThermalCameraSubscriberPtr_) );", "  synchronizerPtr_->registerCallback(", "      boost::bind(&PcThermalSynchronizer::syncPointCloudThermalCallback, this, _1, _2));", "}", "else if (rgbdMode_)", "{", "}", "****************************************************************************", "if (rgbdMode_ || rgbdtMode_)", "{", "  // Subscribe to the hole_fusion lock/unlock topic", "}", "if (thermalMode_)", "{", "  // Subscribe to the topic where the thermal node requests synchronizer", "  // to act.", "  unlockThermalSubscriber_ = nh_.subscribe(", "    unlockThermalTopic_, 1,", "    &PcThermalSynchronizer::unlockThermalCallback, this);", "}", " Subscribe to the topic where the Hole Fusion node requests from the", " synchronizer node to subscribe to the input point cloud topic", " Subscribe to the topic where the Hole Fusion node requests from the", " synchronizer node to leave its subscription to the", " input point cloud topic", "****************************************************************************", "if (rgbdMode_ || rgbdtMode_j", "{", "  // Advertise the synchronized point cloud", "}", "if (rgbdMode_ || rgbdtMode_)", "{", " Advertise the synchronized depth image", " Advertise the synchronized rgb image", "}", "if (rgbdtMode_ || thermalMode_)", "{", " Advertise the synchronized thermal image and its index", "synchronizedThermalImagePublisher_ = nh_.advertise", "  <distrib_msgs::FlirLeptonMsg>", "  (synchronizedThermalImageTopic_, 1);", "thermalOutputReceiverPublisher_ = nh_.advertise", "  <std_msgs::String>", "  (thermalOutputReceiverTopic_, 1);", "}", "if (thermalMode_)", "{", "  enhancedImageCropperPublisher_ = nh_.advertise<pandora_vision_msgs::EnhancedImage>(", "      enhancedImageCropperTopic_, 1);", "}", " inputPointCloudSubscriber_.shutdown();", "", " syncPointCloudSubscriberPtr_->unsubscribe();", " syncThermalCameraSubscriberPtr_->unsubscribe();", "", " Shutdown the input thermal subscriber", "", "", " if (rgbdtMode_ || thermalMode_)", " {", "   syncPointCloudSubscriberPtr_->subscribe();", "   syncThermalCameraSubscriberPtr_->subscribe();", " }", " else if (rgbdMode_)", " {", "   inputPointCloudSubscriber_ = nh_.subscribe(inputPointCloudTopic_, 1,", "       &PcThermalSynchronizer::inputPointCloudCallback, this);", " }", "", " if (rgbdtMode_ || thermalMode_)", " {", "   syncPointCloudSubscriberPtr_->subscribe();", "   syncThermalCameraSubscriberPtr_->subscribe();", " }", " Exctract the pointcloud from the message and convert it", " to PointCloud<T>::Ptr type.", " pcl::PCLPointCloud2 pcl_pc;", " pcl_conversions::toPCL(*pcMsg, pcl_pc);", " The input point cloud is unorganized, in other words,", " simulation is running. Variables are needed to be set in order for", " the point cloud to be functionally exploitable.", " The point cloud's height", " The point cloud's width", " Extract the RGB image from the point cloud", " cv::Mat rgbImage = hole_fusion::MessageConversions::convertPointCloudMessageToImage(", "   pcPtr, CV_8UC3);", " cv_bridge::CvImagePtr rgbImageConverter( new cv_bridge::CvImage() );", " rgbImageConverter->header = pcMsg->header;", " rgbImageConverter->encoding = sensor_msgs::image_encodings::BGR8;", " rgbImageConverter->image = rgbImage;", " rgbImageMessagePtr = rgbImageConverter->toImageMsg();", " Extract the depth image from the point cloud", " depthImageMessagePtr = boost::make_shared<sensor_msgs::Image>();", " MessageConversions::toROSDepthMsg(*pcMsg, *depthImageMessagePtr);", " depthImageMessagePtr->header = pcMsg->header;", "", " Read \"height\" from the nodehandle", " Read \"width\" from the nodehandle", "", " Read the name of the topic from where the rgb_depth_thermal_synchronizer", " node acquires the input pointcloud2", " Read the name of the topic that the Hole Fusion node uses to unlock", " the synchronizer node", " Read the name of the topic from where the rgb_depth_thermalsynchronizer", " node acquires the input thermal message", " not to thermal standalone node.", " Read the name of the topic that the Hole Fusion node uses to request from", " the synchronizer node to subscribe to the input point cloud", " Read the name of the topic that the Hole Fusion node uses to request from", " the synchronizer node to leave its subscription to the input point cloud", " Read the name of the topic that the synchronizer node will be publishing", " the input point cloud to", " Read the name of the topic that the synchronizer node will be publishing", " the depth image extracted from the input point cloud to", " Read the name of the topic that the synchronizer node will be publishing", " the depth image extracted from the input point cloud to", " Read the name of the topic that the synchronizer node will be publishing", " the thermal info extracted from flir camera", " Read the name of the topic that the synchronizer node will be publishing", " the rgb and depth image to thermal cropper node", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_detector_test": ["*******************************************************************", "", "", " Sets up one image: squares_,", " which features three squares of size 100.", " The first one (order matters here) has its upper left vertex at", " (100, 100),", " the second one has its upper right vertex at (WIDTH - 3, 3)", " (so that the blob it represents can barely be identified)", " and the the third one has its lower right vertex at", " (WIDTH - 1, HEIGHT - 1)", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the squares_ image to 1.0", " Construct the lower right square", " Construct the upper right image", " Construct the upper left square", " Construct the square_ image", " Synthesize the final squares_ image", " The images' width and height", " The image that will be used to locate blobs in", "", " Fill the inside of the desired rectangle with the @param depthIn provided", "! Tests HoleDetector::findHoles", " Run HoleDetector:findHoles", " The number of keypoints found", " There should be two keypoints: the one of the upper left square", " and the one of the upper right square. The lower right square is", " adjacent to the edges of the image and will be clipped by the", " edge contamination method", " For every keypoint found, make assertions and expectations", " The location of the keypoint should be near the center of the square", " in which it lies", " The hole should have exactly four vertices", " There should be 400 outline points", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "holes_conveyor_test": ["*******************************************************************", "", " Dummy entries for the src conveyor", " Push back the two holes into the src conveyor", " Dummy entries for the dst conveyor", " Push back the two holes into the dst conveyor", " This is the source conveyor", " This is the destination conveyor", "! Tests HolesConveyorUtils::append", " Backup the original dst", " 2 entries in dst before appending src to it", " Run HolesConveyorUtils::append", " 4 entries in dst after appending src to it", " Check that the initial entries have not been tampered with", " Check the newly appended entries' elements against the original ones", "! Tests HolesConveyorUtils::appendDummyConveyor", " Backup the original dst", " Run HolesConveyorUtils::appendDummyConveyor", " There should now be three entries in dst", " Check that the initial entries have not been tampered with", " The new entry", "! Tests HolesConveyorUtils::clear", " Run HolesConveyorUtils::clear", " The dst conveyor should be empty", "! Tests HolesConveyorUtils::copyTo", " Run HolesConveyorUtils::copyTo", " There should be two hole entries in dst now", " Check the newly appended entries' elements against the original ones", "! Tests HolesConveyorUtils::generateRectangle", " The rectangle's points that will be returned", " The rectangle's vertices that will be returned", " Run HolesConveyorUtils::generateRectangle with intent = 1", " Run HolesConveyorUtils::generateRectangle with intent = 2", " The number of vertices should amount to a number", " lower than the number of points", " There should be four vertices", " There should be 4 * 100 points", "! Tests HolesConveyorUtils::getHole", " Run HolesConveyorUtils::getHole", " There should be one entry inside hole", " src and hole should have exactly the same amount of", " rectangle and outline points", " Check that the entries in src and hole are exactly the same", "! Tests HolesConveyorUtils::merge", " The merged conveyor", " Merge src and dst into merged", " There should be exactly 2 + 2 = 4 entries in merged", " Check the newly appended entries' elements against the original ones", " Check src", " Check dst", "! Tests HolesConveyorUtils::removeHole", " Backup dst", " Two holes before removing one", " Run HolesConveyorUtils::removeHole", " One hole after removing one", " The first entry should be exactly the same as the previously second one", "! Tests HolesConveyorUtils::replace", " Run HolesConveyorUtils::replace", " Check the newly replaced entries' elements against the original ones", "! Tests HolesConveyorUtils::replaceHole", " Backup dst", " Run HolesConveyorUtils::replaceHole", " There should still be two holes inside dst", " The 0-th hole of dst should be the 0-th hole of src", " The 1-st hole of dst should be the 1-st hole of dstBackup", "! Tests HolesConveyorUtils::shuffle", " Backup dst", " Run HolesConveyorUtils::shuffle", " There should still be 2 entries in dst", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "message_conversions_test": ["*******************************************************************", "", " An image of dimensions HEIGHT x WIDTH, representing the conveyor", " A single hole", " Construct a dummy conveyor", " The outline of the hole", " The vertices of the hole's bounding box", " Push hole back into the conveyor", " The images' width and height", " A conveyor of dummy holes", " An image of dimensions HEIGHT x WIDTH, representing the conveyor", "! Tests MessageConversions::convertImageToMessage", " A grayscale image", " Insert randomness into image", " A dummy message. Needed for its header", " Extract the image message and compare this image to the original", " The number of pixels differing between image_8UC1 and extractedImage_8UC1", " There should be no discrepancies", " A RGB image", " Insert randomness into image", " A dummy message. Needed for its header", " Extract the image message and compare this image to the original", " The number of pixels differing between image_8UC3 and extractedImage_8UC3", " There should be no discrepancies", "! Tests MessageConversions::convertPointCloudMessageToImage", " Create a grayscale image", " Fill it with randomness", " Set some NaNs", " Create a RGB image", " Fill it with randomness", " Set some NaNs", " Create a point cloud. The extracted depth values result in image_32FC1", " The extracted RGB values result in image_8UC3.", " Set the depth value for this point", " Set the RGB values for this point", " The extracted depth image", " The number of pixels differing between image_32FC1", " and extracted_32FC1", " There should be 2 pixels different before and after:", " The two NaN values", " The extracted RGB image", " There should be no discrepancies", "! Tests MessageConversions::createCandidateHolesVector", " The vector of messages of candidate holes", " Run MessageConversions::createCandidateHolesVector", " The keypoints should be the same", " The rectangle's vertices should be the same", " The outline points should be the same", "! Tests MessageConversions::createCandidateHolesVectorMessage", " Create a grayscale image", " Fill it with randomness", " The message of candidate holes", " A dummy image. Needed only for its header.", " Run MessageConversions::createCandidateHolesVector", " Check the integrity of image", " The number of pixels differing between image and extracted", " There should be no discrepancies", " Check the integrity of the conveyor", " The keypoints should be the same", " The rectangle's vertices should be the same", " The outline points should be the same", "! Tests MessageConversions::extractImageFromMessage", " Create a grayscale image", " Fill it with randomness", " Run MessageConversions::extractImageFromMessage", " The number of pixels differing between image and extracted", " There should be no discrepancies", "! Tests MessageConversions::extractImageFromMessageContainer", " Create a grayscale image", " Fill it with randomness", " The message of candidate holes", " Run MessageConversions::extractImageFromMessageContainer", " The number of pixels differing between image and extracted", " There should be no discrepancies", "! Tests MessageConversions::fromCandidateHoleMsgToConveyor", " The vector of candidate holes", " The keypoints", " The rectangles", " The outlines", " The conveyor extracted from the message", " Run MessageConversions::fromCandidateHoleMsgToConveyor", " for representationMethod 0", " Check the integrity of the extracted conveyor", " Clear the conveyor", " Run MessageConversions::fromCandidateHoleMsgToConveyor", " for representationMethod 1", " Check the inflated of the extracted conveyor", "! Tests MessageConversions::unpackMessage", " The overall message", " The vector of candidate holes", " The keypoints", " The rectangle points", " The outline points", " A grayscale image", " Insert randomness into image", " Pack image_8UC1 into the message", " The extracted conveyor", " The extracted image", " Run MessageConversions::unpackMessage for representationMethod 0", " Check the integrity of the extracted conveyor", " The number of pixels differing between image_8UC1 and extractedImage", " There should be no discrepancies", " Clear extractedConveyor", " Run MessageConversions::unpackMessage for representationMethod 1", " Check the inflated of the extracted conveyor", " The number of pixels differing between image_8UC1 and extractedImage", " There should be no discrepancies", " rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "morphological_operators_test": ["*******************************************************************", "", " pixel_ holds a single non-zero pixel", " line_ holds a horizontal white line at row 100,", " with width of 1 pixel", " thick_line_ holds horizontal white lines at rows 99, 100 and 101", " square_ is a 100 X 100 opaque square,", " with its upper left corner placed at the upper left corner of the", " image", " frame_ is a white image with only its borders in black colour", " squares_ is an image featuring one square at the edge of each", " corner of the image", " corners_ is an image featuring one square at the very edge of each", " corner of the image", " pixel_ holds a single non-zero pixel", " line_ holds a horizontal white line at row 100,", " with width of 1 pixel", " thick_line_ holds horizontal white lines at rows 99, 100 and 101", " square_ is a 100 X 100 opaque square,", " with its upper left corner placed at the upper left corner of the", " image", " frame_ is a white image with only its borders in black colour", " squares_ is an image featuring one square at the edge of each", " corner of the image", " upper left", " lower left", " upper right", " lower right", " corners_ is an image featuring one square at the very edge of each", " corner of the image", " upper left", " lower left", " upper right", " lower right", " The images' width and height", " pixel_ holds a single non-zero pixel", " line_ holds a horizontal white line at row 100,", " with width of 1 pixel", " thick_line_ holds horizontal white lines at rows 99, 100 and 101", " square_ is a 100 X 100 opaque square,", " with its upper left corner placed at the upper left corner of the", " image", " frame_ is a white image with only its borders in black colour", " squares_ is an image featuring one square at the edge of each", " corner of the image", " corners_ is an image featuring one square at the very edge of each", " corner of the image", " The number of non-zero value pixels before the appliance of an operator", " The number of non-zero value pixels after the appliance of an operator", "! Tests Morphology::closing()", "*************************************************************************", " Keep the original image in the originalPixel image", " Apply the closing operator", " diff_pixel is the difference between the original and the", " closed pixel_ images", " The diff image should be filled with zero value pixels only", "*************************************************************************", " Keep the original image in the originalLine image", " Apply the closing operator", " diff_pixel is the difference between the original and the", " closed line_ mages", " The diff image should be filled with zero value pixels only", "*************************************************************************", " Keep the original image in the originalThick_line image", " Apply the closing operator", " diff_pixel is the difference between the original and the", " closed pixel_ images", " The diff image should be filled with zero value pixels only", "*************************************************************************", " Keep the original image in the originalSquare image", " Apply the closing operator", " diff_square is the difference between the original and the", " closed square_ images", " The diff image should be filled with zero value pixels only", "! Tests Morphology::dilation()", "*************************************************************************", " Perform dilation on the pixel_", " All pixels surrounding immediately the only non-zero one before dilation", " should now have a non-zero value", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", " The number of non-zero pixels before the dilation should be three times", " as many as that of the pixels after", " One row higher and one row lower than 100, all pixels should now", " have a non-zero value", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", " The number of non-zero pixels after the dilation should be", " increased by twice the square_'s size, plus one non-zero pixel", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", " The number of non-zero pixels after the dilation should be equal to the", " area of the image", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", "! Tests Morphology::dilationRelative()", "*************************************************************************", " Perform dilation on the pixel_", " All pixels surrounding immediately the only non-zero one before dilation", " should now have a non-zero value", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", " The number of non-zero pixels before the dilation should be three times", " as many as that of the pixels after", " One row higher and one row lower than 100, all pixels should now", " have a non-zero value", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", " The number of non-zero pixels after the dilation should be", " increased by twice the square_'s size, plus one non-zero pixel", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilationRelative", " The number of non-zero pixels before the dilationRelative should be", " less than that of the pixels after", " The number of non-zero pixels after the dilation should be equal to the", " area of the image", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", "! Tests Morphology::erosion()", "*************************************************************************", " The number of non-zero pixels before erosion", " Erode once", " The number of non-zero pixels after erosion", " The number of non-zero pixels before the erosion should be", " less than that of the pixels after", " The number of non-zero pixels after the erosion should be exactly zero", "*************************************************************************", " The number of non-zero pixels before erosion", " Erode once", " The number of non-zero pixels after erosion", " The number of non-zero pixels before the erosion should be", " greater than that of the pixels after", " The number of non-zero pixels after the erosion should be", " reduced by the size of frame_, minus its four corners", "*************************************************************************", " Because each square has a width of one, dilate once so that the", " result of the erosion can be visible", " The number of non-zero pixels before erosion", " Erode once", " The number of non-zero pixels after erosion", " The number of non-zero pixels before the erosion should be", " greater than that of the pixels after", " Erode once more", " The number of non-zero pixels after erosion", " The number of non-zero pixels before the erosion should be", " greater than that of the pixels after", "! Tests Morphology::kernelCheck()", "*************************************************************************", " pixel_ has all of its neighbors with a zero value", " This should be true: Point( 100, 100 ) has a non-zero value,", " while it is surrounded by zero value pixels", " This should be false: Point ( 200, 200 ) has a zero value and", " it is surrounded by zero value pixels", "*************************************************************************", " line_ has all of its upwards and downwards neighbors with a zero value", " This should be true: all points in row 100 have a non-zero value,", " while they are surrounded by zero value pixels, upwards and downwards", " This should be false: Point ( cols, 200 ) has a zero value and", " it is surrounded by zero value pixels", "! Tests Morphology::opening()", "*************************************************************************", " Apply the opening operator", " The diff image should be filled with zero value pixels only", "*************************************************************************", " Apply the opening operator", " The diff image should be filled with zero value pixels only", "*************************************************************************", " Keep the original image in the originalSquare image", " Apply the opening operator", " diff_square is the difference between the original and the", " closed square_ images", " The diff image should be filled with zero value pixels only", "! Tests Morphology::pruningStrictIterative()", "*************************************************************************", " Apply the pruningStrictIterative operator", " The image should be filled with zero value pixels only", "*************************************************************************", " Keep the original image in the originalPixel_ image", " Attach some garbage pixels to the line in line_.", " They should be deleted by the pruningStrictIterative operator", " Apply the pruningStrictIterative operator", " Garbage pixels should be deleted", "*************************************************************************", " The number of non-zero pixels before pruningStrictIterative", " Apply the pruningStrictIterative operator", " The number of non-zero pixels after pruningStrictIterative", " Only the bottom right corner should be deleted", "*************************************************************************", " The number of non-zero pixels before pruningStrictIterative", " Apply the pruningStrictIterative operator", " The number of non-zero pixels after pruningStrictIterative", " The frame's four corners should be deleted", "! Tests Morphology::thinning()", "*************************************************************************", " Apply the thinning operator", " The line should be the width of one pixel", "*************************************************************************", " Apply the thinning operator", " square_ should have shrunk by 4 pixels:", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "noise_elimination_test": ["*******************************************************************", "", "", "! Sets up images needed for testing", " Construct interpolationMethod0", " Fill interpolationMethod0 with a value of 1.0", " Insert noise", " Uncomment for visual inspection", " Construct interpolationMethod1", " Fill interpolationMethod1 with a value of 0.5", " Insert noise", " Uncomment for visual inspection", " Construct interpolationMethod2", " Fill interpolationMethod2 with a value of 1.0", " Uncomment for visual inspection", " Three images that will be used to test", " methods of class NoiseElimination", " An image with minimal noise (black pixels)", " An image with considerable amount of noise (black pixels)", " An image heavily noisy (black pixels)", "", " Fill the inside of the desired rectangle with the @param value provided", " Tests NoiseElimination::brushfireNear", " Uncomment for visual inspection", "Visualization::showScaled ( \"before brushfireNear\", interpolationMethod1, 0 );", " Run NoiseElimination::brushfireNear on interpolationMethod1", " Uncomment for visual inspection", "Visualization::showScaled ( \"after brushfireNear\", image, 0 );", " The whole of the image should be at 0.5 value", " Run NoiseElimination::brushfireNear on interpolationMethod0", " The whole of the image should be at a value of 1.0", "! Tests NoiseElimination::brushfireNearStep", " Uncomment for visual inspection", " Run NoiseElimination::brushfireNearStep on image interpolationMethod1", " Uncomment for visual inspection", " All pixels of interpolationMethod1 should now have a value of 0.5", " All non-zero value pixels have a value of 0.5", " Test a blank image", " Run NoiseElimination::brushfireNearStep", " All pixels should be still black", " Test an image with square concentrations of noise in each corner of it.", " The rest of the pixels are at random values", " upper left", " lower left", " upper right", " lower right", " The number of non zero pixels before calling any brushfireNearStep", " Run NoiseElimination::brushfireNearStep on image corners_", " The number of non zero pixels after removing the upper left noise", " concentration", "! Tests NoiseElimination::chooseInterpolationMethod", " On interpolationMethod0, Parameters::Depth::interpolation_method", " should be equal to 0", " On interpolationMethod1, Parameters::Depth::interpolation_method", " should be equal to 1", " On interpolationMethod2, Parameters::Depth::interpolation_method", " should be equal to 2", "! Tests NoiseElimination::interpolateImageBorders", " Create an image whose borders are non-zero but the rest of it is", " Run NoiseElimination::interpolateImageBorders", " All border pixels should now have a value of zero", "! Tests NoiseElimination::interpolateZeroPixel", " The return value of NoiseElimination::interpolateZeroPixel", " Zero-out some pixels in image interpolationMethod0", " Run NoiseElimination::interpolateZeroPixel", " At ( 200, 200 ) and around it, everything is black", " Run NoiseElimination::interpolateZeroPixel", " Around ( 1, 500 ), everything is at 1.0 value", " Run NoiseElimination::interpolateZeroPixel", " Around ( 400, 1 ), everything is at 1.0 value", " Run NoiseElimination::interpolateZeroPixel", " Error should be received here", "! Tests NoiseElimination::interpolation", " Run NoiseElimination::interpolation", "! Tests NoiseElimination::interpolationIteration", " The number of zero pixels before the call to interpolationIteration", " Run NoiseElimination::interpolationIteration", " The number of zero pixels after the call to interpolationIteration", " There should be more black pixels before than after the call to", " interpolationIteration", "! Tests NoiseElimination::performeNoiseElimination", " Remove the noise in interpolationMethod0", " The interpolated input image", " Run NoiseElimination::performeNoiseElimination", " There shouldn't be any black pixels in interpolated", " Remove the noise in interpolationMethod1", " Run NoiseElimination::performeNoiseElimination", " There shouldn't be any black pixels in interpolated", " Remove the noise in interpolationMethod2", " Run NoiseElimination::performeNoiseElimination", " There shouldn't be any black pixels in interpolated", "! Tests NoiseElimination::transformNoiseToWhite", " Count how many noisy pixels there are on interpolationMethod0", " Run NoiseElimination::transformNoiseToWhite on interpolationMethod0", " Count how many pixels have obtained the value dictated inside", " NoiseElimination::transformNoiseToWhite (4.0)", " The number of pixels changed should be equal to the intially noisy ones", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "wavelets_test": ["*******************************************************************", "", " Construct the grayscale image", " It features a filled white square of length 100 at (100, 100)", " Construct the RGB image", " It features a filled blue square of length 100 at (100, 100)", " The images' dimensions", " A grayscale image that will be used for testing", " A RGB image that will be used for testing", "! Tests Wavelets::getLowLow", " Find the min and max values in image grayscale", " The output image", " Run Wavelets::getLowLow", " The dimensions of image out should be half of those of image grayscale,", " plus one apparently", " Count the number of non-zero value pixels inside grayscale and out.", " The latter should be one quarter of the former. Because one more", " column and row are added to the halved dimensions, it is expected that", " the above number should be increased by a number of 50 + 50 + 1:", " one halved non-zero column, one halved non-zero row plus one corner pixel", "! Tests Wavelets::getLowLow", " The output image", " Run Wavelets::getLowLow", " The dimensions of image out should be half of those of image grayscale,", " plus one apparently", " Count the number of non-zero value pixels inside rgb and out.", " The latter should be one quarter of the former. Because one more", " column and row are added to the halved dimensions, it is expected that", " the above number should be increased by a number of 50 + 50 + 1:", " one halved non-zero column, one halved non-zero row plus one corner pixel.", " In order to count the non-zero pixels, image rgb should be split into its", " components", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "outline_discovery_test": ["*******************************************************************", "", "", "! Sets up three images: square_, which features a single non-zero value", "! square of size 100 with its upper left vertex at (100, 100),", "! squares_, which features two non-zero value squares of size 100.", "! The first one (order matters here) has its upper left vertex at", "! ( 100, 100 ) and the second one its lower right vertex at", "! ( WIDTH - 1, HEIGHT - 1 )", "! and corners_ which features two semi-closed squares: one with its", "! lower right vertex at ( 99, 99 ) and one with its upper right vertex", "! at ( HEIGHT - 99, WIDTH -99 )", " A square with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100)", " Construct the square_ image", " Locate the outline points of the square in the square_ image", " The number of actual outline points of the square should be", " 4 x 100 - 4", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 100, HEIGHT - 100),", " B' (WIDTH - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 100)", " Construct the squares_ image", " Construct the lower right square", " Add the vector of outline points of the upper left square to the", " vector holding the vectors of outline points of the squares_ image", " Add the vector of outline points of the lower right square to the", " vector holding the vectors of outline points of the squares_ image", " Add the upper left square and the lower right square", " The number of actual outline points of the squares should be", " 4 x 100 - 4", " Construct image corners_", " The images' width and height", " A square with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100)", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 100, HEIGHT - 100),", " B' (WIDTH - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 100)", " Two semi-closed squares", " The vector holding the outline points", " of the square in the square_ image", " The vector holding the vectors of outline points", " of the squares in the squares_ image", "", " The four vertices of the rectangle", "! Tests OutlineDiscovery::brushfireKeypoint()", "*************************************************************************", " Run OutlineDiscovery::brushfireKeypoint", " As a preliminary test, check if the number of outline points found", " is equal to the one it should be. The four vertices of the square are not", " included in the square's outline due to the cross-expanding nature of the", " brushfire algorithm", " The square's area should be the number of visited points of the brushfire", " algorithm, which, excluding the square's four vertices, is 100 x 100 - 4", " Check whether the outline points found are actually the outline points", " of the square in square_", "*************************************************************************", " Run OutlineDiscovery::brushfireKeypoint", " The square's area should be the number of visited points of the brushfire", " algorithm, which, excluding the square's four vertices, is 100 x 100 - 1", " vertex (the lower right one)", " Run OutlineDiscovery::brushfireKeypoint", " The square's area should be the number of visited points of the brushfire", " algorithm, which, excluding the square's four vertices, is 100 x 100 - 1", " vertex (the lower right one)", "! Tests OutlineDiscovery::brushfireKeypoints()", "*************************************************************************", " Push_back the two keypoints", " Run OutlineDiscovery::brushfireKeypoints", " As a preliminary test, check if the number of outline points found", " is equal to the one it should be", " Check whether the outline points found are actually the outline points", " of the sq-th square in square_", " The square's area should be the number of visited points of the", " brushfire algorithm, which,", " excluding the square's four vertices, is 100 x 100 - 4", "! Tests OutlineDiscovery::brushfirePoint()", "*************************************************************************", " The sets of visted points for each square", " Run OutlineDiscovery::brushfirePoint for the upper left square", " The number of visited points should be the number of visited points", " of the brushfire algorithm, which,", " excluding the square's four vertices, is 100 x 100 - 4", " Run OutlineDiscovery::brushfirePoint for the upper left square", " The number of visited points should be the number of visited points", " of the brushfire algorithm, which,", " excluding the square's four vertices, is 100 x 100 - 4", "*************************************************************************", " Run OutlineDiscovery::brushfireKeypoint", " The square's area should be the number of visited points of the brushfire", " algorithm, which, excluding the square's four vertices, is 100 x 100 - 1", " vertex (the lower right one)", " Run OutlineDiscovery::brushfireKeypoint", " The square's area should be the number of visited points of the brushfire", " algorithm, which, excluding the square's four vertices, is 100 x 100 - 1", " vertex (the lower right one)", "! Tests OutlineDiscovery::getShapesClearBorder", " Construct two squares, one within the other", " The number of non-zero pixels before getting the clear borders", " Run EdgeDetection::getShapesClearBorder", " The number of non-zero pixels after getting the clear borders", " The EdgeDetection::getShapesClearBorder method finds all borders,", " not caring about shapes being inside other shapes", "! Tests OutlineDiscovery::getShapesClearBorderSimple", " Construct two squares, one within the other", " The number of non-zero pixels of the shape that encapsulates the one", " below", " Run EdgeDetection::getShapesClearBorderSimple", " The number of non-zero pixels after getting the clear borders", " The EdgeDetection::getShapesClearBorderSimple method finds borders of", " shapes, discarding everything within them: the square does not get", " to be detected :(", "! Tests OutlineDiscovery::raycastKeypoint", "*************************************************************************", " The keypoint of the lower right square", " The vector of outline points", " The blob's area", "Run OutlineDiscovery::raycastKeypoint", " Due to the approximate nature of the raycastKeypoint algorithm,", " the number of outline points found should be smaller or equal to the", " actual number of outline points of the square", " The keypoint of the upper left square", " The vector of outline points", "Run OutlineDiscovery::raycastKeypoint", " Due to the approximate nature of the raycastKeypoint algorithm,", " the number of outline points found should be smaller or equal to the", " actual number of outline points of the square", "! Tests OutlineDiscovery::raycastKeypoints", "*************************************************************************", " The keypoint of the upper left square", " The keypoint of the lower right square", " The vector of keypoints", " Push back the two keypoints", " The vector of outline points", " The vector of blobs' areas", "Run OutlineDiscovery::raycastKeypoints", " Due to the approximate nature of the raycastKeypoint algorithm,", " the number of outline points found should be smaller or equal to the", " actual number of outline points of the square", "*************************************************************************", " Clear the keypoints vector", " Place a new keypoint in the keypoints vector", " Clear the outline vector", " Clear the areas vector", "Run OutlineDiscovery::raycastKeypoints", " There will be exactly one keypoint, although the rays hit the edges", " of the image", " Approximately, the area of each square will be more than 9500 px2,", " but less than 10000 px2", " rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "edge_detection_test": ["*******************************************************************", "", "", "! Sets up one image: squares_, which features two non-zero value squares", "! of size 100. The first one (order matters here) has its upper left", "! vertex at (100, 100) and the second one its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1). The rest of the image's pixels are with a", "! value of 60", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100)", " The two square outlines", " Construct the upperLeftSquare image", " Locate the outline points of the square in the upperLeftSquare image", " Construct the lower right square", " The edges of this square are not touching the image's borders.", " Remove \"- 1\" for that.", " Locate the outline points of the square in the upperLeftSquare image", " Add the vector of outline points of the upper left square to the", " vector holding the vectors of outline points of the squares_ image", " Add the vector of outline points of the lower right square to the", " vector holding the vectors of outline points of the squares_ image", " Add the upper left square and the lower right square", " The number of actual outline points of the squares should be", " 4 x 100 - 4", " The images' width and height", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100)", " The vector holding the vectors of outline points", " of the squares in the squares_ image", "", " The four vertices of the rectangle", "! Tests EdgeDetection::applyCanny", "! Tests EdgeDetection::applyScharr", "! Tests EdgeDetection::applySobel", "! Tests EdgeDetection::applyLaplacian", "! Tests EdgeDetection::applyEdgeContamination", " Modify the squares_ image. Add squares adjacent to the corners of it.", " The edges of this square are not touching the image's borders.", " Remove \"- 1\" for that.", " Uncomment for visual inspection", "Visualization::show(\"Modified squares_ image\", squares_, 0);", " Obtain the edges image for the squares_ image.", " Here, it does not matter with which operator the edges image is produced,", " provided that the the value tested below changes accordingly", " The number of non-zero pixels before the appliance of edge contamination", " Uncomment for visual inspection", "Visualization::show(\"Before calling applyEdgeContamination\", squares_edges, 0);", " Uncomment for visual inspection", "Visualization::show(\"After calling applyEdgeContamination\", squares_edges, 0);", " The number of non-zero pixels after the appliance of edge contamination", "! Tests EdgeDetection::computeDepthEdges", " Traverse all available edge detectors", " Test the toggle switch", " Convert squares_ into a CV_32FC1 type image", " Add an unfinished square to the squares_32FC1 image", " Uncomment for visual inspection", " Uncomment for visual inspection", "Visualization::show(\"After calling computeDepthEdges\", denoisedEdges, 0);", "! Tests EdgeDetection::computeRgbEdges", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " Uncomment for visual inspection", "Visualization::show(\"Before calling computeRgbEdges\", squares_8UC3, 0);", " The final edges image", " extractionMethod = 0", " A dummy histogram", " Run EdgeDetection::computeRgbEdges", " Uncomment for visual inspection", "Visualization::show(\"After calling computeRgbEdges 0\", denoisedEdges_0, 0);", " The final edges image", " extractionMethod = 1", " Run EdgeDetection::computeRgbEdges", " Because of the void histogram, the edges image is blank", " Uncomment for visual inspection", "Visualization::show(\"After calling computeRgbEdges 1\", denoisedEdges_1, 0);", "! Tests EdgeDetection::connectPairs", " Obtain the edges image for the squares_ image.", " Here, it does not matter with which operator the edges image is produced,", " provided that the the value tested below changes accordingly", " Add an unfinished square to the squares_edges image", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " Uncomment for visual inspection", "Visualization::show(\"squares_edges arc\", squares_edges, 0);", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Connect by line", " The number of non-zero pixels before the connection of the two points", " Connect the two points by line", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"squares_edges line\", squares_edges, 0);", " Commence full blown connectPairs test.", "///////////////////////// Features a U shape /////////////////////////////", " Backup u", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"u arc forward\", u , 0);", " Construct the vector of pairs", " Reverse the order of the graph nodes", " Reset u", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"u arc reverse\", u , 0);", " Connect by line", " Reset u", " The number of non-zero pixels before the connection of the two points", " Connect the two points by line", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"u line\", u , 0);", "///////////////////////// Features a C shape /////////////////////////////", " Backup c", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"c arc forward\", c , 0);", " Construct the vector of pairs", " Reverse the order of the graph nodes", " Reset c", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"c arc reverse\", c , 0);", " Connect by line", " Reset c", " The number of non-zero pixels before the connection of the two points", " Connect the two points by line", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"c line\", c , 0);", "///////////////////////// Features a pi shape ////////////////////////////", " Backup pi", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"pi arc forward\", pi , 0);", " Construct the vector of pairs", " Reverse the order of the graph nodes", " Reset pi", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"pi arc reverse\", pi , 0);", " Connect by line", " Reset pi", " The number of non-zero pixels before the connection of the two points", " Connect the two points by line", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"pi line\", pi , 0);", "///////////////////// Features a backwards C shape ///////////////////////", " Backup bc", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"bc arc forward\", bc , 0);", " Construct the vector of pairs", " Reverse the order of the graph nodes", " Reset bc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"bc arc reverse\", bc , 0);", " Connect by line", " Reset bc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by line", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"bc line\", bc , 0);", "///////////////////// Features a | | shape ///////////////////////", " This is made to test that if no outline point is found,", " the image is preserved and the points are not connected", " Backup ii", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"ii failure\", ii , 0);", "! Tests EdgeDetection::detectEdges", " Traverse all available edge detectors", " Test the toggle switch", " Convert squares_ into a CV_32FC1 type image", " Add an unfinished square to the squares_32FC1 image", " The squares_32FC1 image in 8UC1 format, scaled", " The image of edges", "! Tests EdgeDetection::denoiseEdges", " Obtain the edges image for the squares_ image.", " Here, it does not matter with which operator the edges image is produced,", " provided that the the value tested below changes accordingly", " The number of non-zero pixels in the edges image, before denoising", " Add an unfinished square to the squares_edges image", " Run EdgeDetection::denoiseEdges", " The number of non-zero pixels in the edges image, after denoising", " The type of the edges image should be CV_8UC1", " In this particular test, where the lower right square vanishes due to", " appliance of the edge contamination method, and the unfinished square's", " end points are connected, the number of non-zero pixels after the", " denoising of the edges image should amount to lower than that of before", " Tests EdgeDetection::floodFillPostprocess", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " Run EdgeDetection::floodFillPostprocess", "! Tests EdgeDetection::identifyCurveAndEndpoints", " A gamma shape", " Find the end points of a curve where a point trully lies on", " The point should lie on a curve.", " The curve should indeed be a curve: it is constituted by points", " The first end point's coordinates", " The second end point's coordinates", " Find the end points of a curve where a point trully lies on", " The point should not lie on a curve.", " The first end point's coordinates will be the origin", " The second end point's coordinates will be also be the origin", "! Tests EdgeDetection::identifyCurvesAndEndpoints", " Three gamma shapes", " Valid", " Invalid", " Valid", " Run EdgeDetection::identifyCurvesAndEndpoints", " There should be as many lines as there are pairs of end-points", " The gammas image should be processed and turned void", " There should be two curves exceeding the length threshold,", " hence there are two different entries for curves and end-points", " Every curve found should have a length greater than the threshold set.", " The coordinates of the end-points found", " The second end point's coordinates", " The first end point's coordinates", " The second end point's coordinates", "! Tests EdgeDetection::produceEdgesViaBackprojection", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " A dummy histogram", " Uncomment for visual inspection", " Run EdgeDetection::segmentation", " Uncomment for visual inspection", " The edges image should not be blank", " The edges image should be of type CV_8UC1", "! Tests EdgeDetection::produceEdgesViaSegmentation", " Traverse all available edge detectors", " Posterize?", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " Uncomment for visual inspection", "Visualization::show(\"Before calling produceEdgesViaSegmentation 0\",", "squares_8UC3, 0);", " Segmentation using cv::pyrMeanShiftFiltering", " Run EdgeDetection::segmentation", " segmentation method = 0", " Uncomment for visual inspection", " The image should not be blank", " The edges image should be of type CV_8UC1", " Uncomment for visual inspection", "! Tests EdgeDetection::segmentation", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " Uncomment for visual inspection", "Visualization::show(\"Before calling segmentation\", squares_8UC3, 0);", " Segmentation using cv::pyrMeanShiftFiltering", " Run EdgeDetection::segmentation", " Uncomment for visual inspection", "Visualization::show(\"After calling segmentation\", segmented, 0);", "! Tests EdgeDetection::watershedViaBackprojection", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " Uncomment for visual inspection", "Visualization::show(\"Before\", squares_8UC3, 0);", " A dummy backprojection image", " The watersheded image", " Run EdgeDetection::watershedViaBackprojection", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "blob_vector_test": ["*******************************************************************", "", " Dummy entries for the src conveyor", " Push back the two holes into the src conveyor", " Dummy entries for the dst conveyor", " Push back the two holes into the dst conveyor", " This is the source conveyor", " This is the destination conveyor", "! Tests BlobVector::extend", " Backup the original dst", " 2 entries in dst before appending src to it", " Run BlobVector::extend", " 4 entries in dst after appending src to it", " Check that the initial entries have not been tampered with", " Check the newly appended entries' elements against the original ones", "! Tests HolesConveyorUtils::appendDummyConveyor", " Backup the original dst", " Run BlobVector::append", " There should now be three entries in dst", " Check that the initial entries have not been tampered with", " The new entry", "", "! Tests BlobVector::clear", " Run BlobVector::clear", " The dst conveyor should be empty", "! Tests BlobVector::copy", " Run BlobVector::copy", " There should be two hole entries in dst now", " Check the newly appended entries' elements against the original ones", "! Tests HolesConveyorUtils::generateRectangle", "~ TEST_F ( HolesConveyorUtilsTest, generateRectangleTest )", "~ {", "~ // The rectangle's points that will be returned", "~ std::vector< cv::Point2f > points_1;", "~ ", "~ // The rectangle's vertices that will be returned", "~ std::vector< cv::Point2f > points_2;", "~ ", "~ // Run HolesConveyorUtils::generateRectangle with intent = 1", "~ points_1 = HolesConveyorUtils::generateRectangle", "~ ( cv::Point2f ( 100, 100 ), 100, 100, 1 );", "~ ", "~ // Run HolesConveyorUtils::generateRectangle with intent = 2", "~ points_2 = HolesConveyorUtils::generateRectangle", "~ ( cv::Point2f ( 100, 100 ), 100, 100, 2 );", "~ ", "~ // The number of vertices should amount to a number", "~ // lower than the number of points", "~ ASSERT_LT ( points_2.size(), points_1.size() );", "~ ", "~ // There should be four vertices", "~ EXPECT_EQ ( 4, points_2.size() );", "~ ", "~ EXPECT_EQ ( 100, points_2[0].x );", "~ EXPECT_EQ ( 100, points_2[0].y );", "~ ", "~ // There should be 4 * 100 points", "~ EXPECT_EQ ( 400, points_1.size() );", "~ ", "~ EXPECT_EQ ( 100, points_1[0].x );", "~ EXPECT_EQ ( 100, points_1[0].y );", "~ ", "~ }", "! Tests BlobVector::getBlob", " Run BlobVector::getBlob", " There should be one entry inside hole", " src and hole should have exactly the same amount of", " outline points", " Check that the entries in src and hole are exactly the same", "! Tests BlobVector::merge", " The merged conveyor", " Merge src and dst into merged", " There should be exactly 2 + 2 = 4 entries in merged", " Check the newly appended entries' elements against the original ones", " Check src", " Check dst", "! Tests BlobVector::removeHole", " Backup dst", " Two holes before removing one", " Run BlobVector::removeHole", " One hole after removing one", " The first entry should be exactly the same as the previously second one", "! Tests BlobVector::replace", " Run BlobVector::replace", " Check the newly replaced entries' elements against the original ones", "! Tests BlobVector::replaceHole", " Backup dst", " Run BlobVector::replaceHole", " There should still be two holes inside dst", " The 0-th hole of dst should be the 0-th hole of src", " The 1-st hole of dst should be the 1-st hole of dstBackup", "! Tests BlobVector::shuffle", " Backup dst", " Run BlobVector::shuffle", " There should still be 2 entries in dst", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "visualization_test": ["*******************************************************************", "", " Construct image floats", " Construct image gray", " Construct image rgb", " Set up the conveyor", " The images' dimensions", " An image containing floats", " A grayscale image", " A RGB image", " A dummy conveyor", "! Tests Visualization::multipleShow", " The input vector of images to show", " Push back the images into the vector", " The vector of titles", " Push back the title of each image into the vector", " Run Visualization::multipleShow", " Uncomment for visual inspection", "Visualization::multipleShow( \"Overall title\", images, titles, 1000, 0 );", "! Tests Visualization::scaleImageForVisualization", " Run Visualization::scaleImageForVisualization", "! Tests Visualization::show", " Run Visualization::show", " Uncomment for visual inspection", "Visualization::show( \"Floats image\", floats, 0 );", "Visualization::show( \"Gray image\", gray, 0 );", "Visualization::show( \"Rgb image\", rgb, 0 );", "! Tests Visualization::showHoles", " The msgs vector", " Run Visualization::showHoles", " Uncomment for visual inspection", "Visualization::showHoles( \"Overall title\", gray, conveyor, 0, msgs, 1 );", " Run Visualization::showHoles", " Uncomment for visual inspection", "Visualization::showHoles( \"Overall title\", rgb, conveyor, 0, msgs, 1 );", "! Tests Visualization::showKeypoints", " The vector of keypoints", " The vector of available images", "! Tests Visualization::showScaled", " Uncomment for visual inspection", "Visualization::showScaled( \"Title\", floats, 0 );", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_filters_test": ["*******************************************************************", "", "", "! Sets up one image: squares_, which features four non-zero value", "! squares of various sizes.", " Four squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100),", " A2 (90, 90), B2 (90, 210), C2 (210, 210), D2 (210, 90),", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100) and", " A'' (200, 200), B'' (200, 300), C'' (300, 300), D'' (300, 200)", " The two square outlines", " Construct the upperLeftSquare image", " Construct the upperLeftSquare2 image", " Construct the lower right square", " Construct the middle square", " Obtain the squares' outline points", " The total squares_ image is the sum of all the square images", " Four squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100),", " A2 (90, 90), B2 (90, 210), C2 (210, 210), D2 (210, 90),", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100) and", " A'' (200, 200), B'' (200, 300), C'' (300, 300), D'' (300, 200)", " Each square's outline points", " Each square's vertices", "", " The four vertices of the rectangle", "! Tests HoleFilters::validateKeypointsToRectangles", " Test two keypoints VS four rectangles", " The inKeyPoints argument", " The inRectangles argument", " The inRectanglesArea argument", " The inContours argument", " The HolesConveyor struct", " Run HoleFilters::validateKeypointsToRectangles", " There should be two entries in the conveyor", " The amount of points in the outlines of the two holes should be", " equal to 4 * 100 - 4", " The first vertex of the first hole", " The last vertex of the first hole", " The first vertex of the second hole", " The last vertex of the second hole", "! Tests HoleFilters::validateBlobs", " The keyPoints argument", " The HolesConveyor struct", " Run HoleFilters::validateBlobs, using Brushfire", " There should be two entries in the conveyor", " The amount of points in the outlines of the two holes should be", " equal to 4 * 100 - 8", " The first vertex of the first hole.", " Upper right corner, going counter-clockwise", " The last vertex of the first hole", " Lower right corner, going counter-clockwise", " The first vertex of the second hole", " Upper right corner, going counter-clockwise", " The last vertex of the second hole", " Lower right corner, going counter-clockwise", " Run HoleFilters::validateBlobs, using Raycast", " First, clear the conveyor", " There should be two entries in the conveyor", " The amount of points in the outlines of the two holes should be", " equal to 4 * 100 - 8", " The first vertex of the first hole.", " Lower right corner, going counter-clockwise", " The last vertex of the first hole", " Upper right corner, going counter-clockwise", " The first vertex of the second hole", " Lower right corner, going counter-clockwise", " The last vertex of the second hole", " Lower right corner, going counter-clockwise", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "bounding_box_detection_test": ["*******************************************************************", "", "", "! Sets up one image: squares_, which features two non-zero value squares", "! of size 100. The first one (order matters here) has its upper left", "! vertex at (100, 100) and the second one its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1). The rest of the image's pixels are with a", "! value of 60", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100)", " The two square outlines", " Construct the upperLeftSquare image", " Locate the outline points of the square in the upperLeftSquare image", " Construct the lower right square", " Locate the outline points of the square in the upperLeftSquare image", " Add the vector of outline points of the upper left square to the", " vector holding the vectors of outline points of the squares_ image", " Add the vector of outline points of the lower right square to the", " vector holding the vectors of outline points of the squares_ image", " Add the upper left square and the lower right square", " The number of actual outline points of the squares should be", " 4 x 100 - 4", " The images' width and height", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100)", " The vector holding the vectors of outline points", " of the squares in the squares_ image", "", " The four vertices of the rectangle", "! Tests BoundingBoxDetection::findRotatedBoundingBoxesFromOutline", " The square's area", " Run BoundingBoxDetection::findRotatedBoundingBoxesFromOutline", " Clear the blobsArea vector and replace it with values that should mean", " that the squares' area is lower than the accepted threshold", " Run BoundingBoxDetection::findRotatedBoundingBoxesFromOutline", " namespace rgb", " namespace pandora_vision_victim", " namespace pandora_vision"], "hole_merger_test": ["*******************************************************************", "", "", "", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the squares_ image to 1.0", " Construct the main square. This will be the assimilator,", " amalgamator and connector", " Construct the assimilable", " Construct the amalgamatable", " Construct the connectable", " Construct the outlier", " Compose the final squares_ image", " Construct the point cloud corresponding to the squares_ image", " Fill in the cloud data", " Generate the data", " Row", " Column", " The images' width and height", " The image that will be used to locate blobs in", " The conveyor of holes that will be used to test methods of class", " DepthFilters", " The point cloud corresponding to the squares_ image", "", " Fill the inside of the desired rectangle with the @param depthIn provided", "", " A single hole", " The hole's keypoint", " The four vertices of the rectangle", " The outline points of the hole will be obtained through the depiction", " of the points consisting the rectangle", " Push the hole back into a HolesConveyor", "! Tests HoleMerger::applyMergeOperation", " Keep a backup of the original conveyor", " Run HoleMerger::applyMergeOperation for operationId = 0 : assimilation", " The number of holes should have shrunk by one", " Entry #0 should be intact", " Original entry #2 should now be entry #1", " Original entry #3 should now be entry #2", " Original entry #4 should now be entry #3", " Restore conveyor to its original state", " Run HoleMerger::applyMergeOperation for operationId = 1 : amalgamation", " The number of holes should have shrunk by one", " The amalgamator should have grown in terms of outline points", " The amalgamator's keypoint should have moved a tiny bit to the right,", " but not significantly vertically", " Entry #1 should be intact", " Original entry #3 should now be #2", " Original entry #4 should now be #3", " Run HoleMerger::applyMergeOperation for operationId = 2 : connection", " But first, restore conveyor to its original state", " Modify the connection parameters", " The number of holes should have shrunk by one", " The connector should have grown in terms of outline points", " The connector's keypoint should have moved a bit to the left,", " and a bit lower than before", " Original entry #1 should now be entry #1", " Original entry #2 should now be entry #2", " Original entry #4 should now be entry #3", " Restore conveyor to its original state", " Run HoleMerger::applyMergeOperation for all operations", " The number of holes should have shrunk to two", " Apply preposterous thresholds", " Restore conveyor to its original state", " Run HoleMerger::applyMergeOperation for all operations", " No assimilation or amalgamation or connection should have happened", "! Tests HoleMerger::applyMergeOperationWithoutValidation", " Keep a backup of the original conveyor", " Run HoleMerger::applyMergeOperationWithoutValidation", " for operationId = 0 : assimilation", " The number of holes should have shrunk by one", " Entry #0 should be intact", " Original entry #2 should now be entry #1", " Original entry #3 should now be entry #2", " Original entry #4 should now be entry #3", " Restore conveyor to its original state", " Run HoleMerger::applyMergeOperationWithoutValidation", " for operationId = 1 : amalgamation", " The number of holes should have shrunk by one", " The amalgamator should have grown in terms of outline points", " The amalgamator's keypoint should have moved a tiny bit to the right,", " but not significantly vertically", " Entry #1 should be intact", " Original entry #3 should now be #2", " Original entry #4 should now be #3", " Restore conveyor to its original state", " Run HoleMerger::applyMergeOperationWithoutValidation", " for all operations", " The number of holes should have shrunk to three", "! Tests HoleMerger::isCapableOfAssimilating", " Construct the hole mask sets for all the holes", " Here, the main square will be the assimilator, amalgamator and connector", " Run HoleMerger::isCapableOfAssimilating", " The main square should be able to assimilate only the assimilable", "! Tests HoleMerger::isCapableOfAmalgamating", " Construct the hole mask sets for all the holes", " Here, the main square will be the assimilator, amalgamator and connector", " Run HoleMerger::isCapableOfAmalgamating", " The main square should be able to amalgamate only the amalgamatable", "! Tests HoleMerger::amalgamateOnce", " Construct the hole mask sets for all the holes", " Here, the main square will be the assimilator, amalgamator and connector", " Keep a backup of the original amalgamator", " The amalgamator should have grown in terms of outline points", " The amalgamator's keypoint should have moved a tiny bit to the right,", " but not significantly vertically", "! Tests HoleMerger::isCapableOfConnecting", " Construct the hole mask sets for all the holes", " Here, the main square will be the assimilator, amalgamator and connector", " Modify the connection parameters", " Run HoleMerger::isCapableOfConnecting", " The main square should be able to amalgamate only the amalgamatable", " Modify the connection parameters so as to test that not only distance", " plays a role. There has to be mutual exclusion regarding the points", " inside each hole too", " Run HoleMerger::isCapableOfConnecting", " The main square should be able to connect only with the connectable", " Modify the connection parameters so as to test that not only distance", " plays a role. There has to be mutual exclusion regarding the points", " inside each hole too", " Run HoleMerger::isCapableOfConnecting", " The connectable should not be able to be connected with the", " connector for max_distance = 10", " Default the connection parameters", "! Tests HoleMerger::connectOnce", " Construct the hole mask sets for all the holes", " Here, the main square will be the assimilator, amalgamator and connector", " Keep a backup of the original amalgamator", " Run HoleMerger::connectOnce", " The connector should have grown in terms of outline points", " The connector's keypoint should have moved a bit to the left,", " and a bit lower than before", "! Tests HoleMerger::mergeHoles", " Keep a backup of the original conveyor", " The interpolation method. 0 for using depth filters validation", " Apply reasonable thresholds", " Restore conveyor to its original state", "HolesConveyorUtils::replace( originConveyor, &conveyor );", " Run HoleMerger::mergeHoles", " The number of holes should have shrunk to two", " The interpolation method. 1 for not using depth filters validation", " Restore conveyor to its original state", " Run HoleMerger::mergeHoles", " The number of holes should have shrunk to three", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "rgb_filters_test": ["*******************************************************************", "", "", "", "! Sets up one image: squares_,", "! which features four squares of size 100, and one of size 140", "! The first one (order matters here) has its upper left vertex at", "! (100, 100),", "! the second one has its upper right vertex at (WIDTH - 3, 3)", "! (so that the blob it represents can barely be identified)", "! and the the third one has its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1).", "! It creates a square whose upper left vertex is located", "! at ( 250, 250 ), filled with random colours.", "! Finally, there is the square with edges of length 140px, which", "! surrounds the upper left square, and is of black colour", "! (constructed to test the RgbFilters::checkHolesLuminosityDiff method)", "! It creates the corresponding conveyor entries for these square holes.", " Construct the lower right square", " Construct the upper right image", " Construct the upper left square", " Construct the square surrounding the upper left square", " Construct the middle square. In contrast to the other three", " rectangles, this is scattered with random colours inside it", " The seed for the rand_r method", " The image upon which the squares will be inprinted", " Compose the final squares_ image", " Construct the squares_ image. The entire image is at a colour of", " value approximate the the colour value of the images of walls", " The images' width and height", " The image that will be used to locate blobs in", " The conveyor of holes that will be used to test methods of class", " RgbFilters", "", " Fill the inside of the desired rectangle with the @param rgbIn provided", "", " A single hole", " The hole's keypoint", " The four vertices of the rectangle", " The outline points of the hole will be obtained through the depiction", " of the points consisting the rectangle", " Push hole back into a HolesConveyor", " Tests RgbFilters::checkHolesColorHomogeneity", " Generate the needed resources", " The vector of probabilities returned", " Run RgbFilters::checkHolesColorHomogeneity", " All squares except the one whose internal colours are randomly", " generated are dull.", "! Tests RgbFilters::checkHolesLuminosityDiff", " Generate the needed resources for an inflation size of value 0", " The vector of set masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of sets", " The vector of probabilities returned", " Run RgbFilters::checkHolesLuminosityDiff", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " Generate the needed resources for an inflation size of value 10", " The vector of set masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of sets", " The vector of probabilities returned", " Run RgbFilters::checkHolesLuminosityDiff", " The inflated rectangles of the lower right and upper right rectangles", " are out of the image's bounds.", " The upper left rectangle is surrounded by a black rectangle, so there goes", " The surrounding rectangle and the middle one are just fine", "! Tests RgbFilters::checkHolesTextureBackProject", " Generate the needed resources for an inflation size of value 0", " The vector of set masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of sets", " The vector of probabilities returned", " Generate the histogram of walls", " Run RgbFilters::checkHolesTextureBackProject", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " Generate the needed resources for an inflation size of value 10", " The vector of set masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of sets", " The vector of probabilities returned", " Run RgbFilters::checkHolesTextureBackProject", " The inflated rectangles of the lower right and upper right rectangles", " are out of the image's bounds.", " The upper left rectangle is surrounded by a black rectangle, so there goes", " The surrounding rectangle and the middle one are just fine", "! Tests RgbFilters::checkHolesTextureDiff", " Histogram generation : secondary channel toggle", " Generate the needed resources for an inflation size of value 0", " The vector of image masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of images", " There shouldn't be any non-zero pixels inside each mask", " The vector of probabilities returned", " Generate the histogram of walls", " Run RgbFilters:checkHolesTextureDiff:", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsImageVector_0 vector is zero", " Histogram generation : secondary channel toggle", " Generate the needed resources for an inflation size of value 10", " The vector of set masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of images", " There should be more than zero non-zero pixels inside each mask", " The vector of probabilities returned", " Set the texture threshold to 0.9, or else all probabilities would be", " equal to zero", " Generate the histogram of walls", " Run RgbFilters:checkHolesTextureDiff:", " For some reason, using the saturation as the secondary channel for", " the generation of the histograms, gives all probabilities", " equal to zero. Crappy behaviour.", " The inflated rectangles of the lower right and upper right rectangles", " are out of the image's bounds.", " The upper left rectangle is surrounded by a black rectangle,", " so there goes.", " The surrounding rectangle and the middle one are just fine", " namespace hole_fusion", " namespace pandora_vision_victim", " namespace pandora_vision"], "hole_validation_test": ["*******************************************************************", "", " A vector of probabilities for when in RGBD_MODE,", " when all available filters are active", " A vector of probabilities for when in RGBD_MODE,", " when some of the available filters are active", " A vector of probabilities for when in RGB_ONLY_MODE,", " when all available filters are active", " A vector of probabilities for when in RGB_ONLY_MODE,", " when some of the available filters are active", "! Tests HoleValidation::validateHoles", "////////////////////////////// RGBD_MODE /////////////////////////////////", "////////////////////////////// All filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Luminosity diff", " Rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHoles for RGBD_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of some available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Rectangle plane constitution", " Texture backprojection", " Intermediate points plane constitution", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesfor RGBD_MODE", " Only the second hole should have been deemed valid", "//////////////////////////// RGB_ONLY_MODE ///////////////////////////////", "///////////////////////////// All filters ////////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesfor RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesfor RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "! Tests HoleValidation::validateHolesViaThresholdedWeighting", "////////////////////////////// RGBD_MODE /////////////////////////////////", "////////////////////////////// All filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Luminosity diff", " Rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholdedWeighting for RGBD_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of some available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Rectangle plane constitution", " Texture backprojection", " Intermediate points plane constitution", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholdedWeighting for RGBD_MODE", " Only the second hole should have been deemed valid", "//////////////////////////// RGB_ONLY_MODE ///////////////////////////////", "///////////////////////////// All filters ////////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholdedWeighting for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholdedWeighting for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "! Tests HoleValidation::validateHolesViaThresholding", "////////////////////////////// RGBD_MODE /////////////////////////////////", "////////////////////////////// All filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Luminosity diff", " Rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholding for RGBD_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of some available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Rectangle plane constitution", " Texture backprojection", " Intermediate points plane constitution", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholding for RGBD_MODE", " Only the second hole should have been deemed valid", "//////////////////////////// RGB_ONLY_MODE ///////////////////////////////", "///////////////////////////// All filters ////////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholding for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholding for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "! Tests HoleValidation::validateHolesViaWeighting", "////////////////////////////// RGBD_MODE /////////////////////////////////", "////////////////////////////// All filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Luminosity diff", " Rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaWeighting for RGBD_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of some available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Rectangle plane constitution", " Texture backprojection", " Intermediate points plane constitution", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaWeighting for RGBD_MODE", " Only the second hole should have been deemed valid", "//////////////////////////// RGB_ONLY_MODE ///////////////////////////////", "///////////////////////////// All filters ////////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaWeighting for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaWeighting for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_uniqueness_test": ["*******************************************************************", "", "! Tests HoleUniqueness::makeHolesUnique (a)", " The container of holes", " A container of one hole", " Construct hole_1", " A container of another hole", " Construct hole_2", " A container of a third hole", " Construct hole_3", " Holes 1 and 2 will be multiple, in a random order.", " Run HoleUniqueness::makeHolesUnique (a)", " There should be only three unique holes inside the container", "! Tests HoleUniqueness::makeHolesUnique (b)", " What one needs to do here, is to construct a swarm of holes", " around some point and give each hole a validity probability.", " First swarm; swarm a", " Second swarm; swarm b", " Add another, unique, hole", " Push all the holes back into a container", " Construct a validity map", " Run HoleUniqueness::makeHolesUnique (b)", " There should be three unique holes", " Inquire about the internals of the unique holes", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "filters_test": ["*******************************************************************", "", "", "", "", "! Sets up two images: depthSquares_,", "! which features three squares of size 100.", "! The first one (order matters here) has its upper left vertex at", "! (100, 100),", "! the second one has its upper right vertex at (WIDTH - 3, 3)", "! (so that the blob it represents can barely be identified)", "! and the the third one has its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1).", "! It creates the corresponding conveyor entries for these square holes", "! and the corresponding point cloud to match the depthSquares_ depth image.", "! The second image is rgbSquares_,", "! which features four squares of size 100, and one of size 140", "! The first one (order matters here) has its upper left vertex at", "! (100, 100),", "! the second one has its upper right vertex at (WIDTH - 3, 3)", "! (so that the blob it represents can barely be identified)", "! and the the third one has its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1).", "! It creates a square whose upper left vertex is located", "! at ( 250, 250 ), filled with random colours.", "! Finally, there is the square with edges of length 140px, which", "! surrounds the upper left square, and is of black colour", "! (constructed to test the Filters::checkHolesLuminosityDiff method)", "! It creates the corresponding conveyor entries for these square holes.", "/////////// Construct the depth image and the point cloud ////////////", " The image upon which the squares will be inprinted", " Construct the depthSquares_ image", " Set the depth for each point of the depthSquares_ image to 1.0", " Construct the lower right square", " Construct the upper right image", " Construct the upper left square", " Compose the final depthSquares_ image", " Construct the point cloud corresponding to the depthSquares_ image", " Fill in the cloud data", " Generate the data", " Row", " Column", "///////////////////// Construct the rgb image ////////////////////////", " Construct the lower right square", " Construct the upper right image", " Construct the upper left square", " Construct the square surrounding the upper left square", " Construct the middle square. In contrast to the other three", " rectangles, this is scattered with random colours inside it", " The seed for the rand_r method", " Create the conveyor of candidate holes for both images", " The image upon which the squares will be inprinted", " Compose the final rgbSquares_ image", " Construct the rgbSquares_ image. The entire image is at a colour of", " value approximate the the colour value of the images of walls", " The images' width and height", " The depth image", " The RGB image", " The conveyor of holes that will be used to test methods of class", " Filters", " The point cloud corresponding to the depthSquares_ image", "", " Fill the inside of the desired rectangle with the @param depthIn provided", "", " Fill the inside of the desired rectangle with the @param rgbIn provided", "", " What will be returned: the internal elements of one hole", " The hole's keypoint", " The four vertices of the rectangle", " The outline points of the hole will be obtained through the depiction", " of the points consisting the rectangle", " Push hole into a HolesConveyor", "! Tests Filters::applyFilter", " Inflations size : 0", " Create the needed by the Filters::applyFilter method vectors", " The vector of mask images", " The intermediate points vector of sets", " The intermediate points vector of images", " Run Filters::applyFilter for every filter,", " except for the ones that utilize textures", " A dummy histogram", " Run Filters::applyFilter", " Color homogeneity", " All squares except the one whose internal colours are randomly", " generated are dull.", " Luminosity difference", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " Texture-based filters are not tested yet.", " TODO: import an image from the walls directory in order to test them", " Depth difference", " The surrounding square has its vertices closer than its keypoint", " Rectangle points plane constitution", " Depth / area", " Intermediate points plane constitution", " Depth homogeneity", " The east and south edges of the lower right square are clipped", " The surrounding square encloses a hole which actually has edges", " Inflations size : 10", " Create the needed by the Filters::applyFilter method vectors", " The vector of mask images", " The intermediate points vector of images", " Run Filters::applyFilter for every filter", " except for the ones that utilize textures", " Run Filters::applyFilter", " Color homogeneity", " All squares except the one whose internal colours are randomly", " generated are dull.", " Luminosity difference", " The inflated rectangles of the lower right and upper right rectangles", " are out of the image's bounds.", " The upper left rectangle is surrounded by a black rectangle,", " so there goes", " The surrounding rectangle and the middle one are just fine", " Texture-based filters are not tested yet.", " TODO: import an image from the walls directory in order to test them", " Depth difference", " Only the last two holes should have an inflated rectangle", " for inflation size of value 10", " Rectangle points plane constitution", " Depth / area", " Intermediate points plane constitution", " Depth homogeneity", " The east and south edges of the lower right square are clipped", "! Tests Filters::applyFiltersTest:", "///////////////////////// Inflations size : 0 ////////////////////////////", " Create the needed by the Filters::applyFilters method vectors", " The vector of mask images", " The intermediate points vector of sets", " The intermediate points vector of images", " ------------------------------ RGBD_MODE --------------------------------", " Set the order of the filters' execution in random", " Apply all active filters and obtain a 2D vector containing the", " probabilities of validity of each candidate hole, produced by all", " active filters", " Seven RGB + D filters in total", " (Nine excluding the ones using textures)", " A dummy histogram", " Test all RGB and Depth filters", " Run Filters::applyFilters", " Filter-wise", " The east and south edges of the lower right square are clipped", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " ---------------------------- RGB_ONLY_MODE ------------------------------", " Set the order of the filters' execution in random", " Apply all active filters and obtain a 2D vector containing the", " probabilities of validity of each candidate hole, produced by all", " active filters", " (Four excluding the ones using textures)", " Test only the RGB filters", " Run Filters::applyFilters", " Filter-wise", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", "//////////////////////// Inflations size : 10 ////////////////////////////", " Create the needed by the Filters::applyFilters method vectors", " The vector of mask images", " The intermediate points vector of sets", " The intermediate points vector of images", " ------------------------------ RGBD_MODE --------------------------------", " Set the order of the filters' execution in random", " Apply all active filters and obtain a 2D vector containing the", " probabilities of validity of each candidate hole, produced by all", " active filters", " Seven RGB + D filters in total", " (Nine excluding the ones using textures)", " Test all RGB and Depth filters", " Run Filters::applyFilters", " Filter-wise", " The east and south edges of the lower right square are clipped", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " ---------------------------- RGB_ONLY_MODE ------------------------------", " Set the order of the filters' execution in random", " Apply all active filters and obtain a 2D vector containing the", " probabilities of validity of each candidate hole, produced by all", " active filters", " (Four excluding the ones using textures)", " Test only the RGB filters", " Run Filters::applyFilters", " Filter-wise", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " namespace hole_fusion", " namespace pandora_vision_victim", " namespace pandora_vision"], "filters_resources_test": ["*******************************************************************", "", "", " An image needed only for its size", " In total, there should be three holes", " An image needed only for its size", " Dimensions of the squares_ image", " The overall conveyor holding the holes", "", " A single hole", " The hole's keypoint", " The four vertices of the rectangle", " The outline points of the hole will be obtained through the depiction", " of the points consisting the rectangle", " Push back hole into a HolesConveyor", "! Tests FiltersResources::createCheckerRequiredVectors", "/////////////////////////////// RGBD_MODE ////////////////////////////////", " The needed resources", " Run FiltersResources::createCheckerRequiredVectors", " Inquire about holesMasksImageVector", " There should be three images of masks of holes", " There should be 100 X 100 points in each mask", " No masks if the corresponding filters to variables", " a and c are disabled", " Inquire about holesMasksSetVector", " There should be three masks of holes", " Each mask should have 100 X 100 points", " No masks if the corresponding filters to variables", " b, d, f and i are disabled", " Inquire about inflatedRectangles*", " The number of rectangles should be equal to the", " number of indices", " In this case, with an inflation size of value 10,", " there should be two holes", " Each rectangle should have exactly four vertices", " The number of rectangles should be equal to the", " number of indices", " No masks if the corresponding filters to variables", " b, c, d, e, g and h are disabled", " Inquire about intermediatePointsImageVector", " There should be two masks of intermediate points", " There should be more than 400 intermediate points", " No masks if the corresponding filter to variable", " c is disabled", " Inquire about intermediatePointsSetVector", " There should be two masks of intermediate points", " There should be more than 400 intermediate points", " No masks if the corresponding filters to variables", " b, d and g are disabled", " Clear the vectors for the next run", "///////////////////////////// RGB_ONLY_MODE //////////////////////////////", " The needed resources", " Run FiltersResources::createCheckerRequiredVectors", " Inquire about holesMasksImageVector", " There should be three images of masks of holes", " There should be 100 X 100 points in each mask", " No masks if the corresponding filters to variables", " a and c are disabled", " Inquire about holesMasksSetVector", " There should be three masks of holes", " Each mask should have 100 X 100 points", " No masks if the corresponding filters to variables", " b, d, f and i are disabled", " Inquire about inflatedRectangles*", " The number of rectangles should be equal to the", " number of indices", " In this case, with an inflation size of value 10,", " there should be two holes", " Each rectangle should have exactly four vertices", " The number of rectangles should be equal to the", " number of indices", " No masks if the corresponding filters to variables", " b, c, d, e, g and h are disabled", " Inquire about intermediatePointsImageVector", " There should be two masks of intermediate points", " There should be more than 400 intermediate points", " No masks if the corresponding filter to variable", " c is disabled", " Inquire about intermediatePointsSetVector", " There should be two masks of intermediate points", " There should be more than 400 intermediate points", " No masks if the corresponding filters to variables", " b, d and g are disabled", " Clear the vectors for the next run", "! Tests FiltersResources::createHolesMasksVectors", " The vector of images of masks", " The indices of points inside the holes in conveyor", " Run FiltersResources::createHolesMasksVectors", " There should be three masks in total", " The number of non-zero value pixels in all of the images", " The total number of non-zero value pixels in all of the images should", " be equal to three times as much as in any image, which is 100 X 100", "! Tests FiltersResources::createHolesMasksImageVector", " The vector of images of masks", " Run FiltersResources::createHolesMasksImageVector", " There should be three images in total", " The images' type should be CV_8UC1", " The number of non-zero value pixels in all of the images", " The total number of non-zero value pixels in all of the images should", " be equal to three times as much as in any image, which is 100 X 100", "! Tests FiltersResources::createHolesMasksSetVector", " The indices of points inside the holes in conveyor", " Run FiltersResources::createHolesMasksSetVector", " Each mask should have 100 X 100 points", " Uncomment for visual inspection", "! Tests FiltersResources::createInflatedRectanglesVector", " The vector holding the inflated rectangles vertices per hole for", " inflation size equal to zero", " The indices of holes inside the conveyor whose inflated rectangles is", " actually inside the image's bounds for", " inflation size equal to zero", " Run FiltersResources::createInflatedRectanglesVector", " with inflation size of value 0", " All holes' inflated rectangles should be inside the image's bounds", " All rectangles should be of size four (four vertices)", " The vector holding the inflated rectangles vertices per hole for", " inflation size equal to two", " The indices of holes inside the conveyor whose inflated rectangles is", " actually inside the image's bounds for", " inflation size equal to two", " Run FiltersResources::createInflatedRectanglesVector", " with inflation size of value 2", " The lower right hole's inflated rectangle should exceed", " the image's bounds", " All rectangles should be of size four (four vertices)", " The first valid inflated rectangle should be conveyor[1]", " The second valid inflated rectangle should be conveyor[2]", "! Tests FiltersResources::createIntermediateHolesPointsVectors", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 0", " The intermediate points vector for all holes", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsVectors", " Intermediate points positions should only exist for all of the holes", " The total number of intermediate points in all of the images", " There shouldn't be any intermediate points for inflation size equal to 0", " There shouldn't be any intermediate points for inflation size equal to 0", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 2", " The intermediate points vector for all holes", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsVectors", " Intermediate points positions should only exist for all of the holes", " whose iflated rectangle is within the image's bounds", " The total number of intermediate points in all of the images", " There shouldn't be any intermediate points for inflation size equal to 0", " There shouldn't be any intermediate points for inflation size equal to 0", "! Tests FiltersResources::createIntermediateHolesPointsImageVector", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 0", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsImageVector", " Intermediate points positions should exist for all of the holes", " The total number of intermediate points in all of the images", " There shouldn't be any intermediate points for inflation size equal to 0", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 2", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsImageVector", " Intermediate points should only exist for the two holes", " The total number of intermediate points in all of the images", " There should be two valid inflated rectangles, so the total number", " of intermediate points should be greater than two times the outline", " of each hole", "! Tests FiltersResources::createIntermediateHolesPointsSetVector", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 0", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsSetVector", " Intermediate points positions should exist for all of the holes", " There shouldn't be any intermediate points for inflation size equal to 0", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 2", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsSetVector", " Intermediate points should only exist for the two holes", " There should be more than 4 X 100 intermediate points", " Uncomment for visual inspection", " hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "depth_filters_test": ["*******************************************************************", "", "", "", "! Sets up one image: squares_,", "! which features three squares of size 100.", "! The first one (order matters here) has its upper left vertex at", "! (100, 100),", "! the second one has its upper right vertex at (WIDTH - 3, 3)", "! (so that the blob it represents can barely be identified)", "! and the the third one has its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1).", "! It creates the corresponding conveyor entries for these square holes", "! and the corresponding point cloud to match the squares_ depth image", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the squares_ image to 1.0", " Construct the lower right square", " Construct the upper right image", " Construct the upper left square", " Compose the final squares_ image", " Construct the point cloud corresponding to the squares_ image", " Fill in the cloud data", " Generate the data", " Row", " Column", " The images' width and height", " The image that will be used to locate blobs in", " The conveyor of holes that will be used to test methods of class", " DepthFilters", " The point cloud corresponding to the squares_ image", "", " Fill the inside of the desired rectangle with the @param depthIn provided", "", " What will be returned: the internal elements of one hole", " The hole's keypoint", " The four vertices of the rectangle", " The outline points of the hole will be obtained through the depiction", " of the points consisting the rectangle", " Push hole into a HolesConveyor", "! Tests DepthFilters::checkHolesDepthArea", " Generate the vector of holes' mask (set)", " Needed vectors by the DepthFilters::checkHolesDepthDiff method", " Run DepthFilters::checkHolesDepthDiff", "! Tests DepthFilters::checkHolesDepthDiff", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 0", " Needed vectors by the DepthFilters::checkHolesDepthDiff method", " Run DepthFilters::checkHolesDepthDiff", " All three holes should have an inflated rectangle for inflation", " size of value 0", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 2", " Needed vectors by the DepthFilters::checkHolesDepthDiff method", " Run DepthFilters::checkHolesDepthDiff", " Only the last two holes should have an inflated rectangle", " for inflation size of value 2", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 8", " Needed vectors by the DepthFilters::checkHolesDepthDiff method", " Run DepthFilters::checkHolesDepthDiff", " Only the last two holes should have an inflated rectangle", " for inflation size of value 2", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 180", " Needed vectors by the DepthFilters::checkHolesDepthDiff method", " Run DepthFilters::checkHolesDepthDiff", " Only the last two holes should have an inflated rectangle", " for inflation size of value 2", "! Tests DepthFilters::checkHolesDepthHomogeneity", " Generate the vector of holes' mask (set)", " Needed vectors by the DepthFilters::checkHolesDepthHomogeneity method", " Run DepthFilters::checkHolesDepthHomogeneity", " The east and south edges of the lower right square are clipped", "! Tests DepthFilters::checkHolesOutlineToRectanglePlaneConstitution", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 0", " Generate the intermediate points set vector", " Needed vectors by the", " DepthFilters::checkHolesOutlineToRectanglePlaneConstitution method", " Run DepthFilters::checkHolesOutlineToRectanglePlaneConstitution", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 10", " Generate the intermediate points set vector", " Needed vectors by the", " DepthFilters::checkHolesOutlineToRectanglePlaneConstitution method", " Run DepthFilters::checkHolesOutlineToRectanglePlaneConstitution", "! Tests DepthFilters::checkHolesRectangleEdgesPlaneConstitution", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 0", " Needed vectors by the", " DepthFilters::checkHolesRectangleEdgesPlaneConstitution method", " Run DepthFilters::checkHolesRectangleEdgesPlaneConstitution", " All of the rectangles lie on planes", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 10", " Needed vectors by the", " DepthFilters::checkHolesRectangleEdgesPlaneConstitution method", " Run DepthFilters::checkHolesRectangleEdgesPlaneConstitution", " The lower right and upper right squares' inflated rectangles", " exceed the image's boundaries, hence, their probability of lying on", " a plane is diminished to zero", " Only the upper left square's inflated rectangle is within the image's", " bounds.", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "planes_detection_test": ["*******************************************************************", "", " Construct the point cloud", " The height and width of the point cloud", " The point cloud which the test are relied on", "! Tests PlanesDetection::applyVoxelGridFilter", " Run PlanesDetection::applyVoxelGridFilter", "! Tests PlanesDetection::locatePlanes", " Run PlanesDetection::locatePlanes without applying voxel filtering", " There should be two planes detected", " The first plane is comprised of the three quarters", " of the entire point cloud", " The remaining quarter is the second point cloud", " Run PlanesDetection::locatePlanes with voxel filtering", " There should be two planes detected", " The first plane is comprised of the one hundredth of three quarters", " of the entire point cloud", " The remaining one hundredth quarter is the second point cloud", "! Tests PlanesDetection::locatePlanesUsingSACSegmentation", " The planar point clouds' vector", " The vector of coefficients per plane", " The vector of inliers per plane", " There should be two planes detected", " The first plane is comprised of the three quarters", " of the entire point cloud", " The remaining quarter is the second point cloud", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "interface_tester": ["*******************************************************************"], "tf_monitor": ["* \\author Wim Meeussen ", "Lookup the authority "], "interfaces_xml_parser": ["*******************************************************************"], "node_diagnostics": ["*******************************************************************", "~ Suppose there is only one package element in each document"], "generic_diagnostic": ["*******************************************************************"], "interface_diagnostics_node": ["*******************************************************************", "~ InterfaceDiagnostics id;"], "interface_diagnostics": ["*******************************************************************", "~ Suppose there is only one package element in each document"], "xmega_hardware_interface": ["*******************************************************************", " connect and register power supply interface", " connect and register range sensor interface", " connect and register joint state interface", " make radians value between [-pi, pi]", " read joint names from param server", " connect and register the joint state interface", " namespace xmega", " namespace pandora_hardware_interface"], "xmega_hardware_interface_node": ["*******************************************************************"], "battery_controller": ["*******************************************************************", " Get sensor names from interface", " Read publish rate from yaml", " Get sensor handles from interface", " Create publisher", " Initialize last time published", " Publish messages", " Fill voltage", " namespace arm", " namespace pandora_hardware_interface"], "range_sensor_controller": ["*******************************************************************", " Get sensor names from interface", " Read publish rate from yaml", " Get sensor handles from interface", " Create publisher for each controller", " resize last times published", " Initialize last time published", " Publish messages", " Fill range msg", " publish the message", " namespace arm", " namespace pandora_hardware_interface"], "encoder_sensor": ["*******************************************************************", "", " namespace xmega", " namespace pandora_hardware_interface"], "test": ["*******************************************************************"], "range_sensor": ["*******************************************************************", " namespace xmega", " namespace pandora_hardware_interface"], "battery_sensor": ["*******************************************************************", " <calculated scale factor error for Electronics line> ", " namespace xmega", " namespace pandora_hardware_interface"], "xmega_serial_interface": ["*******************************************************************", "------------- Private Members -------------------//", " <IDLE_STATE indicates the state waiting for start of transmission characters> ", " +0.5 is used for rounding positive values", " cleanup", " ' ' after sensor id", " ' ' after sensor type", " battery, not i2c sensor", " encoder, not i2c sensor", " ' ' after sensor i2c address", " ' ' after sensor status", " LF after Data", " processing error", " successful processing", "----------SerialIO------------------------//", "serialPtr_->flush(); /* <Flush I/O software buffers on startup.> */", " <Flush Input software buffer on startup.> ", " <Flush Output software buffer on startup.> ", "serialPtr_->flush(); /* <Flush I/O software buffers on termination.> */", " <Flush Input software buffer on termination.> ", " <Flush Output software buffer on termination.> ", "initialize size of data.Size of command data is 1 byte", " <If they match the start of data package char sequence (0x0C , 0x0A)> ", "dataSiz buffer where the size of data is written", "Initialize size of dataSiz.", "to change????", " negative or dekadiko???????????????", " namespace xmega", " namespace pandora_hardware_interface"], "linear_actuator_hardware_interface_node": ["*******************************************************************"], "linear_actuator_hardware_interface": ["*******************************************************************", " initialize position of linear actuator", " connect and register the joint state interface", " connect and register the joint position interface", " get feedback and convert from [cm] to [m]", " clip target command", " namespace linear_actuator", " namespace pandora_hardware_interface"], "firgelli_com_interface": ["*******************************************************************", " set accuracy", " Low", " High", " set retract limit", " Low", " High", " set extend limit", " Low", " High", " set movement threshold", " Low", " High", " set stall time", " Low", " High", " set PWM threshold", " Low", " High", " set Derivative Threshold", " Low", " High", " set max derivative", " Low", " High", " set min derivative", " Low", " High", " set max pwm", " Low", " High", " set min pwm", " Low", " High", " set Kp", " Low", " High", " set Kd", " Low", " High", " set average RC", " Low", " High", " set average ADC", " Low", " High", " set speed", " Low", " High", " Microtech", " ??", " useless", " Low", " High", " namespace linear_actuator", " namespace pandora_hardware_interface"], "jrk_com_interface": ["*******************************************************************", " open serial communication port, the device is connected to", " flush both Input and output buffers", " clear errors of linear actuator controller on startup", " Flush both input and output buffers on exit", " flush written but not send data", " flush received, but unread data", "Gets error flags halting and clears any latched errors", " namespace linear_actuator", " namespace pandora_hardware_interface"], "jrk_communicator": ["*******************************************************************", " Send 'target position' over the serial port", " Get feedback", " Get feedback"], "thermal_sensor_controller": ["*******************************************************************", " Get sensor names from interface", " Read publish rate from yaml", " Get sensor handles from interface", " Create publisher for each controller", " resize last times published", " Initialize last time published", " Publish messages", " namespace arm", " namespace pandora_hardware_interface"], "co2_sensor_controller": ["*******************************************************************", " Get sensor names from interface", " Read publish rate from yaml", " Get sensor handles from interface", " Create publisher for each controller", " resize last times published", " Initialize last time published", " Publish messages", " Fill co2 msg", " namespace arm", " namespace pandora_hardware_interface"], "arm_hardware_interface_node": ["*******************************************************************"], "arm_hardware_interface": ["*******************************************************************", " connect and register co2 sensor interface", " connect and register thermal sensor interface", " connect and register range sensor interface", " connect and register battery interface", " connect and register joint state interface", " ROS_INFO(\"Will read CO2\");", " read CO2 percentage from CO2 sensors", " read thermal image from grideye sensors", " ROS_INFO(\"Will read GEYE loop/n\");", " ROS_INFO(\"Will read SONARS\");", " read distances from range sensors", " ROS_INFO(\"Will read BATTERIES\");", " read voltage of batteries", " read encoder degrees", " make radians value between [-pi, pi]", " read joint names from param server", " connect and register the joint state interface", " namespace arm", " namespace pandora_hardware_interface"], "arm_usb_interface": ["*******************************************************************", "  fcntl(fd, F_SETFL, FNDELAY);    //make read() non-blocking", "  fcntl(fd, F_SETFL, 0);  //make read() blocking", " To make read non-blocking use the following:", " fd = open(\"/dev/arm\", O_RDWR | O_NOCTTY | O_NDELAY);", " Needs some time to initialize, even though it opens succesfully.", " tcflush() didn't work without waiting at least 8 ms", " To save time you can see and change terminal settings in command line with stty command,", " before implementing in software. Note: stty prefixes disabled flags with a dash.", " See:  http://man7.org/linux/man-pages/man3/termios.3.html", " set timeout to 100ms", " flush both data received but not read and data written but not transmitted", " ROS_INFO(\"JUST FLUSHED BUFFER\");", " clear the set ", " add our file descriptor to the set ", "------------- READ NACK -------------", " union", " {", "   uint16_t nackBufInUint16;", " };", " ROS_INFO(\"After Write Process\");", " an error accured ", " a timeout occured ", " ROS_INFO(\"Before NACK read\");", " ROS_INFO(\"After NACK read %x\",*(nackBufInUint8));", " else if (nr != NACK_NBYTES)", " {", "  ROS_ERROR(\"[Arm]: Wrong number of bytes read\\n\");", "  reconnectUsb();", "  return INCORRECT_NUM_OF_BYTES;", " }", " end for", " else", " ROS_INFO(\"Received ACK!!!!!!!!!!!!!! : %x\",nack16);", " ------------------------------------------------------", " an error accured ", " a timeout occured ", " ROS_INFO(\"Before BUFFER READ\");", " blocking", " ROS_INFO(\"After BUFFER READ\");", " else if (nr != read_bytes)", " {", "   ROS_ERROR(\"[Arm]: Wrong number of bytes read, nr = %d, read = %d\",nr,read_bytes);", "   reconnectUsb();", "   return INCORRECT_NUM_OF_BYTES;", " }", " readBuf = buff;", " shouldn't get in there", " reconnectUsb() should be called until communication is restored.", " namespace arm", " namespace pandora_hardware_interface"], "arm_usb_interface_demo": ["*******************************************************************", " 0 in temperature indicates communication problem"], "imu_hardware_interface": ["*******************************************************************", " initialize imu interface", " apply offsets to pitch, roll and yaw", " namespace imu", " namespace pandora_hardware_interface"], "imu_hardware_interface_node": ["*******************************************************************", " ~ ros::Duration(0.1).sleep();"], "imu_rpy_controller": ["*******************************************************************", " get all joint states from the hardware interface", " get publishing period", " sensor handle", " Roll, Pitch, Yaw realtime publisher", " Last published times", " initialize time", " limit rate of publishing", " try to publish", " we're actually publishing, so increment time", " populate message", " namespace imu", " namespace pandora_hardware_interface"], "ahrs_com_interface": ["*******************************************************************", " flush input buffer from remainder packets", " write getData command", " read data from serial port", " check data packet", " parse data packet", " write command to ahrs", " invert pitch reading to comply with pandora conventions", " namespace imu", " namespace pandora_hardware_interface"], "trax_ahrs_configuration_node": ["*******************************************************************", " configure device for ahrs mode (not compass mode)", " configure endianess of data in ahrs packet", " configure packet composition of ahrs", " configure ahrs for polling mode", " tell ahrs to save the configurations"], "imu_com_interface": ["*******************************************************************", " get whole packet", " timeout handling", " namespace imu", " namespace pandora_hardware_interface"], "serial_epos2_handler": ["*******************************************************************", "--<Load epos2 interface configs from parameter server>--", "-------------------------------------------------------", " ---<Initiate Communication with epos2 gateway >--- ", " sleep for a second", " ------------------------------------------------- ", " Initialize motor controller states {Enabled}", " Read current state of the Motors", " Calls the state handler to handle the states", " Set every epos2 controller at profileVelocityMode on startup", " Setting operation mode to velocity_mode", " DISABLE STATE", " ENABLE STATE", " QUICKSTOP STATE", " FAULTY STATE", " CANNOT COMMUNICATE", " Cannot communicate with epos2-Gateway", " UKNOWN STATE", " ----< Read velocity values from Epos2Gateway >---- ", " ------------------------------------------------- ", " ----< Read velocity values from Epos2Gateway >---- ", " ------------------------------------------------- ", " Define new array to store current values", " Fill with current values using getCurrent method", " Convert to Torques", " Step I :Convert Torques to currents", " Step II: Send commands to motors", " Activate Velocity Mode", " Activate Current Mode", " namespace motor", " namespace pandora_hardware_interface"], "epos2_test": ["*******************************************************************"], "epos_serial_gateway": ["*************************************************************************", " gateway is not initialized until we actually connect to the RS232 port", " initialize POSIX thread mutex, for use during read/write operations", " failed to connect to serial port", " we are connected, set object as initialized", " read a single character from the RS232 port", " check the number of characters that were actually read", " no characters read, timeout", " one character read, it's a NACK", " Should never happen, violates EPOS Communication Guide", " RS232 error", " 1 character read, equal to 'O' (ACK)", " ACK signal is a single character equal to 'O'", " Rs232 write method should return 0, if all went well", " Allright", " In order to debug the actual communication between the PC and the RS232 port", " you can define the DEBUG_EposRs232Gateway macro. This will enable debugging", " code that prints the communication to the standard output. This generates", " allot of output, and should be used only for debugging purposes. Having the", " printout of the communication is sometimes the only to way to debug since", " underlying synchronization issues exist (i.e. timeouts)", " #define DEBUG_EposRs232Gateway", " check to see if gateway is initialized", " cannot use the gateway if the object is not initialized first", " frame size must be a positive integer no greater than 255. This restriction", " is enforced by hardware, and protocol specifications", " *** input arguments are valid *** //", " *** Calculate CRC *** //", " CRC is calculated on the transmition data + the op code and the data length", " The op code and the data length are stuffed in a single EPOS word", " load the first word of the data input for the CRC method, opcode + length", " EPOS CRC calculation requires data to be Big-Endian (MSB first)", " get CRC", " Load the transmition buffer", " Frame data are sent LSB first", " Communication variables", " We are about to start transmiting data, lock the communication mutex", "  === State 1: Send opCode ===", "  === State 2: Wait for ACK ===", " === State 3: Send len-1 ===", " === State 4: Send data ===", " === State 5: Send CRC ===", " === State 6: Wait for ACK ===", " Command Sent Successfully", "  === State 7: Wait for responce opCode ===", " === State 8: Send ACK ===", " === State 9: Receive len-1 ===", " === State 10: Receive data ===", " === State 11: Receive CRC ===", " === State 12: Send ACK or NACK ===", " Append a zero-word to packet", " Calculate CRC using polyonym: x^16+x^12+x^5+x^0", " Initialize BitX to Bit15", " Copy next Data uint16_t to c", " Check if Bit15 of CRC is set", " CRC = CRC * 2", " CRC = CRC + 1, if BitX is set in c", " CRC = CRC XOR G(x), if carry is true", " Set BitX to next lower Bit, shifter = shifter/2", " namespace motor", " namespace pandora_hardware_interface"], "Utils": ["*******************************************************************", " file io streams", " string streams", " namespace motor", " namespace pandora_hardware_interface"], "serial_epos_handler": ["*************************************************************************", "--<Fix ST for values above 2^31>--", " Minus because of motor reverse direction torsion", "-------------------------------------------------", "-----<Read Right-Rear Motor velocity>-----", " Minus because of motor reverse direction torsion", "------------------------------------------", "-----<Read Left-Front Motor velocity>-----", "------------------------------------------", "-----<Read Left-Rear Motor velocity>------", "------------------------------------------", "", "---------------------------------------------------", "-----<Read Right-Rear Motor current>-----", "------------------------------------------", "-----<Read Left-Front Motor current>-----", "------------------------------------------", "-----<Read Left-Rear Motor current>------", "------------------------------------------", " Right motor rpm speed needs to be reversed because of its placement in the vehicle", " namespace motor", " namespace pandora_hardware_interface"], "abstract_epos_handler": ["*************************************************************************", " namespace motor", " namespace pandora_hardware_interface"], "error_codes_test": ["*******************************************************************", " Input", " Input"], "epos2_gateway": ["*******************************************************************", " TODO(klpanagi): --- Read number of Nodes from a yaml", " Deleting void pointer is undefined;", " delete comHandler_;", " =================<GATEWAY COMMUNICATION Methods>=====================", " #####################################################################", "--<Open Device Communication Port>--", " =======================<STATE MACHINE Methods>=======================", " #####################################################################", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " Will return error to serial_epos2_handler to handle.", " Command executed succesfully", " isEnabled => 1: Device Enabled, 0: Device NOT Enabled", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " ROS_FATAL(\"\\033[0m[Epos2-Gateway]: Received error {%d} on command \"", " \"execution -- isEnableState, nodeId=%d\",", " _errorCode, nodeId);", " Command executed succesfully", " Device is at Enabled State", " Device is NOT at Enabled State", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " Command executed succesfully", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " ROS_FATAL(\"\\033[0m[Epos2-Gateway]: Received error {%d} on command \"", " \"execution -- isDisableState, nodeId=%d\",", " _errorCode, nodeId);", " Command executed succesfully", " Device is at Disabled State", " Device is NOT at Disabled State", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " Command executed succesfully", " Device is at Fault State", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " Command executed succesfully", " Device is at \"QuickStop\" State", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " =======================PROFILE VELOCITY MODE Methods=================", " #####################################################################", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " input value for target velocity should be int32_t type according to", " the EPOS_COMMAND_LIBRARY but it aint -- BUG_REPORT", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " =======================CURRENT MODE Methods==========================", " #####################################################################", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " ======================MOTION INFO Methods============================", " #####################################################################", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " namespace motor", " namespace pandora_hardware_interface"], "motor_hardware_interface": ["*******************************************************************", " connect and register the joint state interface", " connect and register the joint velocity interface", " Add effortJointInterface!", " TODO(zisikons): CHANGE COMMAND_VECTOR", " Set motor control mode to velocity control mode", " Initiallize jointLimits", " TODO(gkouros): initialize softLimits_", " Register handle in joint limits interface", " We read the state and read/write the command", " Limits spec", " Soft limits spec.Not required in our implementation.", " to do or not to do ???", "--<Read motors actual velocity value from EPOS controllers>--", "-------------------------------------------------------------", "--<Read motors actual current value from EPOS controllers>---", "-------------------------------------------------------------", "--<Read motors actual torque value from EPOS controllers>---", "-------------------------------------------------------------", "--<Update local velocity, current, and position values>--", "---------------------------------------------------------", "--<Publish motors currents at the specific topic>--", "---------------------------------------------------", " why period needed ?", " Velocity Control Mode", " Probably add if else struct for controlling torque limits", " !!! IMPORTANT : Make sure that torque commands are given in the correct order", " namespace motor", " namespace pandora_hardware_interface"], "motor_hardware_interface_node": ["*******************************************************************"], "skid_steer_velocity_controller": ["*******************************************************************", " min(max(x, minVal), maxVal)", " Load parameters", " Get joint Handles from hw interface", " Physical properties", " Detect if running on simulation", " Measurements for linear velocity", " Measurements for angular velocity", " Get limits from measurement velocities", " Degree of polynoms", " Increase degree because the coefficients also include the constant of the polynom (a0 * x^0)", " Calculate coefficients", " We need (degree + 1) measurements to calculate the polynom, otherwise we set (y = 1.0 * x^1)", " Subscirbe to cmd_vel", " Update cmd_vel commands", " Compute wheels velocities", " namespace motor", " namespace pandora_hardware_interface"], "skid_steer_torque_controller": ["*******************************************************************", " Load Joints from HW Interface , load joint NAMES from YAML", " Get joint Handles from hw interface", " Subscirbe to cmd_vel", " Update command_struct_ with latest information", " namespace motor", " namespace pandora_hardware_interface"], "leddar_hardware_interface": ["*******************************************************************", " initialize serial communication", " connect and register leddar interface", " get the measurements from the serial interface object", " create leddar sensor handle", " register the handle on the leddar sensor interface", " register the leddar sensor interface", " namespace leddar", " namespace pandora_hardware_interface"], "leddar_hardware_interface_node": ["*******************************************************************"], "Leddar": [" *****************************************************************************", " Module..: SDK -- Software development kit for Leddar products. RS-485", "           demonstration program.", "", "/ \\file    Leddar.c", "/", "/ \\brief   Function definitions for the Leddar layer of the demo.", "/", " Copyright (c) 2013 LeddarTech Inc. All rights reserved.", " Information contained herein is or may be confidential and proprietary to", " LeddarTech inc. Prior to using any part of the software development kit", " accompanying this notice, you must accept and agree to be bound to the", " terms of the LeddarTech Inc. license agreement accompanying this file.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarConnect", "", "/ \\brief   Try to connect to a sensor on the given serial port.", "/", "/ \\param   aPortName  Name of serial port to open (e.g.: COM4 on Windows or", "/                     ttyUSB0 on Linux).", "/ \\param   aAddress   The Modbus address of the sensor to talk to.", "/", "/ \\return  LT_SUCCESS or any one of the LT error codes.", " *****************************************************************************", " Identify which of the Leddar sensor model we are talking", " to, to know features are available.", " Module", " Industrial sensor", " Eval kit", " Unrecognized device!", " *****************************************************************************", " Function: LeddarDisconnect", "", "/ \\brief   Disconnect. Has no effect if was not connected.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarConfigurationLevel", "", "/ \\brief   Property reader for the level of configurability of the", "/          currently connected sensor.", "/", "/ \\return  One of the LEDDAR_*_CONFIGURATION constants.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarGetResults", "", "/ \\brief   Use Leddar custom function 0x41 to retrieve the detections and", "/          other acquisition results.", "/          Note that due to the payload length limitation in Modbus, at", "/          most 48 detections can be returned (this maximum can be configured", "/          to a lower value).", "/", "/ \\param   aDetections  Pointer to array where detections will be written.", "/", "/ \\return  The number of detections retrieved. Will be a negative (error code)", "/          in case of problem.", " *****************************************************************************", " Get the extra info after the detections", " *****************************************************************************", " Function: LeddarGetTemperature", "", "/ \\brief   Return the current sensor internal temperature.", "/", "/ \\param   aValue  Pointer to a variable that on output will contain the", "/                  temperature in degree Celsius if no error.", "/", "/ \\return  LT_SUCCESS or any of the LT error codes.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarGetParameter", "", "/ \\brief   Generic configuration parameter read access function (for integer", "/          parameters).", "/", "/ \\param   aNo     Number of parameter to read (one of the LEDDAR_CONFIG_*", "/                  constants).", "/ \\param   aValue  Pointer to a variable that on output will contain the", "/                  value if LT_SUCCESS is returned.", "/", "/ \\return  LT_SUCCESS or any of the LT error codes.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarSetParameter", "", "/ \\brief   Generic configuration parameter write access function (for integer", "/          parameters).", "/", "/ \\param   aNo     Number of parameter to write (one of the LEDDAR_CONFIG_*", "/                  constants).", "/ \\param   aValue  The new value to set.", "/", "/ \\return  LT_SUCCESS or any of the LT error codes.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarGetThreshold", "", "/ \\brief   Get the current detection threshold offset.", "/", "/ \\param   aValue  Pointer to a variable that will contain the value on", "/                  output if LT_SUCCESS is returned.", "/", "/ \\return  LT_SUCCESS or any of the LT error codes.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarSetThreshold", "", "/ \\brief   Set the current detection threshold offset.", "/", "/ \\param   aValue  New value to set.", "/", "/ \\return  LT_SUCCESS or any of the LT error codes.", " *****************************************************************************", " End of file Leddar.c"], "leddar_serial_interface_demo": ["*******************************************************************"], "OS": [" *****************************************************************************", " Module..: SDK -- Software development kit for Leddar products. RS-485", "           demonstration program.", "", "/ \\file    OS.c", "/", "/ \\brief   Function definitions for the OS dependant part of the demo.", "/", "/ You may have to modify this file if you use a non-standard operating", "/ system. Definitions provided are correct for Windows and Fedora Linux.", "/", " Copyright (c) 2013 LeddarTech Inc. All rights reserved.", " Information contained herein is or may be confidential and proprietary to", " LeddarTech inc. Prior to using any part of the software development kit", " accompanying this notice, you must accept and agree to be bound to the", " terms of the LeddarTech Inc. license agreement accompanying this file.", " *****************************************************************************", " *****************************************************************************", " Function: SetNonBlocking", "", "/ \\brief   Special helper function to implement the equivalent of _kbhit and", "/          _getch in Linux.", "/", "/ \\param   aState  If LT_FALSE, the terminal will be put in the state in", "/                  which it was at the start of the program which is", "/                  normally CANONICAL with ECHO. Otherwise the canonical and", "/                  echo mode will be disabled.", " *****************************************************************************", " LT_LINUX", " *****************************************************************************", " Function: KeyPressed", "", "/ \\brief   Verify if a key was pressed and is waiting in the buffer (used", "/          to check if the user has requested to stop when continuously", "/          displaying detections.", "/", "/ \\return  LT_TRUE or LT_FALSE.", " *****************************************************************************", " *****************************************************************************", " Function: GetKey", "", "/ \\brief   Returns the next character in the keyboard buffer without a need", "/          to press enter (used to navigate the menu).", "/", "/ \\return  The character (may have some special values for non printable", "/          keys).", " *****************************************************************************", " *****************************************************************************", " Function: OpenSerialPort", "", "/ \\brief   Open the serial port with the given name.", "/", "/ \\param   aPortName  Name of the device to open (must be valid for the", "/                     platform).", "/ \\param   aHandle    Pointer to variable that will receive the handle on", "/                     output.", "/", "/ \\return  LT_SUCCESS or LT_ERROR.", " *****************************************************************************", " The inter character timeout should be much shorter but it does not seem", " reliable when we put it lower.", " Must be false otherwise we have to call ClearCommError on every error.", " LT_WINDOWS", " 8 bits per char, ignore modem control lines, enable receiver.", " Enable parity checking on input", " So special output processing", " Raw mode", " None of the 4 modes provided by VMIN and VTIME correspond to", " what we need with Modbus, so we set 0 on both which gives", " immediate return on call to read whatever the availability", " of data.", " LT_LINUX", " *****************************************************************************", " Function: CloseSerialPort", "", "/ \\brief   Close the serial port for the given handle.", "/", "/ \\param   aHandle  Handle returned by OpenSerialPort.", " *****************************************************************************", " *****************************************************************************", " Function: WriteToSerialPort", "", "/ \\brief   Write data to the serial port.", "/", "/ \\param   aHandle  Handle returned by OpenSerialPort.", "/ \\param   aData    Pointer to data to write.", "/ \\param   aLength  Number of bytes from aData to write.", "/", "/ \\return  The number of bytes actually written or LT_ERROR.", " *****************************************************************************", " Discard any bytes that could have arrived unexpectedly.", " *****************************************************************************", " Function: ReadFromSerialPort", "", "/ \\brief   Read data from the serial port.", "/", "/ \\param   aHandle  Handle returned by OpenSerialPort.", "/ \\param   aData    Pointer to where to put the data read.", "/ \\param   aLength  Maximum number of bytes to read (number read may", "/                   actually be lower).", "/", "/ \\return  The number of bytes actually read or LT_ERROR.", " *****************************************************************************", " Wait for the first byte with a long timeout to let time for the sensor", " to process the command.", " In theory we want an inter-character timeout of 2 character but", " in practice setting a value too low is not reliable.", " Now read the data with a short inter-byte timeout.", " We end either when we have received the number of bytes or", " there is a too long interval between 2 bytes (indicating", " the end of the message).", " End of file OS.c"], "leddar_serial_interface": ["*******************************************************************", " namespace leddar", " namespace pandora_hardware_interface"], "leddar_usb_interface_demo": ["*******************************************************************", " create publisher to publish all the readings from the leddar", " create the msg to be published", " TODO(gKouros): reexamine", " TODO(gKouros): reexamine", " TODO(gKouros): reexamine", " If a live connection is active we need to ping it periodically.", " fill the msg with the detections", " publish the msg", " sleep for 0.5 seconds"], "leddar_usb_interface": ["*******************************************************************", " Spawn a worker thread that continuously reads the sensor", " spawn a worker thread that activates for receiving the measurements", " 1->gets called again, 0->gets called only once", " namespace leddar", " namespace pandora_hardware_interface"], "leddar_sensor_controller": ["*******************************************************************", " Get sensor names from interface", " Read publish rate from yaml", " Get sensor handles from interface", " Create publisher for each controller", " TODO set params of msg (angle_min, angle_max, angle_increment, ", " time_increment, scan_time, range_min, range_max) from yaml", "    controllerNodeHandle.getParam(\"time_increment\", temp_param); ", "    &realtimePublishers_[ii]->msg_.time_increment = (float)temp_param;", " resize last times published", " Initialize last time published", " Publish messages", " Fill leddar msg", " namespace leddar", " namespace pandora_hardware_interface"], "joint_states_wrapper": ["*******************************************************************", " namespace dynamixel", " namespace pandora_hardware_interface", " PANDORA_DYNAMIXEL_HARDWARE_INTERFACE_JOINT_STATES_WRAPPER_H"], "gio_gazebo_interface": ["*******************************************************************", " namespace", " Physical properties", " Number of elements", " The rate that each element gets updated", " Resizing vector according to num of elements", " Register each hardware_interface", " Load gazebo joints", " Load PID controllers and initialize/set the limits", " const ros::NodeHandle nh (modelNh_, robotnamespace_ + \"/gazebo_ros_control/pid_gains/\" + jointName_[i]);", " pidController_[i].init (nh);", " Load gazebo imu link", " CO2 sensors subscriber", " Range sensors subscriber", " Wheel joints", " Side joints", " Laser roll joint", " Laser pitch joint", " Kinect pitch joint", " Kinect yaw joint", " Linear actuaator joint", " Camera effector pan joint", " Camera effector tilt joint", " Connect and register the joint state interface", " Connect and register the joint interfaces", " Imu sensor", " Connect and register the imu sensor interface", " Imu RPY", " Connect and register the imu rpy interface", " CO2 sensors", " Connect and register the co2 sensor interface", " Electronics battery sensor", " Motors battery sensor", " Connect and register the battery interface", " Range sensors", " Connect and register the range sensor interface", " Read joint position", " Read joint velocity", " Read robot orientation for IMU", " Read robot rpy for IMU", " Read co2 sensors", " Read battery sensors", " immobilizeRobot (batteryName_[n], batteryVoltage_[n]);", " Read range sensors", " namespace pandora_gazebo_interface"], "pandora_wheel_physics_plugin": ["*******************************************************************", " Implementations ", " Load Parameters", " Load SDF Parameters", " Initiallize NodeHandle for Dynamic Reconfigure Namespace", " Set Up dynamic Reconfgure Server", " ############################ LOAD NAMESPACE (from sdf) ############################", " Load Namespace from sdf", " ######################### LEFT FRONT WHEEL #########################", " Load Link", " Load Surface Parameters", " ######################### LEFT REAR WHEEL #########################", " Load Link", " Load Surface Parameters", " ######################### RIGHT FRONT WHEEL #########################", " Load Link", " Load Surface Parameters", " ######################### RIGHT REAR WHEEL #########################", " Load Link", " Load Surface Parameters", " mu1", " mu2", " slip1", " slip2", " kp", " kd", " minDepth", " maxVel", " bounce", " bounceThreshold", " namespace gazebo"], "pandora_fdir_plugin": ["*******************************************************************", " Load Parameters", " Connect with world update Event", " Load SDF Parameters", " ############### LOAD NAMESPACE (from sdf) ############### ", " Load Namespace from sdf", " ############### LEFT REAR WHEEL ############### ", " ############### LEFT FRONT WHEEL ############### ", " ############### RIGHT REAR WHEEL ############### ", " ############### RIGHT FRONT WHEEL ###############", "_info", " Read Yaw", " Change fdir vector to ALL wheels:", " namespace gazebo"], "pandora_differential_plugin": ["*******************************************************************", " Register this plugin with the simulator", " Constructor", " Destructor", " Differential Dynamic Reconfigure", " Finalize the controller", " Save pointers", " ROS callback queue for processing subscription", " Initialize the variables used in the PID algorithm", " Make sure the ROS node for Gazebo has already been initialized", " Publish multi queue", " /\\brief Start a thread for the differential dynamic reconfigure node", " FIXME: Wait for the rest of the plugin to load", " Advertise services on the custom queue", " New Mechanism for Updating every World Cycle", " Listen to the update event. This event is broadcast every", " simulation iteration.", " TODO(gerom): Get the value directly from the joints.", " TODO(gerom): Test when callback is executed.", " Returns true always", " Initialize the forces to be set", " Calculate and normalize the positive angle difference", " Calculate the forces for each link", " TODO(gerom): Test if the force are applied with the correct sign.", " Set the forces to the wheel links", " TODO(gerom): Implement maximum side joint damping", "       and normalize side joint damping.", " Get the linear velocity of each link in the z axis in ( mm / sec )", " Initialize the downforces to be set", " Calculate the downforce for each link", " Set the downforces to the wheel links", " TODO(gerom): Implement integral clamping.", " Calculate the time between two engine iterations", " Calculate the proportional contribution to output", " Calculate the integral contribution to output", " Calculate the derivative error & update the previous error", " Calculate the derivative contribution to output", " Calculate the output", " Calculate the error of the loop ( target - state )", " double error = ( left_angle_abs - right_angle_abs );", " Normalize the error", " Initialize the force to be applied", " Calculate the force", " Apply the correction force at the base link", " Separate the sign and the value of the angles.", " Calculate the error", " Maximum hardcoded force to be applied", " Apply the correction forces at the side joints accordingly", " left_front_wheel_link_->AddRelativeForce(math::Vector3(0, 0, force_multiplier * (left_front_z - min_z)));", " left_rear_wheel_link_->AddRelativeForce(math::Vector3(0, 0, force_multiplier * (left_rear_z - min_z)));", " right_front_wheel_link_->AddRelativeForce(math::Vector3(0, 0, force_multiplier * (right_front_z - min_z)));", " right_rear_wheel_link_->AddRelativeForce(math::Vector3(0, 0, force_multiplier * (right_rear_z - min_z)));", " ROS_INFO(\"LEFT:%f\", left_front_wheel_link_->GetRelativeForce().z);", " ROS_ERROR(\"RIGHT:%f\", right_front_wheel_link_->GetRelativeForce().z);", " Get the angles in the current iteration of the engine", " Add PID controlled force at base link (marginally stable)", " GazeboRosDifferential::AddBaseCorrectionForce ( );", " Add hardcoded forces (semi-control, working - error not well defined)", " Add forces at z axis to overcome high side joint damping (virtual forces)", " GazeboRosDifferential::AddDownforces ( );", " Add forces at y / z axes (real forces, applied due to the differential)", " GazeboRosDifferential::AddDifferentialForces ( );", " Add forces to improve robot's behaviour (due to poorly simulated physics)", " GazeboRosDifferential::AddPhysicsForces ( );", " Publish joint states to be used in RViz", " namespace gazebo"], "pandora_microphone_plugin": ["*******************************************************************", " Load the controller", " load plugin", " Get then name of the parent sensor", " Get the world name.", " Make sure the ROS node for Gazebo has already been initialized", " resolve tf prefix", " set size of cloud message, starts at 0!! FIXME: not necessary", " this->cloud_msg_.points.clear();", " this->cloud_msg_.channels.clear();", " this->cloud_msg_.channels.push_back(sensor_msgs::ChannelFloat32());", " Custom Callback Queue", " sensor generation off by default", " start custom queue for laser", " Increment count", "//////////////////////////////////////////////////////////////////////////////", " Decrement count", " soundMsg_.header.stamp = ros::Time::now ( );", " soundMsg_.header.frame_id = this->frame_name_;", " sound is represented by blue", " soundMsg_.certainty = certainty;", " Sound detection condition", " namespace gazebo"], "pandora_co2_plugin": ["*******************************************************************", " Load the controller", " load plugin", " Get then name of the parent sensor", " Get the world name.", "  Probability of not intented namespace", " Make sure the ROS node for Gazebo has already been initialized", " resolve tf prefix", " set size of cloud message, starts at 0!! FIXME: not necessary", " this->cloud_msg_.points.clear();", " this->cloud_msg_.channels.clear();", " this->cloud_msg_.channels.push_back(sensor_msgs::ChannelFloat32());", " Custom Callback Queue", " sensor generation off by default", " start custom queue for laser", " Increment count", " Decrement count", " co2 is represented by green", " namespace gazebo"], "pandora_sonar_plugin": ["*******************************************************************", " Register this plugin with the simulator", " Constructor", " Destructor", " Finalize the controller / Custom Callback Queue", " Load the controller", " load plugin", " Get then name of the parent sensor", " Get the world name.", " Make sure the ROS node for Gazebo has already been initialized", " resolve tf prefix", " set size of cloud message, starts at 0!! FIXME: not necessary", " Custom Callback Queue", " sensor generation off by default", " start custom queue for laser", " Increment count", " Decrement count", " Update the controller", " Put laser data to the interface", " four corners indices", " four corner values + interpolated range", " set size of cloud message everytime!", " int r_size = rangeCount * verticalRangeCount;", " point scan from laser", " Add Frame Name", " interpolating in vertical direction", " fraction from min", " Interpolate the range readings from the rays in horizontal direction", " fraction from min", " indices of 4 corners", " range readings of 4 corners", " Range is linear interpolation if values are close,", " and min if they are very different", " Intensity is averaged", " get angles of ray to get xyz for point", " point scan from laser", " no noise if at max range", " pAngle is rotated by yAngle:", " pAngle is rotated by yAngle:", " only 1 channel", " Utility for adding noise", " using Box-Muller transform to generate two independent standard normally disbributed normal variables", " normalized uniform random variable", " normalized uniform random variable", " double Y = sqrt(-2.0 *::log(U)) * sin( 2.0*M_PI * V); // the other indep. normal variable", " we'll just use X", " scale to our mu and sigma", " custom callback queue thread", " namespace gazebo"], "pandora_thermal_plugin": ["*******************************************************************", " Load the controller", " load plugin", " Get then name of the parent sensor", " Get the world name.", " Make sure the ROS node for Gazebo has already been initialized", " resolve tf prefix", " set size of cloud message, starts at 0!! FIXME: not necessary", " this->cloud_msg_.points.clear();", " this->cloud_msg_.channels.clear();", " this->cloud_msg_.channels.push_back(sensor_msgs::ChannelFloat32());", " Custom Callback Queue", " sensor generation off by default", " start custom queue for laser", " Increment count", " Decrement count", " temperature is represented by red", " namespace gazebo"], "pandora_p3d_plugin": ["www.apache.org/licenses/LICENSE-2.0", "//////////////////////////////////////////////////////////////////////////////", " Constructor", "//////////////////////////////////////////////////////////////////////////////", " Destructor", " Finalize the controller", "//////////////////////////////////////////////////////////////////////////////", " Load the controller", " Get the world name.", " load parameters", " Make sure the ROS node for Gazebo has already been initialized", " publish multi queue", " resolve tf prefix", " initialize body", " if frameName specified is \"world\", \"/map\" or \"map\" report", " back inertial values in the gazebo world", " init reference frame state", " start custom queue for p3d", " New Mechanism for Updating every World Cycle", " Listen to the update event. This event is broadcast every", " simulation iteration.", "//////////////////////////////////////////////////////////////////////////////", " Update the controller", " rate control", " differentiate to get accelerations", " copy data into pose message", " get inertial Rates", " Get Pose/Orientation", " Apply Reference Frame", " convert to relative pose", " convert to relative rates", " Apply Constant Offsets", " apply xyz offsets and get position and rotation components", " apply rpy offsets", " compute accelerations (not used)", " Fill out messages", " pass euler angular rates", " fill in covariance matrix", "/ @todo: let user set separate linear and angular covariance values.", " publish to ros", " save last time stamp", "////////////////////////////////////////////////////////////////////////////", " Utility for adding noise", " using Box-Muller transform to generate two independent standard", " normally disbributed normal variables see wikipedia", " normalized uniform random variable", " normalized uniform random variable", " double Y = sqrt(-2.0 * ::log(U)) * sin(2.0*M_PI * V);", " there are 2 indep. vars, we'll just use X", " scale to our mu and sigma", "//////////////////////////////////////////////////////////////////////////////", " Put laser data to the interface", " namespace gazebo"], "pandora_imu_stabilizer_plugin": ["www.apache.org/licenses/LICENSE-2.0", " Register this plugin with the simulator", "//////////////////////////////////////////////////////////////////////////////", " Constructor", "//////////////////////////////////////////////////////////////////////////////", " Destructor", " Finalize the controller", "//////////////////////////////////////////////////////////////////////////////", " Load the controller", " save pointers", " ros callback queue for processing subscription", "//////////////////////////////////////////////////////////////////////////////", " Load the controller", " load parameters", " Make sure the ROS node for Gazebo has already been initialized", " publish multi queue", " assert that the body by link_name_ exists", " if topic name specified as empty, do not publish", " advertise services on the custom queue", " Initialize the controller", " this->initial_pose_ = this->link->GetPose();", " start custom queue for imu", " New Mechanism for Updating every World Cycle", " Listen to the update event. This event is broadcast every", " simulation iteration.", "//////////////////////////////////////////////////////////////////////////////", " returns true always, imu is always calibrated in sim", "//////////////////////////////////////////////////////////////////////////////", " Update the controller", " Get Pose/Orientation ///@todo: verify correctness", " apply xyz offsets and get position and rotation components", " apply rpy offsets", " get Rates", " differentiate to get accelerations", " copy data into pose message", " orientation quaternion", " uncomment this if we are reporting orientation in the local frame", " not the case for our imu definition", " // apply fixed orientation offsets of initial pose", " rot = this->initial_pose_.rot*rot;", " rot.Normalize();", " pass euler angular rates", " rotate into local frame", " @todo: deal with offsets!", " pass accelerations", " rotate into local frame", " @todo: deal with offsets!", " fill in covariance matrix", "/ @todo: let user set separate linear and angular covariance values.", "/ @todo: apply appropriate rotations from frame_pose", " publish to ros", " save last time stamp", " publish to ros", "////////////////////////////////////////////////////////////////////////////", " Utility for adding noise", " using Box-Muller transform to generate two independent standard", " normally disbributed normal variables see wikipedia", " normalized uniform random variable", " normalized uniform random variable", " double Y = sqrt(-2.0 * ::log(U)) * sin(2.0*M_PI * V);", " there are 2 indep. vars, we'll just use X", " scale to our mu and sigma", "//////////////////////////////////////////////////////////////////////////////", " Put laser data to the interface", " namespace gazebo"], "state_server": ["", "Create watchdog", "Subcriber and Publisher declaration", "! Wait 10 seconds for all nodes to start.", " Disable watchdog.", " The client sent a wrong request code and the server responds with an", " error code.", "First retrieve all nodes", "Disable watchdog"], "state_client": ["*******************************************************************", " ROS_INFO(\"[%s] Received new information from state server\", node_name_.c_str());", " namespace state_manager"], "state_client_nodelet": ["*******************************************************************", " ROS_INFO(\"[%s] Received new information from state server\", node_name_.c_str());", " namespace state_manager"], "state_changer": ["*******************************************************************", " namespace state_manager"], "dummy_handler": ["*******************************************************************", " ................", " namespace sensor_processor"], "dummy_preprocessor": ["*******************************************************************", " namespace sensor_processor"], "dummy_processor_node": ["*******************************************************************"], "dummy_postprocessor": ["*******************************************************************", " namespace sensor_processor"], "bag_player_for_tests": ["", "", "~ ros::Rate loop_rate(10);", "~ while(ros::ok() && !_playedBags){", "~ ros::spinOnce();", "~ loop_rate.sleep();", "~ }", ""], "customized_player": ["*******************************************************************", " PlayerOptions", " Player", " Open all the bag files", " Publish all messages in the bags", " Advertise all of our messages", " Set up our time_translator and publishers", " Call do-publish for each message", " If immediate specified, play immediately", " If skip_empty is specified, skip this region and shift.", "Keep pushing ourself out in 10-sec increments (avoids fancy math dealing with the end of time)", " don't actually need anything but the default, alternatively try this", "DWORD event_mode = ENABLE_WINDOW_INPUT | ENABLE_MOUSE_INPUT;", "if (! SetConsoleMode(input_handle, event_mode) )", "{", " std::cout << \"Failed to set the console mode.\" << std::endl;", " return;", "}", " set raw (unset canonical modes)", " i.e. min 1 char for blocking, 0 chars for non-blocking", " block if waiting for char", " namespace rosbag"], "map_loader": ["*******************************************************************", "", " The document loading process changed in yaml-cpp 0.5.", " dirname can modify what you pass it", " namespace map_loader"], "watchdog": [""], "watchdog_monitor": ["", "! WDT already exists", "! WDT does not exist"], "mutex_guard": [""], "standalone_mutex": [""], "remote_mutex": [""], "kinect_movement_filter": ["*******************************************************************", " namespace pandora_common"], "exploration_controller": ["*******************************************************************", " register preempt callback", " load max goal searches", " proporsional to number of frontiers?", " robot has that many seconds to reach a goal", " TODO(czalidis): it could be proportional to path's length", " start exploration server", " Check if given exploration_type is known to the explorer, if it's not abort", " Check if we hold a goal selector of the appropriate exploration_type, if", " we do not, then create one and insert it into the goal_selector_map_", " wait for move_base to set-up", " reset aborts from previous time, this shouldn't really happen", " while we didn't receive a preempt request", " if we can't find more frontiers and we have reached our goal we end the exploration", " Check for timeouts", " if the exploration_type is DEEP(coverage_exploration) and coverage_goal_selector_", " is not NULL, then we do coverage based exploration. To create the coverage", " goal_selector we have to set the param use_coverage to true.", " to current goal gemizetai me to stoxo pou tha vrei o goal selector", " If success is false that means we cant find more frontiers", " if succes is false, dld an den exei vrei stoxo, auksanoume ta goal searches", " wait a little", " we have a valid goal", " reset failures", " prepare a MoveBaseGoal", " send new goal to move_base", " cancel goals before?", " set selected goal to all goal selectors", " end of outer while", " goal should never be active at this point", " check if we are close to target", " TODO(czalidis): check for race condition", " Auto ousiastika klanei to navi gt den perimenei na tou pei an eftase, alla", " to apofasizei mono tou, omws den douleuei swsta gt otan ftanei to navi,", " o explorer perimenei na faei timeout gia na vgalei epomeno stoxo.", " something is wrong here", " goal_expired_count_ ++;", " if (goal_expired_count_ >= 5)", " goal_expired_count_ = 0;", " namespace pandora_explorer"], "exploration_controller_node": ["*******************************************************************"], "navfn_frontier_path_generator": ["*******************************************************************", " get planner's name", " check if planner plugin exists", " create planner, exception is throwed if plugin is not available", " calculate path for each frontier", " Here we will store the plan to", " check to what point we want to plan", " start pose, goal pose, plan filled by the planner", " TODO(dimkirt) isws edw kati den paei kala, an xrhsimopoiithei autos o generator", " to make plan epistrefei true an vrhke ena valid plan alliws false.", " store the calculated plan to frontier.path variable", " namespace pandora_explorer"], "navfn_service_frontier_path_generator": ["*******************************************************************", " service name will be loaded here from parameter server", " find service", " track start", " calculate path for each frontier", " check to what point we want to plan", " send a valid pose", " call service", " if max time alloted return", " namespace pandora_explorer"], "map_frontier_search": [" make sure map is consistent and locked for duration of search", " Sanity check that robot is inside costmap bounds before searching", " initialize flag arrays to keep track of visited and frontier cells", " initialize breadth first search", " find closest clear cell to start search", " iterate over 4-connected neighbourhood", " add to queue all free, unvisited cells, use descending search in case initialized on", " non-free cell", " check if cell is new frontier cell (unvisited, NO_INFORMATION, free neighbour)", " initialize frontier structure", " htan 1", " record initial contact point for frontier", " push initial gridcell onto queue", " cache reference position in world coords", " try adding cells in 8-connected neighborhood to frontier", " check if neighbour is a potential frontier cell", " mark cell as frontier", " update frontier size", " update frontier points", " update centroid of frontier", " determine frontier's distance from robot, going by closest gridcell to robot", " add to queue for breadth first search", " find midpoint of frontier", " output.size -> segfault", " average out frontier centroid", " keep track of creation time", "~     output.header.frame_id = \"map\";", " check that cell is unknown and not already marked as frontier", " frontier_flag[idx] = true means that this frontier has already marked as a valid frontier", " frontier cells should have at least one cell in 4-connected neighbourhood that is free", " namespace pandora_explorer"], "frontier_goal_selector": ["*******************************************************************", " setup exploration costmap", " setup marker publisher", " load path distance scale and straight scale", " load frontier size scale", " load frontier alignment scale", " load frontier alignment scale", " valid types: initial, middle, centroid", " visualize paths to all frontiers", " planner timeout duration;", " set-up map frontier search", " set-up navfn path generator", "frontier_path_generator_.reset( new NavfnFrontierPathGenerator(frontier_representation_,", "explore_costmap_ros_) );", " set-up cost functions, using the scales previously loaded", " set-up frontier list", " clear previous frontiers", " get robot pose", " iterate over all frontier searches and find new frontiers", " insert new frontiers to global list", " if no frontiers found return false", " sort frontier list so closer frontier are first", " sorting in respect with min_distance", " find paths to all frontiers", " run all cost functions", " visualize new frontiers", " find the best frontier", " correct final target orientation", " keep track of selected frontier", " set as goal the last point in plan", " search over all frontier to find max cost", " did not found a frontier with positive cost", " path at least of 10 points, otherwise unstable orientations calculated", " find orientation of last 2 points", " assign orientation to last point in path", " no point to run, if no one is listening", " find also best frontier", " visualize frontier as sphere", "marker.color.g = 0.0;", "marker.color.b = 0.0;", " visualize frontier cost as marker text", " visualize frontier size", " visualize path size", " visualize paths to all frontiers as line strip", "paths_marker.color.r = 0.0;", "paths_marker.color.b = 0.0;", " visualize frontier as a line", " update best frontier", " add best frontier as blue sphere", "marker.color.r = 0.0;", "marker.color.g = 0.0;", " \"a\" is by default \"0\" if you forget it marker will be invisble", " publish markers", " namespace pandora_explorer"], "distance_cost_function": ["*******************************************************************", " for the usage of M_E", " iterate over all frontiers and find max distance", " iterate over all frontiers", " if frontier has a already negative cost no point to run this cost function", " find path distance based on path", " frontier.path", " if no path found penalize frontier", " size of path shows \"straightness\" and lenght of the path, this has to be reviewed", " update frontier's cost", " namespace pandora_explorer"], "visited_cost_function": ["*******************************************************************", " iterate over all frontiers", " if frontier has a already negative cost no point to run this cost function", " how many times we have send a similar goal", " iterate over all previous goals", " find distance between selected_goal and frontier", " using initial point, maybe get from param later", "    std::cout << (1.0 - pow((1.0/freq), 1.0/5.0)) << std::endl;", "    std::cout << exp(-static_cast<double>(times_seen)) << std::endl;", " update cost", "    frontier.cost += scale_ * (1.0 - pow((1.0/freq), 1.0/5.0));", " namespace pandora_explorer"], "alignment_cost_function": ["*******************************************************************", " iterate over all frontiers", " if frontier has already negative cost no point to run this cost function", " select a point in path to find angle to", " if no valid plan to frontier, cost should already be negative", " and this function will never run", " this is done to calculate the true alignment to goal of the robot footprint", " find angle from robot to goal", " find shortest angle, result from -pi to pi", " update frontier's cost", " namespace pandora_explorer"], "size_cost_function": ["*******************************************************************", " for M_E usage", " iterate over all frontiers and find max distance", " iterate over all frontiers", " if frontier has a already negative cost no point to run this cost function", " update frontier's cost", " Cost are normalized, frontier with the highest size scores 1.", " namespace pandora_explorer"], "map_frontier_search_test": ["*******************************************************************", " Needed for ros::Time:now()", " create a new costmap2D 10x10", " Now pass the costmap created to mapFronterSearch ", " HELPER FUNCTIONS ", "", "", "", " MAP CREATORS ", "", " fill the first half of the map with zeros", "fill the second half with ones", "", " fill the first half of the map with zeros", "fill the second half with ones", "", " fill costmap with zeros", "", " fill costmap with 255", "", " fill costmap with 255", " put middle known point on costmap", "", " fill costmap with zeros", " put middle unknown point on costmap", " Accessors", " Given the coordinates returns the index", " Variables", "", " NORMAL CASE", "vector with 1 zero element", " NO_INFO SPACE CASE", " KNOWN CELL CASE", "**** CASES WERE ALL FRONTIERS ARE MARKED  *******", " NO_INFO SPACE CASE", " KNOWN CELL CASE", "", " Map creation", " origin of robot", " To build the frontier initial must be a cell with a neighbour in nhood8, who is frontier cell.", " mark reference", " mark initial cell", " fill col 5 with zeros", " robot pose", " To size genika vgainei oso einai +1, akomh ki an den xtistei frontier dinei size 1.", " initial frontier point", " centroid frontier point", " We can test the precision by looking the frontier", " tolerance of one cell", "EXPECT_NEAR();", "EXPECT_NEAR();", "EXPECT_EQ();", "EXPECT_EQ();", "", " Map creation", " To build the frontier initial must be a cell with a neighbour in nhood8, who is frontier cell.", "fillCostmapRow(4,0);", " robot pose", " To size genika vgainei oso einai +1, akomh ki an den xtistei frontier dinei size 1.", "", " Map creation", " To build the frontier initial must be a cell with a neighbour in nhood8, who is frontier cell.", "fillCostmapRow(4,0);", " robot pose", " To size genika vgainei oso einai +1, akomh ki an den xtistei frontier dinei size 1."], "costmap_tools_test": ["*******************************************************************", " create a new costmap2D 10x10", " create costmap2D, sizeX,sizeY,res,originX,originY", " Variables", " All possible cases of nhood4 and nhood8", " 4,4 is a centric point", " nhood returns a vector, so we check its size", " Create a list of edge points to check the nhoods", " Create a list of all corner points to check the nhoods", " Nearest Cell Function Tests ", " create a new costmap2D 10x10", " create costmap2D, sizeX,sizeY,res,originX,originY", " fill the first half of the map with zeros", "fill the second half with ones", " Prints the costmap ", " Prints the coordinates of the expected result and the real result ", " Variables", "  TODO more tests, for bfs accuracy.", " Case where the value we want is at the starting cell ", " result will hold the nearest cell with the value we want", " bfs is used to decide the nearest cell.", " Searches for value=1 starting from cell 95", " Checks if nearestCell bfs is working ", " Case where the cell is out off the map ", " Check if bfs works properly ", " mark the starting cell for visualization reasons", " namespace pandora_explorer"], "surface_checker": ["*******************************************************************", " Declare helper variables.", " For every direction in sensor's field of view, ray trace on 3d map.", " If it hits successfully find its corresponding coverage (metric) and", " save ray to surface coverage.", " coveredSurfacePtr_->updateInnerOccupancy();", " if surface coverage is to be taken as a binary quantity.", " else it is assumed that coverage is a percentage of the best view", " one can get at the wall.", " find for constant z = point.z, the normal vector on the line which", " results from intersection of the surface-wall (approx. a plane) with the", " plane z = point.z", " find the intersection of the plane [1] (\u03bbx, \u03bby, z) ~\u03bb,z with the plane which", " results from the far-most points on wall and on the plane [1]. This is going", " to be wall's normal vector.", " namespace pandora_sensor_coverage", " namespace pandora_exploration"], "sensor_coverage": ["*******************************************************************", "  initialize NodeHandle and Map.", "  Subscribe to 3d slam topic.", "  Subscribe to 2d slam topic.", " Server of flushing service", "  Set up occupancy grid 2d map occupancy threshold.", "  Set up maximum height of interest.", "  Set up footprint's width.", "  Set up footprint's height.", "  Set up orientation circle.", "  Set up maps' global static frame.", "  Set up robot's base frame name.", "  Get map's origin (can be either SLAM or TEST).", "  Get frames that will be tracked to produce their coverage patch maps.", "  For each frame make a Sensor object.", " namespace pandora_sensor_coverage", " namespace pandora_exploration"], "main": ["*******************************************************************"], "sensor": ["*******************************************************************", " nav_msgs::OccupancyGridPtr", " Sensor::", " getCoverage() const", " {", "   return spaceChecker_->getSpaceCoverage();", " }", " If sensor is not open and working, do not update coverage patch.", " DANGER ZONE dereferencing boost shr_ptr to share ptr", " If it does, fetch current transformation.", "  Update coverage perception.", "  Publish updated coverage perception.", " namespace pandora_sensor_coverage", " namespace pandora_exploration"], "utils": ["*******************************************************************", "", " namespace pandora_sensor_processing"], "coverage_checker": ["*******************************************************************", " namespace pandora_sensor_coverage", " namespace pandora_exploration"], "sensor_planner": ["*******************************************************************", "  initialize NodeHandle and Map.", "  Subscribe to Octomap topic.", "  Subscribe to Occupancy Grid topic."], "interactive_command_publisher_marker": [" create an interactive marker server on the topic namespace", " interactive_tf_publisher_marker", " get params from param server", " create an interactive marker for our server", " create a red sphere marker", " create a non-interactive control which contains the box", " add the control to the interactive marker", " create publishers", " create a control which will move the marker around x", " add the control to the interactive marker", " create a control which will move the marker around y", " add the control to the interactive marker", " create a control which will move the marker around z", " add the control to the interactive marker", " create a control which will rotate the marker around x", " add the control to the interactive marker", " create a control which will rotate the marker around y", " add the control to the interactive marker", " create a control which will rotate the marker around z", " add the control to the interactive marker", " add the interactive marker to our collection &", " tell the server to call processFeedback() when feedback arrives for it", " 'commit' changes and send to all clients", " namespace pandora_visualization"], "interactive_tf_publisher_marker": [" create an interactive marker server on the topic namespace", " interactive_tf_publisher_marker", " get params from param server", " initialize transform_", " create an interactive marker for our server", " create a red sphere marker", " create a non-interactive control which contains the box", " add the control to the interactive marker", " create a control which will move the marker around x", " create a control which will move the marker around y", " create a control which will move the marker around z", " create a control which will rotate the marker around x", " create a control which will rotate the marker around y", " create a control which will rotate the marker around z", " add the control to the interactive marker", " add the interactive marker to our collection &", " tell the server to call processFeedback() when feedback arrives for it", " 'commit' changes and send to all clients", " namespace pandora_visualization"], "temprature_visualization": ["FIXME: Receive from param                             ", "Grid-eye sensor limits", "TODO: Take temprature limits from dynamic reconfigure"], "data_fusion_object_visualization": ["!< Timers for visualization", "~ ros::Duration(15).sleep();"], "pandora_qr_csv_node": ["*******************************************************************"], "qr_csv_creator": ["*******************************************************************", "", "", "", " A blank line is needed.", " Body descripion.", " Sort QRs.", " Append QRs to the csv file.", " Sort Obstacles.", " Append Obstacles to the csv file.", " namespace pandora_qr_csv"], "server": ["*******************************************************************", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", " Save geotiff to the home directory.", " Reset the environment.", " namespace pandora_geotiff"], "creator": ["*******************************************************************", " Create a QApplication cause otherwise drawing text will crash.", " These parameters should be moved in a yaml file in a later version.", " These parameters are given theris real values in a different state.", " This function must only be called after geotiffMapIm is initialized!", " Draw (checkerboard) grid.", " Drawing the main length unit side.", " Drawing the length unit up side (1/12 of the checker size).", " Drawing the length unit down side (1/12 of the checker size).", " Draw the length unit point 1m.", " Drawing the lines.", " Drawing the Y arrow.", " Drawing The X arrow.", " Drawing Y.", " Drawing X.", " i,j MUST BE xsize and J must be y size if you want to swap y with x u must change a lot of things", " namespace pandora_geotiff"], "pandora_geotiff_node": ["*******************************************************************"], "utilities": ["*******************************************************************", " Create random poses with times in descending order.", " namespace pandora_geotiff"], "geotiff_creator_test": ["*******************************************************************", " Save to the home directory.", " namespace pandora_geotiff"], "ros_tf_listener": ["*******************************************************************", " namespace pandora_data_fusion_utils", " namespace pandora_data_fusion"], "utils_test": ["*******************************************************************", " namespace pandora_sensor_processing"], "pandora_alert_handler_node": ["*******************************************************************", " ros::MultiThreadedSpinner spinner(2); // Use 2 threads", " spinner.spin(); // spin"], "object_factory": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "alert_handler": ["*******************************************************************", "", " Alert-concerned Subscribers", " Map Subscriber", " Publishers", " Action Servers", " Service Servers", " Dynamic Reconfigure Server", " Timers", "  Other Callbacks  ", "/////////////////////////////////////////////////////", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "landoltc": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "motion": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "obstacle": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "visual_victim": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "qr": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "sound": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "co2": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "soft_obstacle": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "hard_obstacle": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "hole": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "hazmat": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim": ["*******************************************************************", "", "", "", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "barrel": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "data_matrix": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "filter_model": ["*******************************************************************", "", "!< System Model Initialization", "!< Filter's combined matrix", "!< Filter's system matrix A", "!< Filter's system matrix B", "!< Filter's system noise mean", "!< Filter's system noise covariance", "!< Measurement Model Initialization", "!< Filter's measurement matrix H", "!< Filter's measurement noise mean", "!< Filter's measurement noise covariance", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_clusterer": ["*******************************************************************", "", "", " if (currentObj->getType() != Sound::getObjectType() &&", "     currentObj->getType() != Co2::getObjectType())", "", "", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "object_handler": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_list": ["*******************************************************************", "", "", "", "", "", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "obstacle_list": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "object_list_test": ["*******************************************************************", " Constructor/Destructor ", " SetUp/TearDown definitions ", " Helper functions ", " Function to fill qrList.qrs_ ", "!< Spawns Qrs In a fixed radius Around the qrX", "!< Returns distance between 2 qrs.", " Accessors for private methods/members of QrList ", " Variables ", " It shouldn't find that Qr4 already exists.", " Qr4 won't correlate with Qr1 because dist equals DIST_THRES!", " It should find that qr5  exists in 2 places.", " It should find that qr6 exists only  in 1 place( same as qr 3).", " Changed distance must find Qr 6 in  3 places( qr1 qr2 qr3).", " Or it doesn't find it.", " Zero Distance Threshold makes impossible same Qr recognition.", " Maximum (Infinite) Distance Threshold makes impossible Qr distinction.", " Add (0.4,0.1,0)", " Add (0.5, 0, 0) Qr 3 will not be Added Same as Qr 9", " Add (0.125, 0.125, 0) Qr 8 will not be Added Same as Qr 9", " Add (0.6, 0.2, 0.1) Qr 10 will not be Added Same as Qr 9", " Add (0.6, 0.2, 0.1) Qr 10 will not be Added Same as Qr 9", " Add (0.125, 0.125, 0) Qr 9 will not be Added Same as Qr 9", " Add (0.125, 0.125, 0) Qr 8 will not be Added Same as Qr 9", " Add (0.125, 0.125, 0) Qr 9 will not be Added Same as Qr 9", " Qr  1(-0,5,0,0) Qr 4 (-1 ,0,0) Qr11 (-0.75 ,0, 0)", " This will spawn Qrs in the middle so both Qrs should became legit", " They should have moved closer to each other", " They should become Legit!", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "object_factory_test": ["*******************************************************************", " Constructor SetUp ", "!< Loading the Map and initializing Objectfactory with a", "!< very small orientation circle(The other Params are the same)", "!< Creating all the Different Alerts we will use", " Helper Functions ", "!< Creating 3 HoleAlerts two on Walls and one very High", " Creating 3 QrAlerts two on Walls and one very High", " Creating 3 HazmatAlerts two on Walls and one very High", " Creating 2 ThermalAlerts one on Wall and one very High", " variables ", " The tf that is used is created in mock object tfFinder", " With origin (5,5,0.3) and (roll.info.pitch.info.yaw)=(0,0,0)", " Test Cases ", "!<  A vector is returned although thermal will always be alone :(", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_clusterer_test": ["*******************************************************************", " Helper functions ", "!< We create manually Thermal1(0, 3.87, 4),", "!< Thermal2(1, 0, 2), Hole1(-1, 0, 2)", "!< We create manually Thermal1(2, 3, 4),", "!< Hole1(4, 3, 2), Hole2(0, 4, 2) with yaw=PI/4", "!< We create manually Thermal1(0, 3.87, 4), Thermal2(1, 0, 2), Hole1(-1, 0, 2)", " Accesing private functions ", " Accesing private variables ", " variables ", "!< Checks if construstors behave correctly.", " Thermal1(0, 3.87, 4), Thermal2(1, 0, 2), Hole1(-1, 0, 2)", " Thermal1(2, 3, 4), Hole1(4, 3, 2), Hole2(0, 4, 2)", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_test": ["*******************************************************************", "!< create the Objectvector1 and fill it with various objects", "!< Thermal1(2, 3, 4) Thermal2(4, 3, 2) Hole1(1, 2, 0)", "!< (yaw = 0) ApproachDist = 5", "!< create the Objectvector2 and fill it with various objects", "!< Thermal1(2, 3, 4) Hole1(4, 3, 2) Hole2(0, 4, 2)", "!< (yaw = PI/4) ApproachDist = 6", "!< create the Objectvector3 and fill it with various objects", "!< Thermal1(2, 3, 4) Hole1(4, 3, 2) Hole2(0, 4, 2)", "!< (yaw = PI/4) ApproachDist = 6", " Helper functions ", "!< Returns distance between 2 objects.", "!< We create manually Thermal1(2, 3, 4),", "!< Thermal2(4, 3, 2), Hole1(1, 2, 0)", "!< We create manually Thermal1(2, 3, 4),", "!< Hole1(4, 3, 2), Hole2(0, 4, 2) with yaw=PI/4", "!< We create manually thermal1(2, 3, 4) thermal2(4, 3, 2) thermal3(0, 4, 2)", "!< Yaw = PI/4", "!< We create manually thermal1(2, 3, 4) thermal2(4, 3, 2) thermal3(0, 4, 2)", "!< Yaw = PI/4", " Accessors to private functions ", " Accessors to private variables ", " Variables ", " There will be 2 objects left in victim1_. One Hole and one Thermal type.", " Hole objects are prefered over Thermal objects regarding representatives.", " victim1_'s Thermal object should be the thermalPtr1! thermalPtr1 had more confidence", " in its belief about position that thermalPtr2, so it was prefered during", " setObject()", " thermalPtr1 object should be updated so that its position is", " closer to thermalPtr2's", " There will be 2 objects left in victim1_. One Hole and one Thermal type.", " Hole objects are prefered over Thermal objects regarding representatives.", " victim1_'s Thermal object should be the thermalPtr1! thermalPtr1 had more confidence", " in its belief about position that thermalPtr2, so it was prefered during", " setObject()", " thermalPtr1 object should be updated so that its position is", " closer to thermalPtr2's", " Thermal1(2, 3, 4) Thermal2(4, 3, 2) Hole1(1, 2, 0)", " thermal1 is erased.", " hole1 is erased", " Thermal1(2, 3, 4) Hole1(4, 3, 2) Hole2(0, 4, 2)", " Erase hole1. Now thermal1 is the representative object.", " Erase the last object (thermal1).", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "objects_test": ["*******************************************************************", " Seting up all the different objects that will be used", " for our test cases. The distance between the points", " (0,0,0), (4,3,0) is 5.", "!< Check that initializeObjectFilter works as intended!", " Helper functions ", " Variables ", " TEST_F(ObjectsTest, updateWithZeroProbability)", " {", "   qr2_->setProbability(0);", "   qr2_->initializeObjectFilter();", "   float probabilityBefore = qr1_->getProbability();", "   float stdDevBefore = qr1_->getStdDevX();", "   geometry_msgs::Pose poseBefore = qr1_->getPose();", "   qr1_->update(qr2_);", "   EXPECT_FALSE(qr1_->getLegit());", "   EXPECT_LT(qr1_->getProbability(), probabilityBefore);", "   EXPECT_GT(qr1_->getStdDevX(), stdDevBefore);", "   EXPECT_LT(distance(qr1_->getPose(), poseBefore), 0.6);", " }", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_list_test": ["*******************************************************************", " Helper functions ", "!< We fill the iteratorList_ specifically around victim2_.", "!< Thermal1(-1, 0, 0), Thermal2(1, 0, 0), Hole1(0 , 1, 0)", "!< Thermal1(2, 3, 0), Hole1(3, 3, 0), Hole2(2, 2.5, 0)", "!< Thermal1(2.7, 3, 0), Thermal2(3, 3, 0)", "!< Thermal1(3, 3, 0), Hole1(10, 3, 0)", " Accesors to private functions ", " Variables ", " Victim1 Thermal(1, 0, 0) Hole(0, 1, 0)", " Victim2 Thermal(2, 3, 0) Hole(3, 3, 0)", " Victim3 Thermal(3, 3, 0)", " Victim4 Thermal(3, 3, 0) Hole(10, 3, 0)", " victim 3 is the same as victim 2 (samePosition)", " VictimList2 has all 4 victims inside", " Victim3 will be removed", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "clusterer": ["*******************************************************************", "", " get current measurement time", "", "!< Implementation of 2-means clustering", "!< Choosing cluster according to datum euclidean distance from means.", " dist1 = Utils::getMahalanobisDistance(dataSet_.col(jj), mean1_, covariance1_);", " dist2 = Utils::getMahalanobisDistance(dataSet_.col(jj), mean2_, covariance2_);", "!< Tracking data in cluster which correspond to current measurement.", "!< Resizing cluster1_ by on column and appending qualified datum.", "!< Tracking data in cluster which correspond to current measurement.", "!< Resizing cluster2_ by on column and appending qualified datum.", "!< Calculate clusters' means and covariances and check for convergence.", "!< If converged then return success and find for each cluster", "!< current measurement's means. If there is no data in a cluster from", "!< current measurement, then this procedure is skipped.", "", "", "!< Choosing cluster according to datum euclidean distance from means.", "!< Resizing cluster1_ by on column and appending qualified datum.", "!< Resizing cluster2_ by on column and appending qualified datum.", " namespace pandora_sensor_processing"], "co2_processor": ["*******************************************************************", " spikeFound_ = false;", " spikeTime_ = 0;", "", " Measurement has no information because it has the same value with the ambience.", " namespace pandora_sensor_processing"], "co2_node": ["*******************************************************************"], "thermal_processor": ["*******************************************************************", "", "", " OK. Warmer cluster has a cell from current measurement.", " Considering cluster to be a valid alert!", " namespace pandora_sensor_processing"], "thermal_processor_test": ["*******************************************************************", " helper functions ", "", " accessors to private functions ", " accessors to private variables ", " variables ", " Unit Tests ", " Functional Tests ", " This is cool because raw measurement is to be qualified to an alert.", " This in not cool because image is not the same size as the other images", " of frame \"pur\"", " This is not cool because this image does not contain info that can make", " an alert.", " Failing or not qualifying images do not interfere with the processor.", " This image shall qualify to an alert.", " namespace pandora_sensor_processing"], "clusterer_test": ["*******************************************************************", "", " Helper Functions ", "", "", "", "", "", "", " Accessors to private variables ", " Accessors to private methods ", " Variables ", " Test Cases ", " namespace pandora_sensor_processing"], "pose_finder": ["*******************************************************************", " Absolute depth and depth difference are evaluated at", " pandora_vision_obstacle", " geometry_msgs::Point lowPoint = findAlertPosition(pointsYaw[3],", "     pointsPitch[3], tfTransform);", " geometry_msgs::Point rightPoint = findAlertPosition(pointsYaw[1],", "     pointsPitch[1], tfTransform);", " namespace pose_finder", " namespace pandora_data_fusion"], "pose_finder_test": ["*******************************************************************", "", " Accessors for private methods of PoseFinder ", " Methods ", "", "", " Variables ", " Expect default parameters", " Expect updated parameters", " Make a tfTransform [tf::Transform], check for various yaw [float]", " and pitches [float] for the expected geometry_msgs::Pose", " With given map [OccupancyGrid], make points [geometry_msgs::Point] and test", " their supposed positions on wall with various angles [float]", " Given the height [float] of the robot coord. frame origin, check for", " various distances from wall (distFromAlert) [float] and pitches [float]", " the corresponding alert height on wall", " EXPECT_THROW( calcHeight(1.04720, h, -1) , AlertException );", " EXPECT_THROW( calcHeight(0.52360, h, -1) , AlertException );", " EXPECT_THROW( calcHeight(-0.52360, h, -1) , AlertException );", " EXPECT_THROW( calcHeight(-0.26180, h, -1) , AlertException );", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Near corner (inside)", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Near corner (outside)", " Given various vectors of points [std::vector<geometry_msgs::Point>] test if the", " largest distance between them id given by the two points", " [std::pair<geometry_msgs::Point, geometry_msgs::Point>] returned.", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "keypoint_transformer": ["*******************************************************************", " #1 Calculate yaw and pitch from origin camera frame towards the point we", " want to transform", " #2 Calculate position of the point we want to transform in the world", " #3 Calculate yaw and pitch from target camera frame towards the point we", " want to transform", " change this later", " #4 Calculate point on target camera frame on which we see the same object", " in the world", " namespace frame_matcher", " namespace pandora_data_fusion"], "view_pose_finder": ["*******************************************************************", " namespace frame_matcher", " namespace pandora_data_fusion"], "roi_transformer": ["*******************************************************************", " namespace frame_matcher", " namespace pandora_data_fusion"], "frame_matcher_node": ["*******************************************************************"], "frame_matcher": ["*******************************************************************", " loadPreProcessor<EnhancedImagePreProcessor>(\"~\");", " loadPostProcessor(\"~postprocessor\", postprocessor_type_);", " namespace frame_matcher", " namespace pandora_data_fusion"], "matcher_processor": ["*******************************************************************", "", "", " Set output correctly from input", " Give Roi rgb sensor image and points", " ROS_INFO(\"[%s] Map callback called\", this->getName().c_str());", " ROS_INFO(\"[%s] Target image callback called\", this->getName().c_str());", " namespace frame_matcher", " namespace pandora_data_fusion"], "enhanced_image_postprocessor": ["*******************************************************************", "", "", " namespace frame_matcher", " namespace pandora_data_fusion"], "candidate_hole_postprocessor": ["*******************************************************************", "", " namespace frame_matcher", " namespace pandora_data_fusion"], "enhanced_image_preprocessor": ["*******************************************************************", "", "", " namespace frame_matcher", " namespace pandora_data_fusion"]}, "code_comments_python": {"setup": ["!/usr/bin/env python"], "test_flow": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "test_move_end_effector_server": ["!/usr/bin/env python"], "test_effector_clients": ["!/usr/bin/env python", " Following three must be in accordance to client_dict", " Following three must be in accordance to client_dict", " Following three must be in accordance to client_dict"], "test_client_factory": ["!/usr/bin/env python"], "command_mapping_dict": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "client_factory": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "effector_clients": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "move_end_effector_server": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "move_eef_script": ["! /usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "topics": [" Action to delete a victim from the data fusion's registry.", " Action to validate a victim.", " Action to notify data fusion about the current target.", " Publishing QR notificatios from the data fusion's registry.", " Holds the score for the robocup competition.", " Keeps track of the covered area.", " Used by data fusion to publish the world model.", " Action to wait for validation from the operator.", " Used to reset the robot.", " Used to restart the robot.", " Close the agent's process", " Action to communicate with the navigation node.", " Subscriber on the navigation node.", " Possible arena types:", "   - Yellow         -> 0", "   - Orange         -> 1", "   - YellowAndBlack -> 2", "   - Red            -> 3", " Moves the robot.", " Action to change the global state.", " Monitors the number of clients registered in the State Manager.", " Stops the current task.", " Moves end effector to a point of interest."], "client_dict": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "client_list": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "end_effector_controller_node": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "states": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Voulgarakis George", " class HeadOrientationState(SimpleActionState):", "     def __init__(self):", "         SimpleActionState.__init__(self, move_head_topic,", "                                    MoveSensorAction,", "                                    goal_cb=self.goal_cb,", "                                    outcomes=['succeeded',", "                                              'aborted',", "                                              'preempted'],", "                                    input_keys=['move_end_effector_msg'],", "                                    output_keys=['move_end_effector_msg'])", "     def goal_cb(self, userdata, goal):", "         goal = MoveSensorGoal()", "         goal.command = userdata.move_end_effector_msg.command", "         goal.point_of_interest = \\", "             userdata.move_end_effector_msg.point_of_interest", "         return goal", " class LinearActuatorState(SimpleActionState):", "     def __init__(self):", "         SimpleActionState.__init__(self, linear_actuator_topic,", "                                    MoveLinearActuatorAction,", "                                    goal_cb=self.goal_cb,", "                                    outcomes=['succeeded',", "                                              'aborted',", "                                              'preempted'],", "                                    input_keys=['move_end_effector_msg'],", "                                    output_keys=['move_end_effector_msg'])", " def goal_cb(self, userdata, goal):", "     goal = MoveLinearActuatorGoal()", "     goal.command = userdata.move_end_effector_msg.command", "     goal.point_of_interest = \\", "         userdata.move_end_effector_msg.point_of_interest", "     goal.center_point = userdata.move_end_effector_msg.center_point", "     return goal"], "mock_end_effector_planner": [" !/usr/bin/env python", " !/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "goal_maker": ["!/usr/bin/env python"], "action_servers": ["! /usr/bin/env python", " Messages", " Make a move.", " Send feedback"], "test_pandora_stabilizer_node": ["!/usr/bin/env python"], "move_kinect_script": ["! /usr/bin/env python"], "move_head_script": ["! /usr/bin/env python"], "move_linear_actuator_script": ["! /usr/bin/env python"], "motors_joyop": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2015, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas", " Open the js0 device as if it were a file in read mode.", " Create an empty list to store read characters.", " Loop forever.", " For each character read from the /dev/input/js0 pipe...", " append the integer representation of the unicode character read to the msg list.", " If the length of the msg list is 8...", " Button event if 6th byte is 1", " Axis event if 6th byte is 2", " Axis 3", " Reset msg as an empty list.", "~ while not rospy.is_shutdown():"], "keyop": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2015, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: George Kouros", " kinect - xtion pan n' tilt mode key", " linear actuator mode key", " motors mode key", " pi-cam pan n' tilt mode key", " motors linear velocity", " motors angular velocity", " linear actuator vertical position", " xtion yaw", " xtion pitch", " picam yaw", " picam pitch", " initialize mode to motors mode", " motors velocity msg", " linear actuator msg", " xtion yaw msg", " xtion pitch msg", " picam yaw msg", " picam pitch msg", " ctr-c or q"], "joyop": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2015, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: George Kouros", " launch joystick node", " erase previous prints"], "dataset_utils": ["# -- Set and hold RlData directory path -- ##", "# ---------------------------------------- ##", "# ------------------- Usefull Path Definitions -------------------------- ##", "# ---------------------------------------------------------------------- ##", "#", "  Create symbolic link to repository", "", " Symlinc || directory allready exists", "#", "  Copies from local data dir to repo dir", "#"], "motion_reward": [" Cost_to_Reward function Parameters", " If total_cost > cost_threshold , then reward shall be negatives", " Clear Trajectories from trajectory node.", " # Reset Case:", " if clear:", "     self.trajectory_cost_node.clear_trajectories()", " Checks trajectory", " Goal Related"], "experiment": [" Keep latest agent's action until update", " State Change steps", " If SLAM failed , reduce loacal step so next callback is also final", " get informed about vehicle's current state", " get informed about last action's reward", " inform agent about last action's reward", " inform agent about vehicle's current state", " ask agent to decide what the current action will be", " ask agent to update its estimations about expected returns", " perform cmd command in the environment , using agent's last action", " Save Action Value Table"], "kinodynamic_control": ["!/usr/bin/env python", " Navigation Task", " Number of States : (read from params)", " Total number of states:", " Number of actions", " Action Value Table directory", " Action Value Table setup", " Declare ROS Service to store Action Value Table", " Set up task parameters:", " Agent set up", " Experiment set up", " Start print table thread", "thread.start_new_thread(self.print_table,())", " Terminate visualization thread", " Copy learned data to repo", " Spawn ROS node , create controller and spin!", " try:", "     # Spawn ROS node , create controller and spin!", "     rospy.init_node('kinodynamic_controller')", "     controller = KinodynamicController()", "     rospy.spin()", " except:", "     # Case when RL modules fails for some reason , reset velocity controller", "     # to nomral control mode (all parameters set to 1)", "     pub = rospy.Publisher(COMMAND_TOPIC, KinematicParameters, queue_size=1)", "", "     # Fill reset msg", "     params = KinematicParameters()", "     params.scale_left = 1", "     params.scale_right = 1", "     params.terrain_param = 1", "", "     pub.publish(params)", "     print \"RL module failed.Switching to controller-only mode\"", " try:", "     # Spawn ROS node , create controller and spin!", "     rospy.init_node('kinodynamic_controller')", "     controller = KinodynamicController()", "     rospy.spin()", " except:", "     # Case when RL modules fails for some reason , reset velocity controller", "     # to nomral control mode (all parameters set to 1)", "     pub = rospy.Publisher(COMMAND_TOPIC, KinematicParameters, queue_size=1)", "", "     # Fill reset msg", "     params = KinematicParameters()", "     params.scale_left = 1", "     params.scale_right = 1", "     params.terrain_param = 1", "", "     pub.publish(params)", "     print \"RL module failed.Switching to controller-only mode\""], "params": [" Reinforcement Learning Related:", " 1) States:", " i) Number of States", " ii) Limits of each state [format = (low,high)]", " input in rads", " input in rads", " in m/s", " in rad/s", " 2) Actions:", " i) Number of Actions", " ii) Action ranges", " 3) Agent", " default value = 0.29", " 4) Cost Function :", " 5) General:", " cmd_vel callbacks ,until agent learn", " 6) Store Results:"], "navigation_environment": [" Find x y yaw from Tranformation", " Initiallization of time for limiting actual_trajectory from SLAM", " Read trajecotry from SLAM /robot_trajecotry", " The list must be reversed , otherwise it will immedatelly break", "Stop if point time stamp < than last_time_stamp", "Tranformation from geometry_msgs.quaternion to numpy array", " transform quaternion to euler angles , using tf library", "for every point belonging in last trajectory , save needed information", " Case actual_path is empty (which means SLAM hasn't updated /robot_trajecotry yet)", " Form a new empty parameter message", " Scale left/right not used in this version", " Fill terrain parameter", " Terrain parameter (= agent's action)"], "navigation_task": [" Navigation Command related", " Parameters", " Discretization Parameters", " (list containing number of states to produce in each element of sensros list)", " Flags", " State Processing:", " 1) Read Info from environment", " Find current pose, return pitch, roll denormalized states", " 2) Trajectory Related:", " Get actual trajectory as resulted from last command", " Read Data:", " Set latest action's expected trajectory in motion reward object", " Construct current expected trajectory from current pose, velocity", " command and trajectory duration in time", " 3)Retruns:", " returns True so that callback can continue process", " Make a state vector of (roll,pitch, linear, angular)", " Discretization can be applied only to normalized values", " Map sub-states to a total state:", " Make a final action vector of (velocity command, params)", " Delegate interaction with environment to NavigationEnvironment", " Task Related", " Reward Related", " Adjust sensor limits:"], "utils": [" Input Data", " Case 1: Linear Movement (angular velocity  = 0)", " Distance to travel", " Step size", " Pick Points", " Calculate (x,y)", " Insert points list in an numpy matrix for tranformations", " Case 2: Linear + Angular Movement (works also on Linear = 0)", " Movement metrics", " Point Counter", " Pick Points:", " Calculate (x,y) based on polar coordinates", " Add new point to lists", " Insert points list in an numpy matrix for tranformations", " 1) Transform first point to (0,0)", " 2) If angular velocity is negative , then , reverse over x axis", " --------------------- Transformations ---------------------", " Rotate points around (0,0)", " 4) Transform to robot_origin", " 5) Output Form", " Ensure ,input pair is vectors of same dimension", " Rotation Matrix", " Multiply points with rotation matrix", " Transformation from [-1,1] to [0,2]", " Split a number into the integer and decimal", " Construct Coefficients vector:", " Possible actions must be at least 2", " Low Limit", " High Limit"], "goal_cost": [" Relative Reward mode:", " Absolute Rewards:   (BEWARE : requires retuning of cost_to_reward function)", "self._cost = find_distance(self.expected_pose, self.actual_pose)"], "fuse_cost_node": [" In current Implementation , cost is calculated only from child nodes", " self._inside_update_cost()", " self.process_cost()"], "mock_local_patcher": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Constructor", " Publisher to the HardLayer", " Copy data from slam map", " Fill origin orientation", " (roll, pitch, yaw), in rads", " initialize the map with NO_INFORMATION cells", " Set the patch", " Set the timestamp"], "static_patch": [" 10 Hz", " se rads", " (roll, pitch, yaw)", " Msg creation", " TODO Assure that slam doesnt clear the patch", "", " map_update_msg.info.origin.orientation.x = quat[0]", " map_update_msg.info.origin.orientation.y = quat[1]", " map_update_msg.info.origin.orientation.z = quat[2]", " map_update_msg.info.origin.orientation.w = quat[3]", "for i in range(0,map_update_msg.info.width * map_update_msg.info.height/2):", "  temp_array[i] = 0;", " Initialize the node "], "move_base": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "mock_data_fusion": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " 1Hz", " Do message stuff", " 0.9013425", " 0.5", " publish message", " obs = ObstacleInfo()", " obs.id = 2", " obs.obstaclePose.header.frame_id = \"map\"", " obs.timeFound = rospy.get_rostime()", " obs.obstaclePose.pose.position.x = 9", " obs.obstaclePose.pose.position.y = 9", " obs.obstaclePose.pose.position.z = 0", " obs.obstaclePose.pose.orientation.x = 0", " obs.obstaclePose.pose.orientation.y = 0", " obs.obstaclePose.pose.orientation.z = 0", " obs.obstaclePose.pose.orientation.w = 1", " obs.length = 1", " obs.width = 1", " obs.type = 2", " publish message"], "hard_obstacle_patcher": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "\tnotice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "\tcopyright notice, this list of conditions and the following", "\tdisclaimer in the documentation and/or other materials provided", "\twith the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "\tcontributors may be used to endorse or promote products derived", "\tfrom this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Publisher of the hard obstacle map", " Subscriber to the SLAM map", " initialize the map with NO_INFORMATION cells", " The initial patch center", " The new center is the position we get from the obstacle_msg", " Position is in meters, th in radians, we rotate clockwise so the", " angle th is negative", " PLUS the position of the slam map", " print str(dx)+\" \"+str(dy)", " Transformation (Rotation and Translation)", " Set the timestamp and publish the hard_map"], "tururu": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "\tnotice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "\tcopyright notice, this list of conditions and the following", "\tdisclaimer in the documentation and/or other materials provided", "\twith the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "\tcontributors may be used to endorse or promote products derived", "\tfrom this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Publisher of the hard obstacle map", " Subscriber to the SLAM map", " initialize the map with NO_INFORMATION cells", " The initial patch center", " The new center is the position we get from the obstacle_msg", " Position is in meters, th in radians, we rotate clockwise so the", " angle th is negative", " PLUS the position of the slam map", " print str(dx)+\" \"+str(dy)", " Transformation (Rotation and Translation)", " Set the timestamp and publish the hard_map"], "mock_params": [" The topic where the mock data_fusion posts the obstacles"], "obstacle_test": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Case where obstacle is not initialized", "obs = Obstacle()", " Case where obstacle is initialized", "obs_normal = Obstacle()", " Message Creation", " Obstacle creation"], "map_utils_test": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " [m]", " [m]", " [m]", " [m/cell]", " [cells]", " [cells]", " An array of 20 cells with values of 100", " Call the function", " [m]", " [m]", " [m]", " [m/cell]", " [cells]", " [cells]", " inits everything with zeros (0,0,0,0)", " inits everything with zeros (0,0,0,0)", " Normal Cases", " Case 1", " The old map is equal to the new because we don't have NO_INFOs", " Case 2", " The old map didn't change because we only have NO_INFOs", " Case 3", " The old map change only at the cells without NO_INFO", " Extreme Cases", " Empty list case", " Both lists empty case", " Lists with same meta data but different array size", " Lists are ok but width and height are different", " Width and height are the same but they are zero", " Maps not initialized", " Normal Cases", " Case 1", " The old map will always be equal to the new map", " Case 2", " The old map should change even though we have only NO_INFOs", " Case 3", " The old map change at every cell", " Extreme Cases", " Empty list case", " Both lists empty case", " Lists with same meta data but different array size", " Lists are ok but width and height are different", " Width and height are the same but they are zero", " Maps not initialized", " Used to test invalid quaternions", " Case where both maps are empty", " False because we have initialized quaternions", " Case where everything is not initialized except the quaternion", " Case where we have not valid quaternions in both maps", " Case where we have valid but different quaternions", " Case where we have different widths", " [cells]", " [cells]", " Case where we have different heights", " [cells]", " [cells]", " [cells]", " [cells]", " Case where we have different resolutions", " [cells]", " [cells]", " [cell/m]", " [cells]", " [cells]", " [cell/m]", " Case where we have different frame_id", " [cells]", " [cells]", " [cell/m]", " [cells]", " [cells]", " [cell/m]", " Case where all MapMetaData are the same", " [cells]", " [cells]", " [cell/m]", " [cells]", " [cells]", " [cell/m]", " We print the map in row major order", " Both maps are empty", " Only new map is empty", " Only old map is empty", " One of the two maps has zero resolution", " Normal case with no origin difference, just resizing"], "__init__": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "obstacle": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " We store only the data we use from the message", " This is the frame id of the pose that defines the obstacle patch", " Not the frame of the obstacle itself.", " It must be /map", " in radians", " in meters", " in meters", " if type equals 1 we have soft obstacle, if equals 2 we have hard obstacle", " Create the quaternion to pass it"], "map_utils": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " # # # Map Patcher Utilities  # # # # #", " initialize the map with NO_INFORMATION cells", " Save the old map", " Set the MetaData of the old map to the new map", " clear old map", " resize the old map", " Find x,y,yaw differences", " print str(x_diff) + \",\" + str(y_diff)", " Find old and new yaw to find yaw_diff", " This would never happen because we get the orientation from SLAM", " old_quat = [", "     oldMap.info.origin.orientation.x, oldMap.info.origin.orientation.y,", "     oldMap.info.origin.orientation.z, oldMap.info.origin.orientation.w", " ]", "", " (old_roll, old_pitch, old_yaw) = euler_from_quaternion(old_quat)", "", " new_quat = [", "     newMap.info.origin.orientation.x, newMap.info.origin.orientation.y,", "     newMap.info.origin.orientation.z, newMap.info.origin.orientation.w", " ]", " (new_roll, new_pitch, new_yaw) = euler_from_quaternion(new_quat)", "", " yaw_diff = new_yaw - old_yaw", "print \"Yaw diff: \" + str(yaw_diff)", " print \"xdiff:\" + str(x_diff) + \",\" + \"ydiff:\" + str(y_diff)", " print \"width old:\" + str(oldMap.info.width) + \",\" + \"height old:\" + str(", "     oldMap.info.height)", "", " print \"width new:\" + str(newMap.info.width) + \",\" + \"height new:\" + str(", "     newMap.info.height)", " Transform the old map to the new size", " for i in xrange(0, oldMap.info.width):", "     for j in xrange(0, oldMap.info.height):", "         # old x,y in meters", "         x = i * oldMap.info.resolution", "         y = j * oldMap.info.resolution", "", "         # new x,y in meters", "         xn = math.cos(yaw_diff) * x - math.sin(yaw_diff) * y - x_diff", "         yn = math.sin(yaw_diff) * x + math.cos(yaw_diff) * y - y_diff", "         #print \"x_diff: [\" + str(x_diff) + \"]\"", "         #print \"y_diff: [\" + str(y_diff) + \"]\"", "         # new x,y in cells", "         xn_cell = int(round((xn / res), 0))", "         yn_cell = int(round((yn / res), 0))", "", "         coords = xn_cell + yn_cell * i - 1", "         if (coords < 0) or (coords > new_size):", "             rospy.logerr(\"[Map Resizer] Error in resizing xn_cell: [%d] \\", "             yn_cell: [%d] coords: [%d] new_size[%d]\", xn_cell, yn_cell,", "                          coords, new_size)", "         else:", "             temp = temp_old_map[i + j * oldMap.info.width]", "             #print \"coords: \" + str(coords)", "             oldMap.data[coords] = temp", "             # Dilation ??", "", "             # Copy the MapMetaData of the new map", " Copy the header (problems with the stamp?)", " Check frame_id of incoming OGM", " Check resolution of incoming OGM", " Check width of incoming OGM", " Check height of incoming OGM", " Check if quaternion contains NaNs or Infs", " Check if quaternion contains only zeros (not valid)", " Check the origin of the OGM", " noqa", " Maybe check something about the time?", " If everything is OK we return True", " noqa", " noqa", " noqa", " noqa"], "map_patch_params": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " The topic of the map we take from SLAM", " The topic that sends the obstacle messages", " The topic where we post the new map with obstacle on it", " Unknown cost param"], "map_patch": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " An occupancy grid to hold the hard obstacles", " Subscriber to SLAM to get the map info", " Subscriber to the obstacles posted by data_fusion", " Publisher to the HardLayer", " Init soft_obstacle map, using slam MapMetaDeta and set every cell to NO_INFO", " If obstacle list is empty then we just fill the map layer with no", " information and then we post it.", " If we have obstacles in the list we transform each object and publish the map", " If list is empty", " Set the timestamp", " Publish the map with NO_INFORMATION", " If obstacle list is not empty", " Set the patch, in meters to the bottom left corner, yaw in radians", " 1.57 rad = 90 deg, 0.785 rad = 45 deg", " Check if the obstacle is in the right map frame", " The initial patch center", " The new center is the position we get from the obstacle_msg", " Position is in meters, th in radians, we rotate clockwise so the", " angle th is negative", " PLUS the position of the slam map", " print str(dx)+\" \"+str(dy)", " Transformation (Rotation and Translation)", " Set the timestamp and publish the map_patch", " Check type of obstacle and quaternion", " noqa", " noqa", " TODO (dimkirts) Check if length and width are very big", " Create an obstacle from the message of the callback", " Search inside the list if we have an obstacle with the same id", " If we do, we delete it and then append the new version of this obstacle", " If we can't find a duplicate obstacle we append it"], "co2_widget": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Load UI and name the widget.", " Create the subcribers.", " Create and connect the timer.", " Connected slot to the timer in order to refresh."], "widget_info": ["!/usr/bin/env python", " Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "message_data_model": [" Software License Agreement (BSD License)", "", " Copyright (c) 2012, Willow Garage, Inc.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of Willow Garage, Inc. nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", " the column names must match the message attributes", " BEGIN Required implementations of QAbstractTableModel functions", "%d' % msg.id", " map severity enum to label", " implode topic names", " append row number to define strict order", " append row number to define strict order", " shortest string representation to compare stamps", " print(column, data, str(index.row()).zfill(len(str(len(self._messages)))))", " decorate message column with severity icon", " colorize severity label", " <font> tag enables word wrap by forcing rich text", "')", " END Required implementations of QAbstractTableModel functions", " never try to insert more message than the limit", " reduce model before insert", " insert newest messages"], "battery_widget": [" Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Load Ui and name the widget", " create the subcribers", " create and connect the timer", " Connected slot to the timer in order to refresh", " Method called when the Widget is terminated"], "pandora_gui": [" Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "console": [" Software License Agreement (BSD License)", "", " Copyright (c) 2012, Willow Garage, Inc.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of Willow Garage, Inc. nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", " Queue to store incoming data which get flushed periodically", " to the model.", " Required since QSortProxyModel can not handle a high insert rate."], "save_mission_client": ["!/usr/bin/env python"], "probability_info": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Create the subcribers.", " Create and connect the timer.", " Connected slot to the timer in order to refresh."], "rpc_client": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "console_widget": [" Software License Agreement (BSD License)", "", " Copyright (c) 2012, Willow Garage, Inc.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of Willow Garage, Inc. nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", " These are lists of Tuples = (,)", " self.exclude_group_box.close()", " self.highlight_group_box.close()", " Filter factory dictionary:", " index 0 is a label describing the widget, index 1 is the class that provides filtering logic", " index 2 is the widget that sets the data in the filter class,", " index 3 are the arguments for the widget class constructor", " list of TextBrowserDialogs to close when cleaning up", " This defaults the filters panel to start by taking 50% of the available space", " flattens the _highlight filters list and only adds the item if it doesn't already exist", " pack the new filter tuple onto the filter list", " place the widget in the proper location", " flattens the _exclude filters list and only adds the item if it doesn't already exist", " pack the new filter tuple onto the filter list", " place the widget in the proper location", " Test if the filter we are adding already exists if it does use the existing filter", " Test if the filter we are adding already exists if it does use the existing filter", " menutext entries turned into", " This processes the dynamic list entries (severity, node and topic)", " extract column header", " join wrapped lines", " ignore empty lines", " check for quotes and remove them", " ignore line without prefix if previous line was not wrapped", " remove wrapped line which is not continued on the next line", " add/append lines", " add line without quote prefix", " generate message for each row"], "sonars_widget": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Load UI and name the widget.", " Create the subcribers.", " Create and connect the timer.", " Connected slot to the timer in order to refresh."], "temp_widget": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Load Ui and name the widget.", " Create the subcribers.", " Create and connect the timer.", " Connected slot to the timer in order to refresh."], "standar_widget": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Load the UI", " Add Console in the 2,1 position of InternalGrid", " Use full ABSOLUTE path to the image, not relative", " ValidateVictimActionServer is used called when a victim is found", " Dynamic_reconfigure client is used to change the parameters", " self.dynamic_reconfigure_client =", " dynamic_reconfigure.client.Client(\"agent\")", " The SaveMissionClient is used to save the mission geotiff", " RPC client", " Subscribe the score the world_model_info and Info", " Connecting the radioButtons", " Connecting the Buttons", " Connecting the CheckBoxes", " In the beggining all the checkboxes are unchecked.", " The left panel is visible", " Resize at first", " Show the console options at first", " Refresh timer", " Refreshing the topics", " Enable the victim found Options if it is found", " Start the timer", " Bring up the agent.", " Stop the timer and The robot", " Shutdown the agent.", " The checkboxes slots.", " Method called when the Widget is terminated."], "main_widget": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Widgetlists created for dynamic show", " Create and set the Layouts.", " Timers to refresh 1 sec.", " Add the extra widget if checked or remove if unckecked", " Add if not already added.", " Remove if not already removed."], "gui_state_client": [" Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "victim_found_server": ["!/usr/bin/env python", " Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Victim action found callback", " store  Info", " helper variables"], "rqt_gui": ["!/usr/bin/env python", " Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "listener": ["!/usr/bin/env python", " in ROS, nodes are unique named. If two nodes with the same", " node are launched, the previous one is kicked off. The", " anonymous=True flag means that rospy will choose a unique", " name for our 'listener' node so that multiple listeners can", " run simultaenously.", " spin() simply keeps python from exiting until this node is stopped"], "victim_action_client": ["! /usr/bin/env python", " Creates the SimpleActionClient, passing the type of the action", " Waits until the action server has started up and started", " listening for goals.", " Create a random goal to send to the action server.", " Sends the goal to the action server.", " Waits for the server to finish performing the action.", " Prints out the result of executing the action"], "talker": ["!/usr/bin/env python"], "victim_propabilities": ["!/usr/bin/env python"], "pandora_rqt_gui": ["!/usr/bin/env python"], "accuracy_test": ["!/usr/bin/env python", " Read the next image."], "victim_benchmark_test": ["!/usr/bin/env python", " Wait for the alert to arrive.", " Set the processor block to notify the program that the processor", " answered", " Notify the program that an alert has been received.", " Initialize the node"], "random_dataset_creator": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Check that the file exists.", " Check that the file extension is appropriate.", " Read the annotations file.", " Ensure that the file was read successfully.", " Read file and save contents in a dictionary.", " Check that the path exists.", " Check that the file extension is appropriate.", " Open the annotations file.", " Save new annotations in file.", " Save new annotations in file.", " Create random sub-sets for positive and negative images.", " Create the new annotations dictionary.", " Set the auto completion scheme"], "check_annotations_file": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "transform_annotations_to_full_frame": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "benchmark_tests_automation": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Set the auto completion scheme", " Sleep for a while until the process is fully finished."], "rename_dataset": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "training_automation": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Set the auto completion scheme", " Sleep for a while until the process is fully finished."], "qrcode_benchmark_test": ["!/usr/bin/env python", " Initialize the node"], "barrel_benchmark_test": ["!/usr/bin/env python", " Initialize the node"], "rgb_to_enhanced": ["!/usr/bin/env python", " encoding: utf-8", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", "\"):"], "vision_benchmark_test_base": [" Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Read the next image.", " If the image was not read succesfully continue to the", " next file.", " If the tested algorithm is not Victim, there is no need to use", " depth and thermal images.", " Store the image.", " Read the next bag.", " If the bag was not read succesfully continue to the", " next file.", " Store the bag.", "\"):", "\"):", " Wait for the alert to arrive.", " Set the processor block to notify the program that the processor", " answered", " Notify the program that an alert has been received.", " Read Annotations for a Set of Images", " Create Helper Structures for Benchmarking", " Test Parameters and Variables", " Read Benchmark Parameters for a Set of Images", " Read Images Sequentially", " Publish image files sequentially and wait for an alert.", " Confirm the authenticity of the alert using the annotator", " groundtruth set.", " Estimate alert center point from message parameters", " Calculate the Benchmarking Results.", " Estimate Recall values for each set of", " (Distance, Horizontal Angle, Vertical Angle)"], "pkg.develspace.context.pc": [" generated from catkin/cmake/template/pkg.context.pc.in"], "pkg.installspace.context.pc": [" generated from catkin/cmake/template/pkg.context.pc.in"], "images_to_bag": ["!/usr/bin/python", " this package name"], "split_bag": ["!/usr/bin/python"], "landoltc_benchmark_test": ["!/usr/bin/env python"], "hazmat_benchmark_test": ["!/usr/bin/env python", " Initialize the node"], "hole_detector_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " tests the function of the hole detector package", " how many alert messages have been published", " how many alerts have been sent with the first message", " the coordinates of the first valid hole's keypoint", " the coordinates of the first valid hole's keypoint relative to the", " center of the image", " the hole's expected yaw", " the hole's expected pitch", " tests the function of the depth node", " how many alert messages have been published", " how many alerts have been sent with the first message", " make assertions about the first candidate hole", " the coordinates of the first valid hole's data", " are halved because of the wavelet analysis used", " The first hole's keypoint", " There should be equal number of elements in both vertices vectors", " The first hole's bounding box is itself bounded", " in a bounding box", " There should be equal number of elements in both outline vectors", " The minimum x coordinate of the bounding box's points", " The minimum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The first hole's outline is bounded by its bounding box", " make assertions about the second candidate hole", " the coordinates of the second valid hole's data", " are halved because of the wavelet analysis used", " The second hole's keypoint", " There should be equal number of elements in both vertices vectors", " The second hole's bounding box is itself bounded in a bounding box", " There should be equal number of elements in both outline vectors", " The minimum x coordinate of the bounding box's points", " The minimum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The first hole's outline is bounded by its bounding box", " tests the function of the rgb node", " how many alert messages have been published", " how many alerts have been sent with the first message", " make assertions about the first candidate hole", " the coordinates of the first valid hole's data", " are halved because of the wavelet analysis used", " The first hole's keypoint", " There should be equal number of elements in both vertices vectors", " The first hole's bounding box is itself bounded", " in a bounding box", " There should be equal number of elements in both outline vectors", " The minimum x coordinate of the bounding box's points", " The minimum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The first hole's outline is bounded by its bounding box", " make assertions about the second candidate hole", " the coordinates of the second valid hole's data", " are halved because of the wavelet analysis used", " The second hole's keypoint", " There should be equal number of elements in both vertices vectors", " The second hole's bounding box is itself bounded in a bounding box", " There should be equal number of elements in both outline vectors", " The minimum x coordinate of the bounding box's points", " The minimum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The first hole's outline is bounded by its bounding box", " how many alert messages have been published", " how many alerts have been sent with the first message", " depth analysis is possible", " the first hole", " The first hole's keypoint", " There should be equal number of elements in both vertices vectors", " The first hole's bounding box is itself bounded", " in a bounding box"], "hole_benchmark_test": ["!/usr/bin/env python", " Initialize the node"], "rgb_depth_thermal_synchronizer": ["!/usr/bin/env python", "Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", " * Redistributions of source code must retain the above copyright", " notice, this list of conditions and the following disclaimer.", " * Redistributions in binary form must reproduce the above", " copyright notice, this list of conditions and the following", " disclaimer in the documentation and/or other materials provided", " with the distribution.", " * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", " contributors may be used to endorse or promote products derived", " from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Here the synchronized messages from kinect and flir are sent", " to the synchronizer node as one united message.", " Check if topic for synchronized message has been given properly if yes pass it to the variable", " Make topic's name absolute", "rospy.loginfo(\"[Rgbdt_synchronizer] is publishing to: %s\", synch_topic)", " Publisher of PointCloud2 and flirLeptonMsg messages", " Pack the message to be sent.", " Publish the message to the synchronizer node", " Check if topic for synchronized message has been given properly if yes pass it to the variable", " Make topic's name absolute", "rospy.loginfo(\"[Rgbdt_synchronizer] is publishing to: %s\", synch_topic)", " Publisher of PointCloud2 and flirLeptonMsg messages", " Pack the message to be sent.", " Publish the message to the synchronizer node", " Initialization of rgbdt_synchronizer node", " Check if kinect topic has been given properly if yes pass it to the variable", " Check if flir topic has been given properly if yes pass it to the variable", " Check in which mode Hole package is running", " Continue the process based on packages mode. If mode = true thermal", " included", " Subscribers of kinect and flir messages", " Synchronize kinect and flir topics"], "cpu_temperature_monitor": ["!/usr/bin/env python", " Hz", " read temperature", " find the number of thermal_zone dirs in /sys/class/thermal", "initialize temperature buffer", " initialize msg", " for each core", " remove oldest temperature in buffer of each core", " store temperature file path in filename", " append new temperature at end of buffer of each core", " calculate average of temperatures in the buffer of the core", " store average temperature of core in msg", " publish the message", " if (high temperature) enable beeper"], "battery_monitor": ["!/usr/bin/env python"], "state_indicator": ["!/usr/bin/env python"], "end": ["!/usr/bin/env python"], "init": ["!/usr/bin/env python", " If the end effector is not responsive the init", " task will loop forever. Using this decorator", " we limit the execution time of the task.", " Wrap your function and test the wrapper."], "sensor_hold": ["!/usr/bin/env python"], "identification": ["!/usr/bin/env python", " The mock should be called only once because the updated goal is", " within the acceptable limits"], "fusion_validation": ["!/usr/bin/env python"], "victim_deletion": ["!/usr/bin/env python"], "operator_validation": ["!/usr/bin/env python"], "exploration": ["!/usr/bin/env python", " This goal will move the agent to the end state.", " Long goals that will not affect the test.", " Only one thread should acquire the lock."], "fsm_framework": ["!/usr/bin/env python", " Define with list of dictionaries", " Define with list of lists", " First pass positional and keyword args directly to the callback", " Now wrap arguments in an EventData instance", " Should fail if auto transitions is off...", " Include initial state in loop", " Test user-determined sequence and trigger name", " Via init argument"], "utilities": ["!/usr/bin/env python", " Make sure the action clients are instantiated.", " Make sure the subscribers are instantiated.", " Make sure global state transition functios have been generated.", " Empty variables", " TODO Write test with full functionality"], "world_model": ["!/usr/bin/env python", " Set up testing mocks"], "navigator": ["!/usr/bin/env python", " Register the mock servers."], "effector": ["!/usr/bin/env python", " Register the mock servers."], "explorer": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "data_fusion": ["%d as %s.', victim_id, victim_status)", "%d', victim_id)", "%d, selected as the current target', victim_id)"], "gui": ["!/usr/bin/env python"], "mocks": ["!/usr/bin/env python", " Action Servers"], "agent_standalone": ["!/usr/bin/env python", " Start the agent."], "target": [" Reset the target's state.", "%d with probability %.2f', id, probability)", "%d is verified with %.2f',", "%d is identified with %.2f',"], "agent": [" Configuration folder", " Dispatcher for event based communication.", " SUBSCRIBERS.", " ACTION CLIENTS.", " State client", " General information.", " Victim information.", " Between-transition information.", " Utility Variables", " Expose client methods to class", "#####################################################", "                   UTILITIES                        #", "#####################################################", " Removing the implementation of the given state.", " Read the configuration file.", " Setting up the FSM", " Get all the states for the given strategy.", " Set up states tasks.", " Create the transition table.", " Sets up the initial state", "#####################################################", "               DISPATCHER'S CALLBACKS               #", "#####################################################", " This is a bug.", " Ensure that poi found is not called twice with the same target.", "%d.', self.target.info.id)", " The agent tries again.", " The agent changes state.", " The target is valid and the next state is hold_sensors.", " The target is not valid and we delete it.", "#####################################################", "               SUBSCRIBER'S CALLBACKS               #", "#####################################################", " Change to teleoperation", " Cancel all goals", " Kill the process", " If no targets are available there is nothing to do.", " Remember the available targets.", " Set a new target from the available ones.", " Check for invalid target acquisition.", "%d has been acquired.', idx)", " Update the current target.", "#####################################################", "                 AGENT'S ACTIONS                    #", "#####################################################", " Move base to the target.", " Point sensors to the target.", " Start timer to cancel all goals if the move base is unresponsive.", " Point sensors to the target.", "%s' % (target_id))", "#####################################################", "                  AGENT LOGIC                       #", "#####################################################", " Should never be called with empty targets.", " self.current_pose = self.explorer.pose_stamped.pose", "#####################################################", "               GLOBAL STATE TRANSITIONS             #", "#####################################################"], "config": [" Probability limit for a target to be verified as victim.", " Probability limit for a target to be identified as a potential victim.", " Time needed for the sensors to verify the current target.", " Time limit for a global state change.", " Number of MoveBase failures before the agent aborts the current goal.", " Time limit for the MoveBase to succeed at a given goal.", " Minimum radius to classify a pose as different from the current goal."], "msgs": ["! /usr/bin/env python"], "publishers": ["! /usr/bin/env python", " Messages"], "transition": [" Check if all the conditions are met.", " Starting the transition.", " First run all the before callbacks.", " Exit the current state and run the on_exit", " callback for the current state.", " Enter the next state.", " Run the on_enter callback for the next state.", " Finally run all the after callbacks.", " The transition completed."], "machine": [" Creates a `state` attribute in the context class", " holding the name of the current state of the machine.", " The `states` lists holds all the available State instances.", " Creates an is_`state` method in the context class for this state,", " checking whether the context class is in the `state`.", " Creates a on_enter_`state` and on_exit_`state` method for the", " context class.", " Add automatic transitions after all states have been created.", " Use the wildcard `*` to use all the available states as the source.", " need to listify for Python3"], "state": [" Holds all the callbacks for the enter event.", " Holds all the callbacks for the exit event."], "event": [" Encapsulating arguments from higher levels into an EventData object."], "agent_end_effector_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " does end effector test?", " does end effector park?", " is end effector tracking?", " is end effector scanning?", " does end effector track?", " does end effector track?", " does end effector track?", " is end effector scanning?"], "data_fusion_agent_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", "DataFusionAgentTest.disconnect()", "rospy.signal_shutdown(\"test_finished\")"], "agent_explorer_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "hole_data_fusion_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", "self.assertTrue(self.replied)"], "processing": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Nikolaos Tsipas", " 64 windows (~8 seconds)", " 16 windows (~2 second)", " similarity distance in radians (~30 degrees)", " excluding the last element which is the most recent"], "capture": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Nikolaos Tsipas"], "monitor": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Nikolaos Tsipas"], "record": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Nikolaos Tsipas"], "transport_image_topics": ["!/usr/bin/env python", " System calls", " System calls as subprocesses", " Regular Expressions", "# @brief Execute a shell command as a subprocess", "  @param command Command to execute as subprocess", "  @return", "# @brief Execute a shell command as a subprocess -- Detatched", "  @param command Command to execute as a detatched subprocess", "  @return Bool True if command executed succesfully. False otherwhise", " Execute command", " On failed to execute command", " On success execution", "# @brief Extracts Topic-Name and Topic-Type from given publisher", "  @param publisher Publisher to extract info from", "  @return List. Containes 'name' and 'type' parameters", "# @brief TSearch for active publishers from a given node", "  @param node Node to search for publishers", "  @return Found publishers", "# @brief Tries to match a machine namespace from a given topic name", "  @return Returns True if RegExpr mathced with success.", "# @brief Checks for sensor_msgs/Image topic type", "  @param topic Topic to check for.", "  @return Bool. True on found. False otherwise", "# @brief Search for active nodes on remote machone", "  @param machine The machine nodes to search for.", "  @return Nodes found on remote machine", "# @brief Republish a topic using image_transport", "   Use this re republish nodes running on remote machine, on local machine.", "  @param in_topic Topic to transport (e.g Remote machine topic)", "  @param out_topic Transported topic (e.g Local machine topic)", "print cmd", " ----------------Initialize console args parser------------------------- #", " Parse console arguments.", " Did not set machine", "machine = \"rpi2\""], "state_manager_test": ["!/usr/bin/env python"], "state_client": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Authors: Chris Zalidis <zalidis@gmail.com>", "          Konstantinos Sideris <siderisk@auth.gr>", " There is a bug with the server.", " There is a bug with the server."], "test_client": ["!/usr/bin/env python"], "sensor_processor_test": ["!/usr/bin/env python", " encoding: utf-8"], "dummy_node": ["!/usr/bin/env python"], "test_dummy_node": ["!/usr/bin/env python"], "mocksubscriber": ["~ rospy.loginfo('got data %s', data)"], "moxcomparators": ["~ self.recurseRepr(self.obj_,'')"], "messageInfoParser": ["'"], "generic_mock": ["!/usr/bin/env python", "~ construct a dictionary holding for each topic requested, a mock object ", "~ subscribing to it", "~ open a bag and register all the messages to the ", "~ mock object of the corresponding topic (if the topic is listed in the given)", "~ Tell the mock objects that we finished registering method calls and are now", "~ verifying", "~ Call the action that replays the bag. Here we use the same bag to check if everything works", "~ In real testing this should be replaced by waiting for the real code to produce output", "~ Nevertheless, the bag replay action could still be used for something else", "~ (maybe change to service??)", "~ Verify that the registered callbacks are called , i.e. all the messages in the ", "~ bag we opened were heard in this order"], "test_base": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "alert_delivery": ["!usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "integration_tester": ["!usr/bin/env python"], "parse_extra_files": ["!/usr/bin/env python", " relative to the dir of the 'extra_files.yml'", " if destination is absolute", " project source dir", " project devel dir", " try to compose something that makes sense", "print(arguments)"], "download_checkmd5": ["!/usr/bin/env python", " on first connection check server capabilities", " on resume verify that server understood range header and responded accordingly", " if no bytes have been received abort download", " when content length is unknown it is assumed that the download is complete", " or when enough data has been downloaded (> is especially a valid case)", " Create intermediate directories as necessary, #2970", " delete partially downloaded data"], "exploration_caller": ["! /usr/bin/env python", "if client.get_state() == actionlib.GoalStatus.ACTIVE:"], "objects_srv": ["!/usr/bin/env python", "rospy.Service('data_fusion_geotiff', GetGeotiff, send_objects)"], "save_csv": ["!/usr/bin/env python"], "subscriber_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Benchmark new subscriber style..."], "mass_alert_publisher": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "alert_handler_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "alert_handler_static_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " The order had only holes in it!", " If measurement does not differ from the expected position, the updated", " expected position will not change.", " I expect that 3-4 alerts would bring the conviction high enough to be", " recognised as a victim, but no less.", " If the measurement differs the same way, then the updated expected position", " should draw closer to that measurement - towards the same direction.  That", " means that expected position's distance from the initial expected position", " should be greater as the different measurement insists.", " We consider that conviction of the object about its position is lot higher now.", " I assume that its expected position will be around position0.  So:", " The order had only holes in it!", " A measurement off will not throw away very much a stable object.", " That measurement off will throw away the object even less, if more", " stable measurements have occured.", " Filtering makes object resistant to gaussian noise!", "self.assertGreater(self.currentVictimList[0].probability, 0.9) #"], "co2_processor_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "frame_matcher_functional": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " # At least one message has been published by node", " self.assertTrue(self.repliedList[self.output_topic])", " # Only one message has been published by node", " print rospy.loginfo(self.messageList[self.output_topic])", " self.assertEqual(len(self.messageList[self.output_topic]), 1)", " message = self.messageList[self.output_topic][0]", " # Only one ROI has been included in output EnhancedImage", " self.assertEqual(len(message.regionsOfInterest), 1)", " annotation = self.annotations[\"frame0.png\"]", " expected_roi = rgb_to_enhanced.annotation_to_roi(annotation)", " actual_roi = message.regionsOfInterest[0]", " distance = utils.distance_keypoints(expected_roi.center, actual_roi.center)", " rospy.loginfo(\"Distance between centers is: \"+str(distance))", " self.assertLess(distance, 5)", " width_error = math.fabs(actual_roi.width - expected_roi.width)", " self.assertLess(width_error, 3)", " height_error = math.fabs(actual_roi.height - expected_roi.height)", " self.assertLess(height_error, 3)"]}}
,{"git_repo_name": "iop_core", "code_comments_file_names": ["AccessControlClientPlugin", "AccessControlPlugin", "main", "RemoteComponentList", "RemoteComponent", "AccessControlClient_ReceiveFSM", "AccessControl_ReceiveFSM", "cpp", "chmerge", "cpy", "mss", "ServiceInfo", "Slave", "Component", "EventsConfig", "main", "EventsPlugin", "InternalEvent", "EventsClientPlugin", "InternalEventList", "InternalEventClient", "EventsClient_ReceiveFSM", "Events_ReceiveFSM", "main", "iop_component", "ListManagerClientPlugin", "InternalElement", "main", "InternalElementList", "ListManagerPlugin", "ListManager_ReceiveFSM", "ListManagerClient_ReceiveFSM", "main", "TransportPlugin", "ManagementClientPlugin", "main", "ManagementPlugin", "Management_ReceiveFSM", "ManagementClient_ReceiveFSM", "DiscoveryServiceList", "DiscoveryComponent", "DiscoveryClientPlugin", "DiscoveryServiceDef", "DiscoveryConfig", "DiscoveryComponentList", "main", "DiscoveryClient", "DiscoveryRosInterface", "DiscoveryPlugin", "DiscoveryClient_ReceiveFSM", "Discovery_ReceiveFSM", "EventReceiver", "jFixedLengthString", "Service", "SimpleThread", "Address", "JrLogger", "JUDPTransport", "OS", "XmlConfig", "JausTransport", "JuniorAPI", "JuniorMgr", "ChecksumCRC", "JausAddress", "JrSockets", "Send", "Receive", "InternalEventHandler", "JUDPTransportLB", "jts_node_manager", "JSerial", "JuniorRTE", "TCPConnection", "JTCPTransport", "main", "LivenessPlugin", "Liveness_ReceiveFSM"], "md_file_names": ["README", "README", "README", "README", "iop_core_packages", "howto_minimal_config", "howto_create_plugin", "other_packages", "install_oracle_java", "examples", "how_it_works", "README", "README", "README", "README", "README", "README", "README"], "md_contents": {"README": ["This package is part of [ROS/IOP Bridge](https://github.com/fkie/iop_core/blob/master/README).\n", "\n", "\n", "## _fkie_iop_liveness:_ Liveness\n", "\n", "This service sends ReportHeartbeatPulse on request or as event.\n", "\n", "#### Parameter:\n", "\n", "> None\n", "\n", "#### Publisher:\n", "\n", "> None\n", "\n", "#### Subscriber:\n", "\n", "> None\n", "\n"], "iop_core_packages": ["### fkie_iop_builder\n", "It contains the basic functionality and must be included in each component of the IOP/ROS bridge. The detailed overview of this package you find [here](../fkie_iop_builder/README).\n", "\n", "### fkie_iop_component\n", "Contains the plugin interface for all IOP services. The services which implement this interface can be included into the component on start. The **fkie_iop_component** binary represents an IOP component. The services of this component can be configured dynamically. For further details see [how it works](../doc/how_it_works) or [simulation example](https://github.com/fkie/iop_examples/blob/master/fkie_iop_cfg_sim_turtle/README)\n", "\n", "### fkie_iop_ocu_slavelib\n", "A helper library for ROS/IOP-Bridge OCU nodes. The detailed overview of this package you find [here](../fkie_iop_ocu_slavelib/README).\n", "\n", "## JAUS Core Services\n", "\n", "[fkie_iop_accesscontrol: AccessControl](../fkie_iop_accesscontrol/README)  \n", "[fkie_iop_accesscontrol: AccessControlClient](../fkie_iop_accesscontrol/README#fkie_iop_accesscontrol-accesscontrolclient)  \n", "[fkie_iop_discovery: Discovery](../fkie_iop_discovery/README)  \n", "[fkie_iop_discovery: DiscoveryClient](../fkie_iop_discovery/README#fkie_iop_discovery-discoveryclient)  \n", "[fkie_iop_events: Events](../fkie_iop_events/README)  \n", "[fkie_iop_events: EventsClient](../fkie_iop_events/README#fkie_iop_events-eventsclient)  \n", "[fkie_iop_list_manager: ListManager](../fkie_iop_list_manager/README)  \n", "[fkie_iop_list_manager: ListManagerClient](../fkie_iop_list_manager/README#fkie_iop_list_manager-listmanagerclient)  \n", "[fkie_iop_liveness: Liveness](../fkie_iop_liveness/README)  \n", "[fkie_iop_management: Management](../fkie_iop_management/README)  \n", "[fkie_iop_management: ManagementClient](../fkie_iop_management/README#fkie_iop_management-managementclient)  \n", "[fkie_iop_transport: Transport](../fkie_iop_transport/README)  \n"], "howto_minimal_config": ["## How to start with own configuration\n", "\n", "First of all you need a running `JAUS Node Manager` on **each host** where you start ROS/IOP components. `JAUS Node Manager` is part of JTS, but we created a script, so you can include it into ROS launch files, see [jaus_node_manager.launch](https://github.com/fkie/iop_examples/blob/master/fkie_iop_cfg_sim_stage/launch/jaus_node_manager.launch). Or you run it directly `JTSNodeManager path/to/nm.cfg`.\n", "\n", "### Create configuration for robot\n", "\n", "In JAUS/IOP a robot represents a subsystem with all his payloads and computers. For a whole subsystem we have to setup exact one component, which manage the discovering of all IOP/JAUS services. Usually it is a component named `platfrom_manager` with `node id` **15**.\n", "```\n", "    <param name=\"name_subsystem\" value=\"Bob\"/>\n", "    <node name=\"iop_platform_manager\" pkg=\"fkie_iop_component\" type=\"iop_component\">\n", "        <param name=\"name_node\" value=\"platform manager\"/>\n", "        <param name=\"iop_address\" value=\"1.1.15\"/>\n", "    </node>\n", "```\n", ">IOPv2 defines dynamic address assignment. This feature currently not implemented in ROS/IOP Bridge. You have to define your own JAUS ID with Subsystem.Node.Component.\n", "\n", ">`name_subsystem` parameter specifies the name of the subsystem discovered by OCU.\n", "\n", "The minimal set of services in `platform_manager` fontains of:\n", "\n", "* urn:jaus:jss:core:Discovery\n", "* urn:jaus:jss:core:Liveness\n", "* urn:jaus:jss:iop:DigitalResourceDiscovery\n", "* urn:jaus:jss:exp:aeodrs:HealthMonitor\n", "\n", "Add these services and also all serviceses inherits of to `platform_manager`:\n", "```\n", "    <param name=\"name_subsystem\" value=\"Bob\"/>\n", "    <node name=\"iop_platform_manager\" pkg=\"fkie_iop_component\" type=\"iop_component\">\n", "        <param name=\"name_node\" value=\"platform manager\"/>\n", "        <param name=\"iop_address\" value=\"1.1.15\"/>\n", "        <rosparam param=\"services\">\n", "            [\n", "            fkie_iop_transport: \"Transport\",\n", "            fkie_iop_events: \"Events\",\n", "            fkie_iop_events: \"EventsClient\",\n", "            fkie_iop_accesscontrol: \"AccessControl\",\n", "            fkie_iop_discovery: \"Discovery\",\n", "            fkie_iop_discovery: \"DiscoveryClient\",\n", "            fkie_iop_liveness: \"Liveness\",\n", "            fkie_iop_digital_resource_discovery: \"DigitalResourceDiscovery\",\n", "            fkie_iop_health_monitor: \"HealthMonitor\",\n", "            ]\n", "        </rosparam>\n", "    </node>\n", "```\n", "`DiscoveryClient` service is included to register our own services by `Discovery` services, so they can be found by other components. `EventsClient` service is included because `DiscoveryClient` inherits of it.\n", "\n", "Now we have to configure the `Discovery` service to enable the service registration management:\n", "```\n", "    <param name=\"name_subsystem\" value=\"Bob\"/>\n", "    <node name=\"iop_platform_manager\" pkg=\"fkie_iop_component\" type=\"iop_component\">\n", "        <param name=\"name_node\" value=\"platform manager\"/>\n", "        <param name=\"iop_address\" value=\"1.1.15\"/>\n", "        <rosparam param=\"services\">\n", "            [\n", "            fkie_iop_transport: \"Transport\",\n", "            fkie_iop_events: \"Events\",\n", "            fkie_iop_events: \"EventsClient\",\n", "            fkie_iop_accesscontrol: \"AccessControl\",\n", "            fkie_iop_discovery: \"Discovery\",\n", "            fkie_iop_discovery: \"DiscoveryClient\",\n", "            fkie_iop_liveness: \"Liveness\",\n", "            fkie_iop_digital_resource_discovery: \"DigitalResourceDiscovery\",\n", "            fkie_iop_health_monitor: \"HealthMonitor\",\n", "            ]\n", "        </rosparam>\n", "        <rosparam subst_value=\"true\">\n", "            Discovery:\n", "                # 2: Subsystem Identification, 3: Node Identification, 4: Component Identification\n", "                system_id: 2\n", "                # 10001: VEHICLE, 20001: OCU, 30001: OTHER_SUBSYSTEM, 40001: NODE, 50001: PAYLOAD, 60001: COMPONENT\n", "                system_type: 10001\n", "        </rosparam>\n", "    </node>\n", "```\n", "\n", "This is the minimal configuration. The robot will be discovered by IOP OCU but will not provide any functional services. You can add this services to the `platform_manager` component or create a new one. See `iop_costmap2d` component in [fkie_iop_cfg_sim_stage](https://github.com/fkie/iop_examples/blob/master/fkie_iop_cfg_sim_stage/launch/inc_iop_robot.launch) example.\n", "\n", "### Create configuration for OCU\n", "\n", "Now we create a minimal configuration for a component running on OCU. You have to also specify the JAUS ID and can define a name:\n", "```\n", "    <node name=\"iop_ocu_client\" pkg=\"fkie_iop_component\" type=\"iop_component\">\n", "        <param name=\"iop_address\" value=\"150.64.200\"/>\n", "        <param name=\"name_node\" value=\"control_client\"/>\n", "        <rosparam param=\"services\">\n", "          [\n", "            fkie_iop_transport: \"Transport\",\n", "            fkie_iop_events: \"EventsClient\",\n", "            fkie_iop_discovery: \"DiscoveryClient\",\n", "          ]\n", "        </rosparam>\n", "        <rosparam subst_value=\"true\">\n", "            use_queries: false\n", "            DiscoveryClient:\n", "                register_own_services: false\n", "                enable_ros_interface: true\n", "        </rosparam>\n", "    </node>\n", "```\n", "\n", "To discover the IOP robot you have to include the `DiscoveryClient`:\n", "```\n", "    <node name=\"iop_ocu_client\" pkg=\"fkie_iop_component\" type=\"iop_component\">\n", "        <param name=\"iop_address\" value=\"150.64.200\"/>\n", "        <param name=\"name_node\" value=\"control_client\"/>\n", "        <rosparam param=\"services\">\n", "          [\n", "            fkie_iop_transport: \"Transport\",\n", "            fkie_iop_events: \"EventsClient\",\n", "            fkie_iop_discovery: \"DiscoveryClient\",\n", "          ]\n", "        </rosparam>\n", "    </node>\n", "```\n", "Since the `DsicoveryClient` also used to register own services by `Discovery` services, the ROS interface for discovered services is disabled by default. You have to enable this by setting the parameter `enable_ros_interface` to `true`. Furthermore you can disable the registration of client service of the OCU, since they consumes only the functionality of robot service. And there is no need to register them in the subsystem:\n", "```\n", "    <node name=\"iop_ocu_client\" pkg=\"fkie_iop_component\" type=\"iop_component\">\n", "        <param name=\"iop_address\" value=\"150.64.200\"/>\n", "        <param name=\"name_node\" value=\"control_client\"/>\n", "        <rosparam param=\"services\">\n", "          [\n", "            fkie_iop_transport: \"Transport\",\n", "            fkie_iop_events: \"EventsClient\",\n", "            fkie_iop_discovery: \"DiscoveryClient\",\n", "          ]\n", "        </rosparam>\n", "        <rosparam subst_value=\"true\">\n", "            DiscoveryClient:\n", "                register_own_services: false\n", "                enable_ros_interface: true\n", "        </rosparam>\n", "    </node>\n", "```\n", "\n", "If you now launch JAUS Node Manager and new launch files you get the discovered system overview on OCU by calling\n", "```\n", "rostopic echo /iop_system\n", "```\n", "\n", "As with the robot, you can extend the functionality of the OCU client component by adding the services to the `services` parameter.\n", ">Note: for services, which control the robot, you need to get **access control** (for managed services also resume from standby). For these porposes it is easier to use the *rqt* plugin from **fkie_iop_rqt_access_control**.\n", "\n"], "howto_create_plugin": ["## How to create your own plugin for ROS/IOP-Bridge\n", "\n", "Let's see all the steps we need to create a plugin to use within ROS/IOP-Bridge. For this example we take an existing service which offers own functionality and also exports a library which is used by other services: *urn:jaus:jss:environmentSensing:VisualSensor*.\n", "\n", "First of all we need an JSIDL which describes the service with all input/output messages and protocol behaviour. You find these definitions in the JAUS standard, in JAUS Toolset (GUI/resources/xml/.) or in `fkie_iop_builder/jsidl/`. The definitions in `fkie_iop_builder/jsidl/` are copies from JTS. The JSIDL files already used in plugins were modified to pass the received message as argument to the service handler:\n", "```\n", "    <action name=\"accessControl.events.transport.Send\">             -->  <action name=\"sendReportVisualSensorCapabilities\">\n", "       <argument value=\" 'ReportVisualSensorCapabilities' \"/>       -->  <argument value=\"msg\"/>\n", "       <argument value=\"transportData\"/>\n", "    </action>\n", "```\n", "\n", "Now we create a new ROS package (in our case *fkie_iop_visual_sensor*) which depends on `roscpp`, `fkie_iop_component` and `fkie_iop_accesscontrol`. Each plugin should depend on `fkie_iop_component` to get the funtionatlities of [Bridge-Plugins](../fkie_iop_component/README) and [Builder-package](../fkie_iop_builder/README). The `fkie_iop_accesscontrol` package is included, because the *VisualSensor* inherits from *AccessControl* service. Our depends in package.xml looks now like:\n", "```\n", "    <buildtool_depend>catkin</buildtool_depend>\n", "    <build_depend>roscpp</build_depend>\n", "    <build_depend>fkie_iop_accesscontrol</build_depend>\n", "    <run_depend>roscpp</run_depend>\n", "    <run_depend>fkie_iop_accesscontrol</run_depend>\n", "    <run_depend>fkie_iop_component</run_depend>\n", "```\n", "\n", "### Generate and include JTS source\n", "\n", "In the next step we add JAUS services to `CMakeLists.txt`:\n", "```makefile\n", "    iop_init(COMPONENT_ID 0)\n", "    iop_code_generator(\n", "      IDLS\n", "        urn.jaus.jss.core-v1.0/AccessControl.xml\n", "        urn.jaus.jss.core-v1.0/Events.xml\n", "        urn.jaus.jss.core-v1.0/Transport.xml\n", "        urn.jaus.jss.environmentSensing/VisualSensor.xml\n", "      OWN_IDLS\n", "      OVERRIDES\n", "      EXTERN_SERVICES\n", "        urn_jaus_jss_core_Events\n", "        urn_jaus_jss_core_AccessControl\n", "        urn_jaus_jss_core_Transport\n", "      GENERATED_SOURCES cppfiles\n", "    )\n", "```\n", "The call `iop_init(COMPONENT_ID 0)` can stay for all plugins the same. In `iop_code_generator::IDLS` we list all JAUS services included in this plugin. It is our service and all services in the inherit tree. The services we inherit from are already implemented in other packages and we want use them. To do this we add this services to `iop_code_generator::EXTERN_SERVICES`. Thereby we use the directory name created by JTS for these services.\n", "> ! internally our build script deletes all generated sources defined in `EXTERN_SERVICES` after creation by JTS.\n", "\n", "Now we open a terminal and go to our package and run `catkin build --this`. This generates in `catkin_ws/build/fkie_iop_visual_sensor/jaus/Fkie_iop_visual_sensor_0` the source files for our service. In order to extend the functionality of the generated service, we copy the following files into our package, respecting the directory structure:\n", "```\n", "    include/urn_jaus_jss_environmentSensing_VisualSensor/VisualSensor_ReceiveFSM.h\n", "    src/urn_jaus_jss_environmentSensing_VisualSensor/VisualSensor_ReceiveFSM\n", "```\n", "Additionally we create an empty file `src/main`.\n", "\n", "These files we add to `iop_code_generator::OVERRIDES` in `CMakeLists.txt`:\n", "```\n", "    iop_code_generator(\n", "      :\n", "      OVERRIDES\n", "        include/urn_jaus_jss_environmentSensing_VisualSensor/VisualSensor_ReceiveFSM.h\n", "        src/urn_jaus_jss_environmentSensing_VisualSensor/VisualSensor_ReceiveFSM\n", "        src/main\n", "      :\n", "    )\n", "```\n", "\n", "Now we can implement the functionality for the service by extending the two files.\n", "\n", "\n", "### Add plugin functionality\n", "\n", "Additionally we have to add the plugin functionality! We have to create a plugin class inherited from `iop::PluginInterface` which is localted at `fkie_iop_component/iop_plugin_interface.h`. The plugin class should create an instance of our new JAUS service by providing the needed parameter to it. We create two files `src/VisualSensorPlugin.h` and `src/VisualSensorPlugin` with folling content:\n", "#### src/VisualSensorPlugin.h:\n", "```cpp\n", "#ifndef VISUALSENSORPLUGIN_H\n", "#define VISUALSENSORPLUGIN_H\n", "\n", "#include \"urn_jaus_jss_environmentSensing_VisualSensor/VisualSensorService.h\"\n", "#include \"urn_jaus_jss_core_AccessControl/AccessControlService.h\"\n", "#include \"urn_jaus_jss_core_Events/EventsService.h\"\n", "#include \"urn_jaus_jss_core_Transport/TransportService.h\"\n", "\n", "#include <fkie_iop_component/iop_plugin_interface.h>\n", "\n", "namespace iop\n", "{\n", "\n", "class DllExport VisualSensorPlugin : public PluginInterface\n", "{\n", "public:\n", "\tVisualSensorPlugin();\n", "\n", "\tJTS::Service* get_service();\n", "\tvoid create_service(JTS::JausRouter* jaus_router);\n", "\n", "protected:\n", "\turn_jaus_jss_environmentSensing_VisualSensor::VisualSensorService *p_my_service;\n", "\turn_jaus_jss_core_AccessControl::AccessControlService *p_base_service;\n", "\turn_jaus_jss_core_Events::EventsService *p_events_service;\n", "\turn_jaus_jss_core_Transport::TransportService *p_transport_service;\n", "\n", "};\n", "\n", "};\n", "\n", "#endif\n", "```\n", "\n", "#### src/VisualSensorPlugin:\n", "```cpp\n", "#include <pluginlib/class_list_macros.h>\n", "#include \"VisualSensorPlugin.h\"\n", "\n", "using namespace iop;\n", "using namespace urn_jaus_jss_environmentSensing_VisualSensor ;\n", "using namespace urn_jaus_jss_core_AccessControl;\n", "using namespace urn_jaus_jss_core_Events;\n", "using namespace urn_jaus_jss_core_Transport;\n", "\n", "\n", "VisualSensorPlugin::VisualSensorPlugin()\n", "{\n", "\tp_my_service = NULL;\n", "\tp_base_service = NULL;\n", "\tp_events_service = NULL;\n", "\tp_transport_service = NULL;\n", "}\n", "\n", "JTS::Service* VisualSensorPlugin::get_service()\n", "{\n", "\treturn p_my_service;\n", "}\n", "\n", "void VisualSensorPlugin::create_service(JTS::JausRouter* jaus_router)\n", "{\n", "\tp_base_service = static_cast<AccessControlService *>(get_base_service());\n", "\tp_events_service = static_cast<EventsService *>(get_base_service(2));\n", "\tp_transport_service = static_cast<TransportService *>(get_base_service(3));\n", "\tp_my_service = new VisualSensorService(jaus_router, p_transport_service, p_events_service, p_base_service);\n", "}\n", "\n", "PLUGINLIB_EXPORT_CLASS(iop::VisualSensorPlugin, iop::PluginInterface)\n", "```\n", "\n", "Do not forget to add the  file to the `CMakeLists.txt`:\n", "```makefile\n", "    add_library(${PROJECT_NAME}\n", "                src/VisualSensorPlugin\n", "                ${cppfiles}\n", "    )\n", "```\n", "\n", "Now we specify the IOP plugin description, so it can be found if we include it into our component. We create a new file `plugin_iop.xml` in root of our package with follow content:\n", "```\n", "    <library path=\"libfkie_iop_visual_sensor\">\n", "      <class name=\"VisualSensor\" type=\"iop::VisualSensorPlugin\" base_class_type=\"iop::PluginInterface\">\n", "        <description>\n", "          VisualSensor Service Plugin\n", "        </description>\n", "        <iop_service name=\"VisualSensor\" id=\"urn:jaus:jss:environmentSensing:VisualSensor\" version=\"1.0\">\n", "          <inherits_from id=\"urn:jaus:jss:core:AccessControl\" min_version=\"1.0\"/>\n", "        </iop_service>\n", "      </class>\n", "    </library>\n", "```\n", "The values for *iop_service* tag are taken from JSIDL definition. The *class* tag describes our plugin and the class we created. For more details see [Bridge-Plugins](../fkie_iop_component/README).\n", "\n", "Then we include our plugin definition to the `package.xml`:\n", "```\n", "    <export>\n", "      <fkie_iop_component plugin=\"${prefix}/plugin_iop.xml\" />\n", "    </export>\n", "```\n", "\n", "Now is the `package.xml` done.\n", "\n", "### Provide catkin specific configuration `CMakeLists.txt`\n", "Set include directories:\n", "``` include_directories(${catkin_INCLUDE_DIRS})```\n", "\n", "Add source files to the library:\n", "```add_library(${PROJECT_NAME} src/VisualSensorPlugin ${cppfiles}) ```\n", "\n", "Specify libraries to link a library against:\n", "```target_link_libraries(${PROJECT_NAME} ${catkin_LIBRARIES})```\n", "\n", "The service of this package is used by other packages, like *fkie_iop_digital_video* or *fkie_iop_still_image*. So that catkin works properly we have to configure `catkin_package`:\n", "```makefile\n", "    catkin_package(\n", "        LIBRARIES ${PROJECT_NAME}\n", "        CATKIN_DEPENDS fkie_iop_accesscontrol\n", "    )\n", "```\n", "\n", "If the package will be used as installed package we have to add install directives:\n", "\n", "```makefile\n", "    # Mark IOP include files for installation\n", "    install(\n", "      DIRECTORY ${IOP_INSTALL_INCLUDE_DIRS} DESTINATION ${CATKIN_GLOBAL_INCLUDE_DESTINATION}\n", "      PATTERN \"*.old\" EXCLUDE\n", "      PATTERN \"*.gen\" EXCLUDE\n", "    )\n", "\n", "    # Mark executables and/or libraries for installation\n", "    install(TARGETS ${PROJECT_NAME}\n", "      ARCHIVE DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n", "      LIBRARY DESTINATION ${CATKIN_PACKAGE_LIB_DESTINATION}\n", "      RUNTIME DESTINATION ${CATKIN_PACKAGE_BIN_DESTINATION}\n", "    )\n", "\n", "    ## Mark other files for installation (e.g. launch and bag files, etc.)\n", "    install(\n", "       FILES ./plugin_iop.xml\n", "       DESTINATION ${CATKIN_PACKAGE_SHARE_DESTINATION}\n", "    )\n", "```\n", "\n", "done! Build the package with `catkin build fkie_iop_visual_sensor`"], "other_packages": ["## Main Repository of ROS/IOP Bridge\n", "Core pakages of the ROS/IOP-Bridge needed to build the bridge. For interface description of core packages see [here](iop_core_packages). The interface description of other services is located in corresponding repository.\n", "\n", "_git clone https://github.com/fkie/iop_core_\n", "\n", "## Repositories with packages implementing the SEA JAUS Services\n", "\n", "- **core**: _urn.jaus.jss.core_ - services\n", "    - fkie_iop_accesscontrol\n", "    - fkie_iop_discovery\n", "    - fkie_iop_events\n", "    - fkie_iop_list_manager\n", "    - fkie_iop_liveness\n", "    - fkie_iop_management\n", "    - fkie_iop_transport\n", "\n", "- **manipulator**: _urn.jaus.jss.manipulator-v2.0_ - services\n", "    - _git clone [https://github.com/fkie/iop_jaus_manipulator](https://github.com/fkie/iop_jaus_manipulator)_\n", "    - fkie_iop_manipulator_joint_position_sensor\n", "    - fkie_iop_manipulator_specification_service\n", "    - fkie_iop_pantilt_joint_position_driver\n", "    - fkie_iop_pantilt_specification_service\n", "    - fkie_iop_primitive_endeffector\n", "    - fkie_iop_primitive_manipulator\n", "    - fkie_iop_primitive_pantilt\n", "\n", "- **mobility**: _urn.jaus.jss.mobility_ - services\n", "    - _git clone [https://github.com/fkie/iop_jaus_mobility](https://github.com/fkie/iop_jaus_mobility)_\n", "    - fkie_iop_global_pose_sensor\n", "    - fkie_iop_global_waypoint_driver\n", "    - fkie_iop_global_waypoint_list_driver\n", "    - fkie_iop_local_pose_sensor\n", "    - fkie_iop_local_waypoint_driver\n", "    - fkie_iop_local_waypoint_list_driver\n", "    - fkie_iop_primitive_driver\n", "    - fkie_iop_velocity_state_sensor\n", "\n", "- **sensing**: _urn.jaus.jss.environmentSensing_ - services\n", "    - _git clone [https://github.com/fkie/iop_jaus_sensing](https://github.com/fkie/iop_jaus_sensing)_\n", "    - fkie_iop_digital_video\n", "    - fkie_iop_range_sensor\n", "    - fkie_iop_still_image\n", "    - fkie_iop_visual_sensor\n", "\n", "- **ugv**: _urn.jaus.jss.ugv_ - services\n", "    - _git clone [https://github.com/fkie/iop_jaus_ugv](https://github.com/fkie/iop_jaus_ugv)_\n", "    - fkie_iop_illumination\n", "    - fkie_iop_power_plant\n", "    - fkie_iop_stabilizer_driver\n", "\n", "\n", "## Repositories with packages implementing the **clients** for SEA JAUS Services\n", "\n", "The clients are used on the OCU side to control an IOP compliant robot.\n", "\n", "- **manipulator_clients**: clients for _urn.jaus.jss.manipulator-v2.0_ - services\n", "    - _git clone [https://github.com/fkie/iop_jaus_manipulator_clients](https://github.com/fkie/iop_jaus_manipulator_clients)_\n", "    - fkie_iop_client_manipulator_joint_position_sensor\n", "    - fkie_iop_client_manipulator_specification\n", "    - fkie_iop_client_pantilt_joint_position_driver\n", "    - fkie_iop_client_pantilt_specification_service\n", "    - fkie_iop_client_primitive_endeffector\n", "    - fkie_iop_client_primitive_manipulator\n", "    - fkie_iop_client_primitive_pantilt\n", "\n", "- **mobility_clients**: clients for _urn.jaus.jss.mobility_ - services\n", "    - _git clone [https://github.com/fkie/iop_jaus_mobility_clients](https://github.com/fkie/iop_jaus_mobility_clients)_\n", "    - fkie_iop_client_global_pose_sensor\n", "    - fkie_iop_client_global_waypoint_driver\n", "    - fkie_iop_client_global_waypoint_list_driver\n", "    - fkie_iop_client_local_pose_sensor\n", "    - fkie_iop_client_local_waypoint_driver\n", "    - fkie_iop_client_local_waypoint_list_driver\n", "    - fkie_iop_client_primitive_driver\n", "    - fkie_iop_client_velocity_state_sensor\n", "\n", "- **sensing_clients**: clients for _urn.jaus.jss.environmentSensing_ - services\n", "    - _git clone [https://github.com/fkie/iop_jaus_sensing_clients](https://github.com/fkie/iop_jaus_sensing_clients)_\n", "    - fkie_iop_client_digital_video\n", "    - fkie_iop_client_range_sensor\n", "    - fkie_iop_client_still_image\n", "    - fkie_iop_client_visual_sensor\n", "\n", "- **ugv**: clients for _urn.jaus.jss.ugv_ - services\n", "    - _git clone [https://github.com/fkie/iop_jaus_ugv_clients](https://github.com/fkie/iop_jaus_ugv_clients)_\n", "    - fkie_iop_client_illumination\n", "    - fkie_iop_client_power_plant\n", "    - fkie_iop_client_stabilizer_driver\n", "\n", "## IOP services\n", "- **iop_platform**: the platform services including all services to create a platform\n", "    - _git clone [https://github.com/fkie/iop_platform](https://github.com/fkie/iop_platform)_\n", "    - fkie_iop_client_digital_resource\n", "    - fkie_iop_digital_resource_discovery\n", "    - fkie_iop_handoff\n", "    - fkie_iop_health_monitor\n", "    - fkie_iop_platform_manager\n", "    - fkie_iop_platform_mode\n", "    - fkie_iop_platform_state\n", "    - fkie_iop_unsolicited_heartbeat\n", "\n", "- **iop_sensing**: sensor services\n", "    - _git clone [https://github.com/fkie/iop_sensing](https://github.com/fkie/iop_sensing)_\n", "    - fkie_iop_costmap2d\n", "    - fkie_iop_measurement_sensor\n", "    - fkie_iop_path_reporter\n", "\n", "- **iop_sensing_clients**: clients for sensor services\n", "    - _git clone [https://github.com/fkie/iop_sensing_clients](https://github.com/fkie/iop_sensing_clients)_\n", "    - fkie_iop_client_costmap2d\n", "    - fkie_iop_client_measurement_sensor\n", "    - fkie_iop_client_path_reporter\n", "\n", "\n", "## ROS Messages\n", "For some functionallity we defined ROS messages.\n", "\n", "_git clone [https://github.com/fkie/iop_msgs](https://github.com/fkie/iop_msgs)_\n", "\n", "\n", "## ROS GUI for IOP services\n", "Basically we can use the available ROS GUIs. But some GUI components are very special, e.g. visualisation of the IOP components. In `gui` location are some GUI components using ROS *rqt*.\n", "\n", "- _git clone [https://github.com/fkie/iop_gui](https://github.com/fkie/iop_gui)_\n", "- fkie_iop_rqt_access_control\n", "- fkie_iop_rqt_digital_resource_viewer\n", "\n", "## Configuration Examples\n", "- **iop_examples**: Example with state simulator\n", "\t- _git clone [https://github.com/fkie/iop_examples](https://github.com/fkie/iop_examples)_\n", "\t- iop_cfg_sim_stage\n", "\t- iop_cfg_sim_turtle\n"], "install_oracle_java": ["# Installation of [Oracle Java 7 JDK](https://help.ubuntu.com/community/Java)\n", "\n", "    >JAUS Tool Set does not work with java 8!\n", "\n", "    sudo apt-get install python-software-properties\n", "    sudo add-apt-repository ppa:webupd8team/java\n", "    sudo apt-get update\n", "    sudo apt-get install oracle-java7-installer\n", "    sudo apt-get install oracle-java7-set-default\n"], "examples": ["For convenient usage of ROS environment use the `node_manager` of `multimaster_fkie`. You can install it from ROS apt repository or from  [https://github.com/fkie/multimaster_fkie](https://github.com/fkie/multimaster_fkie) using\n", "\n", "    git clone https://github.com/fkie/multimaster_fkie\n", "\n", "On each host you run IOP components you need to start the JTS-`nodeManager`:\n", "```bash\n", "rosrun fkie_iop_builder jaus_node_manager.sh start\n", "```\n", "\n", "## `fkie_iop_cfg_sim_stage`\n", "This package contains working configuration files specified to run with a stage simulator.\n", "\n", "You can find the description to this example on https://github.com/fkie/iop_examples/blob/master/fkie_iop_cfg_sim_stage/README\n"], "how_it_works": ["## How ROS/IOP-Bridge works - an overview\n", "\n", "The ROS/IOP-Bridge consists of a lot of independent components. This components represent in case one the IOP components:\n", "By **fkie_iop_component** it is now possible to configure the set of the services included into one component. All services of the ROS/IOP Bridge are implemented as a plugin. You can configure to use all services in one component or in a lot of independent components.\n", "\n", "![](images/iop-bridge-case1.png)\n", "\n", "For the IOP-OCU it looks like IOP components, but in the background they use the ROS data.\n", "In the second case the ROS/IOP-Bridge components are used on the OCU side to process the JAUS data and make it available for ROS-GUI, like rqt:\n", "\n", "![](images/iop-bridge-case2.png)\n", "\n", "### Component structure\n", "As an example we look at the PrimitiveDriver service plugin. This component is located in [iop_mobility](https://github.com/fkie/iop_jaus_mobility) and implemnents the translation of `SetWrenchEffort` and `ReportWrenchEffort` to ROS messages:\n", "\n", "![](images/iop-bridge-component.png)\n", "\n", "To reduce the implementation effort of included JAUS services like `AccessControl`, `Discovery` and other we implemented these as libraries wich are included by the component. Look at `package.xml` and `CMakeLists.txt` of `fkie_iop_primitive_driver` package to see how they can be included.\n", "\n", "### Components on the OCU side\n", "The ROS/IOP-Bridge components on the OCU side consume the JAUS data, e.g. of the PrimitiveDriver. This components are located in packages beginning with `iop_client_` prefix and include the client services for `AccessControl`, `Discovery` and other. Additionally, we created `fkie_iop_ocu_slavelib` and `fkie_iop_rqt_access_control` packages to control the independent client components simultaneously. This is useful to release or get access for a whole robot for example.\n", "\n", "![](images/iop-bridge-controllib-layer.png)\n"]}, "code_comments_c++": {"AccessControlClientPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "AccessControlPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "main": [" empty, if no executable service implemented for this library"], "RemoteComponentList": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "RemoteComponent": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "AccessControlClient_ReceiveFSM": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " determine timouted components", " send request, request time was set while time_to_send_ack()", " send requests", " send request, request time was set while time_to_send_ack()", " create a new event, since the InternalEventHandler deletes the given."], "AccessControl_ReceiveFSM": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " Helper function.  This needs to be static so we can", " call it from pthread_create.", " create a new event, since the InternalEventHandler deletes the given.", "/ Insert User Code HERE", "/ Insert User Code HERE", "  printf(\"[AccessControl] ResetTimerAction: restart timer\\n\");", " Now send it to the requesting component", " Now send it to the requesting component", " Now send it to the requesting component", "/ Insert User Code HERE", "/ Insert User Code HERE", "/ Insert User Code HERE"], "ServiceInfo": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " std::find"], "Slave": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " set callbacks", " start discovering", " try to get the address of the component specified for this slave to avoid discovering", "\tiop::Component &cmp = iop::Component::get_instance();", "\tp_handoff_supported = cmp.has_service(\"urn:jaus:jss:iop:HandoffController\");", " publish the feedback with settings", " is the command for specific client?", " apply default control address", " TODO: read services from discover client service", "apply commands to each component", " it is new control for the component or new authority", " send request access", "\t\tpGetAccesscontrolClient()->requestAccess(address, &Slave::pAccessControlClientReplyHandler, this, authority);", "\t\t\tpGetAccesscontrolClient()->releaseAccess(address, &Slave::pAccessControlClientReplyHandler, this);", " access released -> stop control", " the services are informed before release access was send", " pApplyToService(address, Component::ACCESS_CONTROL_RELEASE);", " pass authority to the handler", " send updated info to ROS", "test for current control state, do we need to send access control request", "\t\t\tpApplyControl(*it, it->get_address(), it->get_access_control(address), it->get_authority(address));"], "Component": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " std::find"], "EventsConfig": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "EventsPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "InternalEvent": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " : InternalEvent(event_list)  warning: delegating constructors only available with -std=c++11 or -std=gnu++11", ": InternalEvent(event_list, request_id, query_msg_id) warning: delegating constructors only available with -std=c++11 or -std=gnu++11", " send on change", " do nothing, the report will be send on next timer call", " report is available and we have periodic event -> create timer", " send on change", " save the last send timestamp for a given ID", " it is initialized, check for changed event type or rate", " save the last send timestamp for a given ID"], "EventsClientPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "InternalEventList": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " update current events", "", "\t\t\tp_events.insert(std::map<jUnsignedByte, boost::shared_ptr<iop::InternalEvent> >::value_type(event_id, boost::make_shared<iop::InternalEvent>(*this, event_id, request_id, query_msg_id, event_type, event_rate, *query_msg, requestor)));", "\t\t\treturn p_events.find(event_id)->second;"], "InternalEventClient": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "EventsClient_ReceiveFSM": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", "lock_type lock(p_mutex);", "TODO", "/ Insert User Code HERE"], "Events_ReceiveFSM": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", "\trvent_rec->setErrorMessage(\"error, invalid event ID for cancel event\");", " send confirm message", " send Reject message", " add filter support specified in QueryEvents message", " send confirm message", " send Reject message"], "iop_component": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " read configuration from private parameter", " read configuration from namespace parameter", " try to detect from jaustoolset package", " spawn another thread", " determine paths for xml files with plugin description", " test for uninitialized pugins", " register the services", " plugin was not defined in our list, serch for a default one", " search in already created plugins", " search in readed manifests", "", " When a component receives an internal event, it passes it", " to the services to handling, children services first.  If the", " event is not processed by normal transitions, it's passed", " again to the services (children first) for default transitions.", " A given event may only be processed by at most one service.", "", " lookup in cache", "Step into the filter list if necessary", " test for class name and skip parsing if it is wrong class id", "step to next class_element", "step to next class_element", " format: <iop_service name=\"Events\" id=\"urn:jaus:jss:core:Events\" version=\"1.0\">", " get version", " get required_service spec, format: <inherits_from id=\"urn:jaus:jss:core:Transport\" min_version=\"1.0\"/>", " get version", " get plugins depend on, format: <depend id=\"urn:jaus:jss:core:Transport\"/>", "step to next class_element"], "ListManagerClientPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "InternalElement": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "InternalElementList": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " inform service with current execution to stop.", " we have a loop -> stop fill the list. The execution can be continue after this part of list is executed.", " try to update existing element", " try to find the insert position", " we have to insert at the begin", " we have to insert at the end", " find the position of the previous UID", " stop execution", " stop execution", " stop execution", " delete supports: 0 first element, 65535: all elements", " test for next uid"], "ListManagerPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "ListManager_ReceiveFSM": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " delete supports: 0 first element, 65535: all elements", "// By default, inherited guards call the parent function.", "// This can be replaced or modified as needed."], "ListManagerClient_ReceiveFSM": [" reset states", "/ Insert User Code HERE", " added elements are removed from the list. It is not save.", " If the message goes lost or reject, the elements are lost and will not be resent.", " TODO: put the to into retry list."], "TransportPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "ManagementClientPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "ManagementPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "Management_ReceiveFSM": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", "\tcontext->setDebugFlag(true);", "/ Insert User Code HERE", "/ Insert User Code HERE", "/ Insert User Code HERE", "// By default, inherited guards call the parent function.", "// This can be replaced or modified as needed."], "ManagementClient_ReceiveFSM": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " emergency state", "    p_on_status_query = false;", "    if (p_do_resume and p_status != 3) {", "      ROS_DEBUG_NAMED(\"ManagementClient\", \"  Resume!\\n\");", "      p_do_resume = false;", "      queryStatus(sender);", "    }", "  pAccessControlClient_ReceiveFSM->requestAccess(address, authority);"], "DiscoveryServiceList": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "DiscoveryComponent": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " comparable for the map"], "DiscoveryClientPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "DiscoveryServiceDef": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " comparable for the map"], "DiscoveryConfig": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " report as subsystem", " report as vehicle", " Get the parameter for component/node/subsystem identification", "\tint id_component = 0;", "\t\t\tid_component = p3; // ignore the component ID", " if no ~iop_address was found or it was invalid, we search for id_.. parameter"], "DiscoveryComponentList": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " collect expired components", " remove expired components collected in previous step"], "DiscoveryClient": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " Create a static signal to catch interrupts", " Catch exit signals", " Start the component and the services", " Wait until signaled to exit", " Shutdown the component and threads", " Give a little time for proper shutdown", " Free the component"], "DiscoveryRosInterface": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", "0xFFFF, 0xFF, 0xFF", " SYSTEM TYPE", " SUBSYSTEM TYPE", " NODE TYPE", " COMPONENT TYPE", " Create ROS message from components", " update the object with discovered system and publish it to ROS", " Create ROS message from components", " update the object with discovered system and publish it to ROS", " create subsystem", " create a new node if need. this node is already added to subsystem", " create component", " add services", " do not compare the component ID:  ros_ident.address.component_id == addr.getComponentID()", " create new one"], "DiscoveryPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "DiscoveryClient_ReceiveFSM": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " parsce jaus address", " only uses if it is defined as SUBSYSTEM", " TODO forward to discovery service", "p_discovery_fsm->sendReportIdentificationAction(msg, transportData);", " reply with component name", " COMPONENT", " COMPONENT", " the service was found, forward the address to the callback", " create a new event, since the InternalEventHandler deletes the given.", "/ Insert User Code HERE", " request nodes of the subsystem", " request configuration", " This message is received after own services are registered -> test is service registered?", " or after QueryServices was send", " -> test is service registered?", " create a list with all service URI's associated with own JAUS address", " test all own URI's are in the registered list", " update ROS interface", " check for services to discover, but only if a discovery_handler is set", "\t\tif (!p_discover_services[i].discovered) {", " the service was found, forward the address to the callback", "\t\t}", "/ Insert User Code HERE", " This message is received after own services are registered -> test is service registered?", " or after QueryServices was send", " -> test is service registered?", " create a list with all service URI's associated with own JAUS address", " test all own URI's are in the registered list", " update ROS interface", " check for services to discover, but only if a discovery_handler is set", "\t\tif (!p_discover_services[i].discovered) {", " the service was found, forward the address to the callback", "\t\t}", "/ Insert User Code HERE", " remove expired subsystems (not responding to query identification messages)", " send discovery to unicast addresses", " if ROS interface enabled we send component queries to get names for components", " if we descovered all services and have enabled ROS interface we send subsystem and component queries", " we are subsystem -> discover system", "0xFFFF", " we are node -> find subsystem discovery service and register own services", " if this discovery service is included in a component.", " IOP 5a: A QueryIdentification message shall be broadcast by", " every JAUS component on the subsystem at a rate of at least once per 5 minutes for the", " purpose of finding and registering services with the Discovery service.", " is set by default...", " send query for services to discover, if these are not in the same subsystem", "\t\t\t\tQueryIdentification msg;", "\t\t\t\tmsg.getBody()->getQueryIdentificationRec()->setQueryType(TYPE_SUBSYSTEM);", "\t\t\t\tprintf(\"[DiscoveryClient] send QueryIdentification to subsystem: %d of type: %d (SUBSYSTEM)\\n\", subsystem_id, TYPE_SUBSYSTEM);", "\t\t\t\tsendJausMessage(msg,JausAddress(subsystem_id, 0xFF, 0xFF)); //0xFFFF, 0xFF, 0xFF", "/ Insert User Code HERE", " do not register, if we have no services to register setted by appendServiceUri()", "\t\t\t\tQueryServices msg;", "\t\t\t\tQueryServices::Body::NodeList nlist;", "\t\t\t\tQueryServices::Body::NodeList::NodeSeq nseq;", "\t\t\t\tQueryServices::Body::NodeList::NodeSeq::NodeRec nreq;", "\t\t\t\tQueryServices::Body::NodeList::NodeSeq::ComponentList clist;", "\t\t\t\tQueryServices::Body::NodeList::NodeSeq::ComponentList::ComponentRec creq;", "", "\t\t\t\tnreq.setNodeID(jausRouter->getJausAddress()->getNodeID());", "\t\t\t\tcreq.setComponentID(jausRouter->getJausAddress()->getComponentID());", "\t\t\t\tclist.addElement(creq);", "\t\t\t\tnseq.setComponentList(clist);", "\t\t\t\tnseq.setNodeRec(nreq);", "\t\t\t\tnlist.addElement(nseq);", "\t\t\t\tmsg.getBody()->setNodeList(nlist);", " add a discovery service for ReportSubsystemLIst", " it was the discovery service where we register our services. We need to register again.", " remove expired subsystems", "/ Insert User Code HERE", " search in own services", "\tint query_type = TYPE_SUBSYSTEM;", "\tunsigned short subsystem_id = subsystem;", "\tQueryIdentification msg;", "\tmsg.getBody()->getQueryIdentificationRec()->setQueryType(query_type);", "\tROS_DEBUG_NAMED(\"DiscoveryClient\", \"discover, send QueryIdentification to subsystem: %d\", subsystem_id);", "\tsendJausMessage(msg,JausAddress(subsystem_id, 0xFF, 0xFF)); //0xFFFF, 0xFF, 0xFF", "0xFFFF, 0xFF, 0xFF", " go through all discovered robots", "\t\tit->second.clear();", "\t\tp_discover_callbacks.erase(it);"], "Discovery_ReceiveFSM": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", " Extract the sender information", " define filter for requested configuration", " HACK to avoid long wait times after restart only the component with discovery service", " check subsystem ID: 65535 -> all subsystem IDs", " check node ID: 255 -> all node IDs", " check the component ID; 255 -> all components of the node", " check node ID: 255 -> all node IDs", " check the component ID; 255 -> all components of the node", " add only the discovery services of a subsystems", " new requester", " services was not requested -> send on second "], "EventReceiver": ["**********           LICENSE HEADER   ******************************", "", "", "", "", "/ Run receive loop...", " Let each inherited child handle the internal event differently...", " free the incoming message", "/ Wait for message to be received"], "jFixedLengthString": ["**********           LICENSE HEADER   ******************************", " If the provided const char* is longer than the jFixedLengthString", " they are NOT equal", " If the provided string is longer than the jFixedLengthString", " they are NOT equal", " 2 jFixedLengthStrings need to be identical (same size and contents) for them", " to be equal.", " If the provided string is longer than then FixedLengthString this function", " will return true.", " If the sizes of the 2 jFixedLengthStrings are not the same then they are not equal."], "Service": ["**********           LICENSE HEADER   ******************************", "Service::Service(Router *msgRouter)", " Invoke the FSM transition for this event.  If no explicit transition", " is defined, try a default transition..."], "SimpleThread": ["**********           LICENSE HEADER   ******************************", "", "", ""], "Address": ["**********           LICENSE HEADER   ******************************"], "JrLogger": ["www.gnu.org/licenses/>.", "", " Return a reference to the active stream.", "", " Check the message type against the current level.", " If the message type is too high for the current level,", " return a closed stream (no output).", " If the file stream is not open, just use standard out", "", " Start a new enty on the active stream", "", " get the desired stream", " flush any previous messages", " Insert formatted text", "", " helper function to convert the numberation to a string literal", "", "", " Open the given log file for output", "", " If the stream is current open, close it.", " Open the given filename", "", " closes the log file.  Subsequent log outputs", " will be forced to standard out.", ""], "JUDPTransport": ["www.gnu.org/licenses/>.", " Read the configuration file, and set-up defaults for anything", " that isn't specified.", " Set-up the multicast address based on config data", " Must initialize the windows socket library before using", " Create the socket", " Bind the socket to the public JAUS port", " Increase the size of the send/receive buffers", "", " Set-up for multicast:", "  1) No loopback", "  2) TTL value set by configuration file", "/ 3) Send out our socket.", "  4) Join the multicast group set by configuration file", "", "", " INADDR_ANY join the multicast group on the default NIC", "    always do this, just in case _interfaces.size() == 0", "", " Using INADDR_ANY causes us to join the multicast group, but only", " on the default NIC.  When multiple NICs are present, we need to join", " each manually.  Loop through all available addresses...", " Get a list of IP addresses associated with this host.", " do not print error if it is allready in use. This is already bind by join to any address.", " UDP sockets support run-time discovery.  It's also possible, however,", " to initialize the map statically through a config file.", " Assume the worst...", "", " Get the destination id from the message.", "", "", " Creating a byte stream (payload) for the message", "", "", " Loop through all known destination, sending to each match.", "", " Store a local variable for convenience", " Check this ID against the message's destination", "", " Change the destination to the specific JAUS_ID.  In most cases,", " this does nothing.  In some cases, it will remove wildcard characters", " to prevent messages from being repeatedly forwarded.  This", " must be done before the message is packed.", "", " NOTE!!! We should optimize this later so we're not always", " packing the message for each destination.", "", "", " Now pack the message into the transport archive.  Note that the", " header format depends on the version, which in turn depends on", " the presence of a non-zero message code.", "", " If we've received a message from this destination before, use", " the version of that received message.", " pack for the selected version", " Create the destination address structure", " Lastly, send the message.", " Note that we may have changed the destination of the message,", " so we need to restore it before returning.  In most cases,", " this will do nothing.", " Check the recv port in a loop, exiting only when we have", " no messages in the buffer (or we received 10 packets).", " See if we have anything waiting before we call recvfrom", " Check the socket for a message", "", " Pull off the source IP info for convenience.", "", "", " Getting to this point means we have a message.", " Check what type, so we use the appropriate archive.", "", " Otherwise, set the data from the receive buffer.", " A single packet may have multiple JAUS messages on it, each", " with there own header compression flags.  We need to parse through", " the entire packet, remove each message one at a time and", " adding it to the return list.", " Extract the payload into a message", "", " Add the source to the transport discovery map.", " We also need to remember the format that was used.", "", " Add the message to the list and change the return value", " Remove this message from the archive, so", " we can process the next message in the packet.", " If we didn't find any message, return NoMessage.  Otherwise, Ok.", "", " Now pack the message for network transport.  If the message contains", " a zero command code, use the AS5669A header.  Otherwise, use", " the AS 5669 header", "", " Create the destination address structure", " Send message on all available interfaces", " Lastly, send the message."], "OS": ["www.gnu.org/licenses/>.", " Windows gives us the createProcess function.  We just need to", " make sure it doesn't already exist.", " turn off the window", " Now create the process that points to the path", " Wait for it to spool up before returning", " For Unix, we need to fork and manually start the new process", " First check for existence of the process", " Not found.  Start a new process...", " Getting here means we failed to start the process", " Wait for it to spool up before returning", " Return the current time (in milliseconds)", " Return a list of IP addresses with all the NIC associate with this host", " Windows doesn't support ioctl calls, and the gethostbyname is a", " better method anyway....", " On Linux, we can use getifaddrs supported by BSD libraries.", " Loop through each interface, adding the address to the list", " We need to free the memory allocated by getifaddrs", " Brute force.  Sleep until we pass the elapsed time.", " We don't want the user to have to mess with the", " stupid signal_t stuff, so provide translation.", " stop any existing timers...", " Spawn a thread that sleeps for the requested duration.", " We do this since the Mac API doesn't have a lot", " of good options for asynchronous timers.", " posix timers.", " thread died on run to completion."], "XmlConfig": ["www.gnu.org/licenses/>.", " Cast the TinyXML errors to our enum", " getValue implementations make use of templated accessor", " Get the first occurrence of the requested element", " Loop through the index values to find the requested element number", " Now that we have the right element, pull the requested attribute.", " Success!", " Get the first occurrence of the requested element", " Walk through the attributes, returning a string for each"], "JausTransport": ["**********           LICENSE HEADER   ******************************", "", "/ Pull the destination ID", " If the destination is local, loopback to the routeMessage function", " Otherwise, forward Message to NodeManager.", "JrErrorCode ret =", " Send a message to ourselves to wake-up the thread", " See if we got an exit signal while we were pending", " Create a component message wrapper to pass to the services...", " throttle"], "JuniorAPI": ["www.gnu.org/licenses/>.", " This function checks all known handles for pending", " messages.  Any handle with 1 or more messages", " waiting is returned in the list.  This function does", " not allocate any memory; therefore, the list must be", " allocated by the calling application, with a maximum", " size passed in 'size_of_list'.  This value will be modified", " to equal the total number of handles with messages waiting.", "", " Check each known handle for outstanding messages.", " If we actually have more handles with messages than", " the list allows us to return, mark as Overflow.", " Create and initialize Junior Manager, to manage this", " connection to the RTE.", " find it in the static list"], "JuniorMgr": ["www.gnu.org/licenses/>.", " Initialize config data", " as a message count", " in seconds", " in milliseconds", " clear priority queue", " Found a non-empty buffer.  Pop the message out and delete data.", " Check each priority based send buffer (highest first) looking for a message to send.", " Found a non-empty buffer.  Pop the message out and return the data.", " Normally, the Manager forward messages directly to the JuniorRTE", " for intelligent distribution.  When building for a single application,", " however, the Run-Time Engine is disabled.  Some of the intelligence", " must therefore be pulled into the Manager.", " Regular send", " If we don't have an entry in our address book, broadcast this message.", " First set the ack/nak bit, though, so that if we do find the endpoint", " we can learn its address.", " If the destination contains wildcards, or we didn't find", " a match, broadcast it.", " Send this message to all recipients on all transports.", " Returns the number of messages waiting, either in a local buffer or", " in the queue", " Helper function to detect duplicate messages", " This checking can be configured off.", " Make sure this entry isn't old (in time)", " Check if this element is a match for the incoming message", " Increment the iterator to check the next element", " Push this message into our recently received list, so we", " can detect future duplicates.  Make sure our list doesn't get too big.", " This code works, but is absolutely atrocious.", " I need to rework this for improved readability.", " This function checks the large message buffer", " (a temporary holding cell while we wait for all the pieces", " of a divided message) for completed transmissions.", " If the message in the history buffer is too old, discard it.", " This prevents us from filling the buffer with partial messages", " that never found a mate.", " Discard the message and remove from the list", " If this is the first message of a sequence, try to find the rest of 'em.", " Search the message list for the next one in the sequence.", " If we didn't find the next message in the sequence,", " break from this interior \"while\" loop, returning to", " the \"for\" loop.", " If this message is not the last message in the sequence,", " continue the interior \"while\" loop until we find a missing", " message or the true end.", " Getting to this point means we know that all the messages", " in a sequence are available.  Reconstruct the original message.", "std::cout << \"big message ok with \" << msgcount << \" parts\" << std::endl;", " Now that we have a complete message, add it to the delivery buffer", " and remove it from the unfinished message buffer.", " Last, we need to erase the first message in the set from", " the large message buffer.  Note that we don't delete", " the actual message, since it still needs to be delivered to the app.", " Try the next message in the buffer", " If the source of this message is the RTE, throw it away.", " If this is an ack/nak response or a duplicate message, disregard it.", " If this message is part of a larger set, add it to the", " \"waiting for a complete\" message queue.", " We need to manage the large message buffer, so we don't have messages", " that never vanish.", " Otherwise, put the message in a priority-based buffer, being", " careful to make sure that the priority is in range.", " Check for degenerate case", " Modify the priority to not exceed the 4 bit space", "    printf(\"send with prio: %d, flags: %d\\n\", priority, flags);", " As per the Standard, ServiceConnection and ACK/NAK cannot", " be set at the same time", " If the destination identifier contains wildcard characters,", " we need to route the message as a broadcast instead of a unicast.", " This is a broadcast, so make sure we turn off ack/nak,", " and we meet the size limit (broadcasts cannot be parsed into", " multiple packets.", " If we're not trying to detect duplicate messages, we follow JAUS 5669, v1.", " As a result, the sequence number must start at zero for large data sets.", " We can never send more than 4079 bytes in a single", " message, so break up large data sets.", " printf(\"PID of this process: %d\\n\", getpid());", " Create the message", " The outstanding ACK request is shared with the receive loop.", " Increment the counter so the next message gets a new sequence number", " Set the payload, being careful not to exceed", " 4079 bytes on any individual message.", " Fill in the data control flags, so the receiver", " can piece together the original message if it was", " broken up.", " Send the message to the RTE for distribution", " not used in", "        // Pend here for ACK-NAK.  This will be triggered by the JrReceive call.", "        // We wait a configurable period of time, resend a configurable number of times.", "        if (flags & GuaranteeDelivery)", "        {", "\t\t\tunsigned long last_msg_time = JrGetTimestamp();", "            unsigned int send_count = 0;", "            while (!_outstanding_ack_request_acked)", "            {", "", "                // See if it's time to resend the message (or timeout)", "                if ((unsigned long)(JrGetTimestamp() - last_msg_time) > _ack_timeout)", "                {", "\t\t\t\t\t// If we exceeded the max tries count, return failure", "                    if (++send_count > _max_retries)", "\t\t\t\t\t\treturn Timeout;", "", "\t\t\t\t\t// If we have to resend a message that is part of a large data", "\t\t\t\t\t// stream, the data control flags need to be updated.  This", "\t\t\t\t\t// seems wonky to have to do, but it's part of JAUS.", "\t\t\t\t\tif (msg.getDataControlFlag() == Message::MiddleMsg)", "\t\t\t\t\t\tmsg.setDataControlFlag(Message::MiddleResentMsg);", "", "\t\t\t\t\t// Resend the message and update the \"last sent\" timestamp", "                    sendOrBroadcast(msg);", "                    last_msg_time = JrGetTimestamp();", "                }", "", "\t\t\t\t// sleep a bit to free up the CPU", "                JrSleep(10);", "            }", "        }", " continue to loop until we've sent", " the entire buffer.", " Put the entire message in an archive, so we can", " Check the socket for incoming messages.", " Transport::TransportError ret =", " Process each message in the received list", " Extract the message from the list", " Found a message.  Form a response if ACK/NAK selected.", " Check if this is the acknowledgement we've been waiting for.", " Found a match.  Signal to the send call that it", " no longer has to wait on the ack.", " Add this message to a priority buffer", " Either this is a NAK, or an unexpected ACK. Silently discard.", " Check each priority based buffer (highest first) looking for a message", " to deliver.", " Found a non-empty buffer.  Pop the message out and return the data.", " Extract the data fields", " Assume success", " Create a return buffer big enough to the data", " Delete the message and return the allocated buffer", " Getting to this point means we have no messages to return.", " Connect() directly uses the JUDPTransport library when using a single point", " Junior version.  This is not recommended for general use, and is intended", " only for limited functionality targets, like handheld devices (iPhone).", " For single application, we don't use configuration files.", " All parameters are pre-compiled defaults.", " Set-up the data logger", " Check for degenerate value", " Make sure the ID doesn't contain any wildcards.", " Connect() implementation for full Junior version that includes Run-Time Engine", " and application-to-application message support.", " Parse the config file & read logger settings", " Now set-up the data logger", " Check for degenerate value", " Make sure the ID doesn't contain any wildcards.", " Spawn the RTE.  Note that hte spawn process will", " ensure that we don't create a duplicate.", " NOTE: We assume that someone else runs NodeManager for us.", " JrSpawnProcess(\"NodeManager\", config_file);", " The name of our local socket is the string form of our ID.", " First open a socket with the given name.", " We only send to the RTE, so we can explicitly connect", " Send a connection request.  This will cause the RTE", " to look for private traffic on a socket with the Identifier name.", " Wait for a connection accept message", " timeout.", "            JrError << \"Timeout waiting for response from Run-Time Engine (Timeout=\" << connection_timeout << \")\\n\";", " Resend the connection request msg", " Check for incoming messages", " Switch the socket to PEND mode", " Success.  Store values", " Initialize config data from file", " we send through domain socket, the messages should be save or we have  another problems...", " config.getValue(_max_retries, \"MaxAckNakRetries\", \"API_Configuration\");", " config.getValue(_ack_timeout, \"AckTimeout\", \"API_Configuration\");"], "ChecksumCRC": ["**********           LICENSE HEADER   ******************************", "  Accumulate one byte of data into the CRC.", "  For a \"message\" of length bytes contained in the unsigned character", "  array pointed to by pBuffer, calculate the CRC."], "JausAddress": ["**********           LICENSE HEADER   ******************************"], "JrSockets": ["www.gnu.org/licenses/>.", " Returns the number of messages waiting in the queue", " for Linux, we can't know the number of messages, just that", " there is more than zero.", " For Windows, we need to open a mailslot back to the sender, if we", " don't already have it.", " For Unix, we just use the ID as the name of the socket.", " The AddressMap class will prevent duplicates.", " Serialize the message before sending it.  Note that the header", " version depends on the setting of the message code.", " Send to the given socket", " If the socket is connected, the endpoint is pre-specified.", " We can send the archive without much fuss.", " Send it to the connected socket", " Otherwise, send to the destination id specified.  Note that the destination", " specified in the message may contain wildcard characters.  We need to loop", " through all known destinations, sending to any that match (except the source).", " If we failed to send to this destination, remove", " it from our map.", " Restore the initial destination identifier before we return.", " Assume we don't have any messages to return...", " Recv the message into a finite sized buffer", " Check the recv port in a loop, exiting only when we have", " no messages in the buffer (POLL) or we've received 1 messages (PEND)", " Read the mailslot as if it's a file descriptor", " See if we have anything waiting before we call recvfrom", " Getting here means we have a message.  Read and process it.", " If we didn't receive anything, break from the read loop.", " Now that we have a datagram in our buffer, move it to an archive.", " And unpack it...", " If we're not a connected socket, open a response", " channel to the sender so we can talk to it later.", " Add the message to the MessageList and change the return value", " Connected sockets send to a single destination only.", " Loop through all known destinations, sending the message to", " each socket that matches the destination (including wildcards).", " If we failed to send to this destination, remove", " it from our map.", " Set-up is considerably different for UNIX sockets and", " Windows named pipes.", " Create the socket", " Bind to the given filename", " in case of restart nodes we need to wait until previous node unlinks the socket", " Read the configuration file for buffer size info", " Increase the size of the send/receive buffers", " Connect to the given endpoint", " For Windows, we need to close the mailslot associated", " with this destination", " Remove this destination from the map"], "Send": ["**********           LICENSE HEADER   ******************************", " removed namespace to avoid compiler erro C2872 in visual studio", "namespace JTS", "{", "", "/ Initiliaze the protected variables", "/ Copy the values", "", "/ Initiliaze the protected variables", "/ Copy the values", "", " This case should never be true since it should not be possible", " for the two variables to have equal lengths but one has no data.", " This check is placed here as a secondary check.", " This case should never be true since length should be equal but is", " placed here as a secondary check", "/ Initiliaze the protected variables", "/ Copy the values", "", "/ No Initialization of m_DestinationID necessary.", "/ No Initialization of m_SourceID necessary.", "/ No Initialization of m_MessagePayload necessary.", "/ Initiliaze the protected variables", "/ No Initialization of m_DestinationID necessary.", "/ No Initialization of m_SourceID necessary.", "/ No Initialization of m_MessagePayload necessary.", "/ Copy the values", "", "/ This code is currently not supported", "/ This code is currently not supported", "/ This code is currently not supported", "/ No Initialization of m_SendRec necessary.", "/ Initiliaze the protected variables", "/ No Initialization of m_SendRec necessary.", "/ Copy the values", "/ This code is currently not supported", "", "/ No Initialization of m_Body necessary.", "/ Initiliaze the protected variables", "/ No Initialization of m_Body necessary.", "/ Copy the values", "}"], "Receive": ["**********           LICENSE HEADER   ******************************", " removed namespace to avoid compiler erro C2872 in visual studio", "namespace JTS", "{", "", "/ Initiliaze the protected variables", "/ Copy the values", "", " This case should never be true since it should not be possible", " for the two variables to have equal lengths but one has no data.", " This check is placed here as a secondary check.", " This case should never be true since length should be equal but is", " placed here as a secondary check", "/ Initiliaze the protected variables", "/ Copy the values", "", "/ No Initialization of m_SourceID necessary.", "/ No Initialization of m_MessagePayload necessary.", "/ Initiliaze the protected variables", "/ No Initialization of m_SourceID necessary.", "/ No Initialization of m_MessagePayload necessary.", "/ Copy the values", "", "/ This code is currently not supported", "/ This code is currently not supported", "/ This code is currently not supported", "/ No Initialization of m_ReceiveRec necessary.", "/ Initiliaze the protected variables", "/ No Initialization of m_ReceiveRec necessary.", "/ Copy the values", "/ This code is currently not supported", "", "/ No Initialization of m_Body necessary.", "/ Initiliaze the protected variables", "/ No Initialization of m_Body necessary.", "/ Copy the values", "}"], "InternalEventHandler": ["**********           LICENSE HEADER   ******************************", "#define DEBUG"], "JUDPTransportLB": ["www.gnu.org/licenses/>.", " Read the configuration file, and set-up defaults for anything", " that isn't specified.", " Set-up the multicast address based on config data", " Set-up the loopback address based on config data", " Must initialize the windows socket library before using", " Create the socket", " Bind the socket to the public JAUS port", " Increase the size of the send/receive buffers", "", " Set-up for multicast:", "  1) No loopback", "  2) TTL value set by configuration file", "/ 3) Send out our socket.", "  4) Join the multicast group set by configuration file", "", " Using INADDR_ANY causes us to join the multicast group, but only", " on the default NIC.  When multiple NICs are present, we need to join", " each manually.  Loop through all available addresses...", " Get a list of IP addresses associated with this host.", " UDP sockets support run-time discovery.  It's also possible, however,", " to initialize the map statically through a config file.", " Assume the worst...", "", " Creating a byte stream (payload) for the message", "", " pack for the selected version", " Create the destination address structure", " Lastly, send the message.", " Check the recv port in a loop, exiting only when we have", " no messages in the buffer (or we received 10 packets).", " See if we have anything waiting before we call recvfrom", " Check the socket for a message", " If we didn't find any message, return NoMessage.  Otherwise, Ok.", "", " Now pack the message for network transport.  If the message contains", " a zero command code, use the AS5669A header.  Otherwise, use", " the AS 5669 header", "", " Create the destination address structure", " Send message on all available interfaces", " Just get the first interface", " if it is not the end, setup and send", " Lastly, send the message."], "jts_node_manager": ["**********           LICENSE HEADER   ******************************", " Main loop", " Pull the config file from the command line arguments"], "JSerial": ["www.gnu.org/licenses/>.", " Define JSerial constants", " Some values are different in Linux/Windows environment", "./\"", " For Linux, we also need to convert baud rates", " into the supported enum values.", " Class definition", " Check for valid parameters", " debug", " Get the Data Control Block", " Set-up for configured parity, baud, and stop", " Configure for software flow control (XOn/XOff)", " Configure for hardware flow control (RTS-CTS)", " Get comm timeouts", " Set the comm timeouts to values we like", " Get the current options set", " set the baud rate", " set the character size", " set the parity", " set the stop bits", " Set receiver and local modes", " flow control (hardware or software)", " Configure for software flow control (XOn/XOff)", " Configure for hardware flow control (RTS-CTS)", " enable raw mode (this prevent interpretation of", " the data stream for things line CR-LR", " set the timing (no wait)", " Set the new options", " Pull the com port name and compatbility mode", " Open a file for reading/writing to the port", " Open a file descriptor", "| O_NDELAY", " Check for valid response", " Configure the link for parity, baud rate, etc.", " Only send messages if the destination is known to us", " Send to this entry", " Assume the best...", "", " Now pack the message for network transport", "", " Write to the open port", " make sure we wrote the whole packet", " Read from the serial port", "JrError << \"Failed to read serial port.  Error:\" <<  getlasterror << std::endl;", " Nothing to do if we didn't read any bytes", " We need to process the incoming stream byte-wise, since the", " stream may contain DLE-marked instructions.", " Previous byte was a DLE marker.  Next byte", " tells the interpretation of the instruction.", " DLE was used to mark a data element that", " coincidentally had the same value as the", " DLE marker.  Strip the unnecessary DLE from", " the packet.", " DLE marks a packet start.  See if the", " unused bytes contain a valid packet", " Update the log if we're discarding", " a non-empty packet", " Now clear the unused bytes buffer", " so we can start the new packet.", " Add the DLE marker (from the previous byte)", " as well as the current byte to the", " unusedBytes buffer.", " Reset the flag indicating previous byte was DLE", " DLE marker preceding special byte.", " regular data byte", " Check packet for completeness.  If so, parse message(s).", " done processing this read.  return.", " Broadcast for serial is the same as a send.", " Check for trivial case", " A single packet may have multiple JAUS messages on it, each", " with there own header compression flags.  We need to parse through", " the entire packet, remove each message one at a time and", " adding it to the return list.", " Extract the payload into a message", "", " Add the source to the transport discovery map.", "", " Add the message to the list and change the return value", " Remove this message from the archive, so", " we can process the next message in the packet.", " Clear the data buffer and return"], "JuniorRTE": ["www.gnu.org/licenses/>.", " Define a signal handler, so we can clean-up properly", " Main loop", " This is the main entry point for hte Junior Run-Time engine.", " First thing we need to do is initialize the log, but we can't", " do that until we read in the log file name from the configuration", " file.  So we start with opening and parsing the config file...", " preset-up the data logger", " We can finally output some proof-of-life info", " Now set-up the data logger", " And now we can read the rest of the config file, with the benefit", " of logging....", " For linux, we need to break from the parent's signals", " Create the public socket that allows APIs to find us.", " Catch the termination signals", " Maintain a list of connected clients.  Note that we store the", " raw unsigned long, rather than the JAUS_ID, so that operator== means", " \"strictly equal to\".  This allows us to detected when a message is for a local", " client, and a local client only (it contains no wildcard characters).", " Create a list of all supported transports.", " Add UDP, if selected", " Create the transport object, initialize it, then add it to the list.", " Add UDP Loopback, if selected", " Create the transport object, initialize it", " Add TCP, if selected", " Add Serial, if selected", " decrement the count for the next loop", " instantiate a new serial transport.", " Since we can support multiple serial connections, each", " one must have an zero-based index associated with it.", " Predefine a list of messages we receive from the transports.", " Process messages.", " Wait a bit so we don't hog the CPU", " Check the public socket for outgoing requests", " Get the first message from the list", " Process the message request", " Connection request from client.", " Disconnect client.", " If the destination contains no wildcards, try to send it", " as a point-to-point message.", " Send this message to the recipients on any transport.", " skip if the loopback transport", " send out the loopback if JSockets or JSerial transport matchFound to capture with Wireshark", " If we don't have an entry in our address book, broadcast this message.", " First set the ack/nak bit, though, so that if we do find the endpoint", " we can learn its address.", " If the destination contains wildcards, or we didn't find", " a match, broadcast it.", " Send this message to all recipients on all transports.", " Done with this message.", " Now check receive messages on all other transports", " Don't check the socket in this loop, since we already did it.", " Get the first message from the list", " In repeater mode, the Junior RTE will broadcast any incoming message", " on all interfaces.  THIS MODE SHOULD BE USED WITH CAUTION!!!", " If multiple junior instances are set to repeater mode, network traffic", " will continuous bounce between them until the end of time.", " If relay is off, or this message is intended for a local client (and a", " local client only), send it only on the socket interface.", " Match found.  Send to the socket interface.", " Otherwise, forward this message on all channels (unless it originated locally)", " If the transport is JSerial, forword the recived msg out the loopback port", " Done processing this message", " Received termination signal.  Clean-up"], "TCPConnection": ["www.gnu.org/licenses/>.", " TCP Connection class implementation", " Helper function to send to a given socket", " Serialize the message to send.", " By default, a JTCPArchive includes the version byte.", " After we send the first message, however, the version byte is not needed.", " Send the data", " We need to check the socket for waiting data.  If we", " process data on the socket, we can", " subsequently check the archive to see if it contains a full", " message.  Any messages get added to the list returned", " to the caller.", " getting here means we have data.  pull it.", " Since TCP data represents a stream, we can't assume the data", " read represents a complete message.  Add it to the data previously", " received.", " If we've accrued a valid packet, shape it into a message", " Make sure we record the JAUS_ID of the sender", " Add the message to the list and change the return value", " Remove this message from the archive.", " Implementation for Connection List Manager", " Make sure we don't already have a connection.", " Create the TCP Connection object for this socket", " Add it to the map", " Make sure we have a connection.", " Close it", " And remove from the map", " Loop through the map entries, deleting the connection", " before clearing the entire map.", " check for null case. JAUS ids of zero are not permitted.", " look-up connection by JAUS id.  This is a little harder since we have", " to romp through the map manually.", " These functions act on all elements in the list", " remote entity has closed the connection", " be careful removing this element from the map.  we need to", " update the iterator BEFORE erasing the element.", " manually increment the iterator for the next loop"], "JTCPTransport": ["www.gnu.org/licenses/>.", " Helper function.  This needs to be static so we can", " call it from pthread_create.", " TCP Class implementation", " Read the configuration file, and set-up defaults for anything", " that isn't specified.", " Must initialize the windows socket library before using", " Create the socket", " Set the socket option to permit immediate re-use after close", " Bind the socket to the specified port", " Set the socket as a listening socket since it's TCP based", " Increase the size of the send/receive buffers", " Initialize the address book", " Spawn the thread that will accept incoming connections", " Get the destination id from the message.  ", " Also note which header version we're using", " First check to see if we have an open socket.", " Didn't find a match in the list of open sockets.", " Do we know the ip address for the given destination?", " Didn't find a match of known addresses.  Since", " TCP only supports point-to-point connections,", " we have no way of sending this message.", " Try to open a socket to the specified IP address", " Connect to the given IP address and port", " Add this to the connection list.  The list manager will create", " the connection object.", " debug", " Also set the JAUS_ID & version for this destination.", " Getting to this point means we have a valid connection object for", " the specified destination.  Try to send the message.  If it fails,", " close the connection.", " TCP doesn't support true broadcast.  Best we can do is send ", " the message on all known sockets.", " keep looping until requested to exit", " we need to seed the address size before calling accept()", " wait for new connection requests", " throw a little debug", " Add this connection to the list"], "LivenessPlugin": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko "], "Liveness_ReceiveFSM": ["", "www.gnu.de/documents/gpl-2.0.html>", "* \\author Alexander Tiderko ", "/ Insert User Code HERE", "/ Insert User Code HERE"]}, "code_comments_python": {"cpp": ["!/usr/bin/python", " ROS/IOP Bridge", " Copyright (c) 2017 Fraunhofer", "", " This program is dual licensed; you can redistribute it and/or", " modify it under the terms of the GNU General Public License", " version 2 as published by the Free Software Foundation, or", " enter into a proprietary license agreement with the copyright", " holder.", "", " This program is distributed in the hope that it will be useful,", " but WITHOUT ANY WARRANTY; without even the implied warranty of", " MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the", " GNU General Public License for more details.", "", " You should have received a copy of the GNU General Public License", " along with this program; or you can read the full license at", " <http://www.gnu.de/documents/gpl-2.0.html>", "", " :author: Alexander Tiderko", "### %s #### */\" % fshort)"], "chmerge": ["!/usr/bin/python", " ROS/IOP Bridge", " Copyright (c) 2017 Fraunhofer", "", " This program is dual licensed; you can redistribute it and/or", " modify it under the terms of the GNU General Public License", " version 2 as published by the Free Software Foundation, or", " enter into a proprietary license agreement with the copyright", " holder.", "", " This program is distributed in the hope that it will be useful,", " but WITHOUT ANY WARRANTY; without even the implied warranty of", " MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the", " GNU General Public License for more details.", "", " You should have received a copy of the GNU General Public License", " along with this program; or you can read the full license at", " <http://www.gnu.de/documents/gpl-2.0.html>", "", " :author: Alexander Tiderko", "TODO: Added a proper merge function to print all errors", "       diff = differ.compare(a, b)", "       result = []", "       removed_lines = []", "       last_removed_line = ''", "       compare2last = False", "       for line in diff:", "         if line:", "           print \"line:\", line", "           if line[0:2] == '? ':", "             if last_removed_line:", "               compare2last = True", "             pass", "           elif line[0:2] == '- ':", "             removed_content = line[2:].strip()", "             if removed_content and removed_content[0] not in ['/', '*', '#']:", "               removed_lines.append(removed_content)", "               last_removed_line = removed_content", "           elif line[0:2] == '+ ':", "             if compare2last:", "               # are tabs replaced by spaces?", "               if not last_removed_line.replace(line[2:].strip(), '').strip():", "                 removed_lines.pop()", "             result.append(line[2:])", "             removed_content = ''", "             compare2last = False", "           else:", "             result.append(line[2:])", "             removed_content = ''", "             compare2last = False", "       if removed_lines:", "         error_msg = \"WARNING: outdated OVERRIDE file:\\n\"", "         error_msg += \"  --> %s\\n\"%hfile", "         error_msg += \"  override files remove the generated code by JAUS toolkit:\\n---\\n%s\\n---\\n\"%'\\n'.join(removed_lines)", "         error_msg += \"  Update your code!\\n\"", "         error_msg += \"You can see all changes by calling:\\n\"", "         error_msg += \"  diff %s.gen %s\\n\"%(srcfile, srcfile)", "         if dstfile.endswith('.h'):", "           error_msgs.append(error_msg)", "         else:", "           print error_msg", "              copy2 (dstfile, \"%s.gen\"%dstfile)", "              print \"JAUS:   you find this file in: %s.gen\"%dstfile", "        file(dstfile, 'w').writelines(result)"], "cpy": ["!/usr/bin/python", " ROS/IOP Bridge", " Copyright (c) 2017 Fraunhofer", "", " This program is dual licensed; you can redistribute it and/or", " modify it under the terms of the GNU General Public License", " version 2 as published by the Free Software Foundation, or", " enter into a proprietary license agreement with the copyright", " holder.", "", " This program is distributed in the hope that it will be useful,", " but WITHOUT ANY WARRANTY; without even the implied warranty of", " MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the", " GNU General Public License for more details.", "", " You should have received a copy of the GNU General Public License", " along with this program; or you can read the full license at", " <http://www.gnu.de/documents/gpl-2.0.html>", "", " :author: Alexander Tiderko"], "mss": ["!/usr/bin/python", " ROS/IOP Bridge", " Copyright (c) 2017 Fraunhofer", "", " This program is dual licensed; you can redistribute it and/or", " modify it under the terms of the GNU General Public License", " version 2 as published by the Free Software Foundation, or", " enter into a proprietary license agreement with the copyright", " holder.", "", " This program is distributed in the hope that it will be useful,", " but WITHOUT ANY WARRANTY; without even the implied warranty of", " MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the", " GNU General Public License for more details.", "", " You should have received a copy of the GNU General Public License", " along with this program; or you can read the full license at", " <http://www.gnu.de/documents/gpl-2.0.html>", "", " :author: Alexander Tiderko", " the defined consts are in the separate file, only add to the knonwn list", " search for const declarations, append to known and replace all used constants", "              declared_const_set_ref", " replace referenced constants", " the declared_type_set is in this service definition, search for first occurrence of 'declared_type_set'", " replace the attributes of referenced object", " in case it is not done before"]}}
,{"git_repo_name": "autorally", "code_comments_file_names": ["setup", "autorally_controller", "ground_truth_republisher", "joystickControlMain", "JoystickControl", "autorally_plant", "status_monitor", "param_getter", "lap_stats", "track_generator", "track_converter", "gpsWaypoint", "ConstantSpeedController", "setup", "__init__", "chronyStatus", "RingBuffer", "Diagnostics", "ImageRepublisher", "RunStop", "ImageMaskEntry", "main_window", "main", "DiagnosticsEntry", "qnode", "SerialSensorInterface", "SerialInterfaceThreaded", "SerialCommon", "systemStatus", "__init__", "wheel_odometry", "StateEstimator", "GPSHemisphere", "CameraTrigger", "AutoRallyChassis", "CameraAutoBalancePtGrey", "CameraAutoBalanceFLIR", "FlycaptureAdjuster", "CameraAutoBalance", "SpinnakerAdjuster", "XbeeNode", "XbeeInterface", "XbeeCoordinator", "SafeSpeed", "serialSensorInterfaceTest", "diagnosticsTest", "pololuMicroMaestroTest"], "md_file_names": ["README", "LICENSE", "README", "README", "LICENSE"], "md_contents": {"README": ["This folder contains the parameters for the AutoRally dynamics models used by MPPI. All of the models take as input 4 (roll, longitudenal velocity, lateral velocity, heading rate) state variables and \n", "the commanded steering and throttle, and they output the time derivative of the state variables.\n", "\n", "## autorally_nnet_09_12_2018.npz \n", "This is a neural network with 2 hidden layers and tanh non-linearities, which means that the total configuration of the network is 6-32-32-4. This network is meant to be used by the class neural_net_model.cuh, which takes the 6-32-32-4 shape as a template parameter. Within neural_net_model.cuh, the model is loaded in by the function \"loadParams(std::string model_path)\", where model path is the path to this file. This network was trained on real world data collected at CCRF on the beta chassis. It was initially\n", "trained to minimize one-step prediction error, and then fine-tuned using back-prop through time in order to minimize multi-step prediction error. For both phases of training stochastic gradient descent with ADAM was used.\n", "\n", "## basis_function_09_12_2018.npz \n", "This model predicts the time derivative of the state as a linear combination of a set of pre-defined basis functions. The basis functions that are used are defined \n", "in the file car_bfs.cuh. This model is meant to be used by the class generalized_linear.cuh, which takes the basis functions defined by car_bfs.cuh as a template parameter. Within\n", "generalized_linear.cuh, the model is loaded in by \"loadParams(std::string model_path)\" where model_path is the path to this file.\n", "\n", "## gazebo_nnet_09_12_2018.npz \n", "This is an old neural network based on the ROS indigo 2.x version of Gazebo. It has the exact same format as autorally_nnet.npz This model should not be used except to compare with previously published results. The paper \"Robust Sampling Based Model Predictive Control with Sparse Objective Information\" presented at RSS 2018 used this model with Gazebo 2.x. Note that with Gazebo 7+ the physics are vastly improved and the model trained on real-world data performs better than this network.\n"], "LICENSE": ["Apache License\n", "Version 2.0, January 2004\n", "http://www.apache.org/licenses/\n", "\n", "TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n", "\n", "1. Definitions.\n", "\n", "\"License\" shall mean the terms and conditions for use, reproduction, and\n", "distribution as defined by Sections 1 through 9 of this document.\n", "\n", "\"Licensor\" shall mean the copyright owner or entity authorized by the copyright\n", "owner that is granting the License.\n", "\n", "\"Legal Entity\" shall mean the union of the acting entity and all other entities\n", "that control, are controlled by, or are under common control with that entity.\n", "For the purposes of this definition, \"control\" means (i) the power, direct or\n", "indirect, to cause the direction or management of such entity, whether by\n", "contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the\n", "outstanding shares, or (iii) beneficial ownership of such entity.\n", "\n", "\"You\" (or \"Your\") shall mean an individual or Legal Entity exercising\n", "permissions granted by this License.\n", "\n", "\"Source\" form shall mean the preferred form for making modifications, including\n", "but not limited to software source code, documentation source, and configuration\n", "files.\n", "\n", "\"Object\" form shall mean any form resulting from mechanical transformation or\n", "translation of a Source form, including but not limited to compiled object code,\n", "generated documentation, and conversions to other media types.\n", "\n", "\"Work\" shall mean the work of authorship, whether in Source or Object form, made\n", "available under the License, as indicated by a copyright notice that is included\n", "in or attached to the work (an example is provided in the Appendix below).\n", "\n", "\"Derivative Works\" shall mean any work, whether in Source or Object form, that\n", "is based on (or derived from) the Work and for which the editorial revisions,\n", "annotations, elaborations, or other modifications represent, as a whole, an\n", "original work of authorship. For the purposes of this License, Derivative Works\n", "shall not include works that remain separable from, or merely link (or bind by\n", "name) to the interfaces of, the Work and Derivative Works thereof.\n", "\n", "\"Contribution\" shall mean any work of authorship, including the original version\n", "of the Work and any modifications or additions to that Work or Derivative Works\n", "thereof, that is intentionally submitted to Licensor for inclusion in the Work\n", "by the copyright owner or by an individual or Legal Entity authorized to submit\n", "on behalf of the copyright owner. For the purposes of this definition,\n", "\"submitted\" means any form of electronic, verbal, or written communication sent\n", "to the Licensor or its representatives, including but not limited to\n", "communication on electronic mailing lists, source code control systems, and\n", "issue tracking systems that are managed by, or on behalf of, the Licensor for\n", "the purpose of discussing and improving the Work, but excluding communication\n", "that is conspicuously marked or otherwise designated in writing by the copyright\n", "owner as \"Not a Contribution.\"\n", "\n", "\"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf\n", "of whom a Contribution has been received by Licensor and subsequently\n", "incorporated within the Work.\n", "\n", "2. Grant of Copyright License.\n", "\n", "Subject to the terms and conditions of this License, each Contributor hereby\n", "grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free,\n", "irrevocable copyright license to reproduce, prepare Derivative Works of,\n", "publicly display, publicly perform, sublicense, and distribute the Work and such\n", "Derivative Works in Source or Object form.\n", "\n", "3. Grant of Patent License.\n", "\n", "Subject to the terms and conditions of this License, each Contributor hereby\n", "grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free,\n", "irrevocable (except as stated in this section) patent license to make, have\n", "made, use, offer to sell, sell, import, and otherwise transfer the Work, where\n", "such license applies only to those patent claims licensable by such Contributor\n", "that are necessarily infringed by their Contribution(s) alone or by combination\n", "of their Contribution(s) with the Work to which such Contribution(s) was\n", "submitted. If You institute patent litigation against any entity (including a\n", "cross-claim or counterclaim in a lawsuit) alleging that the Work or a\n", "Contribution incorporated within the Work constitutes direct or contributory\n", "patent infringement, then any patent licenses granted to You under this License\n", "for that Work shall terminate as of the date such litigation is filed.\n", "\n", "4. Redistribution.\n", "\n", "You may reproduce and distribute copies of the Work or Derivative Works thereof\n", "in any medium, with or without modifications, and in Source or Object form,\n", "provided that You meet the following conditions:\n", "\n", "You must give any other recipients of the Work or Derivative Works a copy of\n", "this License; and\n", "You must cause any modified files to carry prominent notices stating that You\n", "changed the files; and\n", "You must retain, in the Source form of any Derivative Works that You distribute,\n", "all copyright, patent, trademark, and attribution notices from the Source form\n", "of the Work, excluding those notices that do not pertain to any part of the\n", "Derivative Works; and\n", "If the Work includes a \"NOTICE\" text file as part of its distribution, then any\n", "Derivative Works that You distribute must include a readable copy of the\n", "attribution notices contained within such NOTICE file, excluding those notices\n", "that do not pertain to any part of the Derivative Works, in at least one of the\n", "following places: within a NOTICE text file distributed as part of the\n", "Derivative Works; within the Source form or documentation, if provided along\n", "with the Derivative Works; or, within a display generated by the Derivative\n", "Works, if and wherever such third-party notices normally appear. The contents of\n", "the NOTICE file are for informational purposes only and do not modify the\n", "License. You may add Your own attribution notices within Derivative Works that\n", "You distribute, alongside or as an addendum to the NOTICE text from the Work,\n", "provided that such additional attribution notices cannot be construed as\n", "modifying the License.\n", "You may add Your own copyright statement to Your modifications and may provide\n", "additional or different license terms and conditions for use, reproduction, or\n", "distribution of Your modifications, or for any such Derivative Works as a whole,\n", "provided Your use, reproduction, and distribution of the Work otherwise complies\n", "with the conditions stated in this License.\n", "\n", "5. Submission of Contributions.\n", "\n", "Unless You explicitly state otherwise, any Contribution intentionally submitted\n", "for inclusion in the Work by You to the Licensor shall be under the terms and\n", "conditions of this License, without any additional terms or conditions.\n", "Notwithstanding the above, nothing herein shall supersede or modify the terms of\n", "any separate license agreement you may have executed with Licensor regarding\n", "such Contributions.\n", "\n", "6. Trademarks.\n", "\n", "This License does not grant permission to use the trade names, trademarks,\n", "service marks, or product names of the Licensor, except as required for\n", "reasonable and customary use in describing the origin of the Work and\n", "reproducing the content of the NOTICE file.\n", "\n", "7. Disclaimer of Warranty.\n", "\n", "Unless required by applicable law or agreed to in writing, Licensor provides the\n", "Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS,\n", "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied,\n", "including, without limitation, any warranties or conditions of TITLE,\n", "NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are\n", "solely responsible for determining the appropriateness of using or\n", "redistributing the Work and assume any risks associated with Your exercise of\n", "permissions under this License.\n", "\n", "8. Limitation of Liability.\n", "\n", "In no event and under no legal theory, whether in tort (including negligence),\n", "contract, or otherwise, unless required by applicable law (such as deliberate\n", "and grossly negligent acts) or agreed to in writing, shall any Contributor be\n", "liable to You for damages, including any direct, indirect, special, incidental,\n", "or consequential damages of any character arising as a result of this License or\n", "out of the use or inability to use the Work (including but not limited to\n", "damages for loss of goodwill, work stoppage, computer failure or malfunction, or\n", "any and all other commercial damages or losses), even if such Contributor has\n", "been advised of the possibility of such damages.\n", "\n", "9. Accepting Warranty or Additional Liability.\n", "\n", "While redistributing the Work or Derivative Works thereof, You may choose to\n", "offer, and charge a fee for, acceptance of support, warranty, indemnity, or\n", "other liability obligations and/or rights consistent with this License. However,\n", "in accepting such obligations, You may act only on Your own behalf and on Your\n", "sole responsibility, not on behalf of any other Contributor, and only if You\n", "agree to indemnify, defend, and hold each Contributor harmless for any liability\n", "incurred by, or claims asserted against, such Contributor by reason of your\n", "accepting any such warranty or additional liability.\n", "\n", "END OF TERMS AND CONDITIONS\n", "\n", "APPENDIX: How to apply the Apache License to your work\n", "\n", "To apply the Apache License to your work, attach the following boilerplate\n", "notice, with the fields enclosed by brackets \"[]\" replaced with your own\n", "identifying information. (Don't include the brackets!) The text should be\n", "enclosed in the appropriate comment syntax for the file format. We also\n", "recommend that a file or class name and description of purpose be included on\n", "the same \"printed page\" as the copyright notice for easier identification within\n", "third-party archives.\n", "\n", "   Copyright [yyyy] [name of copyright owner]\n", "\n", "   Licensed under the Apache License, Version 2.0 (the \"License\");\n", "   you may not use this file except in compliance with the License.\n", "   You may obtain a copy of the License at\n", "\n", "     http://www.apache.org/licenses/LICENSE-2.0\n", "\n", "   Unless required by applicable law or agreed to in writing, software\n", "   distributed under the License is distributed on an \"AS IS\" BASIS,\n", "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n", "   See the License for the specific language governing permissions and\n", "   limitations under the License.\n"]}, "code_comments_c++": {"joystickControlMain": ["********************************************"], "JoystickControl": ["********************************************", "toggle runstop if a runstop toggle button changed from 0 to 1", "can enable/disable throttle control with L2 on game pad, only toggle if button changed from 0 to 1", "can enable/disable steering control with R2 on game pad, only toggle if button changed from 0 to 1"], "autorally_plant": ["********************************************", "Initialize the publishers.", "Initialize the subscribers.", "Timer callback for path publisher", "Initialize auxiliary variables.", "Initialize yaw derivative to zero", "Debug image display signaller", ".clear();", "Update the timestamp", "Set activated to true --> we are receiving state messages.", "Update position", "Grab the quaternion", "Update euler angles. These use the 1-2-3 Euler angle convention.", "Don't allow heading to wrap around", "Update the quaternion", "Update the world frame velocity", "Update the body frame longitudenal and lateral velocity", "Update the minus yaw derivative.", "Interpolate and publish the current control", "Just publish the computed open loop controls", "Compute the error between the current and actual state and apply feedback gains", "Copy network structure into description", "Compute total number of weights", "/< Autorally control message initialization.", "Publish the steering and throttle commands", "Nan control publish zeros and exit.", "No use trying to recover, quitting is the best option.", "Publish the computed control input.", "Everything is good.", "Shutdown timers, subscribers, and dynamic reconfigure", "server_.clearCallback();", "namespace autorally_control"], "status_monitor": ["********************************************"], "param_getter": ["********************************************"], "gpsWaypoint": ["********************************************", "    m_poseSub = m_nh.subscribe(\"Pose\", 1, &GpsWaypoint::Posecb, this);", "    m_paramTimer = m_nh.createTimer(ros::Rate(1),", "                   &GpsWaypoint::paramCallback, this);", " Get our heading from the message", " Now we have all the latest data, do some maths", " Are we at the next waypoint?", " Get the next wp", "ROS_INFO(\"Hit a waypoint\");", " UTM is a ENU system", " imugps node uses a local ENU system", " so our heading is measured from the positive x axis, meaning 0 is pointing east", " and this lets a normal x-y axis system drawn on paper represent our system with x pointing up.", "m_imMask.lines[0].end.x = 256 - (100 * cos((command.steering * PI / 2.0) + PI/2.0));", "m_imMask.lines[0].end.y = 320 - (100 * sin((command.steering * PI / 2.0) + PI/2.0));", " std::cout << \" Error \" << error << \" Steering \" << command.steering;", " std::cout << \"At theta \" << theta << \" bearing \" << bearing;", " std::cout << \" x \" << x << \" y \" << y << std::endl;", " std::cout << \" xn \" << xn << \" yn \" << yn << std::endl;", " std::cout << \" dx \" << deltaX<< \" dy \" << deltaY << std::endl;", "  void GpsWaypoint::Posecb(sensor_msgs::Imu pose)", "  {", "    m_lock.lock();", "    m_pose = pose;", "    m_lock.unlock();", "  }", "void GpsWaypoint::paramCallback(const ros::TimerEvent& time)", "{", "  m_nh.param(\"HeadingP\", m_headingP, 2.0);", "}", "ROS_INFO(\"Publish markers at %f %f and %f %f\", x, y, xwp, ywp);", "ros::NodeHandle n;"], "ConstantSpeedController": ["********************************************", "m_accelerationProfile = generateAccelerationProfile(100);", "m_backWheelsSpeed = 0.2*m_backWheelsSpeed + 0.4*(msg->lbSpeed + msg->rbSpeed);", " NODELET_INFO(\"interp %f, command %f\",p, command->throttle);"], "RingBuffer": ["********************************************", "already have entry from that time", "do not perform extrapolation", "  std::cout << \"Comparing:\" << value << \" to:\";", "    std::cout << buffIt->second << \" \";", "      std::cout << std::endl;", "std::cout << \"Interpolating key between(\" << buffIt->first << \":\" << (buffIt-1)->first <<", "             \")  for value\" << value << std::endl;", "do not perform extrapolation", "std::cout << \"Comparing:\" << key << \" to:\";", "std::cout << buffIt->first << \" \";", "std::cout << std::endl;", "std::cout << std::endl;"], "Diagnostics": ["********************************************", "can retrieve a global diagnosticsFrequency parameter if diagnostics should", "be published at a differenc frequency than 1.0 second", "time", "force the publishing of a diagnostics array based on the desired frequency", "add current overall diagnostic level and message", "Frequency messages are added to diagnotics only if tick() is being called", "remove all tick counts older than 15 seconds", "sum all ticks in the window", "add a diagnostic message with the publishing freq over the sliding window", "strs << sum/((n-mapItF->second.front().second).toSec());", "add new tick entry to vector", "add all queued diganostic messages, clear the queues"], "ImageRepublisher": [" Limit frame rate"], "RunStop": ["********************************************", "publish runsto pat 10Hz into system", "leftfront, rightfront, leftback, rightback, servo, camera", "frame data, and parse if an entire message is waiting", "std::cout << startPosition << \" \" << endPosition << std::endl;", "std::cout << \"message:\" << message.c_str() << std::endl;", "time", "get out all the messages", "std::cout << \".\" << std::endl;", "if no recent message, runstop is false"], "ImageMaskEntry": ["", "pick a random color from", "{Qt::red, Qt::green, Qt::blue, Qt::cyan, Qt::magenta, Qt::yellow}"], "main_window": ["", " Calling this incidentally connects all ui's triggers to on_...() callbacks in this class.", " qApp is a global variable for the application", "ui.backBrakeBar->setFormat(\"Back Brake: %v\");", "automatically connect into ROS system on startup", "ROS_INFO(\"%f\",(time-m_startTime).toSec());", "index", "set image", "set image", "std::cout << warnVal << \" \" << critVal << \" \" << val << std::endl;"], "main": ["", "***************************************************************************", "***************************************************************************"], "DiagnosticsEntry": ["", "newMessage << new QStandardItem(\"1\");", "go through each DiagnosticStatus in the array", "ROS_INFO(\"Looking at %s\", diagIt->name.c_str());", "find the entry in the diagnostics model, otherwise add a new one", "add new item for the sender", "int count;", "bool ok = false;", "QString num;", "update the message just received", "ROS_INFO(\"%s -%s-\", data.key.c_str(), data.value.c_str());", "if its a normal diagnostic message set the text to the value,", "otherwise it is an auto_rally diagnostic that has a level associated", "count = diagMsg->child(i,2)->text().toInt(&ok) + 1;", "ROS_INFO(\"count %d\", count);", "if(ok && diagMsg->child(i,2))", "{", "num.setNum(count);", "ROS_INFO(\"%s\", diagMsg->child(i,2)->text().toStdString().c_str());", "ROS_INFO(\"num [%s]\", QString::number(count).toStdString().c_str());", "diagMsg->child(i,2)->setText(QString::number(count));", "ROS_INFO(\"after\");", "} else", "{", "  ROS_ERROR(\"Bad conversion\");", "}", "ROS_INFO(\"end count %d\", count);", "ROS_INFO(\"updateKeyValue halfway\");", "if it is a new message from the sender, add it", "set the number of messages for the sender", "ROS_INFO(\"updateKeyValue done\");", "remove the row that was clicked on", "set number of messages for parent entry", "go through each nodes diagnostics messages", "go through each message", "remove that entry by index", "only update the times if the model has time data associated with it", "this allows non auto_rally diagnostic messages to be not colored", "consider message stale if a new one has not been received for a while,", "color part of it magenta as well as part of the parent", "there are no key-value pairs with priority, reset bkgnd color"], "qnode": ["", "register my data types so I can pass them around in signals and slots", "qRegisterMetaType<autorally_msgs::servoMSGConstPtr>", "                (\"autorally_msgs::servoMSGConstPtr\");", " explicitly needed since we use ros::start();", " Add your ros communications here.", "\tm_servoCommandTimer = n.createTimer(ros::Duration(0.1), &QNode::ssTimerCallback, this);", "\tm_servoCommandTimer.stop();", "used to signal the gui to shutdown (useful to roslaunch)", "add new item for the sender", "update the runstop", "found more than one sender with the same name", "  if(m_sendServoCommand)", "set colors for stale", " Swap R & B channels", " Copy G channel directly", " get declared transports", "qDebug(\"ImageView::updateTopicList() declared transport '%s'\", it->c_str());", " strip prefix from transport name"], "SerialSensorInterface": ["********************************************", "std::cout << \"Shutting down \" << m_port.c_str() << \" \" << close(fileDescriptor()) << std::endl;", "get current node name to allow access to the serial parameters", "specific to this node", "set timer to be able to pull 25% more data off serial port than possible", "get up to 100 bytes from the com port, add it to the data buffer", "std::cout<<\"true\";", "time", "get up to 100 bytes from the com port, add it to the data buffer", "ROS_INFO(\"Polling\");", "ROS_INFO(\"RECIEVED\");", "data[received]='\\0';", "time", "queue up a status messages", "diag_warn(\"No data within previous second\");"], "SerialInterfaceThreaded": ["********************************************", "clearDataCallback();", "if the serial thread isnt dead yet, wait for it to close", "std::cout << \"Shutting down \" << m_port.c_str() << \" \" << close(fileDescriptor()) << std::endl;", "get current node name to allow access to the serial parameters", "specific to this node", "std::string nName = nodeName;//+((portHandle.length()>0)?\"/\"+portHandle:\"\");", "std::cout << portName+((portHandle.empty())?\"\":\"/\"+portHandle) << std::endl;", "start worker in separate thread", " Watch stdin (fd 0) to see when it has input. ", " Wait up to one seconds. ", " Don't rely on the value of tv now! ", " FD_ISSET(0, &rfds) will be true. ", "callback triggered within same thread", "catch this exception for cleaner shutdown", "condition can notify (wake) other threads waiting for data", "        m_waitCond.notify_all();", "since ros is shutdown and ROS diag messages wouldnt go anywhere", "void SerialInterfaceThreaded::waitForData()", "{", "  boost::unique_lock<boost::mutex> lock(m_waitMutex);", "  m_waitCond.wait(lock);", "}", "bool SerialInterfaceThreaded::waitForData(const long& timeMS)", "{", "  boost::unique_lock<boost::mutex> lock(m_waitMutex);", "  return m_waitCond.timed_wait(lock, boost::posix_time::milliseconds(timeMS));", "}", "time", "queue up a status messages"], "SerialCommon": ["********************************************", "init in Diagnostics", "m_fd = open(port.c_str(), O_WRONLY | O_NOCTTY | O_NDELAY);", "ioctl(m_fd, USBDEVFS_RESET, 0);", "close(m_fd);", "std::cout << port << \" reset\" << std::endl;", "std::cout << port << \" open attempted\" << std::endl;", " structure to store the port settings in", "Get the current options for the port...", "tcgetattr(m_fd, &m_old_port_settings);", "fcntl(m_fd, F_SETFL, 0);", "fcntl(m_fd, F_SETFL, FNDELAY);", "std::cout << port << \" got attributes\" << std::endl;", " set baud rates", " set 8N1", " no parity bit", " even parity", " enable parity", " even parity", " enable parity", " odd parity", " only one stop bit", " two stop bits", "port_settings.c_cflag |= ~CSIZE;  // clear data bit number", " set 5 data bits", " set 6 data bits", " set 7 data bits", " set 8 data bits", " hardware flow control", " software flow control", "this part is important", " enable reading and ignore control lines", "set raw input mode (not canonical)", "  disable pre-processing of input data", " wait for at least 1 character (read doesn't block)", " 0.5 seconds read timeout", "std::cout << baud << std::endl;", "std::cout << port << \" setting attributes\" << std::endl;", " apply the settings to the port", "  wait for connection to be negotiated", "  found this length through experimentation", "std::cout<<(char*)data.c_str();", "ROS_INFO(\"%s\",\"write() failed!\");", "ROS_INFO(\"%s\",\"write() failed!\");"], "wheel_odometry": ["", " debug mode publishes a different message and subscribes to state estimator for easy visualization", " time_delay parameter is measured in seconds - only used in debug mode", " must be transformed to a number of messages (from /wheelSpeeds) to delay calculations of angular velocity", " /wheelSpeeds publish frequency is 70Hz", " initialize with 0.02s as time step", " the /pose_estime does not conform to usual ROS standard of twist in local frame", " X velocity in local frame", " Y velocity in local frame", " Initialize x, y, and heading to match state estimator", " mapping servo values to their corresponding steering angle", " Servo values are negative for left turns, steering angle is positive for left turns", " correct for values to high and too low", "Simulator steering is ideal", " For first timestep, use .02 which is approximately the timestep between wheelSpeeds messages", " approximately straight steering - turn radius +inf", " Delay this node's angular velocity estimate to account for system delays", " useful for lining up state estimator values and odometry values for data validation", " only run in debug mode", " shift buffer to remove old measurement", " add the new measurements to their buffers", " take the next element for current measurements", " update x and y positions in meters", " Two estimations, based on left and right front wheels", " these are the two error metrics published", " velocity_x_var currently is a constant 0.0569", " function for error_velocity_theta_: -0.6398 * exp(-5.1233 * error_velocity_theta_) + 0.7541", " the pose is relative to the header.frame_id reference published", " the twist is relative to the child_fram_id", " debug mode publishes data for visualization purposes", " Row-major representation of the 6x6 covariance matrix - all covariances that follow take same form", " The orientation parameters use a fixed-axis representation.", " In order, the parameters are:", " (x, y, z, rotation about X axis, rotation about Y axis, rotation about Z axis)", " use delayed time for angular z velocity", " covariance matrix takes same form as above", " covariance matrix takes same form as above", " assume instantaneous y velocity is 0", " covariance matrix takes same form as above"], "StateEstimator": ["********************************************", " Convenience for named keys", " GPS pose", " macro for getting the time stamp of a ros message", " temporary variables to retrieve parameters", " Use an ENU frame", " prior on the first pose", " Add velocity prior", " Add bias prior", " we're choosing this as the origin", " we are given an origin", " Add prior factors on pose, vel and bias", "Factor for imu->gps translation", " add prior values on pose, vel and bias", "Read IMU measurements up to the first GPS measurement", "If we only pop one, we need some dt", " add IMU measurements", " adding the integrated IMU measurements to the factor graph", " Predict forward to get an initial estimate for the pose and velocity", " add GPS measurements that are not ahead of the imu messages", " this is a gps message for a factor", " check if the GPS message is close to our expected position", " if only using odom with no GPS, then remove old messages from queue", " if available, add any odom factors that are not ahead of the imu messages", " if we processed imu - then we can optimize the state", " if we haven't added gps data for 2 message (0.2s) then change status", "ros::Time before = ros::Time::now();", " Push the IMU measurement to the optimization thread", " Each time we get an imu measurement, calculate the incremental pose from the last GTSAM pose", "Grab the most current optimized state", " haven't optimized first state yet", "We need to reset integration and iterate through all our IMU measurements", " ROS_INFO(\"IMU time %f, dt %f\", (*it)->header.stamp.toSec(), dt_temp);", " ROS_INFO(\"Resetting Integration, %d measurements integrated, %d discarded\", numMeasurements, numImuDiscarded);", "Just need to add the newest measurement, no new optimized pose", " ROS_INFO(\"Integrating %f, dt %f\", m_lastImuT, dt);", " predict next state given the imu measurements", "ros::Time after = ros::Time::now();", " publish the status of the estimate - set in the gpsHelper thread", " the local frame velocities", " update the relative position from the initial", "time", "Don't do anything", "diag_info(\"Test\");", "ros::NodeHandle n;"], "GPSHemisphere": ["********************************************", "", "default values reasonable for a crappy gps", "  m_refLocTimer = nh.createTimer(ros::Duration(60.0),", "                    &GPSHemisphere::updateReferenceLocationCallback,", "                    this);", "set real high covariances for now", "since this is only done once, the published utc time messages will not", "be correct if the code is run overnight receiving GPGSA or GPGGA for timing", "make sure data is framed (we expect only NMEA 0183 messages here)", "remove $ at beginning and trailing \\r\\n before further processing", "erase through \\r\\n at end of message", "if a complete message was found, process it", "make sure data is framed", "ROS_WARN_STREAM(\"Not Framed\");", "std::cout << \"Discarding:\" << m_portB.m_data.substr(0, start).size() <<", "  \" Leading with:\" << (unsigned int)(m_portB.m_data[0]&0xff) << std::endl;", "printMessage(m_portB.m_data);", "process if there is enough data to read the header and message type", "printMessage(m_portB.m_data);", "ROS_WARN_STREAM(\"Buffer len:\" << m_portB.m_data.length() <<", "                \" Payload len:\" << len << \" msg type:\" << type);", "record type of message seen in diagnostics", "fill in structure to send message", "std::cout << \"\\t new B Len:\" << m_portB.m_data.length() << std::endl;", "quality token", "std::cout << (double)((int)(ros::Time::now().toSec() + m_gpsTimeOffset) / 86400) << \"Week\" << messageTime << time << std::endl;", "std::cout << (ros::Time::now().toSec()) << std::endl;", " Abandon our timestamp if its too far off", "navigational status should be unsafe when no fix", "std::cout << (double)((int)(ros::Time::now().toSec() + m_gpsTimeOffset) / 86400) << \"Week\" << messageTime << time << std::endl;", "std::cout << (ros::Time::now().toSec()) << std::endl;", " Abandon our timestamp if its too far off", "ignore since its a reply", "only use this if there isn't a better source of covariance information", "and the fix is valid", "choose ideal measurmenet error based on fix type", "use DOP*ideal measurement error for std dev estimates", "HDOP used for lat and lon", "VDOP", "val = boost::lexical_cast<double>(tokens[5])*multiplier;", "check to see better variance source is available, and the message has data", "UTC time", "Token 2 = RMS of std dev of range inputs", "Token 3 = Standard deviation of semi-major axis of error ellipse, meters", "Token 4 = Standard deviation of semi-minor axis of error ellipse, meters", "Token 5 = Error in semi major axis origination, in decimal degrees, true north", "Std dev of latitude error, in meters", "Std dev of longitude error, in meters", "Std dev of altitude error, in meters", "course over ground/ground speed", "detailed UTC time information", "Token 1 = UTC", "Token 2 = UTC day", "Token 3 = UTC month", "Token 4 = UTC year", "Token 5 = Local zone hours", "Token 6 = Local zone minutes", "Minimum message with no satelite info in it.", " Iterate through all of the satellites", "We got complete info", "std::cout << \"lat \" << lat << std::endl;", "std::cout << \"lon \" << lon << std::endl;", "time", "query the current RTK transmission status", "if there are no recent RTK corrections, switch to satellite augmentation", "  if((ros::Time::now()-m_mostRecentRTK).toSec() > 120 && m_rtkEnabled)", "  {", "    unsigned char mode[14] = \"$JDIFF,WAAS\\r\\n\";", "    m_portA.writePort(cmd,14);", "    m_rtkEnabled = false;", "    m_portA.diag_ok(\"Switching to WAAS corrections\");", "  } else if((ros::Time::now()-m_mostRecentRTK).toSec() < 5 && !m_rtkEnabled)", "  {", "    unsigned char mode[16] = \"$JDIFF,BEACON\\r\\n\";", "    m_portA.writePort(cmd,16);", "    m_rtkEnabled = true;", "    m_portA.diag_ok(\"Switching to RTK corrections\");", "  }", "time", "if the unit has augmented position data, update the current reference", "location"], "CameraTrigger": ["********************************************", "set up dynamic_reconfigure server", "make sure data is framed", "try to pull out a full message", "std::cout << \"Looking at^\" << m_port.m_data << \"^\" << std::endl;", "remove # at beginning and trailing \\r\\n before further processing", "erase through \\r\\n at end of message", "level", "NODELET_ERROR_STREAM(\"Triggering FPS \" << m_triggerFPS);  ", "m_port.diag(\"Requested triggering FPS\", std::to_string(m_triggerFPS));", "send new FPS to arduino"], "AutoRallyChassis": ["********************************************", "need entry for each escDataFailCounter_actuator read from RC receiver to keep track of pulse statistics", "callback for serial data from chassis", "subscribe to a one topic for every chassis commander listed in the chassis commander priorities file", "Any variables accessed in here and in other places in the code need to be mutex'd as this fires in a different", "thread than the main thread. This is also a pretyt long callback, and ROS can shutdown underneath us, so check", "if ROS system is still running any time anytseparatedhing ROS is used", "parse all messages from chassis", "look for start and end of message", "pull message out of buffer if start and end are found", "frame data if not framed", "cut out and erase mescDataFailCounter_essage from queue", "process a complete messsage from the chassis with start ('#'), message type, and end ('\\n') characters removed", "look for another message if we haven't looked at all data available yet", "ROS_INFO_STREAM(msgType << \":\" << msg);", "wheel speeds data as comma separated doubles, units in m/s", " Convert from rotations per second to m/s", "Actuator controls from RC input, as comma separated us pulse width, currentl frontBrake is not controlled by RC", "std::cout << std::stoi(data[0]) << \" \" << std::stoi(data[1]) << std::endl;", " setting to zero to make sure brake is neutral", "this line is in here for compatibility with the old servoInterface", "this value can be 0 or 1", "Castle Link ESC data, stored as 9, 2-byte shorts in message", "Expected 18 bytes of ESC data, instead received \" + std::to_string(msg.length()));", "std::cout << msg.length() << std::endl;", "std::cout << escRegisterData_[i].second << \" \" << escRegisterData_[i].first << \" \" <<", "             (((unsigned int)(msg[2*i]&0xFF))<<8) << \" \" << (int)(msg[2*i+1]&0xFF) << std::endl;", "error message as an ASCII string", "check if motion is enabled (all runstop message runstopMotionEnabled = true)", "find highest priority (lowest valuemostRecentRc_) command message for each actuator across all valid actuator commands", "valid throttle commands are on [-1,1], only set throttle value if runstop is enabled", "valid steeringBrake commands are on [-1,1]", "valid frontBrake commands are on [0,1]", "send actuator commands down to chassis, sets to calibrated neutral if no valid commander", "send diagnostic info about who is in control of each actuator", "if we're in autonomous mode, set all the information apppropriately ", "if we're in manual mode, send the most recentl RC command received from the chassis", "publish state message", "assemble send command message for chassis", "steering", "throttle", "frontBrake", "message end signal", "convert actuator command message to raw PWM pulse width in us using the actuator config", "don't need to check if actuatorValue is on [-1, 1] because it was already done", " flip range but still keep it in [0,1]", " flip entire range for throttle and steering", "convert PWM pulse width in us back to actuator command message using the actuator config", "if us value is outside normal servo ranges, complain and don't try to convert", "we've gone 2 cycles without a valid reading, disable RC control of this actuator", "if we only get one invalid pulse width in a row, just use the previous one", "only increment invalid pulses when we get one in a row, not continuously", "NODELET_ERROR_STREAM(getName() << \" RC \" << actuator << \" pulse width out of valid range 900-2100ms (\" <<", "                     pulseWidth << \")\");", "save most recent valid actuator command    ", "read in actuator settings from paramter server that were loaded from the launch file", "add an entry for each actuator (steering, throttle, front brake)", "read in chassisCommandPriorities from the parameter server that were loaded by the launch file", "add entry in priority queue and command map", "sort the loaded commanders according to their priority"], "CameraAutoBalancePtGrey": [""], "CameraAutoBalanceFLIR": [""], "FlycaptureAdjuster": [" namespace autorally_core"], "CameraAutoBalance": ["", " namespace autorally_core"], "SpinnakerAdjuster": [" get camera by serial number from the camera list", " flir_camera_driver handles initializing and de-initing the cameras.", " Attempting to do it here sometimes causes errors and/or race conditions.", " namespace autorally_core"], "XbeeNode": ["********************************************", "until a runstop is received from rf, it will publish runstops", "with this name", "fill out space for incoming RTCM3 message sequences  ", "time", "dont send until we read our own node identifier", "std::cout << \"SENDING:\" << sendData << std::endl;", "once we know the address of the coordinator, start sending periodic info to it", "time", "time", "networkAddress", "std::cout << msg << std::endl;", "ROS_INFO_STREAM(\"Xbee NODE receive:\" << data << \" -\" << msg << \"-\" << m_coordinatorAddress);", "ROS_ERROR(\"XbeeNode: Received pose estimate\");", "std::cout << \"RS:\" << ss << std::endl;", "if I'm receiving targeted xbee runstop messages, ignore broadcast xbee", "runstop messages", "just received first packet of new RTCM3 message  ", "check to make sure there is space in the packet vector (+1 since packets #s start at 1)", "actual RTCM payload data packets start at 1", "clear message data immediately so it can't be accidentally used again", "allocate new message, fill it in", "publish correction into ros", "These will be received but are only needed by coordinator", "time", "ROS_WARN_STREAM(\"Sending position:\" << data);  ", "ROS_WARN_STREAM(\"Received:\" << message << \" from:\" << sender);"], "XbeeInterface": ["Create function pointers to call based on what type of message is", "create vector of all periodically update diagnostic info", "AT command", "frame id", "0x41;", "0x50;", "call appropritate callback", "catch this exception for cleaner shutdown", "append incoming message to vector, stripped of", "start delimiter, length, checksum", "AT command reply byte", "frameid", "Check no error code", "sometimes these AT responses fail (specifically NI request) for some reason,", "and I can't figure out why but they are just debug info, so I send the message", " to debug insted of raising an error", "m_port.diag_error(\"Xbee AT response \" + message.substr(2,2) +", "                  \" error code:\" + std::to_string(message[4]));", "AT command reply byte", "frameid", "Check no error code", "check the message is an AT command reply for the desired command", "AT command reply byte", "frameid", "frame delimiter", "Transmit command", "Random selection", "5-12 64bit address", "broadcast radius set to 0", "multicast set to 0 (unicast)", "while(ros::Time::now()-m_mostRecentXbeeXmit < ros::Duration(0.05))", "{", "usleep(5000);", "ROS_INFO(\"sleepString\");", "}", "m_mostRecentXbeeXmit = ros::Time::now();", "frame delimiter", "Transmit command", "Random selection", "5-12 64bit address", "broadcast radius set to 0", "multicast set to 0 (unicast)", "while(ros::Time::now()-m_mostRecentXbeeXmit < ros::Duration(0.02))", "{", "  usleep(5000);", "  ROS_INFO(\"sleepVec\");", "}", "m_mostRecentXbeeXmit = ros::Time::now();", "time", "time", "allocate space in string", "ROS_ERROR_STREAM(\"Converted:\" << (int)input[i] << \" to:\" << toReturn.substr(2*i,2));"], "XbeeCoordinator": ["networkAddress", "broadcast", "give 5 extra seconds to complete startup before the node is stale", "coordinator doesnt do anything with received odom msgs from nodes right now", "coordinator doesnt do anything with received runstop or GPS correction msgs from another coordinator", "if(data.length() == 62)", "{", "  processXbeeOdom(data, sender);", "}", "else", "  ROS_ERROR(\"XbeeNode: Received incorrect length(%d) odom message \\\"%s\\\"\", (int)data.length(),data.c_str());", "wait to start sending these until we actually get the node identifier from the Xbee", "ros::Time now = ros::Time::now();", "std::map<std::string, RobotState>::const_iterator mapIt;", "if state has not been received from a node in > 2 seconds, send a", "runstop = 0.0 to that node (overriding the broadcast runstop),", "regardless of what overall system runstop is", "for(mapIt = m_robotInfos.begin(); mapIt != m_robotInfos.end(); mapIt++)", "{", "if we received a hearbeat in the last 2 sec from xbee", "if( (ros::Time::now()-mapIt->second.lastHeartbeat) < ros::Duration(2.0) )", "{", "ROS_WARN(\"No recent heartbeat from %s\", mapIt->first.c_str());", "sendData = \"RS \" + msg->sender + \" 0.00\";", "m_xbee.sendTransmitPacket(sendData, mapIt->second.address);", "}", "}", "xbee packet has max len of 72 bytes", "size_t bytesSent = 0;", "each msg gets a unique character to identify it", "this system will break down if more than 27 GPS RTCM msgs are being sent per second", "send a header packet with identifier, msg count, label from the MultiByteArray", "std::string msgHeader = \"GC\" + boost::lexical_cast<std::string>(m_rtkCount) + boost::lexical_cast<std::string>(numMsgs);", "ROS_INFO_STREAM(\"Sending gps correction len \" << correction->data.size() << ", "                \" in \" << numMsgs << \" xbee packets\");", "ROS_INFO_STREAM(msgHeader + boost::lexical_cast<std::string>(msgNum) +", "                            correction->layout.dim.front().label);", "msg payload is 67 bytes of data appended", "correctionSubstr.clear();", "ROS_INFO_STREAM(\"GC\" << m_rtkCount << std::to_string(numMsgs) << ", "                std::to_string(msgNum) << \" positions \" << (msgNum-1)*payloadSize << \":\" <<", "                std::min<int>((msgNum)*payloadSize, correction->data.size()));", "ROS_WARN_STREAM(\"Received:\" << message << \" from:\" << sender);"], "SafeSpeed": ["********************************************", "keep 15 most recent speed values", "update SafeSpeed from sender, and timstamp assosiated with it", "if there is not yet an entry to sender, add it", "if the SafeSpeed is still considered valid", "check if safeSpeed can give up control (if it's in control)", "calculate acceleration", "if all is good, let the throttle do whatever", "NODELET_WARN_STREAM(\"Speed:\" << m_vehicleSpeeds.back().speed << \" Acc:\" << acceleration << \" SafeSpeed:\" << safeSpeed); ", "+acceleration", " cut throttle, act as a speed governer", "compute safeThrottle", "if(!m_throttleMappings.interpolateKey(safeSpeed, safeThrottle))", "{", "  safeThrottle = 0.0;", "  NODELET_WARN_STREAM(", "            \"SafeSpeed: couldn't interpolate a safeThrottle from safeSpeed:\"", "            << safeSpeed);", "}", "ros::NodeHandle nhPvt = getPrivateNodeHandle();"], "serialSensorInterfaceTest": ["********************************************", "", " virtual void TearDown() {}", "", "", ""], "diagnosticsTest": ["********************************************", "", " virtual void TearDown() {}", "", "", "set overall level", "force diagnostic publication", "check overall status is unchanged, then change it", "", "force diagnostic message to be sent", "make sure queue is now empty", "", "force diagnostic message to be sent", "make sure queue is now empty", "", "force diagnostic message to be sent", "make sure queue is now empty", "", "force diagnostic message to be sent", "make sure queue is now empty", "", "force diagnostic message to be sent", "make sure queue is now empty", ""], "pololuMicroMaestroTest": ["********************************************", ""]}, "code_comments_python": {"setup": [" Software License Agreement (BSD License)", " Copyright (c) 2013, Georgia Institute of Technology", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions are met:", "", " 1. Redistributions of source code must retain the above copyright notice, this", " list of conditions and the following disclaimer.", " 2. Redistributions in binary form must reproduce the above copyright notice,", " this list of conditions and the following disclaimer in the documentation", " and/or other materials provided with the distribution.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"", " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE", " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE", " DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE", " FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL", " DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR", " SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,", " OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE", " OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.", "data_files=['src/systemStatus/systemStatus'],", "scripts=['src/systemStatus/systemStatus'],"], "autorally_controller": ["!/usr/bin/env python", " Parameters", " Wheels", " Shock absorbers", " Command timeout", " Publishing frequency", " _last_cmd_time is the time at which the most recent Ackermann", " driving command was received.", " Last steering angle", " Left steering joint angle", " Right steering joint angle", " Last acceleration limit", " Axle angular velocities", " _joint_dist_div_2 is the distance between the steering joints,", " divided by two.", " Front center position", " Rear center position", " Inverse of _wheelbase", "self.lastCmdTime = rospy.get_time()", "load chassis commander priorities", "runstop information", "self.rear_axle_reverse_percent = 0.25 # percent of max_effort applied when reversing", "self.rear_axle_reverse_effort = self.rear_axle_max_effort*self.rear_axle_reverse_percent", " Publishers and subscribers", "don't set up callback until params are initialized", "self.sub = rospy.Subscriber('/autorally_platform/gazebo/link_states', ModelStates, self.callback)", " Too much time has elapsed since the last command. Stop the", " vehicle.", "rospy.logwarn(\"looking for chassis commander %s with priority %d\", cmd, priority)", "rospy.loginfo(\"%s in control of steering\", cmd);", "rospy.loginfo(\"%s in control of throttle\", cmd);", "the brake acts to slow any movement", " Publish the steering and axle joint commands.", "rospy.loginfo()", "self.lastCmdTime = rospy.get_time()", " Get front wheel parameters. Return a tuple containing the steering", " link name, steering controller name, axle controller name (or None),", " and inverse of the circumference.", " Get rear wheel parameters. Return a tuple containing the link name,", " axle controller name, and inverse of the circumference.", " Get parameters used by the front and rear wheels. Return a tuple", " containing the axle controller name (or None) and the inverse of the", " circumference.", " Return the position of the specified link, relative to the right", " rear wheel link.", " Control the steering joints.", " Compute theta, the virtual front wheel's desired steering angle.", " Limit the steering velocity.", " Compute the desired steering angles for the left and right front", " wheels.", " Control the axle joints.", " Compute veh_speed, the vehicle's desired speed.", " Limit the vehicle's acceleration.", " Compute the desired angular velocities of the wheels.", " Front", " Rear", "return data.twist[idx].angular.y * (dia)/2.0 #if data is from linkState message", "print data", "published speeds can't be negative so data mimics the physical platform", " Default wheel diameter. Unit: meter.", " Default equilibrium position. Unit: meter.", " Default command timeout. Unit: second.", " Default publishing frequency. Unit: hertz.", " end _AutoRallyCtrlr", " Wait for the specified controller to be in the \"running\" state.", " Commands can be lost if they are published before their controller is", " running, even if a latched publisher is used.", " Create an axle command publisher.", " Create a command publisher.", " Return the desired steering angle for a front wheel.", " main"], "ground_truth_republisher": ["!/usr/bin/env python", "set frame to be the same as state estimator output", "print msg.pose.pose.position.x, msg.pose.pose.position.y", "rotate position 90 deg around z-axis", "rotate orientation 90 deg around z-axis", "rotate linear velocity 90 deg around z-axis"], "lap_stats": ["!/usr/bin/env python", "Import message types", "Slope, Offset, X min, X max", "Using the 1-2-3 euler angle convention", "Yaw is heading", "Get the pose from the message", "Process the pose to get statistics", "Check if we've completed the last", "Read the launch params"], "track_generator": ["Rotate the image so that the origin is in the top left corner.", "Cast image to numpy array", "Save data to numpy array, each channel is saved individually as an array in row major order."], "track_converter": ["Save data to numpy array, each channel is saved individually as an array in row major order."], "chronyStatus": ["!/usr/bin/env python", " Software License Agreement (BSD License)", " Copyright (c) 2016, Georgia Institute of Technology", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions are met:", "", " 1. Redistributions of source code must retain the above copyright notice, this", " list of conditions and the following disclaimer.", " 2. Redistributions in binary form must reproduce the above copyright notice,", " this list of conditions and the following disclaimer in the documentation", " and/or other materials provided with the distribution.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"", " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE", " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE", " DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE", " FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL", " DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR", " SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,", " OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE", " OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.", "split on first : to separate data field name from value because some values can have : in them", "M = tok[0][0]", "S = tok[0][1]", "all is good if we are synchronizing to a source", "print M, S", " query and publish chrony information once every 5 seconds", "chronyMinVersion = 1.29", "publish error and exit if chronyMinVersion is not satisfied", "if chronyVersion < chronyMinVersion:", "  rospy.logerr('ChronyStatus requires chrony version ' + str(chronyMinVersion) + \\", "               ' or greater, version ' + str(chronyVersion) + ' detected, exiting')", "else:"], "systemStatus": ["!/usr/bin/env python", " Software License Agreement (BSD License)", " Copyright (c) 2013, Georgia Institute of Technology", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions are met:", "", " 1. Redistributions of source code must retain the above copyright notice, this", " list of conditions and the following disclaimer.", " 2. Redistributions in binary form must reproduce the above copyright notice,", " this list of conditions and the following disclaimer in the documentation", " and/or other materials provided with the distribution.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"", " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE", " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE", " DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE", " FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL", " DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR", " SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,", " OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE", " OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.", "# @package systemStatus", "  Gets the wireless signal strength, power status, and CPU temperature. This information is published in the form of ROS messages.", "", "import roslib; roslib.load_manifest('autorally_msgs')", " This shared library is only importable when a GPU is installed", " https://docs.nvidia.com/deploy/nvml-api/group__nvmlDeviceQueries.html#group__nvmlDeviceQueries_1g90843d79066e66430ecb5929c698ce09", "# WirelessStatus.", "", "  Uses iwconfig to retrieve wireless signal strength and then publishes it.", "#  Initializes wirelessSignalStatusMSG", "#  Retrieves wireless signal strength and stores it in the MSG format.", "# PowerStatus.", "", "  Uses acpi to retrieve battery status and then publishes it.", "#  Initializes powerStatusMSG", "#  Retrieves battery status and stores it in the MSG format.", "            print outputString[percentageLocation-2:pPubercentageLocation]", "# M4ATXPowerStatus", "", "  Uses M4API to check compute box battery status and power supply diagnostics", " Battery max voltage 25, fully depleted 19, 6 volt span", "# TempStatus.", "", "  Uses sensors to retrieve CPU temperature and then publishes it.", "#  Initializes tempStatusMSG", "#  Retrieves CPU temperature and fan speed and stores it in the MSG format.", "only try to query GPU if nvml was sucessfully init", " assumes only 1 GPU installed, at index 0          ", "convert reading in milliwatt to W", "uncomment line below to disable m4ATX status updates", "1Hz", " WiFi status is not currently published by our driver", "get available dick space in /media/data", "remove extra spaces and split on remaning/media/data spaces", "check disc usage %              ", "only add part of the df -h output to diagnostics              "]}}
,{"git_repo_name": "Software", "code_comments_file_names": ["send_proto_over_udp", "robot_communicator", "network_medium", "polynomial_1d_test", "polynomial_2d_test", "dribbler_test", "firmware_robot_test", "firmware_world_test", "firmware_ball_test", "chicker_test", "wheel_test", "full_system_main", "polynomial_test", "polynomial", "util_test", "voronoi_diagram_test", "shot", "util", "spline", "voronoi_diagram", "spline_test", "ai", "ai_wrapper", "game_state_play_selection_test", "movespin_primitive_test", "move_primitive", "pivot_primitive_test", "dribble_primitive", "direct_velocity_primitive_test", "move_primitive_test", "direct_wheels_primitive", "stop_primitive", "catch_primitive", "kick_primitive", "direct_velocity_primitive", "catch_primitive_test", "direct_wheels_primitive_test", "movespin_primitive", "chip_primitive", "chip_primitive_test", "kick_primitive_test", "dribble_primitive_test", "stop_primitive_test", "pivot_primitive", "team", "enemy_threat", "pass_test", "ball", "detect_threat_test", "intercept", "robot", "enemy_threat_test", "find_open_areas", "pass", "indirect_chip", "deflect_off_enemy_target_test", "possession", "robot_test", "team_test", "calc_best_shot", "deflect_off_enemy_target", "indirect_chip_test", "ball_test", "intercept_test", "calc_best_shot_test", "detect_threat", "possession_test", "stp_test", "stp", "stp_tactic_assignment_test", "stp_refbox_game_state_play_selection_test", "defense_shadow_enemy_tactic_test", "cherry_pick_tactic", "defense_shadow_enemy_tactic", "receiver_tactic_test", "shadow_freekicker_tactic", "crease_defender_tactic_test", "goalie_tactic", "move_tactic_test", "kickoff_chip_tactic", "kickoff_chip_tactic_test", "chip_tactic", "goalie_tactic_test", "chip_tactic_test", "shadow_enemy_tactic", "passer_tactic_test", "shadow_enemy_tactic_test", "stop_tactic", "move_tactic", "passer_tactic", "cherry_pick_tactic_test", "shadow_freekicker_tactic_test", "receiver_tactic", "stop_tactic_test", "penalty_setup_tactic_test", "penalty_setup_tactic", "shoot_goal_tactic_test", "tactic_test", "penalty_kick_tactic", "tactic_world_params_update_visitor", "shoot_goal_tactic", "crease_defender_tactic", "tactic_world_params_update_visitor_test", "tactic", "patrol_tactic", "move_test_tactic", "goalie_test_tactic", "stop_test_tactic", "example_play_test", "free_kick_play", "enemy_freekick_play", "halt_play_test", "example_play", "halt_play", "penalty_kick_play", "kickoff_enemy_play", "shoot_or_pass_play", "penalty_kick_enemy_play", "shoot_or_chip_play", "defense_play", "corner_kick_play", "kickoff_friendly_play", "stop_play", "play", "halt_test_play", "move_test_play", "pivot_action_test", "chip_action", "stop_action_test", "action", "intercept_ball_action_test", "move_action", "movespin_action", "dribble_action", "action_world_params_update_visitor", "chip_action_test", "kick_action", "action_test", "pivot_action", "stop_action", "kick_action_test", "movespin_action_test", "dribble_action_test", "intercept_ball_action", "move_action_test", "move_test_action", "navigator_test", "navigator", "velocity_obstacle_path_manager", "velocity_obstacle_path_manager_test", "obstacle_test", "obstacle", "obstacle_factory", "one_point_path_test_path_planner", "straight_line_path_planner_test", "theta_star_path_planner_test", "no_path_test_path_planner", "theta_star_path_planner", "straight_line_path_planner", "motion_constraint_manager_test", "motion_constraint", "motion_constraint_manager", "pass_test", "pass_generator", "pass_generator_test", "pass", "cost_function", "cost_function_test", "chip_intent", "kick_intent", "intent_test", "catch_intent", "movespin_intent", "dribble_intent", "move_intent_test", "direct_wheels_intent", "movespin_intent_test", "chip_intent_test", "stop_intent_test", "direct_velocity_intent_test", "direct_velocity_intent", "intent", "pivot_intent_test", "move_intent", "pivot_intent", "direct_wheels_intent_test", "dribble_intent_test", "kick_intent_test", "stop_intent", "catch_intent_test", "team", "field_test", "ball", "game_state", "robot", "ball_state", "world_test", "robot_state", "game_state_test", "robot_test", "team_test", "robot_capabilities_test", "world", "ball_test", "field", "duration_test", "time", "timestamp_test", "timestamp", "duration", "visualizer_wrapper", "geometry_conversion", "team", "ball", "robot", "navigator", "world", "field", "zoomable_qgraphics_view", "visualizer", "robot_status", "world_view", "ai_control", "robot_status_table", "main_widget", "parameters", "constants", "parameter_exists_test", "parameter_test", "config_test", "dynamic_parameters", "generate_parameters_v2", "gradient_descent_test", "math_functions_test", "math_functions", "grsim_backend", "radio_backend", "simulator_backend", "radio_output", "mrf_primitive_visitor", "dongle", "send_reliable_message_operation", "mrf_primitive_visitor_test", "annunciator", "devicehandle", "controltransfer", "libusb", "transfer", "bulktransfer", "errors", "misc", "interrupttransfer", "device", "grsim_output_test", "grsim_output", "movespin_primitive_test", "pivot_primitive_test", "grsim_command_primitive_visitor", "catch_primitive_test", "motion_controller", "motion_controller_test", "dribble_primitive_test", "simulator_ball", "simulator_robot_test", "simulator_robot", "physics_simulator_test", "physics_simulator", "box2d_util", "physics_ball", "physics_field", "physics_robot_test", "physics_field_test", "physics_ball_test", "physics_robot", "box2d_util_test", "physics_world", "network_client", "ssl_vision_client", "ssl_gamecontroller_client", "ssl_protobuf_reader", "robot_filter", "ball_filter_test", "robot_team_filter", "ball_filter", "robot_filter_test", "network_client", "ssl_vision_client", "ssl_gamecontroller_client", "network_filter", "vector_test", "ray", "polynomial_test", "polynomial", "line", "vector", "line_test", "rectangle", "circle_test", "ray_test", "rectangle_test", "point", "triangle", "circle", "convex_polygon", "polygon", "point_test", "polygon_test", "triangle_test", "angle_test", "segment_test", "convex_polygon_test", "closest_point_test", "collinear_test", "distance", "intersection_test", "intersection", "intersects", "collinear", "closest_point", "distance_test", "refbox_data_test", "refbox_data", "vision_detection", "sensor_fusion", "robot_filter", "ball_filter_test", "robot_team_filter", "ball_filter", "robot_filter_test", "simulated_tests_test", "simulated_test_fixture", "mock_ai_wrapper", "continuous_function_validator", "function_validator_test", "function_validator", "world_state_validator", "continuous_function_validator_test", "test_util_test", "test_util", "threaded_observer_test", "observer_test", "thread_safe_buffer_test", "subject_test", "generic_factory_test", "__init__", "util"], "md_file_names": ["README", "PULL_REQUEST_TEMPLATE", "ticket", "HowToBuildAndFlashFirmware", "faq", "software-architecture-and-design", "firmware-architecture-and-design", "workflow", "editing-the-docs", "code-style-guide", "getting-started"], "md_contents": {"README": ["# Software\n", "[![Build Status](https://travis-ci.org/UBC-Thunderbots/Software.svg?branch=master)](https://travis-ci.org/UBC-Thunderbots/Software)\n", "\n", "Our main software repository, for both software and firmware. To get started, please see [getting started](docs/getting-started). Before making *any* contributions, please read over our [style guide](docs/code-style-guide), and [workflow](docs/workflow).\n", "\n", "For an explanation of our software layout and architecture, check out [architecture and design](docs/architecture-and-design).\n", "\n", "Got a question? Look at the [FAQ](docs/faq) to see if it's already been answered!\n", "\n", "Want to learn more about the SSL League? (Teams, rules, etc.) Check out the [Official SSL RoboCup Website](https://ssl.robocup.org/).\n", "\n", "Want to edit these docs? If you're planning on editing diagrams, read the guide on [editing the docs](docs/editing-the-docs)\n"], "PULL_REQUEST_TEMPLATE": ["<!---\n", "This file outlines a list of common things that should be addressed when opening a PR. It's built from previous issues we've seen in a lot of pull requests. If you notice something that's being noted in a lot of PR's, it should probably be added here to help save people time in the future.\n", "-->\n", "\n", "## Please fill out the following before requesting review on this PR\n", "\n", "### Description\n", "\n", "<!--\n", "    Give a high-level description of the changes in this PR\n", "-->\n", "\n", "### Testing Done\n", "\n", "<!--\n", "    Outline any testing that was done for these changes. This could be unit tests, integration tests,etc.\n", "-->\n", "\n", "### Resolved Issues\n", "\n", "<!--\n", "    Link any issues that this PR resolved. Ex. `resolves #1, #2, and #5` (note that they MUST be specified like this so Github can automatically close them then this PR merges)\n", "-->\n", "\n", "### Length Justification\n", "\n", "<!-- If this pull request is longer then **500** lines (additions + deletions), please justify here why we *cannot* break this up into multiple pull requests. -->\n", "\n", "### Review Checklist\n", "\n", "<!--\n", "    (Please check every item to indicate your code complies with it (by changing `[ ]`->`[x]`). This will hopefully save both you and the reviewer(s) a lot of time!)\n", "-->\n", "\n", "**_It is the reviewers responsibility to also make sure every item here has been covered_**\n", "\n", "- [ ] **Function & Class comments**: All function definitions (usually in the `.h` file) should have a javadoc style comment at the start of them. For examples, see the functions defined in `thunderbots/software/geom`. Similarly, all classes should have an associated Javadoc comment explaining the purpose of the class.\n", "- [ ] **Remove all commented out code**\n", "- [ ] **Remove extra print statements**: for example, those just used for testing\n", "- [ ] **Resolve all TODO's**: All `TODO` (or similar) statements should either be completed or associated with a github issue\n", "- [ ] **Justify drops in code coverage**: If this PR results in a non-trivial drop in code coverage (a bot should post a coverage diagram as a comment), please justify why we can't test the code that's not covered.\n", "\n", "<!--\n", "    Feel free to make additions of things that we should be checking to this file if you think there's something missing!!!!\n", "    At the same time, consider that adding things to this list increases the burden on everyone opening a pull request. \n", "    Perhaps there is a way we can automatically enforce whatever item you want to add?\n", "-->\n"], "ticket": ["---\n", "name: Task\n", "about: Defines an item of work for the project\n", "---\n", "\n", "### Description of the task\n", "\n", "<!--\n", "    What does this work depend on?\n", "    What interface will this work use or create?\n", "    What are the main components of the task?\n", "    Where does this work fit in the larger project?\n", "\n", "    It is important to define this task sufficiently so that an untrained\n", "    team member can take it on and know where to start. Feel free to\n", "    link to resources or other team member which could guide the assignee to\n", "    complete the task\n", "-->\n", "\n", "### Acceptance criteria\n", "\n", "<!--\n", "    Checkbox list that outlines what needs to be done in order for this task\n", "    to be considered \"complete\".\n", "\n", "    Specify any implementation requirements such as data structures,\n", "    functionalities, testing requirements, documentation, etc.\n", "-->\n", "\n", "- [ ] Item A\n", "- [ ] Item B\n", "- [ ] Item C\n", "\n", "### Blocked By\n", "\n", "<!--\n", "    List all other issues that need to be completed before this one, ex:\n", "    - #123\n", "    - #374\n", "-->\n", "\n"], "HowToBuildAndFlashFirmware": ["# How to build and flash the robot and dongle (radio) firmware\n", "\n", "## The Robot\n", "To simply build the code, run the `build_robot.sh` script\n", "\n", "To build and flash the code (actually load it onto the robot), do the following:\n", "1. Make sure the robot is turned off (but has a battery)\n", "2. On the back of the robot, on the middle electrical board, there is an array of small switches. Flip the leftmost switch (labeled BL) down. This puts the robot in \"boot mode\"\n", "3. Flick the power switch to turn on the robot, AND HOLD THE SWITCH IN THE \"ON\" POSITION\n", "4. While still holding the power switch, run the `flash_robot.sh` script\n", "5. Wait until the flashing script completes\n", "6. Release the power switch on the robot\n", "7. Turn the robot off\n", "8. Flip the rightmost switch back to the \"up\" position\n", "9. You can now power on the robot, and it should be running the new firmware!\n", "\n", "## The Radio dongle\n", "To simply buildthe code, run the `build_radio.sh` script\n", "\n", "To build and flash the code (actually load it onto the dongle), do the following:\n", "1. Make sure the dongle is unplugged from your comupter (so that it is unpowered)\n", "2. Press and hold down the big red or yellow square button in the middle of the radio dongle board\n", "3. While still holding the button down, plug in the dongle\n", "4. You can now release the button. The dongle should now have a single red LED lit up. This indicates it is in \"boot mode\"\n", "5. Run the `flash_dongle.sh` script. Wait for the script to complete\n", "6. Unplug the dongle to shut it down\n", "7. Plug the dongle back in (no need to hold the button again). The dongle should power up and be running the new firmware!\n", "\n"], "faq": ["# FAQ\n", "\n", "| Question | Solution |\n", "| --- | --- |\n", "| My code completion / IntelliSense isn't working in CLion, but the project seems to be set up correctly and the code is building fine. What's wrong? | Build the project within CLion (rather than with bazel from the command line). You may also need to sync your bazel project. You can either right-click on a folder in CLion and click \"partially sync\", or click the button in the top-right of CLion with the bazel logo to sync the entire project.|\n", "| It feels like the thing I'm working on should have already been done somewhere. There's **no way** we don't already have a function or class for this already, right? | Ask around the team, especially your lead, if they know of something that already does what you need. If it feels like it should already have been done, it likely has and someone can point to to the right place to look. It's better to quickly ask than to duplicate work. |\n"], "software-architecture-and-design": ["# Architecture and Design Rationales\n", "\n", "# Table of Contents\n", "* [Tools](#tools)\n", "  * [SSL-Vision](#ssl-vision)\n", "  * [SSL-Gamecontroller](#ssl-gamecontroller)\n", "  * [grSim](#grsim)\n", "* [Important Classes](#important-classes)\n", "  * [World](#world)\n", "    * [Team](#team)\n", "    * [Robot](#robot)\n", "    * [Ball](#ball)\n", "    * [Field](#field)\n", "    * [Refbox and Gamestate](#refbox--gamestate)\n", "  * [Primitives](#primitives)\n", "  * [Intents](#intents)\n", "  * [Dynamic Parameters](#dynamic-parameters)\n", "  * [Robot Status](#robot-status)\n", "* [Design Patterns](#design-patterns)\n", "  * [Abstract Classes and Inheritance](#abstract-classes-and-inheritance)\n", "  * [Singleton Design Pattern](#singleton-design-pattern)\n", "  * [Factory Design Pattern](#factory-design-pattern)\n", "  * [Visitor Design Pattern](#visitor-design-pattern)\n", "  * [Observer Design Pattern](#observer-design-pattern)\n", "  * [C++ Templating](#c-templating)\n", "* [Coroutines](#coroutines)\n", "  * [What Are Coroutines?](#what-are-coroutines)\n", "  * [What Coroutines Do We Use?](#what-coroutines-do-we-use)\n", "  * [How Do We Use Coroutines?](#how-do-we-use-coroutines)\n", "* [Conventions](#conventions)\n", "  * [Coordinates](#coordinates)\n", "  * [Angles](#angles)\n", "  * [Diagram](#convention-diagram)\n", "* [Architecture Overview](#architecture-overview)\n", "  * [Diagram](#architecture-overview-diagram)\n", "  * [Backend](#backend)\n", "    * [Input](#input-responsibilities)\n", "    * [Output](#output-responsibilities)\n", "    * [Diagram](#backend-diagram)\n", "  * [AI](#ai)\n", "    * [Strategy](#strategy)\n", "      * [Skills / Actions](#skills--actions)\n", "      * [Tactics](#tactics)\n", "      * [Plays](#plays)\n", "    * [Navigation](#navigation)\n", "      * [Path Manager](#path-manager)\n", "      * [Path Objective](#path-objective)\n", "      * [Path Planner](#path-planner)\n", "    * [Diagram](#ai-diagram)\n", "  * [Visualizer](#visualizer)\n", "    * [Diagram](#visualizer-diagram)\n", "    * [Draw Functions](#draw-functions)\n", "    * [Editing the Visualizer](#editing-the-visualizer)\n", "      * [Editing ui files](#editing-ui-files)\n", "      * [Promoting Widgets](#promoting-widgets)\n", "* [Simulated Integration Tests](#simulated-integration-tests)\n", "  * [Architecture](#simulated-integration-tests-architecture)\n", "    * [Simulator Backend](#simulator-backend)\n", "    * [World State Validator](#world-state-validator)\n", "  * [Component Connections and Determinism](#component-connections-and-determinism)\n", "  * [Diagram](#simulated-integration-tests-diagram)\n", "\n", "\n", "# Tools\n", "A few commonly-used terms and tools to be familiar with:\n", "#### SSL-Vision\n", "  * This is the shared vision system used by the Small Size League. It is what connects to the cameras above the field, does the vision processing, and transmits the positional data of everything on the field to our AI computers.\n", "  * The GitHub repository can be found [here](https://github.com/RoboCup-SSL/ssl-vision)\n", "#### SSL-Gamecontroller\n", "  * Sometimes referred to as the \"Refbox\", this is another shared piece of Small Size League software that is used to send gamecontroller and referee commands to the teams. A human controls this application during the games to send the appropriate commands to the robots. For example, some of these commands are what stage the gameplay is in, such as `HALT`, `STOP`, `READY`, or `PLAY`.\n", "  * The GitHub repository can be found [here](https://github.com/RoboCup-SSL/ssl-game-controller)\n", "#### grSim\n", "  * The general robot simulator used by the Small-Size-League. We use this to manually test strategy since it is easy to place the robots and ball in desired locations, run a strategy, and see what the robots do. It is not perfectly accurate, but is useful for testing high-level logic.\n", "  * The GitHub repository can be found [here](https://github.com/RoboCup-SSL/grSim)\n", "\n", "\n", "# Important Classes\n", "These are classes that are either heavily used in our code, or are very important for understanding how the AI works, but are _not_ core components of the AI or other major modules. To learn more about these core modules and their corresponding classes, check out the sections on the [Backend](#backend), [AI](#ai), and [Visualizer](#visualizer).\n", "\n", "## World\n", "The `World` class is what we use to represent the state of the world at any given time. In this context, the world includes the positions and orientations of all robots on the field, the position and velocity of the ball, the dimensions of the field being played on, and the current refbox commands. Altogether, it's the information we have at any given time that we can use to make decisions.\n", "\n", "### Team\n", "A team is a collection of [Robots](#robot)\n", "\n", "### Robot\n", "A Robot class represents the state of a single robot on the field. This includes its position, orientation, velocity, angular velocity, and any other information about its current state.\n", "\n", "### Ball\n", "The Ball class represents the state of the ball. This includes its position and velocity, and any other information about its current state.\n", "\n", "### Field\n", "The Field class represents the state of the physical field being played on, which is primarily its physical dimensions. The Field class provides many functions that make it easy to get points of interest on the field, such as the enemy net, friendly corner, or center circle. Also see the [coordinate convention](#coordinates) we use for the field (and all things on it).\n", "\n", "### Refbox / GameState\n", "These represent the current state of the game as dictated by the Gamecontroller. These provide functions like `isPlaying()`, `isHalted()` which tell the rest of the system what game state we are in, and make decisions accordingly. We need to obey the rules!\n", "\n", "\n", "## Primitives\n", "Primitives are very simple actions of things a robot can do. It does not represent or include _how_ these things are done. Some examples are:\n", "* Moving in a straight line to a position\n", "* Pivoting around a point\n", "* Kicking the ball at a certain direction\n", "\n", "Primitives act as the abstraction between our AI, and our robot firmware. It's much easier for our AI to send a `Primitive` to a robot telling it what it wants it to do, and have the robot responsible for making sure it does what it's told. For every `Primitive` in our `AI` software, there is an equivalent `Primitive` implementation in our robot firmware. When robots receive a `Primitive` command, they perform their own logic and control in order to perform the task specified by the `Primitive`.\n", "\n", "\n", "## Intents\n", "An `Intent` represents a simple thing the `AI` wants (or intends for) a robot to do. It does not represent or include _how_ these things are achieved. Some examples are:\n", "* Moving to a position (without colliding with anything on its way)\n", "* Pivoting around a point\n", "* Kicking the ball at a certain direction or at a target\n", "\n", "Intents are very similar to Primitives, but include slightly more logic. `Intents` can include extra parameters or data that `Primitives` do not, such as how much to avoid the ball by while moving. In this way, `Intents` are more \"context-aware\" than `Primitives`, and represent slightly higher-level commands.\n", "\n", "\n", "## Dynamic Parameters\n", "`Dynamic Parameters` are the system we use to change values in our code at runtime. The reason we want to change values at runtime is primarily because we may want to tweak our strategy or aspects of our gameplay very quickly. During games we are only allowed to touch our computers and make changes during halftime or a timeout, so every second counts! Using `Dynamic Parameters` saves us from having to stop the [AI](#ai), change a constant, recompile the code, and restart the [AI](#ai).\n", "\n", "Additionally, we can use `Dynamic Parameters` to communicate between the [Visualizer](#visualizer) and the rest of our system. The [Visualizer](#visualizer) can change the values of `DynamicParameters` when buttons or menu items are clicked, and these new values will be picked up by the rest of the code. For example, we can define a `Dynamic Parameter` called `run_ai` that is a boolean value. Then when the `Start AI` button is clicked in the [Visualizer](#visualizer), it sets the value of `run_ai` to `true`. In the \"main loop\" for the [AI](#ai), it will check if the value of `run_ai` is true before running its logic. \n", "\n", "Here's a slightly more relevant example of how we used `Dynamic Parameters` during a game in RoboCup 2019. We had a parameter called `enemy_team_can_pass`, which indicates whether or not we think the enemy team can pass. This parameter was used in several places in our defensive logic, and specifically affected how we would shadow enemy robots when we were defending them. If we assumed the enemy team could pass, we would shadow between the robots and the ball to block any passes, otherwise we would shadow between the enemy robot and our net to block shots. During the start of a game, we had `enemy_team_can_pass` set to `false` but the enemy did start to attempt some passes during the game. However, we didn't want to use one of our timeouts to change the value. Luckily later during the half, the enemy team took a time out. Because `Dynamic Parameters` are very quick to change and can leave the `AI` running, we were quickly able to change `enemy_team_can_pass` to `true` while the enemy team took their time out. This made our defence much better against that team and didn't take to much time we had to burn our own timeout. Altogether this is an example of how we use `Dynamic Parameters` to control our [AI](#ai) and other parts of the code.\n", "\n", "It is worth noting that constants are still useful, and should still be used whenever possible. If a value realistically doesn't need to be changed, it should be a constant (with a nice descriptive name) rather than a `Dynamic Parameter`. Having too many `Dynamic Parameters` is overwhelming because there are too many values to understand and change, and this can make it hard to tune values to get the desired behaviour while under pressure during a game.\n", "\n", "\n", "## Robot Status\n", "The `Robot Status` class contains information about the status of a single robot. Examples of the information they include are:\n", "* Robot battery voltage\n", "* Whether or not the robot senses the ball in the breakbeam\n", "* The capacitor charge on the robot\n", "* The temperature of the dribbler motor\n", "\n", "Information received from the robots is stored in `Robot Status` objects so that the rest of the system can easily access and make sense of the information if necessary. For example, we monitor incoming `Robot Status` and display warnings in the [Visualizer](#visualizer) if anything looks wrong so we can be alerted. For example, during a game we may get a \"Low battery warning\" for a certain robot, and then we know to substitute it and replace the battery before it dies on the field.\n", "\n", "\n", "# Design Patterns\n", "Below are the main design patterns we use in our code, and what they are used for.\n", "\n", "## Abstract Classes and Inheritance\n", "Abstract classes let us define interfaces for various components of our code. Then we can implement different objects that obey the interface, and use them interchangeably, with the guarantee that as long as they follow the same interface we can use them in the same way.\n", "\n", "Read [https://www.geeksforgeeks.org/inheritance-in-c/] for more information.\n", "\n", "Examples of this can be found in many places, including:\n", "* [Plays](#plays)\n", "* [Tactics](#tactics)\n", "* [Actions](#skills--actions)\n", "* [Intents](#intents)\n", "* [Primitives](#primitives)\n", "* Different implementations of the [Backend](#backend)\n", "\n", "\n", "## Singleton Design Pattern\n", "The Singleton pattern is useful for having a single, global instance of an object that can be accessed from anywhere. Though it's generally considered an anti-pattern (aka _bad_), it is useful in specific scenarios.\n", "\n", "Read [https://www.tutorialspoint.com/Explain-Cplusplus-Singleton-design-pattern] for more information.\n", "\n", "We use the Singleton pattern for our logger. This allows us to create a single logger for the entire system, and code can make calls to the logger from anywhere, rather than us having to pass a `logger` object literally everywhere.\n", "\n", "\n", "## Factory Design Pattern\n", "The Factory Design Pattern is useful for hiding or abstracting how certain objects are created.\n", "\n", "Read [https://www.geeksforgeeks.org/design-patterns-set-2-factory-method/] for more information.\n", "\n", "Because the Factory needs to know about what objects are available to be created, it can be taken one step further to auto-register these object types. Rather than a developer having to remember to add code to the Factory every time they create a new class, this can be done \"automatically\" with some clever code. This helps reduce mistakes and saves developers work.\n", "\n", "Read [http://derydoca.com/2019/03/c-tutorial-auto-registering-factory/] for more information.\n", "\n", "The auto-registering factory is particularily useful for our `PlayFactory`, which is responsible for creating [Plays](#plays). Every time we run our [AI](#ai) we want to know what [Plays](#plays) are available to choose from. The Factory pattern makes this really easy, and saves us having to remember to update some list of \"available Plays\" each time we add or remove one.\n", "\n", "The Factory pattern is also used to create different [Backends](#backend)\n", "\n", "\n", "## Visitor Design Pattern\n", "The `Visitor Design Pattern` is arguably the most \"advanced\" design pattern we use. It is used when we need to perform different operations on a group of \"similar\" objects, for example a bunch of objects that inherit from the same parent class (eg. [Primitives](#primitives) or [Intents](#intents)). We might only know all these objects are an [Intent](#intent), but we don't know specifically which type each one is (eg. `MoveIntent` vs `KickIntent`). The Visitor Pattern helps us \"recover\" that type information so we can perform different operations on the different types of objects. It is generally preferred to a big `if-block` with a case for each type, because the compiler can help warn you when you've forgotten to handle a certain type, and therefore helps prevent mistakes.\n", "\n", "Read [https://www.geeksforgeeks.org/visitor-design-pattern/] for more information.\n", "\n", "Examples of the Visitor Pattern can be found with the following classes:\n", "* [Intents](#intents)\n", "* [Primitives](#primitives)\n", "* [Tactics](#tactics)\n", "\n", "\n", "## Observer Design Pattern\n", "The Observer Design Pattern is useful for letting components of a system \"notify\" each other when something happens. Read [https://www.geeksforgeeks.org/observer-pattern-set-1-introduction/] for a general introduction to the pattern.\n", "\n", "Our implementation of this pattern consists of two classes, `Observer` and `Subject`. `Observer`s can be registered with a `Subject`, after which new values will be sent from each `Subject` to all of it's registered `Observer`s. Please see the headers of both classes for details. Note that a class can extend both `Observer` and `Subject`, thus receiving and sending out data. In this way we can \"chain\" multiple classes.\n", "\n", "### Threaded Observer\n", "In our system, we need to be able to do multiple things (receive camera data, run the AI, send commands to the robots) at the same time. In order to facilitate this, we extend the `Observer` to the `ThreadedObserver` class. The `ThreadedObserver` starts a thread with an infinite loop that waits for new data from `Subject` and performs some operation with it.\n", "\n", "**WARNING:** If a class extends multiple `ThreadedObserver`s (for example, `AI` could extend `ThreadedObserver<World>` and `ThreadedObserver<RobotStatus>`), then there will be two threads running, one for each observer. We **do not check** for data race conditions between observers, so it's entirely possible that one `ThreadedObserver` thread could read/write from data at the same time as the other `ThreadedObserver` is reading/writing the same data. Please make sure any data read/written to/from multiple `ThreadedObserver`s is thread-safe.\n", "\n", "### Example\n", "One example of this is the `Backend`, which extends `Subject<World>` and the `AI`, which extends `ThreadedObserver<World>`. The backend runs in one thread and sends data to the AI, which receives and processes it another thread.\n", "\n", "## C++ Templating\n", "While debatably not a design pattern depending on who you ask, templating in C++ is a powerful tool that is very useful to understand. [https://www.geeksforgeeks.org/templates-cpp/] gives a great explanantion and example.\n", "\n", "We use templating in a few places around the codebase, with the most notable examples being our [Factory Design Patterns](#factory-design-pattern), and our `Gradient Descent` optimizer.\n", "\n", "\n", "# Coroutines\n", "## What Are Coroutines?\n", "Coroutines are a general control structure where the flow control is cooperatively passed between two different routines without returning, by allowing execution to be suspended and resumed. This is very similar to the `yield` statement and generators in `Python`.\n", "\n", "Rather than using the `return` keyword to return data, coroutines use the `yield` keyword. The main difference is that when `return` is encountered, the data is returned and the function terminates. If the function is called again, it starts back from the beginning. On the other hand, when `yield` is encountered some data is returned, but the state of the function / coroutine is saved and the function does not terminate. This means that when the function is called again, execution resumes immediately after the `yield` statement that previously returned the data, with all the previous context (variables, etc) as if the function never stopped running. This is the \"suspend and resume\" functionality of coroutines.\n", "\n", "See the following C++ pseudocode for an example. This coroutine function computes and returns the fibonacci sequence.\n", "```\n", "int fib(Coroutine::push_type& yield) {\n", "    int f1 = 1;\n", "    int f2 = 0;\n", "    while(true) {\n", "        int fn = f1 + f2; // Compute the next value in the sequence\n", "        f2 = f1; // Save the previous 2 values\n", "        f1 = fn;\n", "        yield(fn);\n", "    }\n", "}\n", "\n", "int main() {\n", "    // Coroutine setup stuff\n", "    // Lets pretend that we have created the Coroutine and called it `yield`\n", "    std::cout << fib(yield) << std::endl; // Prints 1\n", "    std::cout << fib(yield) << std::endl; // Prints 2\n", "    std::cout << fib(yield) << std::endl; // Prints 3\n", "    std::cout << fib(yield) << std::endl; // Prints 5\n", "    std::cout << fib(yield) << std::endl; // Prints 8\n", "    // and so on...\n", "}\n", "```\n", "Lets walk through what's happening here:\n", "1. The first time the `fib` function is called, the variables `f1` and `f2` are initialized, and we go through the first iteration of the loop until `yield` is encountered\n", "2. The `yield` statement is going to return the currently computed value of the fibonacci sequence (the variable `fn`) and save the state of the `fib` function\n", "    * \"yielding\" the data here is effectively returning it so that the code in the `main` function can print the result\n", "3. The second time `main()` calls the `fib()` function, the function will resume immediately after the `yield()` statement. This means that execution will go back to the top of the loop, *and still remember the values of `f1` and `f2` from the last time the function was called*. Since the coroutine saved the function state, it still has the previous values of `f1` and `f2` which it uses to compute the next value in the sequence.\n", "4. Once again when the `yield()` statement is reached, the newly computed value is returned and the function state is saved. You can think of this as \"pausing\" the function.\n", "5. As `main()` keeps calling the `fib()` function, it is computing and returning the values of the fibonacci sequence, and this only works because the coroutine \"remembers\" the values from each previous fibonacci computation which is uses to compute the next value the next time the function is called.\n", "    * If the `yield` was replaced with a regular `return` statement, the function would only ever return the value `1`. This is because using `return` would not save the function state, so the next time it's called the function would start at the beginning again, and only ever compute the first value of the sequence.\n", "\n", "\n", "This example / pseudocode does hide away some details about how coroutines are set up and how we extract values from them, but it's most important to understand how coroutines change the flow of control in the program.\n", "\n", "\n", "## What Coroutines Do We Use?\n", "We use the [boost Coroutine2 library](https://www.boost.org/doc/libs/1_71_0/libs/coroutine2/doc/html/index.html). Specifically, we use Asymetric Coroutines.\n", "\n", "[This stackoverfow answer](https://stackoverflow.com/a/42042904) gives a decent explanation of the difference between Symmetric and Asymmetric Coroutines, but understanding the difference is not critical for our purposes. We use Asymmetric Coroutines because boost does not provide Symmetric Coroutines, and the hierarchical structure of Asymmetric Coroutines is more useful to us.\n", "\n", "\n", "## How Do We Use Coroutines?\n", "We use Coroutines to write our [strategy logic](#strategy). The \"pause and resume\" functionality of Coroutines makes it much easier to write [Plays](#plays), [Tactics](#tactics), and [Actions](#skills--actions).\n", "\n", "Specifically, we use Coroutines as a way to break down our strategy into \"stages\". Once a \"stage\" completes we generally don't want to re-evaluate it, and would rather commit to a decision and move on. Coroutines makes it much easier to write \"stages\" of strategy without requiring complex state machine logic to check what stage we are in, and it's easier for developers to see what the intended order of operations is (eg. \"Line up to take the shot\" -> \"shoot\").\n", "\n", "In the past, we had issues with our gameplay logic \"committing\" to decisions if we were near certain edge cases. This caused robots to behave oddly, and sometimes get significantly slowed down in \"analysis paralysis\". Coroutines solve this problem by allowing us to write \"stages\" that execute top-to-bottom in a function, and once we make a decision we commit to it and move on to the next stage.\n", "\n", "Here's a more specific example. In this example we are going to pretend to write a [Tactic](#tactic) that will pass the ball.\n", "```\n", "def executeStrategy(IntentCoroutine::push_type& yield, Pass pass) {\n", "    do {\n", "        yield(/* align the robot to make the pass */)\n", "    }while(current_time < pass.start_time);\n", "    \n", "    do {\n", "        yield(/* kick the ball at the pass location */)\n", "    }while(/* robot has not kicked the ball */)\n", "}\n", "```\n", "We will pretend that this function is getting called 30 times per second to get the most up-to-date gameplay decision.\n", "\n", "In this example, each `do while()` loop is a \"stage\". When the function is first called, we enter the first stage. In this stage, we will keep telling the robot to line up behind the ball to be ready to make the pass. The robot will continue to do this until it is time to start the pass.\n", "\n", "Once it is time to start the pass, the condition for the loop will become false and we will exit the loop. Then we enter the second loop / stage. The second stage tells the robot to kick the ball, and this continues until the ball has been kicked. Once the ball has been kicked, the loop will terminate and the function will end because the execution reaches the end of the function.\n", "\n", "Once we have entered the second stage, we know we don't have to look at the first stage again. Because the coroutine \"remembers\" where the execution is each time the function is called, we will resume inside the second stage and therefore never execute the first stage again! This makes it much easier to write and read this strategy code, because we can clearly see the 2 stages of the strategy, and we know they will be executed in order.\n", "\n", "\n", "# Conventions\n", "Various conventions we use and follow that you need to know.\n", "\n", "\n", "## Coordinates\n", "We use a slightly custom coordinate convention to make it easier to write our code in a consistent and understandable way. This is particularily important for any code handling gameplay logic and positions on the field.\n", "\n", "The coordinate system is a simple 2D x-y plane. The x-dimension runs between the friendly and enemy goals, along the longer dimension of the field. The y-dimension runs perpendicular to the x-dimension, along the short dimension of the field.\n", "\n", "Because we have to be able to play on either side of a field during a game, this means the \"friendly half of the field\" will not always be in the positive or negative x part of the coordinate plane. This inconsistency is a problem when we want to specify points like \"the friendly net\", or \"the enemy corner\". We can't simple say the friendly net is `(-4.5, 0)` all the time, because this would not be the case if we were defending the other side of the field where the friendly net would be `(4.5, 0)`.\n", "\n", "In order to overcome this, our convention is that:\n", "* The **friendly half** of the field is **always negative x**, and the **enemy half** of the field is **always positive x**\n", "* `y` is positive to the \"left\" of someone looking at the enemy goal from the friendly goal\n", "* The center of the field (inside the center-circle) is the origin / `(0, 0)`\n", "\n", "This is easiest to understand in the [diagram](#convention-diagram) below.\n", "\n", "Based on what side we are defending, the [Backend](#backend) will transform all the coordinates of incoming data so that it will match our convention. This means that from the perspective of the rest of the system, the friendly half of the field is always negative x and the enemy half is always positive x. Now when we want to tell a robot to move to the friendly goal, we can simply tell it so move to `(-4.5, 0)` and we know this will _always_ be the friendly side. All of our code is written with the assumption in mind.\n", "\n", "## Angles\n", "Going along with our coordinate convention, we have a convention for angles as well. An Angle of `0` is along the positive x-axis (facing the enemy goal), and positive rotation is counter-clockwise (from a perspective above the field, looking at it like a regular x-y plane where +y is \"up\"). See the [diagram](#convention-diagram) below.\n", "\n", "Because of our [Coordinate Conventions](#coordinates), this means that an angle of `0` will always face the enemy net regardless of which side of the field we are actually defending.\n", "\n", "## Convention Diagram\n", "![Coordinate Convention Diagram](images/coordinate_and_angle_convention_diagram.svg)\n", "\n", "\n", "# Architecture Overview\n", "At a high-level our system is made of 3 main components: The [Backend](#backend), the [AI](#ai), and the [Visualizer](#visualizer). These 3 components each run in their own thread, and communicate with each other using the [Observer design pattern](#observer-design-pattern). Together, they are what make up our AI.\n", "\n", "The Backend is responsible for communicating with the outside world (network and radio), the AI is what makes the actual gameplay decisions, and the Visualizer shows us what's happening and lets us control the AI.\n", "\n", "Each component is described in more detail in their own sections.\n", "\n", "#### Architecture Overview Diagram\n", "![High Level Architecture Diagram](images/high_level_architecture_diagram.svg)\n", "\n", "\n", "# Backend\n", "The `Backend` is responsible for all communication with the \"outside world\". The responsibilities of the `Backend` can be broken down into Input and Output.\n", "\n", "### Input Responsibilities\n", "1. Receiving robot status messages\n", "2. Receiving vision data about where the robots and ball are (typically provided by [SSL-Vision](#ssl-vision) or [grSim](#grsim))\n", "2. Receiving referee commands (typically from the [SSL-Gamecontroller](#ssl-gamecontroller)\n", "3. Filtering the received data\n", "    * **Why we need to do this:** Programs that provide data like [SSL-Vision](#ssl-vision) only provide raw data. This means that if there are several orange blobs on the field, [SSL-Vision](#ssl-vision) will tell us the ball is in several different locations. It is up to us to filter this data to determine the \"correct\" position of the ball. The same idea applies to robot positions and other data we receive.\n", "4. Storing the filtered data into the [World](#world) datastructures understood by our system\n", "5. Sending the filtered data to the rest of the system\n", "\n", "### Output Responsibilities\n", "1. Sending robot primitives to the robots\n", "\n", "In practice, the `Backend` is just a simple interface that specifies [World](#world) and [Robot Status](#robot-status) objects must be produced, and [Primitves](#primitives) may be consumed. The interface is very generic so that different implementations may be swapped out in order to communicate with different hardware / protocols / programs. For example, we have multiple implementations of the \"output\" part of the backend: one that lets us send data to our real robots using the radio, and one that sends commands to simulated robots in [grSim](#grsim).\n", "\n", "\n", "#### Backend Diagram\n", "![Backend Diagram](images/backend_diagram.svg)\n", "\n", "\n", "# AI\n", "The `AI` is where all of our gameplay logic takes place, and is the main \"brain\" of our system. It uses the information received from the [Backend](#backend) to make decisions, and sends [Primitives](#primitives) back to the [Backend](#backend) for the robots to execute. All together this feedback loop is what allows us to react to what's happening on the field and play soccer in real-time.\n", "\n", "The 2 main components of the AI are strategy and navigation.\n", "\n", "\n", "## Strategy\n", "We use a framework called `STP (Skills, Tactics, Plays)` to implement our stratgy. The `STP` framework was originally proposed by Carnegie Mellon University back in 2004. The original paper can be found [here](https://kilthub.cmu.edu/articles/STP_Skills_Tactics_and_Plays_for_Multi-Robot_Control_in_Adversarial_Environments/6561002/1).\n", "\n", "`STP` is a way of breaking down roles and responsibilities into a simple hierarchy, making it easier to build up more complex strategies from simpler pieces. This is the core of where our strategy is implemented.\n", "\n", "When the [AI](#ai) is given new information and asked to make a decision, our `STP` strategy is what is executed first. It takes in a [World](#world) and returns [Intents](#intents).\n", "\n", "\n", "### Skills / Actions\n", "The `S` in `STP` stands for `Skills`. In our system, we call these `Actions`. Actions represent simple tasks an individual robot can do. Examples include:\n", "1. Moving to a position (without colliding with anything)\n", "2. Shooting the ball at a target\n", "3. Intercepting a moving ball\n", "\n", "Actions use [Intents](#intents) to implement their behaviour. Actions are responsible for obeying any preconditions `Intents` have.\n", "\n", "**It seems like Actions and Intents are basically the same thing. Why aren't they combined into a single class?**\n", "\n", "[Actions](#skills--actions) and [Intents](#intents) are not combined because [Actions](#skills--actions) are part of [STP](#strategy) and our strategy logic, while [Intents](#intents) are more part of the [Navigator](#navigation). Combining them would break the abstraction and couple our strategy implementation to the [Navigator](#navigation), removing our flexibility to implement different strategy systems in the future.\n", "\n", "\n", "### Tactics\n", "The `T` in `STP` stands for `Tactics`. A `Tactic` represents a \"single-robots' role\" on a team. Examples include:\n", "1. Being a goalie\n", "2. Being a passer or pass receiver\n", "3. Being a defender that shadows enemy robots\n", "4. Being a defender that tries to steal the ball from enemies\n", "\n", "Tactics use [Actions](#skills--actions) to implement their behaviour. Using the [Action](#skills--actions) abstraction makes it much easier for Tactics to express what they want to do, and make it easier to design and implement behaviour. Tactics can focus more on what things to do, and when to do them, in order to implement more intelligent and adaptable behaviour.\n", "\n", "### Plays\n", "The `P` in `STP` stands for `Plays`. A `Play` represents a \"team-wide goal\" for the robots. They can be thought of much like Plays in real-life soccer. Examples include:\n", "1. A Play for taking friendly corner kicks\n", "2. A Play for defending enemy kickoffs\n", "3. A general defense play\n", "4. A passing-based offense play\n", "5. A dribbling-based offense play\n", "\n", "Plays are made up of `Tactics`. Plays can have \"stages\" and change what `Tactics` are being used as the state of the game changes, which allows us to implement more complex behaviour. Read the section on [Coroutines](#coroutines) to learn more about how we write strategy with \"stages\".\n", "\n", "Furthermore, every play specifies an `Applicable` and `Invariant` condition. These are used to determine what plays should be run at what time, and when a Play should terminate.\n", "\n", "`Applicable` indicates when a `Play` can be started. For example, we would not want to start a `Defense Play` if our team is in possession of the ball. The `Invariant` condition is a condition that must always be met for the `Play` to continue running. If this condition ever becomes false, the current `Play` will stop running and a new one will be chosen. For example, once we start running a friendly `Corner Kick` play, we want the `Play` to continue running as long as the enemy team does not have possession of the bali.\n", "\n", "\n", "## Navigation\n", "The `Navigator` is responsible for path planning and navigation. Once our strategy has decided what it wants to do, it passes the resulting [Intents](#intents) to the `Navigator`. The `Navigator` is then responsible for breaking down the [Intents](#intents) and turning them into [Primitives](#primitives).\n", "\n", "Most [Intents](#intents) are easy to break down into  [Primitives](#primitives), and can typically just be converted directly without having to do any extra work. However, some [Intents](#intents) like the `MoveIntent` rely on the navigator to implement more complex behaviour like obstacle avoidance. This is where the \"Navigation\" part of the `Navigator` comes in.\n", "\n", "In order for a robot to move to the desired destination of a `MoveIntent`, the Navigator will use various path-planning algorithms to find a path across the field that does not collide with any robots or violate any restrictions set on the `MoveIntent`. The Navigator then translates this path into a series of `MovePrimitives`, which are sent to the robot sequentially so that it follows the planned path across the field.\n", "\n", "### Path Manager\n", "The `Path Manager` is responsible for generating a set of paths that don't collide. It is given a set of [Path Objective](#path-objective)s and [Path Planner](#path-planner), and it will generate paths using the given path planner and arbitrate between paths to prevent collisions.\n", "\n", "### Path Objective\n", "A path objective is a simple datastructure used to communicate between the navigator and the path manager. It conveys information for generating one path, such as start, destination, and obstacles. Path Objectives use very simple datastructures so that Path Planners do not need to know about any world-specific datastructures, such as Robots or the Field.\n", "\n", "### Path Planner\n", "The `Path Planner` is an interface for the responsibility of path planning a single robot around a single set of obstacles from a given start to a given destination. The interface allows us to easily swap out path planners.\n", "\n", "## AI Diagram\n", "![AI Diagram](images/ai_diagram.svg)\n", "\n", "\n", "# Visualizer\n", "The [Visualizer](#visualizer) is exactly what it sounds like: A visualizion of our [AI](#ai). It provides a GUI that shows us the state of the [World](#world), and is also able to display extra information that the [AI](#ai) would like to show. For example, it can show the planned paths of each friendly robot on the field, or highlight which enemy robots it thinks are a threat. Furthermore, it displays any warnings or status messages from the robots, such as if a robot is low on battery.\n", "\n", "The [Visualizer](#visualizer) also lets us control the [AI](#ai) by setting [Dynamic Parameters](#dynamic-parameters). Through the [Visualizer](#visualizer), we can manually choose what strategy the [AI](#ai) should use, what colour we are playing as (yellow or blue), and tune more granular behaviour such as how close an enemy must be to the ball before we consider them a threat.\n", "\n", "The [Visualizer](#visualizer) is connected to the rest of the system using the [Observer Design Pattern](#observer-design-pattern). It observes Subjects that contain information it wants to display, such as the [World](#world) or [DrawFunctions](#draw-functions).\n", "\n", "The [Visualizer](#visualizer) is implemented using [Qt](https://www.qt.io/), a C++ library for creating cross-platform GUIs. The general documentation for [Qt](https://www.qt.io/) can be found [here](https://doc.qt.io/qt-5/index.html). The most important parts for the Visualizer are:\n", "* [Signals and Slots](https://doc.qt.io/qt-5/signalsandslots.html)\n", "* [QtCreator](https://doc.qt.io/qtcreator/creator-using-qt-designer.html) (specifically for Widget-based applications)\n", "* [Widgets](https://doc.qt.io/qt-5/qtwidgets-index.html)\n", "\n", "The [Visualizer](#visualizer) is made up of 3 major components:\n", "* Qt Components\n", "  * The [QApplication](https://doc.qt.io/qt-5/qapplication.html). This is the Qt component that manages the event loop and all the widgets in the GUI.\n", "  * The `Visualizer Widget`. This contains all of the graphical components used in the [Visualizer](#visualizer).\n", "* Non-Qt Components\n", "  * The `VisualizerWrapper`. The `VisualizerWrapper` contains the [QApplication](https://doc.qt.io/qt-5/qapplication.html) and `Visualizer Widget`. It runs the [QApplication](https://doc.qt.io/qt-5/qapplication.html) in a separate thread, so that Qt can run its event loop and handle events and rendering without blocking our main thread.\n", " \n", "\n", "## Visualizer Diagram\n", "![Visualizer Diagram](images/visualizer_diagram.svg)\n", "\n", "## Inter-thread Communication\n", "The `VisualizerWrapper` needs to communicate with the [QApplication](https://doc.qt.io/qt-5/qapplication.html) and `Visualizer Widget` running in its separate thread in order to trigger events like drawing when new data is received. In order to do this, the `VisualizerWrapper` and `Visualizer Widget` use our `ThreadsafeBuffer` class to communicate. The `VisualizerWrapper` pushes data into the buffers, and the `Visualizer Widget` pops the data in a `Producer -> Consumer` pattern. This means the `Visualizer Widget` can handle data at its own rate, independent from the `VisualizerWrapper`.\n", "\n", "In some rare cases, we use the [Qt MetaObject](https://doc.qt.io/qt-5/moc.html) system to send signals to trigger functions in the Qt thread in a thread-safe way. This is further documented in the code.\n", "\n", "## Draw Functions\n", "Although we want to display information about the [AI](#ai) in the [Visualizer](#visualizer), we cannot send copies of an [AI](#ai) object to the [Visualizer](#visualizer) over the [Observer](#observer-design-pattern) system because the [AI](#ai) is non-copyable. [Draw Functions](#draw_functions) are our solution that allow us to draw information in the [Visualizer](#visualizer) for non-copyable types.\n", "\n", "A [DrawFunction](#draw_functions) is essentially a function that tells the [Visualizer](#visualizer) _how_ to draw something. When created, [DrawFunctions](#draw_functions) use [lazy-evaluation](https://www.tutorialspoint.com/functional_programming/functional_programming_lazy_evaluation.htm) to embed the data needed for drawing into the function itself. What is ultimately produced is a function that the [Visualizer](#visualizer) can call, with the data to draw (and the details of how to draw it) already included. This function can then be sent over the Observer system to the [Visualizer](#visualizer). The [Visualizer](#visualizer) can then run this function to perform the actual draw operation.\n", "\n", "## Editing the Visualizer\n", "Qt provides [QtCreator](https://doc.qt.io/qtcreator/creator-using-qt-designer.html), an IDE used for visually creating GUIs and laying out widgets. We use this editor as much as possible since it is easy to learn and use, and saves us having to define the entire GUI in code (which is more complex and makes things generally harder to understand and modify).\n", "\n", "Our rule of thumb is that [QtCreator](https://doc.qt.io/qtcreator/creator-using-qt-designer.html) should be used to define all the widgets in the [Visualizer](#visualizer), and define the layout for everything. All logic (including connecting signals and slots, receiving data from buffers, etc.) should be implemented in the code ourselves.\n", "\n", "For a very quick tutorial on how to use QtCreator, see [this video](https://www.youtube.com/watch?v=R6zWLfHIYJw)\n", "\n", "To summarize, [QtCreator](https://doc.qt.io/qtcreator/creator-using-qt-designer.html) creates and modifies a `.ui` file, which is more-or-less an `XML` describing the GUI application (what components exist, how they are positioned relative to one another, and their attributes). During compilation, this `.ui` file gets generated into code which handles all the setup and layout of the GUI components that have been defined in the `.ui` file. We include the autogenerated code in our [Visualizer](#visualizer) code where we are then able to connect the autogenerated widgets to various functions, and implement the logic we need to.\n", "\n", "### Editing `.ui` files\n", "1. Open QtCreator\n", "2. Click `File -> Open File or Project`\n", "3. Select the `.ui` file.\n", "4. Make your changes (*Don't forget to save. You must save the file for changes to be picked up in compilation*)\n", "\n", "### Promoting Widgets\n", "The most important thing to know about editing the [Visualizer](#visualizer) in [QtCreator](https://doc.qt.io/qtcreator/creator-using-qt-designer.html), is how to promote generic widgets to custom widgets. If we want to extend a QtWidget with custom behavior, we need to create our own class that extends the Widget we want to customize. However, we would still prefer to use [QtCreator](https://doc.qt.io/qtcreator/creator-using-qt-designer.html) to declare this widget and how it fits in the GUI layout.\n", "\n", "\"Promoting\" a widget in [QtCreator](https://doc.qt.io/qtcreator/creator-using-qt-designer.html) allows us to place a \"generic\" widget in the layout, and then tell [QtCreator](https://doc.qt.io/qtcreator/creator-using-qt-designer.html) we actually want that widget to be our custom class. To promote a widget:\n", "1. Right-click the widget you want to promote\n", "2. Click `Promote To` or `Promoted Widgets`\n", "3. Choose the custom widget this widget should be promoted to. Create a new promoted class if necessary.\n", "    1. When creating new promoted classes, make sure to provide the path to the header file relative to the bazel `WORKSPACE` file. This will make the `#include` statements in the generated code use the full path, which is required by `bazel`.\n", "\n", "More information about defining custom widgets in [QtCreator](https://doc.qt.io/qtcreator/creator-using-qt-designer.html) can be found [here](https://doc.qt.io/qt-5/designer-using-custom-widgets.html).\n", "\n", "\n", "# Simulated Integration Tests\n", "When it comes to gameplay logic, it is very difficult if not impossible to unit test anything higher-level than a [Tactic](#tactics) (and even those can be a bit of a challenge). Therefore if we want to test [Plays](#plays) we need a higher-level integration test that can account for all the independent events, sequences of actions, and timings that are not possible to adequately cover in a unit test. For example, testing that a passing play works is effectively impossible to unit test because the logic needed to coordinate a passer and receiver relies on more time-based information like the movement of the ball and robots. We can only validate that decisions at a single point in time are correct, not that the overall objective is achieved successfully.\n", "\n", "Ultimately, we want a test suite that validates our [Plays](#plays) are generally doing the right thing. We might not care exactly where a robot receives the ball during a passing play, as long as the pass was successful overall. The solution to this problem is to use simulation to allow us to deterministically run our entire AI pipeline and validate behaviour.\n", "\n", "The primary design goals of this test system are:\n", "1. **Determinism:** We need tests to pass or fail consistently\n", "2. **Test \"ideal\" behaviour:** We want to test the logic in a \"perfect world\", where we don't care about all the exact limitations of our system in the real world with real physics. Eg. we don't care about modelling robot wheels slipping on the ground as we accelerate.\n", "3. **Ease of use:** It should be as easy and intuitive as possible to write tests, and understand what they are testing.\n", "\n", "## Simulated Integration Tests Architecture\n", "The system consists of three main components:\n", "1. A [Backend](#backend) that performs the simulation\n", "2. A [World State Validator](#world-state-validator) Observer that will handle the \"validation\"\n", "3. The [AI](#ai) under test\n", "\n", "### Simulator Backend\n", "The `SimulatorBackend` is simply another implementation of the [Backend](#backend) interface. It uses a physics library to simulate the various components of the [World](#world), like the [Ball](#ball) and [Robots](#robot). Like any [Backend](#backend), the `SimulatorBackend` publishes the state of the [World](#world) periodically.\n", "\n", "In order to achieve determinism, the `SimulatorBackend` publishes new [World](#world)'s with a fixed time increment (in [World](#world) time), and will wait to receive [Primitives](#primitives) before simulating and publishing the next [World](#world). This means that no matter how much faster or slower the simulation runs than the rest of the system, everything will always happen \"at the same speed\" from the POV of the rest of the system, since each newly published [World](#world) will be a fixed amount of time newer than the last. See the section on [Component Connections and Determinism](#component-connections-and-determinism) for why this is important.\n", "\n", "### World State Validator\n", "The `WorldStateValidator` is an Observer whose purpose is to check that the state of the world is \"correct\" according to some user-provided metrics, or is changing as expected. This is effectively the \"assert\" statements of our tests.\n", "\n", "There are generally 2 \"types\" of conditions we want to validate.\n", "1. Some sequence of states or actions occur **in a given order**. (*Eg. A robot moves to point A, then point B, then kicks the  ball*)\n", "2. Some condition is met for the duration of the test, or for \"all time\". (*Eg. The ball never leaves the field, or robots never collide*)\n", "\n", "We use `ValidationFunctions` to validate both types of conditions. `ValidationFunctions` are essentially functions that contain [Google Test](https://github.com/google/googletest) `ASSERT` statements, and use [Coroutines](#coroutines) to maintain state. This lets us write individual functions that can be continuously run to validate both types of conditions above.\n", "\n", "Benefits of `ValidationFunctions`:\n", "1. They are reuseable. We can write a function that validates the ball never leaves the field, and use it for multiple tests.\n", "2. They can represent assertions for more complex behavior. For example, we can build up simpler `ValidationFunctions` until we have a single `Validation` function for a specific [Tactic](#tactics).\n", "3. They let us validate independent sequences of behaviour. For example, we can give the `WorldStateValidator` a different `ValidationFunction` for each [Robot](#robot) in the test. This makes it easy to validate each [Robot](#robot) is doing the right thing, regardless if they are dependent or independent actions.\n", "\n", "The `WorldStateValidator` accepts lists of `ValidationFunctions` that it will run against each [World](#world) it receives. Once all `ValidationFunctions` have been run, the `WorldStateValidator` publishes the [World](#world) again. See the section on [Component Connections and Determinism](#component-connections-and-determinism) for how this is used and why this is important.\n", "\n", "## Component Connections and Determinism\n", "When testing, determinism is extremely important. With large integration tests with many components, there are all kinds of timings and execution speed differences that can change the behaviour and results. We make use of a few assumptions and connect our components in such a way that prevents these timing issues.\n", "\n", "Most importantly, the [WorldStateValidator](#world-state-validator) acts as a \"middleman\" between the [Backend](#backend) and [AI](#ai). The [WorldStateValidator](#world-state-validator) observes the [World](#world) from the [Backend](#backend), and the [AI](#ai) observes the [World](#world) from the [WorldStateValidator](#world-state-validator). **The [AI](#ai) does not observe the [World](#world) directly from the [Backend](#backend) in this case.** See the [diagram](#simulated-integration-tests-diagram).\n", "\n", "Now we have a nice loop from the `Backend -> WorldStateValidator -> AI -> Backend ...`. As mentioned in their own sections, the [Simulator Backend](#simulator-backend) waits to receive [Primitives](#primitives) from the [AI](#ai) before publishing a new [World](#world), and the [WorldStateValidator](#world-state-validator) waits to receive and validate a [World](#world) before re-publishing the [World](#world). **The final assumption we make to complete this loop is that the [AI](#ai) waits to receive a new [World](#world) before publishing new [Primitives](#primitives).**\n", "\n", "**What this means is that each component in the loop waits for the previous one to finish its task and publish new data before executing.** As a result, no matter how fast each component is able to run, we will not have any issues related to speed or timing because each component is blocked by the previous one. As a result, we can have deterministic behaviour because every component is running at the same speed relative to one another.\n", "\n", "## Simulated Integration Tests Diagram\n", "Notice this is very similar to the [Architecture Overview Diagram](#architecture-overview-diagram), with the only real difference being the [World State Validator](#world-state-validator) being added between the [Backend](#backend) and [AI](#ai).\n", "\n", "The [Visualizer](#visualizer) and connections to it are marked with dashed lines, since they are optional and generally not run during the tests (unless debugging).\n", "\n", "![Simulated Testing High-level Architecture Diagram](images/simulated_integration_test_high_level_architecture.svg)\n", "\n"], "firmware-architecture-and-design": ["# Architecture and Design Rationales\n", "\n", "# Table of Contents\n", "* [General Principles](#general-principles)\n", "* [App/IO Split](#appio-split) \n", "* [Design Patterns](#design-patterns)\n", "  * [Pseudo-Class](#pseudo-class)\n", "\n", "# General Principles\n", "* Avoid memory allocation wherever possible. This means that we usually try to limit our use of pseudo-classes to fairly high level abstractions.\n", "* **REALLY** avoid allocating memory anywhere you don't have a guaranteed upper-bound on the number of times that the allocation will be executed. This is so we can have more guarantees on the upper bound of memory usage, and violating this can potentially cause *very* serious bugs.\n", "* Never use `static` in anything in the `app` layer. As the `app` layer is intended to be portable to our simulator, this means that any `static` variables will be re-used between multiple robots in the simulator, almost guaranteeing undesired behavior.\n", "\n", "# Design Patterns\n", "\n", "## Pseudo-Class\n", "In order to hide implementations away and enable things like the [App/IO Split](#appio-split), we require something _similar_ to a class in C++. How we do this is most easily explained with an example:\n", "\n", "Let's say I have a dog that has a few functions. I would declare the header like so:\n", "\n", "_dog.h_\n", "```\n", "typedef struct Dog Dog_t;\n", "\n", "enum DogColor {BROWN, BLACK};\n", "\n", "/**\n", " * Create a dog\n", " * @param color The color of the dog\n", " * @param attempt_to_run_at_speed A function that can be called to attempt to \n", " *                                set the speed of this dog, returning the max \n", " *                                speed achieved, in m/s.\n", " * @return A pointer to a dog with the given parameters\n", " */\n", "Dog_t* app_dog_create(DogColor color, float (*attempt_to_run_at_speed)(float)); \n", "\n", "/**\n", " * Destroy the given Dog, freeing any memory allocated for it\n", " * @param dog The Dog to destroy\n", " */\n", "void app_dog_destroy(Dog_t* dog);\n", "\n", "/**\n", " * Get the color of a dog\n", " * @param dog The dog to get the color of\n", " * @return The color of the given dog\n", " */\n", "DogColor app_dog_getColor(Dog_t* dog);\n", "\n", "/**\n", " * Attempt to set the speed of a Dog\n", " * @param desired_speed The speed to attempt, in m/s\n", " * @return The maximum speed actually achieved, in m/s\n", " */\n", "float app_dog_attemptToRunAtSpeed(Dog_t* dog, float desired_speed);\n", "```\n", "\n", "There are a few things to note here: \n", "* We have declared a `struct Dog` and typedef'd it to just `Dog_t`, but we *haven't actually said what's in the struct*. This is a crucial point, because it means that anything that includes `dog.h` can only interact with a `struct Dog` through the functions we define here. \n", "* We passed a function into `dog_create`. This is a really useful technique that is part of what enables us to do stuff like providing different \"implementations\" of a robot to the `app` layer depending on if we're in simulation or running on the real robots.\n", "\n", "We would implement this \"class\" as follows:\n", "\n", "_dog.c_\n", "``` C\n", "#include \"dog.h\"\n", "\n", "struct Dog {\n", "    DogColor color;\n", "    float (*attempt_to_run_at_speed)(float);\n", "};\n", "\n", "Dog_t* app_dog_create(DogColor color, float (*attempt_to_run_at_speed)(float)){\n", "    // NOTE: We can't do this outside this `.c` file, because the only place\n", "    //       that we know the size of the `Dog` struct is here.\n", "    Dog_t* dog = (Dog_t*)(malloc(sizeof(Dog_t)));\n", "\n", "    dog->color = color;\n", "    dog->attempt_to_run_at_speed = attempt_to_run_at_speed;\n", "\n", "    return dog;\n", "}\n", "\n", "void app_dog_destroy(Dog_t* dog){\n", "    // NOTE: We can't do this outside this `.c` file, because the only place\n", "    //       that we know the size of the `Dog` struct is here.\n", "    free(dog);\n", "}\n", "\n", "DogColor app_dog_getColor(Dog_t* dog){\n", "    return dog->color;\n", "}\n", "\n", "float app_dog_attemptToRunAtSpeed(Dog_t* dog, float desired_speed){\n", "    return dog->attempt_to_run_at_speed(desired_speed);\n", "}\n", "```\n", "\n", "and we would use this class as follows:\n", "``` C\n", "#include \"dog.h\"\n", "\n", "// Assume we get our \"attempt_to_run_at_speed\" method from this header\n", "#include \"dog_simulator.h\"\n", "\n", "Dog_t* my_dog = app_dog_create(BROWN, &simulated_dog_attempt_speed);\n", "\n", "assert(app_dog_getColor(my_dog) == BROWN);\n", "\n", "float achieved_speed = app_dog_attemptToRunAtSpeed(my_dog, 9001);\n", "\n", "app_dog_destroy(my_dog);\n", "```\n", "\n", "# App/IO Split\n", "The firmware is divided into `app` and `io` layers. \n", "* The `app` layer contains anything that is portable between all our robots and our simulator. Ex. the implementation of primitives in firmware, or our controllers for motion execution\n", "* The `io` layer contains everything below the `app` layer, down to and including calls to libraries like `HAL` (`HAL` is a library that provides thin wrappers around hardware). Ex. the function that actually applies a wheel force or reads the encoders\n", "* The interface between these layers is the `FirmwareWorld` class, which represents an abstraction of the world from the perspective of the robot. **This is the only interface that the `app` layer should ever be able to use to access the outside world**.\n"], "workflow": ["# Workflow\n", "\n", "## Table of Contents\n", "* [Issue and Project Tracking](#issue-and-project-tracking)\n", "    * [Issues](#issues)\n", "* [Git Workflow](#git-workflow)\n", "    * [Forking and Branching](#forking-and-branching)\n", "    * [Creating a new Branch](#creating-a-new-branch)\n", "        * [Why should you only create branches from \"upstream/master\"?](#why-should-you-only-create-branches-from-upstreammaster)\n", "    * [Making Commits](#making-commits)\n", "    * [Updating Your Branch and Resolving Conflicts](#updating-your-branch-and-resolving-conflicts)\n", "    * [Formatting Your Code](#formatting-your-code)\n", "    * [Pull Requests](#pull-requests)\n", "    * [Reviewing Pull Requests](#reviewing-pull-requests)\n", "* [Example Workflow](#example-workflow)\n", "* [Testing](#testing)\n", "\n", "\n", "## Issue and Project Tracking\n", "\n", "We try keep our issue and project tracking fairly simple, to reduce the overhead associated with tracking all the information and to make it easier to follow. If you are unfamiliar with GitHub issues, [this article](https://guides.github.com/features/issues/) gives a good overview.\n", "\n", "### Issues\n", "\n", "We use issues to keep track of bugs in our system, and new features or enhancements we want to add. When creating a new issue, we have a simple \"Task\" template that can be filled out. We *strongly* recommend using the template since it provides guiding questions/headings to make sure we have all the necessary information in each issue.\n", "\n", "*It is very important to give lots of detail and context when creating an issue. It is best to pretend you are writing the issue for someone who has not worked on the relevant part of the system before, and to leave a good enough explanation that someone with very little prior knowledge could get started. Sometimes issues get worked on many months after they were created, and we don't want to forget exactly what we wanted to do and why.*\n", "\n", "In general if you find an issue with the system, first check with others on your team to make sure that this is indeed unintended behavior (you never know), and make sure that an issue has not already been created before you create a new one.  \n", "  \n", "The same goes for feature requests. Just make sure that whatever you want to say doesn't already exist in an issue.\n", "\n", "\n", "## Git Workflow\n", "\n", "### Forking and Branching\n", "\n", "In general, we follow the Forking Workflow\n", "\n", "* [What it is](https://www.atlassian.com/git/tutorials/comparing-workflows#forking-workflow)\n", "* [How to use it](https://gist.github.com/Chaser324/ce0505fbed06b947d962)\n", "* Instructions on obtaining your own Fork of our repository can be found on the [Getting Started](software-setup#getting-the-code) page.\n", "\n", "### Creating a new Branch\n", "\n", "For each Issue of project you are working on, you should have a separate branch. This helps keep work organized and separate.\n", "\n", "**Branches should always be created from the latest code on the `master` branch of our main Software repository**. If you followed the steps in [Getting Started](software-setup), this will be `upstream/master`. Once this branch is created, you can push it to your fork and update it with commits until it is ready to merge. \n", "\n", "1. Navigate to the base folder of your Software repository: `cd path/to/the/repository/Software`\n", "2. Make git aware of any new changes to `upstream` by running `git fetch upstream`\n", "3. Create a new branch from `upstream/master` by running `git checkout -b your-branch-name upstream/master`\n", "   1. Our branch naming convention is: `your_name/branch_name` (all lowercase, words separated by underscores). The branch name should be short and descriptive of the work being done on the branch.\n", "   \n", "**Example:** if you were working on a new navigation system using RRT and your name was \"Bob\" your branch name might look like: `bob/new_rrt_navigator`\n", "4. You can now commit changes to this branch, and push them to your fork with `git push origin your_branch_name`\n", "\n", "#### Why should you only create branches from \"upstream/master\"? \n", "Because we squash our commits when we merge Pull requests, a new commit with a new hash will be created, containing the multiple commits from the PR branch. Because the hashes are different, git will not recognize that the squashed commit and the series of commits that are inside the squashed commit contain the same changes, which can result in conflicts.\n", "\n", "For example, lets pretend you have _branch A_, which was originally branched from `upstream/master`. You make a few commits and open a Pull Request. While you're waiting for the Pull Request to be reviewed and merged, you create a new branch, _branch B_, from _branch A_ to get a head start on a new feature. Eventually _branch A_ gets merged into `upstream/master`. Now you want to pull the latest changes from `upstream/master` into _branch B_ to make sure you have the latest code. git will treat the squashed commit that was merged from _branch A_'s Pull Request as a new change that needs to be merged, since _branch B_ will not have a commit with the same git hash. But _branch B_ already has these changes because it was created from branch A! This will cause massive merge conflicts that are nearly impossible to resolve cleanly.\n", "\n", "tl;dr Always create new branches from upstream/master. Do not create branches from other feature branches.\n", "\n", "### Making Commits\n", "\n", "We don't impose any rules for how you should be committing code, just keep the following general rules in mind:\n", "\n", "1. Commits should represent logical steps in your workflow. Avoid making commits too large, and try keep related changes together\n", "2. Commit messages should give a good idea of the changes made. You don't have to go in-depth with technical details, but no one will know what you've done if your commit message is \"fixed broken stuff\"\n", "3. Do not commit any non-code files such as images, videos, or generated files.\n", "\n", "### Updating Your Branch and Resolving Conflicts\n", "As you are working on your code on your branch and making commits, you'll want to update your branch with the latest code on `upstream/master` to make sure you're working with the latest code. This is important in case someone else merged new code that affects the code you're working on.\n", "\n", "To do this, you have 2 options: rebase or merge. [What's the difference?](https://www.atlassian.com/git/tutorials/merging-vs-rebasing). \n", "\n", "Rebasing is generally recommended but requires slightly more knowledge of git. You can simply `git pull --rebase upstream master` to rebase your branch onto the latest `upstream/master`. If you do find you run into crazy conflicts, it might be worth aborting and attempting a merge.\n", "\n", "To merge, simply run `git pull upstream master`. This _usually_ produces fewer conflicts than rebasing and is a safer option if you just want to get stuff working.\n", "\n", "If you do rebase or merge and get conflicts, you'll need to resolve them manually. [See here for a quick tutorials on what conflicts are and how to resolve them](https://www.atlassian.com/git/tutorials/using-branches/merge-conflicts). Feel free to do this in your IDE or with whatever tool you are most comfortable with. Updating your branch often helps keep conflicts to a minimum, and when they do appear they are usually smaller. Ask for help if you're really stuck!\n", "\n", "### Formatting Your Code\n", "We use [clang-format](https://electronjs.org/docs/development/clang-format) to automatically format our code. Using an automatic tool helps keep things consistent across the codebase without developers having to change their personal style as they write. See the [code style guide](code-style-guide) for more information on exactly what it does.\n", "\n", "To format the code, from the `Software` directory run `./formatting_scripts/fix_formatting.sh`.\n", "\n", "We recommend running the formatting script and then committing all your changes, so that your commits can more easily pass CI.\n", "### Pull Requests\n", "\n", "Pull Requests give us a chance to run our automated tests and review the code before it gets merged. This helps us make sure our code on `upstream/master` always compiles and is as bug-free as possible.\n", "\n", "The code-review process gives us a chance ask questions or suggest improvements regarding a proposed change, so that the code is of the highest possible quality before being merged. It is also a good opportunity for others on the team to see what changes are being made, even if they are not involved in the project.\n", "\n", "The Pull Request process usually looks like the following:\n", " \n", "1. Make sure all the changes you want to make are pushed to a branch on your fork of the repository\n", "2. Make sure you have [updated your branch](#updating-your-branch-and-resolving-conflicts) and [formatted your code](#formatting-your-code). This is to help make sure CI will pass.\n", "3. From the main page of your fork of the Software repository, click on the \"code\" tab and then on the \"branches\" tab below.\n", "4. Find the branch you want to open a Pull Request with and click \"New pull request\"\n", "5. Make sure the target (base-fork) is the `UBC-Thunderbots/Software` repository with branch `master`\n", "6. Give your Pull Request a short but descriptive title (the title should reflect the changes)\n", "7. Fill out the pull request template. This includes things like a description of the changes, indicating which issues the Pull Request resolves, and indicating what testing has been done.\n", "8. Add reviewers. This should be anyone that worked with you on the changes or is working on something that will be affected by the changes. Add your team lead and a few other members. Around 3-4 reviewers is a good number, but use your best judgement. Remember, these reviews also help give other team members an idea of the changes that are being made even if they aren't working on them.\n", "    1. At least one \"Code Owner\" will need to review the change in order for it to be merged\n", "9. Click \"Create pull request\"\n", "10. Now the code can be reviewed. Respond to feedback given by your team members and make changes as necessary by pushing additional commits to your branch.\n", "    1. **If you are a reviewer:**\n", "       1. Look over the code, keeping an eye out for typos or bugs\n", "       2. If you are having trouble understanding what a certain part of the code is doing, that's a great place to suggest adding additional comments!\n", "       3. Remember you are critiquing someone's work. Give useful, constructive feedback and justify your thoughts, and don't be mean or degrading.\n", "       4. During re-reviews (Pull Requests typically involve several rounds of changes and review), **it is your responsability to check that previously requested changes were made and mark the relevant discussions as \"resolved\"**. \"Unresolved\" discussions make a great checklist of things to check during a re-review.\n", "       5. Mark the Pull Request as \"Approved\" when you think it looks good\n", "    2. **If you are the recipient of the review (the PR creator):**\n", "       1. **Make sure to reply to the PR comments as you address / fix issues**. This helps the reviewers know you have made a change without having to go check the code diffs to see if you made a change.\n", "          1. Eg. Reply with \"done\" or \"fixed\" to comments as you address them\n", "          2. Leave comments unresolved, let the reviewer resolve them.\n", "       2. Don't be afraid to ask for clarification regarding changes or suggest alternatives if you don't agree with what was suggested. The reviewers and reviewee should work together to come up with the best solution.\n", "       3. **Do not resolve conversations as you address them** (but make sure to leave a comment as mentioned above). That is the responsibility of the reviewers.\n", "11. Make sure our automated tests with Travis CI are passing. There will be an indicator near the bottom of the Pull Request. If something fails, you can click on the links provided to get more information and debug the problems. More than likely, you'll just need to re-run clang-format on the code.\n", "12. Once your Pull Request has been approved and the automated tests pass, you can merge the code. There will be a big 'merge\" button at the bottom of the Pull Request with several options to choose from\n", "    1. We only allow \"Squash and merge\". This is because it keep the commit history on `upstream/master` shorter and cleaner, without losing any context from the commit messages (since they are combined in the squashed commit. A squashed commit also makes it easier to revert and entire change/feature, rather than having to \"know\" the range of commits to revert.\n", "13. That's it, your changes have been merged! You will be given the option to delete your remote branch. but are not required to do so. We recommend it since it will keep your fork cleaner, but you can do whatever you like.\n", "\n", "*Remember, code reviews can be tough. As a reviewer, it can be very tricky to give useful constructive criticism without coming off as condescending or degrading (emotions are hard to express through text!). As the recipient of a code review, it might feel like you are being criticized too harshly and that your hard work is being attacked. Remember that these are your teammates, who are not trying to arbitrarily devalue your contributions but are trying to help make the code as good as possible, for the good of the team.*\n", "\n", "### Reviewing Pull Requests\n", "\n", "When reviewing pull requests, it can be really difficult to phrase comments in a way that doesn't come across as aggressive or mean. That said, it's really important that we strive to keep pull requests friendly and open, both for the health of everyone involved, and the effectiveness of the code review process. Here are two links that everyone reviewing a pull request should _thoroughly_ read before doing reviews:\n", "\n", "[https://mtlynch.io/human-code-reviews-1/](https://mtlynch.io/human-code-reviews-1/) \n", "\n", "[https://mtlynch.io/human-code-reviews-2/](https://mtlynch.io/human-code-reviews-2/)\n", "\n", "\n", "## Example Workflow\n", "\n", "We find our workflow is best explained by walking through an example. We're assuming you have already cloned the repository and set up your git remotes. If not, check out our [Getting the Code](software-setup#getting-the-code) instructions first and then come back.\n", "\n", "This example incorporates information from the previous sections on [Issue and Project Tracking](#issue-and-project-tracking), and [the Git Workflow](#git-workflow). Make sure you have read those sections first. This example skips over some of the smaller details.\n", "  \n", "We are also assuming all the work done here is in your fork of the repository.\n", "\n", "Let's pretend our goalie strategy isn't that great. You have noticed that and suggested we improve it. Here's what your workflow would likely look like, from start to finish. We will pretend your name is Bob.\n", "\n", "1. Create a new Issue for the goalie strategy if it doesn't already exist\n", "   1. Let's pretend this is `Issue #23`\n", "   2. Add relevant tags to your Issue. In this case, likely \"Enhancement\"\n", "2. Create a new branch from `upstream/master`, called `bob/create_new_goalie_strategy`\n", "   1. `git fetch upstream`\n", "   2. `git checkout -b bob/create_new_goalie_strategy upstream/master`\n", "3. Make your changes\n", "   1. As you make changes and come across new information / challenges, it is good to update the Issue you are working on to document these new changes or requirements. Updating our progress on the ticket also helps other know how your work is going.\n", "      1. `git commit -m \"Improved the goalie's positioning during corner kicks, to block shots near the edge of the net\"`\n", "   2. Don't forget to push your changes to the branch on your fork occasionally, so you don't lose your work if something happens to your computer (it's happened to our team before)\n", "4. Open a Pull Request to the master branch of the main Software repository. This will be a request to merge the branch `bob/create_new_goalie_strategy` from your fork, to the `master` branch of the main `Software` repository.\n", "   1. The description should include `resolves #23`, so we know this Pull Request resolved your ticket\n", "5. Discuss the changes with your reviewers and update the Pull Request by pushing additional commits to your branch\n", "6. Once the Pull Request is approved and all CI checks pass, Squash and merge the changes\n", "7. **Optional:** Delete your remote branch\n", "8. Make sure your issue is marked as resolved. If you remembered to include `resolves #23` in your Pull Request description, this should have been done automatically for you, but it's good to double check.\n", "9. Congratulations, you've now made changes to our main codebase!\n", "\n", "\n", "## Testing\n", "\n", "Testing is an integral part of our development process. If you are writing basically **any** code, it should be tested. If you feel like you can't test your piece of code, it's likely because it was written in a way that makes it difficult to test (which is a strong indicator for other problems, such as too much [coupling](https://en.wikipedia.org/wiki/Coupling_%28computer_programming%29)). _(An exception to this rule is any code that talks **directly** with hardware)_. For some examples of what happens when people don't test their code enough, see [here](http://outfresh.com/knowledge-base/6-famous-software-disasters-due-lack-testing/). How to run tests is explained in the [Getting Started Guide](getting-started/#building-and-running-the-code). \n"], "editing-the-docs": ["# Editing the Docs\n", "A quick guide for editing and updating our documentation.\n", "\n", "Most text can easily be edited with your favourite text editor, or directly in GitHub itself. There's really nothing special here.\n", "\n", "#### Editing Diagrams\n", "Editing diagrams is the tricky part about our documentation. All our diagrams live in the [images](images/) folder. These are all diagrams created by [draw.io](https://www.draw.io/?mode=github). Specifically, this is done with the \"GitHub mode\" of [draw.io](https://www.draw.io/?mode=github). This allows diagrams or images to be saved directly in a git repository, but still edited with [draw.io](https://www.draw.io/?mode=github) when needed.\n", "\n", "We do this so that it's easier for everyone to update the diagrams and have them automatically saved back to our repository, rather than having to save the diagram file in Google Drive, give people access, and remember to export new images and replace them in the docs everytime they need to be updated.\n", "\n", "You can read a bit about how the GitHub mode of [draw.io](https://github.com/jgraph/drawio-github) works at https://github.com/jgraph/drawio-github.\n", "\n", "The gist of it is that these image files are stored in our github repository with extra information embedded that allows [draw.io](https://www.draw.io/?mode=github) to edit them. It's the same data that would be saved as an `XML` file if you simply saved a [draw.io](https://www.draw.io/?mode=github) diagram instead of exporting it as an image.\n", "\n", "The GitHub mode lets you connect your GitHub account, and then you can edit or create documents in any GitHub repository you have access to.\n", "\n", "##### Creating a new Diagram\n", "1. Open [draw.io](https://www.draw.io/?mode=github) and connect your GitHub account if necessary\n", "2. Click `Create New Diagram`\n", "3. Give the diagram a name with `.svg` as the ending. We prefer `.svg` files since they are vector images and therefore scale better without becoming pixelated.\n", "4. Click `Create`. You'll be shown a dialogue with all the repositories your GitHub account has access to. Click on your fork of our `Software` repository. Eg. `MyGitHubUsername/Software`\n", "5. Now you are basically in a filetree of the folders in the repository you selected\n", "6. Change the branch you are looking at if necessary. At the top of the dialogue, click `master` and it will let you select a different branch if one exists.\n", "7. Choose the folder where you want to store the new diagram. In our case that would be in `docs/images`\n", "8. Once you have selected the folder you want to create the new diagram in, click `OK`\n", "9. You'll now be taken to the regular [draw.io](https://github.com/jgraph/drawio-github) canvas where you can create and edit a diagram to your heart's content.\n", "\n", "##### Editing a diagram\n", "This is basically the same procedure as above, except click on `Open Existing Diagram` instead, and select the file you want to edit. **Make sure you're on the right branch.**\n", "\n", "##### Saving Diagrams\n", "Once you have edited a diagram, you will eventually want to save it. Because this is the GitHub mode of [draw.io](https://www.draw.io/?mode=github), this means you actually make a commit back to the repository to save the file.\n", "\n", "To save your changes, you can either click `File -> Save`, or click the red \"save now\" box that appears if you have unsaved changed. In either case, a small dialogue will appear asking you to provide a commit message. Once you click `OK` a new commit will be made to the repository and branch you are editing the diagram in. The new diagram will appear anywhere it's linked without the need to do anything else!\n"], "code-style-guide": ["# Code Style Guide\n", "\n", "## Table of Contents\n", "* [C-specific Guidelines](#c-specific-guidelines)\n", "* [Names and Variables](#names-and-variables)\n", "* [Comments](#comments)\n", "* [Headers](#headers)\n", "* [Includes](#includes)\n", "* [Namespaces](#namespaces)\n", "* [Exceptions](#exceptions)\n", "* [Tests](#tests)\n", "* [Getter And Setter Functions](#getter-and-setter-functions)\n", "* [Spelling](#spelling)\n", "* [Miscellaneous](#miscellaneous)\n", "\n", "\n", "Our C++ coding style is based off of [Google's C++ Style Guide](https://google.github.io/styleguide/cppguide.html). We use [clang-format](https://clang.llvm.org/docs/ClangFormat.html) to enforce most of the nit-picky parts of the style, such as brackets and alignment, so this document highlights the important rules to follow that clang-format cannot enforce.\n", "\n", "If you want to know more about our coding style you can take a look at our [clang-format configuration file](https://github.com/UBC-Thunderbots/Software/blob/master/.clang-format).\n", "\n", "\n", "### C-Specific Guidelines\n", "The vast majority of the things noted in this document will apply to `C` code as well, but there are some special cases / exceptions for `C` code. Please also see the [Firmware architecture and design document](firmware-architecture-and-design) for much of the context needed for these.\n", "* If something is in a header, then it is *always* considered public.\n", "* Public names should always follow the format `PREFIX_FILENAME_NAME`, where:\n", "    * `PREFIX` is one of `app`, `io`, `shared`, depending on the high level folder this is under\n", "    * `FILENAME` is the name of the file (Example: `firmware_robot` for `firmware_robot.h`)\n", "    * `NAME` is the name of whatever the function/variable is, following standard naming rules indicated below for functions/variables.\n", "  \n", "  ```C \n", "  // Incorrect (missing prefix)\n", "  float firmware_robot_getRobotPositionX(Robot* robot);\n", "\n", "  // Incorrect (missing filename)\n", "  float app_getRobotPositionX(Robot* robot);\n", "\n", "  // Incorrect (incorrect function name style)\n", "  float app_firmware_robot_get_robot_position_x(Robot* robot);\n", "\n", "  // Correct\n", "  float app_firmware_robot_getRobotPositionX(Robot* robot);\n", "\n", "  // Correct\n", "  float shared_util_boundValue(float upper, float lower, float value);\n", "\n", "  ```\n", "\n", "* Structs are `CamelCaseUpperFirst`, and struct typedefs are `CamelCaseUpperFirst_t`\n", "\n", "  ``` C\n", "  // Incorrect\n", "  struct myDog;\n", "\n", "  // Incorrect\n", "  typedef struct MyDog MyDog_typedef; \n", "\n", "  // Correct\n", "  typedef struct MyDog MyDog_t;\n", "  ```\n", "\n", "### Names and Variables\n", "\n", "* Classes, structures, namespaces, unions, enumerates, \"typename\"-type template parameters, and typedefs names uses `CamelCase` with a capital letter.\n", "\n", "  ```cpp\n", "  // Incorrect\n", "  class eventHandler;\n", "\n", "  // Incorrect\n", "  class event_handler;\n", "\n", "  // Correct\n", "  class EventHandler;\n", "  ```\n", "\n", "* Constant variables uses `ALL_CAPS_WITH_UNDERSCORES`. Constant variables include _static const_, _const class members_, _const_ global variables, and _const_ enumerations.\n", "* All variable names are `lowercase_with_underscores`\n", "  ```cpp\n", "  // Incorrect\n", "  float calculatedDistnace;\n", "\n", "  // Correct\n", "  float calculated_distance;\n", "  ```\n", "* Function and method names are `camelCase` with leader lowercase letter.\n", "  ```cpp\n", "  // Incorrect\n", "  float get_distance();\n", "\n", "  // Incorrect\n", "  float GetDistance();\n", "\n", "  // Correct\n", "  float getDistance();\n", "  ```\n", "* File names are lower case and can contain underscores. The name should match or similar to the class/classes/functions it contains. Avoid using ambiguous names or names already exist in common libraries.\n", "  ```cpp\n", "  // Incorrect\n", "  ShootGoal.h\n", "\n", "  // Incorrect\n", "  sg.h\n", "\n", "  // Acceptable\n", "  shootgoal.h\n", "\n", "  // Correct\n", "  shoot_goal.h\n", "  ```\n", "* Avoid \"obvious\" or \"magic\" numbers unless it's part of a mathematical or physics formula (ex `A=0.5(b*h)`).\n", "  ```cpp\n", "  // Incorrect\n", "  float distance = catch_distance * 2.15;\n", "\n", "  // Correct\n", "  const float CATCH_DISTANCE_SCALE_FACTOR = 2.15;\n", "  float distance = catch_distance * CATCH_DISTANCE_SCALE_FACTOR;\n", "  ```\n", "* Avoid initializing multiple variables on the same line.\n", "  ```cpp\n", "  // Incorrect\n", "  int x, y, z = 0;\n", "\n", "  // Correct and equivalent to the above\n", "  int x;\n", "  int y;\n", "  int z = 0;\n", "\n", "  // However, the author may have intended the following\n", "  // or a code reader may have assumed the following\n", "  int x = 0;\n", "  int y = 0;\n", "  int z = 0;\n", "  ```\n", "\n", "\n", "### Comments\n", "\n", "Make sure to comment both the interface for a function or class, as well as the logic in the implementation. In general, try to make as many in-code documentations whenever possible.\n", "\n", "As much code documentation as possible should live with the code itself \\(in the form of comments\\). This makes it easier for people working on the code to find the information, and because the code and comments are version-controlled together if we ever go back to an older version of the code, we will have the corresponding older documentation as well.\n", "\n", "*Code comments are very important. Be sure to comment your code well enough so that another member of the team would be able to quickly get an understanding of what your code is doing, **and why**. Try not to make your comments unnecessarily verbose, but include as much detail you feel is necessary adequately explain the code. We realize that sounds contradictory, but use your best judgement as to what you think is clear and readable.*\n", "\n", "If you think some ASCII art will help explain something better, go for it! [asciiflow](http://asciiflow.com/) is a good online tool for creating this.\n", "\n", "* Comments regarding the interface of a class and its methods must be in the header file.\n", "* In-code documentation comments and function comments follow the [javadoc style](https://www.tutorialspoint.com/java/java_documentation.htm).\n", "  ```cpp\n", "  // Incorrect\n", "  // This function returns the power\n", "  float power(float a, float b);\n", "\n", "  // Correct\n", "  /**\n", "   * This function returns the power\n", "   * @param a the base\n", "   * @param b the exponent\n", "   * @return a^b\n", "   */\n", "  float power(float a, float b);\n", "  ```\n", "\n", "\n", "### Headers\n", "\n", "* Use _header guards_ to prevent issues of duplicate or circular includes which cause the source code to be compiled multiple times and cause build errors. \n", "    * If you're writing C++ (ie. not C), use `#pragma once` at the very top of the file. \n", "      ```cpp\n", "      #pragma once\n", "      ```\n", "    * If you're writing C, header guards should be used. They should be fully capitalized and include `_H_` at the end.\n", "      ```c\n", "      #ifndef AI_WORLD_FIELD_H_\n", "      #define AI_WORLD_FIELD_H_\n", "      ```\n", "      At the end of the file, make sure to close the conditional preprocessor. An inline comment must be at the end with the same name as the _\\#define_\n", "      ```cpp\n", "      #endif /* AI_WORLD_FIELD_H_ */\n", "      ```\n", "*In general the reason a header guard's name is so complicated is to make sure that it is unique. There cannot be any other header guards or constants defined with #define anywhere else in the code, or weird build issues may occur.*\n", "\n", "\n", "### Includes\n", "\n", "* Use `#include` sparingly and only include the necessary sources to build the file. Do not include headers whos class or implementation is not used.\n", "* Often `` files include its corresponding header `.h` file, it means the `` file include everything included in the header. Do not have duplicate `#include`'s in both `.h` and `` files.\n", "* `#include`s are generally preferred written on the `` side; use minimum `#include` in the header file. Use _forward declarations_ in headers if necessary.\n", "* Specify full path of the include file on the file system, relative to the top-level project directory or _WORKSPACE_ file. Do not use relative paths.\n", "  ```cpp\n", "  // Incorrect\n", "  #include \"../../tactic/tactic.h\"\n", " \n", "  // Incorrect\n", "  #include \"tactic.h\"\n", "\n", "  // Correct\n", "  #include \"software/ai/hl/stp/tactic/tactic.h\"\n", "  ```\n", "\n", "### Namespaces\n", "* We generally don't use namespaces because they add extra complexity, and we do not really need the protection they provide\n", "    * We have found it's generally more work than it's worth to have everyone remember to put things in the right namespaces when writing code, and remember to manage the namespaces when code is being used\n", "    * The main purpose of namespaces is to compartmentalize code and help avoid conflicts. This way if 2 libraries define functions called `add()`, as long as they are in different namespaces they can be specified and used independently without issue. Because we aren't publishing our code as a library, and most libraries we use already do their own namespacing, we don't _really_ need the protection namespaces provide in this case.\n", "* Do not use `using namespace ...` in header files.\n", "    * This is because any file that includes this header will also implicitly be using the namespace, which can cause subtle issues and naming conflicts.\n", "\n", "\n", "### Exceptions\n", "\n", "* Throwing an exception indicates that the AI has entered an unrecoverable state.\n", "* In almost all cases, it is preferable to return a `std::optional` type, so the caller has to handle the case of the called function \"failing\", perhaps alongside some logging that the error occured.\n", "\n", "\n", "### Tests\n", "Some general guidelines when writing tests are:\n", "\n", "* **Tests should test a single, distinct behaviour, isolated to a single class (or group of functions in C).** For example, if you have a test called `assign_and_clear_goalie`, it should probably be broken up into `assign_goalie` and `clear_goalie`. While `clear_goalie` might depend on `assign_goalie`, structuring things like this allows us to quickly narrow down where the problem might be by just looking at what tests failed, without having to go tear apart large unit tests.\n", "* **Don't be afraid to use long test names.**: When naming things, as programmers we keep names short so that they can be used elsewhere without taking up an entire line. But no one is going to be using your test name elsewhere, so feel free to be verbose. Instead of `equality_operator_3`, call your test `equality_operator_two_teams_different_number_of_robots`\n", "\n", "### Getter And Setter Functions\n", "* in general, getter and setter methods on classes should be written like `getName()`, `setName(string name)`, with the following exceptions\n", "  * getters with the return type `bool` may be prefixed with `is` instead of `get`, ie. `bool isActive()`\n", "  * getters that are used _incredibly_ frequently and are _incredibly_ obvious may not require the `get` prefix. For example `Point::x()` and `Point::y()` \n", "\n", "\n", "### Spelling\n", "\n", "* Code, comment, and documentations should not contain spelling errors.\n", "* Locale-specific English words follow Canadian/British spelling (\"colour\", \"neighbour\", \"honour\", \"metre\").\n", "    * Exceptions:\n", "      * Use \"defense\" in lieu of \"defence\" as it is more similar to the word \"defensive\".\n", "      * Use \"offense\" in lieu of \"offence\".\n", "\n", "\n", "### Miscellaneous\n", "\n", "* All source files should have an empty line at the end of the file to avoid issues with GitHub.\n", "* Avoid using C-style casts like `(int) x`. Use C++ casts such as static cast:\n", "  ```cpp\n", "  static_cast<int>(x);\n", "  ```\n", "* Simple data types \\(`char`, `short`, `int`, `long`, `float`, `double`, `pointers`\\) are generally pass by value.\n", "  ```cpp\n", "  void foo(double x);\n", "  ```\n", "* Non-simple data types are generally passed by _const_ references whenever possible. Try avoid setting values by reference, since this makes it harder to follow the flow of control and data in the program.\n", "  ```cpp\n", "  // Not ideal\n", "  // Pass by reference to set data\n", "  void getVisionPacket(Packet& packet);\n", "\n", "  // Preferred\n", "  // Pass by const reference\n", "  Point predictBallPosition(const Ball& ball);\n", "  ```\n", "* All constructors should be marked with the `explicit` keyword. In the case of a one-argument constructor, this prevents it from being used as an implicit type conversion; in the case of other constructors, it acts as a safeguard in case arguments are later added or removed.\n", "  ```cpp\n", "  explicit AI(const World& world);\n", "  ```\n", "* Use C++ smart pointers and avoid raw pointers. (See also: [what are smart pointers and why they are good](https://stackoverflow.com/questions/106508/what-is-a-smart-pointer-and-when-should-i-use-one))\n", "* Use C++11 keyword `using` to make _type alias_ instead of `typedef` as they're equivalent except the former is compatible with templates.\n", "  ```cpp\n", "  // Incorrect\n", "  typedef std::vector<std::pair<int, int>> PointsArray;\n", "\n", "  // Correct\n", "  using PointsArray = std::vector<std::pair<int, int>>;\n", "  ```\n", "* Avoid initializing multiple variables on the same line.\n", "  ```cpp\n", "  // Incorrect\n", "  int x, y, z = 0;\n", "\n", "  // Correct\n", "  int x;\n", "  int y;\n", "  int z = 0;\n", "\n", "  // However, the author may have intended the following\n", "  // or a code reader may have assumed the following\n", "  int x = 0;\n", "  int y = 0;\n", "  int z = 0;\n", "  ```  \n", "* Avoid ternary operators. Clarity is more important than line count.\n", "  ```cpp\n", "  // Incorrect\n", "  c = ((a == 0) || ((a + b) < 10)) ? a : a + b;\n", "\n", "  // Correct\n", "  if ((a == 0) || ((a + b) < 10))\n", "  {\n", "    c = a;\n", "  }\n", "  else\n", "  {\n", "    c = a + b;\n", "  }\n", "  ```\n", "* Always use curly braces around code blocks, even if the braces surround a single statement.\n", "  ```cpp\n", "  // Incorrect\n", "  while (i < 10)\n", "    i++;\n", "    c[i] = i + 1;\n", "\n", "  // Correct\n", "  while (i < 10)\n", "  {\n", "    i++;\n", "  }\n", "  c[i] = i + 1;\n", "  ```\n", "\n"], "getting-started": ["# Software Setup\n", "\n", "## Table Of Contents\n", "<!-- \n", "    NOTE: when creating or re-creating a table of contents like this, you can\n", "    save a LOT of time by using this tool: \n", "    https://github.com/ekalinin/github-markdown-toc\n", "-->\n", "* [Table Of Contents](#table-of-contents)\n", "* [Introduction](#introduction)\n", "* [Installation and Setup](#installation-and-setup)\n", "* [Operating Systems](#operating-systems)\n", "* [Getting the Code](#getting-the-code)\n", "* [Running the setup scripts](#running-the-setup-scripts)\n", "   * [Installing Software Dependencies](#installing-software-dependencies)\n", "   * [Installing Firmware Dependencies](#installing-firmware-dependencies)\n", "   * [Setting Up USB Permissions](#setting-up-usb-permissions)\n", "   * [Installing grSim](#installing-grsim)\n", "   * [Installing CLion](#installing-clion)\n", "      * [Getting your Student License](#getting-your-student-license)\n", "      * [Installing CLion](#installing-clion-1)\n", "* [Building and Running the Code](#building-and-running-the-code)\n", "* [Debugging](#debugging)\n", "* [Profiling](#profiling)\n", "* [Flashing and Debugging A STM32 MCU](#flashing-and-debugging-a-stm32-mcu)\n", "\n", "## Introduction\n", "These instructions assume that you have the following accounts setup:\n", "- [Github](https://github.com/login)\n", "- [Slack](https://thunderbots.slack.com/)\n", "\n", "These instructions assume you have a basic understanding of Linux and the command-line. There are many great tutorials online, such as [LinuxCommand](http://linuxcommand.org/). The most important things you'll need to know are how to move around the filesystem, and how to run programs or scripts.\n", "\n", "## Installation and Setup\n", "\n", "## Operating Systems\n", "\n", "We currently only support Linux, specifically Ubuntu 18.04 LTS. You are welcome to use a different version or distribution of Linux, but may need to make some tweaks in order for things to work.\n", "\n", "## Getting the Code\n", "\n", "1. Open a new terminal\n", "2. Install git by running `sudo apt-get install git`\n", "3. Go to the [software repository](https://github.com/UBC-Thunderbots/Software)\n", "4. Click the `Fork` button in the top-right to fork the repository ([click here to learn about Forks](https://help.github.com/en/articles/fork-a-repo))\n", "   1. Click on your user when prompted\n", "   2. You should be automatically redirected to your new fork\n", "5. Clone your fork of the repository (you can put it wherever you want)\n", "   1.  Eg. `git clone https://github.com/<your-username>/Software.git`\n", "      1. You can find this link under the green `Clone or Download` button on the main page of the Software repository\n", "   2. We recommend cloning with SSH if you don't like typing your username and password all the time. Instructions can be found [here](https://help.github.com/articles/connecting-to-github-with-ssh/).\n", "6. Set up your git remotes ([what is a remote and how does it work?](https://git-scm.com/book/en/v2/Git-Basics-Working-with-Remotes))\n", "   1. You should have a remote named `origin` that points to your fork of the repository. Git will have set this up automatically when you cloned your fork in the previous step.\n", "   2. You will need to add a second remote, named `upstream`, that points to our main Software repository, which is where you created your fork from. (**Note:** This is _not_ your fork)\n", "      1. Open a terminal and navigate to the folder you cloned (your fork): `cd path/to/the/repository/Software`\n", "      2. Navigate to our main Software repository in your browser and copy the url from the \"Clone or Download\" button. Copy the HTTPS url if you originally cloned with HTTPS, and use the SSH url if you previously cloned with SSH\n", "      3. From your terminal, add the new remote by running `git remote add upstream <the url>` (without the angle brackets)\n", "         1. Eg. `git remote add upstream https://github.com/UBC-Thunderbots/Software.git`\n", "      4. That's it. If you want to double check your remotes are set up correctly, run `git remote -v` from your terminal (at the base of the repository folder again). You should see two entries: `origin` with the url for your fork of the repository, and `upstream` with the url for the main repository\n", "\n", "*See our [workflow document](workflow) for how to use git to make branches, submit Pull Requests, and track issues*\n", "\n", "## Running the setup scripts\n", "\n", "We have several setup scripts to help you easily install the necessary dependencies in order to build and run our code. You will want to run the following scripts, which can all be found in `Software/environment_setup`\n", "\n", "### Installing Software Dependencies\n", "\n", "* Inside a terminal, navigate to the environment_setup folder. Eg. `cd path/to/the/repository/Software/environment_setup`\n", "* Run `./setup_software.sh`\n", "  * You will be prompted for your admin password\n", "  * This script will install everything necessary in order to build and run our main `AI` software \n", "\n", "### Installing Firmware Dependencies\n", "\n", "* Inside a terminal, navigate to the environment_setup folder. Eg. `cd path/to/the/repository/Software/environment_setup`\n", "* Run `./setup_firmware.sh`\n", "  * You will be prompted for your admin password\n", "  * This script will install everything necessary in order to build and run our robot firmware\n", "\n", "### Setting Up USB Permissions\n", "\n", "* inside a terminal, navigate to the `environment_setup` folder. Eg. `cd path/to/the/repository/Software/environment_setup` \n", "  * Run `./setup_udev_rules.sh`\n", "    * You will be prompted for your admin password\n", "    * This script will set up the USB permissions required in order to use our radio/wifi dongle\n", "\n", "### Installing grSim\n", "\n", "* Inside a terminal, navigate to the environment_setup folder. Eg. `cd path/to/the/repository/Software/environment_setup`\n", "* Run `./setup_grsim.sh`\n", "  * You will be prompted for your admin password\n", "  * This script will install `grSim`, which is the main simulator we use for development\n", "\n", "### Installing CLion\n", "\n", "CLion is our main IDE for editing our C/C++ code. It is designed to work with our build system, `bazel`, and has all the great features of an IDE such as code completion, syntax highlighting etc. We **strongly** recommend installing CLion and using it for development.\n", "\n", "#### Getting your Student License\n", "\n", "CLion is free for students, and you can use your UBC alumni email address to create a student account. If you already have a student account with JetBrains, you can skip this step.\n", "\n", "1. If you haven't done so already, setup your UBC alumni email account [here](https://id.ubc.ca/).\n", "2. Using your UBC email account, get a JetBrains education account [here](https://www.jetbrains.com/shop/eform/students).\n", "   1. _JetBrains will send an initial email to confirm the UBC email you inputted. Once you have confirmed, another email will be sent to activate your new education account. You will use this account to set up CLion later on._\n", "\n", "#### Installing CLion\n", "\n", "* Inside a terminal, navigate to the environment_setup folder. Eg. `cd path/to/the/repository/Software/environment_setup`\n", "* Run `./install_clion.sh` (* **DO NOT** download CLion yourself unless you know what you're doing. The `install_clion.sh` script will grab the correct version of CLion and the Bazel plugin to ensure everything is compatible *).\n", "* When you run CLion for the first time you will be prompted to enter your JetBrains account or License credentials. Use your student account.\n", "\n", "## Building and Running the Code\n", "\n", "### From the command-line\n", "\n", "1) Navigate to the root of this repository (wherever you have it cloned on your computer)\n", "2) Navigate to `src`.\n", "3) Build a specific target for running (for example): `bazel build //software/geom:angle_test`\n", "4) Run a specific target by running (for example): `bazel run //software/geom:angle_test`\n", "4) Run a specific *test* by running (for example): `bazel test //software/geom:angle_test`\n", "3) Build everything by running `bazel build //...`\n", "4) Run all the tests by running `bazel test //...`\n", "*See the bazel [command-line docs](https://docs.bazel.build/versions/master/command-line-reference.html) for more info.*\n", "\n", "### With CLion\n", "\n", "First we need to setup CLion\n", "1. Open CLion\n", "2. Select `Import Bazel Project`\n", "3. Set `Workspace` to wherever you cloned the repository + `/src`. So if I cloned the repo to `/home/my_username/Downloads/Software`, my workspace would be `/home/my_username/Downloads/Software/src`.\n", "4. Select `Import project view file`, and select the file `.bazelproject` (which will be under the `src` folder)\n", "5. Click `Next`\n", "6. Change the Project Name to whatever you want. Leave everything else as it is (\"Use shared project view file\" should be selected).\n", "6. Click `Finish` and you're good to go! Give CLion some time to find everything in your repo.\n", "\n", "\n", "Now that you're setup, if you can run it on the command line, you can run it in clion. There are two main ways of doing so.\n", "1. Open any `BUILD` file and right clight in a `cc_library()` call. This will give you the option to `Run` or `Debug` that specific target. Try it by opening `Software/src/software/geom/BUILD` and right-clicking on the `cc_library` for `angle_test`!\n", "2. Add a custom build configuration (more powerful, so make sure you understand this!)\n", "    1. Select `Add Configuration` from the drop-down in the top-right of CLion\n", "    2. Click on `+`, choose `Bazel Command`.\n", "    3. For `Target Expression`, you can put anything that comes after a `build`, `run`, `test`, etc. call on the command line. For example: `//software/geom:angle_test`.\n", "    4. For `Bazel Command` you can put any bazel command, like `build`, `run`, `test`, etc.\n", "    5. Click `Ok`, then there should be a green arrow in the top right corner by the drop-down menu. Click it and the test will run!\n", "\n", "## Debugging\n", "Debugging from the command line is certainly possible, but debugging in a full IDE is *really* nice (plz trust us). \n", "\n", "### With CLion\n", "Debugging in CLion is as simple as running the above instructions for building CLion, but clicking the little green bug in the top right corner instead of the little green arrow!\n", "\n", "### From The Command line\n", "`bazel run -c dbg --run_under=\"gdb\" //some/target:here` will run the target in `gdb`. Please see (here)[https://www.cs.cmu.edu/~gilpin/tutorial/] for a tutorial on how to use `gdb` if you're not familiar with it.\n", "\n", "\n", "## Profiling \n", "Unfortunately profiling for Bazel targets is not supported in CLion at this time. Hence the only way is via command line. Use the following command:\n", "```\n", "bazel run -c dbg --run_under=\"valgrind --tool=callgrind --callgrind-out-file=/ABSOLUTE/PATH/TO/profile.callgrind\" //target/to:run\n", "\n", "// Example\n", "bazel run -c dbg --run_under=\"valgrind --tool=callgrind --callgrind-out-file=/tmp/profile.callgrind\" //software/geom:angle_test\n", "```\n", "This will output the file at the _absolute_ path given via the `--callgrind-out-file` argument. This file can then be viewed using `kcachegrind` (example: `kcachegrind /tmp/profile.callgrind`), giving lots of useful information about where time is being spent in the code.\n", "\n", "## Flashing And Debugging A STM32 MCU\n", "1. Make sure you've followed [Installing Firmware Dependencies](#installing-firmware-dependencies), and have a [NUCLEO-H743ZI](https://www.st.com/en/evaluation-tools/nucleo-h743zi.html) plugged into your computer.\n", "2. From the `src` folder, run `bazel run --cpu=stm32h7 --compilation_mode=dbg //firmware_new/tools:debug_firmware_on_arm_board`. We specify `--cpu=stm32h7` because we want to compile code for the stm32h7 MCU (rather then a `x86_64` processor like you have in your computer), and `--compilation_mode=dbg` in order to build in the debug symbols required so you can step through the code and see what's going on. You'll be given a list of elf files to choose from.\n", "3. Assuming you choose 0 from the list in step (2), run `bazel run --cpu=stm32h7 --compilation_mode=dbg //firmware_new/tools:debug_firmware_on_arm_board 0`. This will load the `.elf` file associated with (0) to the the nucleo and put you into a gdb prompt.\n", "4. At this point you should be in a gdb window. Take a look at [this tutorial](https://www.cprogramming.com/gdb.html) for some basics.\n", "\n", "## Working with CubeMX to regenerate code\n", "1. Make sure you've followed [Installing Firmware Dependencies](#installing-firmware-dependencies)\n", "2. To regenerate code from the `.ioc` file, run `bazel run //firmware_new/tools:cubemx_regen path/to/directory/with/.ioc`. The directory that is passed in as an argument must only contain 1 ioc file, which will be used to generate code into the same directory.\n", "\n", "To make sure we are all using the same cube version, run `STM32CubeMX` when editing the `.ioc` file.\n"]}, "code_comments_c++": {"send_proto_over_udp": [" we create a wheel control msg, and request wheel 1 to spin at 100 rpm forwards", " these wheel profile will be used across multiple wheels", " turn two of the wheels on with this profile", " NOTE that the other two wheels are not being populated", " create a RobotCommunicator with a NetworkMedium", " 4000 hz test"], "robot_communicator": [" start thread to send data from the buffer", " place all templated communcation msg send/receive pair initializations here"], "network_medium": [" TODO change to multicast after firmware is on RTOS", " Throw this exception up to top-level, as we have no valid", " recovery action here", " Stop the io_service. This is safe to call from another thread.", " https://stackoverflow.com/questions/4808848/boost-asio-stopping-io-service", " This MUST be done before attempting to join the thread because otherwise the", " io_service will not stop and the thread will not join", " Join the io_service_thread so that we wait for it to exit before destructing the", " thread object. If we do not wait for the thread to finish executing, it will call", " `std::terminate` when we deallocate the thread object and kill our whole program", " start the thread to run the io_service in the background"], "polynomial_2d_test": [" This function should probably never be used like this, but this checks that", " we're at least executing defined behavior", " This function should probably never be used like this, but this checks that", " we're at least executing defined behavior", " These values were calculated via numerical integration in GNU Octave with the", " following program:", "", " clang-format off", " ```", " f=@(t) sqrt((0.1* t.^2 + 3*t.^1 - 0.5).^2 + (-0.2*t.^2 + 38.2*t.^1 - 3).^2)", " for t = linspace(-6, 6, 17)", "     disp(quadcc(f, -6, t));", "     disp(\",\")", " end", " ```", " clang-format on", " This function should probably never be used like this, but this checks that", " we're at least executing defined behavior", " Note that for the purposes of this test it does not matter what the t and s", " values here actually are, as long as they're both in ascending order, as this", " function's job is merely to interpolate over the given set of values, whatever", " those values might be.", " Check some arc length points that require no interpolation", " Check some arc length points that should be determined via interpolation"], "firmware_robot_test": [" Check initial values", " Modify the values", " Check that the modified values are reflected when we get the ControllerState", " from the robot again"], "full_system_main": [" Member variables we need to maintain state", " They are kept in an anonymous namespace so they are not accessible outside this", " file and are not created as global static variables.", " namespace", " clang-format off", " clang-format on", "", " Build one string with all the backend_names", "", " Setup dynamic parameters", " TODO (Issue #960): Once we're using injected parameters everywhere (instead of", "                    just global accesses, `Util::DynamicParameters` should be", "                    deleted, and we should just create an instance here instead)", " The ai has to be initialized after the backend (which is started in", " parseCommandLineArgs) This is a bug. See #834", " This blocks forever without using the CPU", " Wait for the visualizer to shut down before shutting", " down the rest of the system", " This blocks forever without using the CPU"], "util_test": [" test case 1", " test case 2", " test case 3", " test case 4", " should be random number here", " circle is tangent to triangle, no intersect", " circle is completely inside triangle, intersect", " circle is tangent to vertice, no intersect", " Point in 1st quadrant, rectangle in the 3rd quadrant. Should fail!", " Point in 3rd quadrant, rectangle in the 3rd quadrant. Pass!", " Point is one of the corners of the rectangle. Pass", " Point is on the edge of the rectangle. Pass", " Point in the 1st quadrant, rectangle in the 1st quadrant. Pass", " Point in the 2nd quadrant, rectangle in the 2nd quadrant. Point is off", " above, Fail.", " Point in the 2nd quadrant, rectangle in the 4th quadrant. Point is off to", " the left, Fail.", " Point in the 2nd quadrant, rectangle centered at origin. Point is off", " above, Fail.", " Point in the 2nd quadrant, rectangle centered at origin. Point is off to", " the left, Fail.", " i don't know which intersections will come in which order", " should check for the the rare cases", " generate three random points", " We do not know what the  tolorance of the function is, but we", " probabaly should check if segments overlap completely", " This is a test from a bug found", " should check for the the rare cases", " generate three random points", " We do not know what the  tolorance of the function is, but we", " probabaly should check if segments overlap completely", " the last part", " generate a number", " either bigger or", " smaller than 1", " as a scaling factor for a2 and b2", " uncomment to print out some messages", " should check for the the rare cases", " case where vector faces segment but segment may/ may not be long enough", " generate three random points", " We do not know what the  tolerance of the function is, but we", " probably should check if segments overlap completely", " as a scaling factor for b2", " case where vector does not face segment", " generate three random points", " We do not know what the  tolerance of the function is, but we", " probably should check if segments overlap completely", " as a scaling", " factor for b2,", " make sure it", " is long enough", " I don't know what the function is supposed to return, so I just set the", " test value to the return value of the function for now.", " Test to ensure that intersects(Ray, Segment) does not use ray.getDirection() as a point", " along the ray (Should be ray.getStart() + ray.GetDirection())", " Two vectors that form an acute angle over the negative y-axis", " Two vectors that form an acute angle over the positive y-axis", " Test to see if raySegmentIntersection() returns the correct parameters when the ray and", " segment intersect once", " Test to see if raySegmentIntersection() returns the correct parameters when the ray and", " segment don't intersect", " Test to see if raySegmentIntersection() returns the correct parameters when the ray and", " segment are overlapping and parallel", " Test to see if raySegmentIntersection() returns the correct parameters when the ray and", " segment are overlapping at segment end and parallel", " Test to see if raySegmentIntersection() returns the correct parameters when the ray and", " segment are overlapping at segment start and parallel", " Test to see if the segment start and end are returned if the ray passes through both", " Check the case where both rays intersect the segment only once (forming an intersection", " segment within the segment)", " Test that no segment is returned if both rays do not intersect the segment, and the", " area between the rays do not enclose the segment", " Test that a correct intersection point is returned for 2 rays that intersect once", " Ray at origin pointing upwards", " Ray up and to the right that points right", " Test that an intersection is not returned if the opposite direction of the rays", " intersect", " Ray positioned at origin pointing down", " Test that an intersection is not returned if the Rays are overlapping", " Ray positioned at origin pointing up", " Test that the segment between the intersecting ray and the segment extreme is returned", " when one ray intersects, and the other would intersect an infinitely long segment", " Test that the segment between the intersecting ray and the segment extreme is returned", " when one ray intersects, and the other would intersect an infinitely long segment", " Test that the function returns the segment when the rays enclose the segemnt", " Test that the function returns null when the rays only partially intersect the segment", " Test that the function returns null if the segment is only partially enclosed with 1", " real intersection", " Test that function returns the larger segment when considering 2 redundant segments", " Test that function returns the larger segment when considering 2 non-parallel segments", " Test that function returns one of the segments if they are exactly the same", " Test if segments are merged if they are parallel and only partially overlapping", " Test if segments are merged if they are parallel and only partially overlapping", " Test to see if the 1 is returned when the point exists within the rectangle", " Test to see if the 1 is returned when the point exists on the boundries of the", " rectangle", " Test to see if the 0 is returned when the point exists outside of the rectangle", " Test finding the open circles in rectangle with no points", " Calculated from Voronoi diagram", " Corner Points", " Circle 1", " Circle 2", " Circle 1", " Circle 2"], "util": [" empirically determined EPS value to be close enough while still passing tests"], "spline": [" Note: this could be more performant with binary search", " only splines with more than one point can have segments"], "voronoi_diagram": [" Edges extending outside the rectangle will be infinite edges", " The direction of the infinite vector will be perpendicular to the", " vector connecting the two points which own the two half edges. We can", " use this to calculate another point on the infinite edge as show below", " (the x's are points in this case)", "      +-------------------------------------+", "      |                                     |", "      |                 ^                   |", "      |                 |                   |", "      |                 |                   |", "      |                 |                   |", "      |         X       |        X          |", "      |                 |                   |", "      |                 |                   |", "      |                 v                   |", "      |                                     |", "      +-------------------------------------+", " Extend the edge out to beyond the rectangle to ensure interception", " functions work.", " For each vertex, construct it's delauney triangle and then compute the largest", " empty circle around it", " NOTE: Generally there is a 1:1 mapping from vertex in voronoi diagram to delauney", " triangle, but in the case of a degenerate vertex there may be more then one", " triangle for a given vertex. We just ignore this case because it normally only", " occurs if we created the Voronoi diagram from line segments with shared endpoints", " (and we don't even give it segments!) see \"is_degenerate\" here:", " https://www.boost.org/doc/libs/1_60_0/libs/polygon/doc/voronoi_diagram.htm", " Code is a derivative of the answer to this:", " https://stackoverflow.com/questions/34342038/how-to-triangulate-polygons-in-boost", " We only want to consider vertices within our rectangle", " Find the smallest distance from the vertex to a vertex on it's", " corresponding delauney triangle"], "ai": [" We use the current time in nanoseconds to initialize STP with a \"random\" seed"], "game_state_play_selection_test": [" TEST_P(GameStatePlaySelectionTest, test_play_selection_for_refbox_game_states)", "{", "    world.mutableGameState().updateRefboxGameState(GetParam());", "    ai.getPrimitives(world);", "    // assert that the play name is not \"None\"", "    ASSERT_NE(ai.getPlayInfo().play_name, AI::NO_PLAY_NAME);", "}", "", " auto all_refbox_game_states = ::Test::TestUtil::getAllRefboxGameStates();", "", " INSTANTIATE_TEST_CASE_P(AllRefboxGameStates, GameStatePlaySelectionTest,", "                        ::testing::ValuesIn(all_refbox_game_states.begin(),", "                                            all_refbox_game_states.end()));"], "movespin_primitive_test": [""], "pivot_primitive_test": [" create a test ball, pivot doesn't need a ball", " create primitive visitor", " visit primitive", " get motion command", " robot needs to pick the shortest path to rotate, based on where it is and the magnitude", " of of the vector from its next position to the final position.", " Test picking a clockwise path", " asked to pivot to 1/4 pi below x axis, with radius of 10, from point (10, -10)", " (chosen far so all values pivot cw) which should result in a cw rotation on all", " parameterized pivot points", " place the robot in the first quadrant, should rotate CW", " figure out if the tangential vector is clockwise, take a cross product of a 2d", " vector in 3d plane", " https://math.stackexchange.com/questions/74307/two-2d-vector-angle-clockwise-predicate", " this vector connects the robot to the pivot point, the tangential vectors", " that look at both directions will be perpendicular to this vector", " if c is less than 0, then direction vector is on the clockwise side of radial", " vector, which means the robot is rotating clockwise", " Test picking a counter-clockwise path", " asked to pivot to 3/4 pi above x axis, with radius of 10, from point (-10, 10)", " (chosen far so all values pivot ccw) which should result in a cw rotation on all", " parameterized pivot points", " place the robot in the first quadrant, should rotate CW", " figure out if the tangential vector is clockwise, take a cross product of a 2d", " vector in 3d plane", " https://math.stackexchange.com/questions/74307/two-2d-vector-angle-clockwise-predicate", " this vector connects the robot to the pivot point, the tangential vectors", " that look at both directions will be perpendicular to this vector", " if c is greater than 0, then direction vector is on the counter-clockwise side of", " radial vector, which means the robot is rotating counter-clockwise", " Create the parameterize test case for the tests above", "", " Robot should not move test, uses it for both robot position and pivot point position", " The following two tests use it to place the pivot point at different locations, and", " then the tests make sure that the robot choses the right direction to move.", "", " If stopping, and rotating work, pivot should work"], "direct_velocity_primitive_test": [""], "move_primitive_test": [""], "direct_wheels_primitive": [" Clamp wheel power if out of range, log a warning"], "catch_primitive_test": [""], "direct_wheels_primitive_test": [""], "chip_primitive_test": [""], "kick_primitive_test": [""], "dribble_primitive_test": [""], "stop_primitive_test": [""], "enemy_threat": [" Store a map of robots that can receive the ball, and the list of all robots", " that could pass to them. The custom comparator is necessary to use the Robot", " class as a key in the map", " For each of the passers, check which robots they could pass to", " Create a vector of obstacles that includes all robots except the", " current passer and receiver", " Check if the pass from the passer to the receiver would be blocked by any", " robots", " This receiver already exists in the map and can", " already be passed to by another robot. We add the passer", " to the list of possible passers for this robot", " This receiver robot does not exist in the map. Create a", " new entry to track this receiver and add the passer", " We calculate the minimum number of passes it would take for the initial_passer", " robot to pass the ball to the final_receiver, assuming both robots are on the given", " team", "", " This algorithm essentially treats the team of robots like a Directed Acyclic", " Graph and \"traverses\" the graph to find the shortest path to the robot", " The robots that could have the ball and make a pass at each iteration. They", " are on the \"frontier\" of the graph search", " The remaining robots we haven't checked yet", " Remove the initial passer since we already start off visiting it, and don't need", " to again", " TODO: possibly re-enable using friendly robots as obstacles if we can find a way to", " stop defenders from oscillating between positions See", " https://github.com/UBC-Thunderbots/Software/issues/642", " all_robots.insert(all_robots.end(), other_robots.begin(), other_robots.end());", " On each iteration, check what robots can be passed to. These receivers will", " become the passers on the next iteration. This is like expanding the frontier", " of the graph", "", " We continue to iterate and check greater numbers of passes until one of the", " following cases:", " * There are no more passers at the end of the iteration. This means no more", "   unvisited robots can be passed to", " * There are no more unvisited robots", " * We have iterated up to the size of the team. This is a fallback case to", "   prevent any infinite loops, just in case", "", " We already check the case where the passer and receiver are the same. If this was", " the case, 0 passes would be required. Since that case is already checked, when we", " start the loop we are checking for the possibility of the receiver getting the ball", " in 1 pass. This is why pass_num starts at 1.", " If the robot we are looking for is a receiver, return the number of", " passes and the passer to this robot", " If there are multiple robots that can pass to the robot, we assume", " it will receive the ball from the closest one since this is more", " likely", " Create a list of all robots that could receive the ball this iteration", " All robots that could have received the ball now become passers", " Remove any receivers from the unvisited robots, since they have", " now been visited", " If we have checked all the robots we can and still haven't found the robot we", " are looking for, it must be blocked and unable to be passed to in the current", " state. Therefore, we return an std::nullopt", " A lambda function that implements the '<' operator for the EnemyThreat struct", " so it can be sorted. Lower threats are \"less than\" higher threats.", " Robots with the ball are more threatening than robots without the ball, and", " robots with the ball are the most threatening since they can shoot or move", " the ball towards our net", " If both robots have the ball, the robot with a worse shot on our net is less", " threatening (although this case is unlikely to happen since usually only 1", " robot can have the ball at a time)", " If neither robot has the ball, the robot that takes longer to reach via", " passing is less threatening", " Finally, if both robots can be reached in the same number of passes,", " the robot with a smaller view of the net is considered less", " threatening. The reason we use goal_angle here rather than the", " best_shot_angle is that the goal_angle doesn't change if the robot is", " blocked from shooting (eg. by a defender). This makes the evaluation", " more stable since the value won't change drastically as our robots", " move into defensive positions and change the best_shot_angle. If we had", " fewer robots than the enemy team and were using the best_shot_angle,", " defenders could oscillate between enemies since when the defender", " blocks one enemy, the unblocked one becomes more threatening and the", " defender would then move there.", " Sort threats from highest threat to lowest threat", " Use reverse iterators to sort the vector in descending order", " Get the angle from the robot to each friendly goalpost, then find the", " difference between these angles to get the goal_angle for the robot", " Set default values. If the robot can't be passed to we set the number of passes", " to the size of the enemy team so it is the largest reasonable value, and the", " passer to be an empty optional", " Sort the threats so the \"most threatening threat\" is first in the vector, and the", " \"least threatening threat\" is last in the vector"], "pass_test": [""], "ball": [" The cap style must be NOT be set to SquareCap. It can be set to anything else.", " Drawing a line of length 0 with the SquareCap style causes a large line to be drawn", " The cap style must be NOT be set to SquareCap. It can be set to anything else.", " Drawing a line of length 0 with the SquareCap style causes a large line to be drawn"], "detect_threat_test": ["", " Test where the ball will intersect the friendly net", " Test where the ball will not intersect the friendly net", " Test where the ball will intersect the enemy net", " Test where the ball will not intersect the enemy net"], "intercept": ["", " We use this to take a smooth absolute value in our objective function", " This is the objective function that we want to minimize, finding the", " shortest duration in the future at which we can feasibly intercept the", " ball", " We take the absolute value here because a negative time makes no sense", " If the ball timestamp is less then the robot timestamp, add the difference", " here so that we're optimizing to a duration that is after the robot", " timestamp", " Estimate the ball position", " Figure out how long it will take the robot to get to the new ball position", " Figure out when the robot will reach the new ball position relative to the", " time that the ball will get there (ie. will we get there in time?)", " We want to get to the ball at the earliest opportunity possible, so", " aim for a time diff of zero. We use a smooth approximation of", " the maximum here", " Figure out when/where to intercept the ball. We do this by optimizing over", " the ball position as a function of it's travel time", " We make the weight here an inverse of the ball speed, so that the gradient", " descent takes smaller steps when the ball is moving faster", " In the objective function above, if the robot timestamp > ball timestamp, we", " add on the difference so we get a intercept time after the robot timestamp, so", " we need to do the same here to get the duration we actually optimized on", " Check that we can get to the best position in time", " NOTE: if ball velocity is 0 then ball travel duration is infinite, so this", " check isn't relevent in that case", " Check that the best intercept position is actually on the field", " namespace Evaluation"], "robot": [" The cap style must be NOT be set to SquareCap. It can be set to anything else.", " Drawing a line of length 0 with the SquareCap style causes a large line to be drawn", " This defines the rectangle that will \"clip\" or cover part of the robot ellipse.", " This is what allows us to easily draw the flat front of the robot. We create an", " invisible smaller \"window\" rectangle that the robot ellipse is shown through", " This robot ellipse graphics item is a child of the robot_clipping_rect above so", " that is can be covered / clipped by the clipping rect", " Scale the text down so it fits right below the robot being drawn. We use the width", " to calculate the scaling so that we can always ensure the text will fit within the", " width of the robot's bounding box, and won't overflow if the text gets too long. We", " care less about the height and just allow it to scale along with the width.", " Flip the y-axis so the text show right-side-up. When we set up the GraphicsView", " that contains the scene we apply a transformation to the y-axis so that Qt's", " coordinate system matches ours and we can draw things without changing our", " convention. Unfortunately this flips all text by default, so we need to flip it", " back here.", " Place the text right under the robot", " TODO: Show robot charge state"], "enemy_threat_test": [" Blocks the pass from robot 0 to robot 2", " Blocks the pass from robot 0 to robot 1", " A valid result should have been found", " Robot 0 should be able to pass to robot 1 in a single pass", " A valid result should have been found", " TODO: Re-enable as part of https://github.com/UBC-Thunderbots/Software/issues/642", " TEST(GetNumPassesToRobotTest, two_passes_around_a_single_obstacle)", "{", "    Robot friendly_robot_0 = Robot(0, Point(0, 0), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Robot friendly_robot_1 = Robot(1, Point(3, 1.5), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Robot friendly_robot_2 = Robot(2, Point(5, 0), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Team friendly_team     = Team(Duration::fromSeconds(1));", "    friendly_team.updateRobots({friendly_robot_0, friendly_robot_1, friendly_robot_2});", "", "    Robot enemy_robot_0 = Robot(0, Point(2, 0), Vector(0, 0), Angle::zero(),", "                                AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Team enemy_team     = Team(Duration::fromSeconds(1));", "    enemy_team.updateRobots({enemy_robot_0});", "", "    // The enemy robot is blocking the pass from robot 0 to robot 2, so we expect an", "    // intermediate pass via robot 1", "    auto result = Evaluation::getNumPassesToRobot(friendly_robot_0, friendly_robot_2,", "                                                  friendly_team, enemy_team);", "", "    // A valid result should have been found", "    EXPECT_TRUE(result);", "", "    int num_passes              = result.value().first;", "    std::optional<Robot> passer = result.value().second;", "", "    EXPECT_EQ(2, num_passes);", "    EXPECT_TRUE(passer);", "    EXPECT_EQ(passer.value(), friendly_robot_1);", "}", " TODO: Re-enable as part of https://github.com/UBC-Thunderbots/Software/issues/642", " TEST(GetNumPassesToRobotTest, multiple_friendly_robots_and_blocking_enemies)", "{", "    Robot friendly_robot_0 = Robot(0, Point(0, 0), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Robot friendly_robot_1 = Robot(1, Point(1, 1.5), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Robot friendly_robot_2 = Robot(2, Point(3.5, -2), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Robot friendly_robot_3 = Robot(3, Point(5, 0), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Team friendly_team     = Team(Duration::fromSeconds(1));", "    friendly_team.updateRobots(", "        {friendly_robot_0, friendly_robot_1, friendly_robot_2, friendly_robot_3});", "", "    // Blocks the pass between robot 0 and robot 3", "    Robot enemy_robot_0 = Robot(0, Point(4, 0), Vector(0, 0), Angle::zero(),", "                                AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    // Blocks the pass between robot 1 and 3", "    Robot enemy_robot_1 = Robot(1, Point(1.25, 1.4), Vector(0, 0), Angle::zero(),", "                                AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    // Blocks the pass between robot 0 and 2", "    Robot enemy_robot_2 = Robot(2, Point(1.75, -1), Vector(0, 0), Angle::zero(),", "                                AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Team enemy_team     = Team(Duration::fromSeconds(1));", "    enemy_team.updateRobots({enemy_robot_0, enemy_robot_1, enemy_robot_2});", "", "    // The only way for robot 3 to get the ball is to receive a pass from", "    // robot 0 -> robot 1 -> robot 2 -> robot 3", "    auto result = Evaluation::getNumPassesToRobot(friendly_robot_0, friendly_robot_3,", "                                                  friendly_team, enemy_team);", "", "    // A valid result should have been found", "    ASSERT_TRUE(result);", "", "    int num_passes              = result.value().first;", "    std::optional<Robot> passer = result.value().second;", "", "    EXPECT_EQ(3, num_passes);", "    ASSERT_TRUE(passer);", "    EXPECT_EQ(passer.value(), friendly_robot_2);", "}", " TODO: Re-enable as part of https://github.com/UBC-Thunderbots/Software/issues/642", " TEST(GetNumPassesToRobotTest, all_passes_blocked)", "{", "    Robot friendly_robot_0 = Robot(0, Point(0, 0), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Robot friendly_robot_1 = Robot(1, Point(5, 0), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Team friendly_team     = Team(Duration::fromSeconds(1));", "    friendly_team.updateRobots({friendly_robot_0, friendly_robot_1});", "", "    Robot enemy_robot_0 = Robot(0, Point(2, 0), Vector(0, 0), Angle::zero(),", "                                AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Team enemy_team     = Team(Duration::fromSeconds(1));", "    enemy_team.updateRobots({enemy_robot_0});", "", "    auto result = Evaluation::getNumPassesToRobot(friendly_robot_0, friendly_robot_1,", "                                                  friendly_team, enemy_team);", "", "    // We don't expect any pass info to be returned", "    EXPECT_FALSE(result);", "}", " TEST(GetNumPassesToRobotTest, final_receiver_can_receive_passes_from_multiple_robots)", "{", "    Robot friendly_robot_0 = Robot(0, Point(0, 0), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Robot friendly_robot_1 = Robot(1, Point(1, 1.5), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Robot friendly_robot_2 = Robot(2, Point(3.5, -2), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Robot friendly_robot_3 = Robot(3, Point(5, 0), Vector(0, 0), Angle::zero(),", "                                   AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Team friendly_team     = Team(Duration::fromSeconds(1));", "    friendly_team.updateRobots(", "        {friendly_robot_0, friendly_robot_1, friendly_robot_2, friendly_robot_3});", "", "    // Blocks the pass between robot 0 and robot 3", "    Robot enemy_robot_0 = Robot(0, Point(4, 0), Vector(0, 0), Angle::zero(),", "                                AngularVelocity::zero(), Timestamp::fromSeconds(0));", "    Team enemy_team     = Team(Duration::fromSeconds(1));", "    enemy_team.updateRobots({enemy_robot_0});", "", "    // robot 3 can receive the ball from either:", "    // robot 0 -> robot 1 -> robot 3", "    // or", "    // robot 0 -> robot 2 -> robot 3", "    // Robot 2 is closer to robot 3 so we expect it to be the most likely passer", "    auto result = Evaluation::getNumPassesToRobot(friendly_robot_0, friendly_robot_3,", "                                                  friendly_team, enemy_team);", "", "    // A valid result should have been found", "    EXPECT_TRUE(result);", "", "    int num_passes              = result.value().first;", "    std::optional<Robot> passer = result.value().second;", "", "    EXPECT_EQ(2, num_passes);", "    EXPECT_TRUE(passer);", "    EXPECT_EQ(passer.value(), friendly_robot_2);", "}", " The exact state of the robots don't matter for these tests.", " Only the data in the struct matters", " Despite robot2 having better shooting and scoring opporunity, robot1 has the ball", " so should be more threatening", " The exact state of the robots don't matter for these tests.", " Only the data in the struct matters", " Both robots have posession but robot2 has a better shot on the friendly goal, so", " it should be more threatening", " The exact state of the robots don't matter for these tests.", " Only the data in the struct matters", " robot1 can be reached in fewer passes, so it should be more threatening", " The exact state of the robots don't matter for these tests.", " Only the data in the struct matters", " The passer doesn't matter since it doesn't affect the threat", " It's only for the use of whatever code uses these threat", " evaluations", " The passer doesn't matter since it doesn't affect the threat", " It's only for the use of whatever code uses these threat", " evaluations", " Robot 2 has a better view of the goal so it's more threatening", " Make sure we got the correct number of results", " Make sure we got the correct number of results", " This test evaluates the enemy threat for a 3-vs-1 scenario", "", "                                    enemy robot 2", "", "", "      enemy robot 1", "          ball", "", "                         friendly robot", "", "", "                                                    enemy robot 3", "", "", "                       | friendly net |", "                       ----------------", "", " This tests threat cases where passes between enemy robots are possible, and where", " different robots have significantly different views of the goal.", "", " Enemy robot 1 is the most threatening because it has the ball and has a good view", " of the goal. Enemy robot 2 is the second most threatening because it also has a", " good view of the goal, and can receive the ball quickly via a pass from enemy 1.", " Finally, enemy robot 3 is the least threatening because it would take 2 passes to", " get the ball, and doesn't have a great angle on the goal because it's off to", " the side", " Robots are positioned relative to the friendly goal", " Put the ball right in front of enemy 1", " Make sure we got the correct number of results"], "pass": ["", " namespace Passing"], "indirect_chip": [" Get the largest triangle within the vector of triangles that has area greater", " than minimum area of chip target triangle, and all edge lengths greater than", " minimum edge length of chip target triangle", " Adjust the target point to have a length of distance between itself and the", " ball's position, then scaling it by a certain percentage", " Target should never be further away than maximum chip power", " Set up 3 different points from the vector of non-goalie enemy players'", " positions and the four points for the rectangular region to chip and", " chase at", " With the 3 points, create a possible triangle and place in", " vector of all triangles. Eventually all permutations of points will be", " picked", " For every triangle, the 3 points are adjusted so that the robots making up the", " vertices won't be counted within the triangle, i.e. make every triangle slightly", " smaller", " Takes vector of triangles from input and adjust every single triangle within it"], "possession": [" Find the robot that can intercept the ball the quickest", " Return the robot that can intercept the ball the fastest within the field. If", " no robot is able to intercept the ball within the field, return the closest", " robot to the ball", " Check that the robot has had possession of the ball recently.", " Check that the robot has had possession of the ball recently.", " namespace Evaluation"], "robot_test": [" An arbitrary fixed point in time", " We use this fixed point in time to make the tests deterministic.", " whitelist = all capabilities - blacklist"], "calc_best_shot": [" Use shot evaluation function to get the best Shot", " Use shot evaluation function to get the best Shot", " Use shot evaluation function to get the best Shot", " Only add the robot to the obstacles if it is not ignored", " Only add the robot to the obstacles if it is not ignored", " Calculate the best_shot based on what goal we're shooting at", " Ignore the robot shooting the ball", " Ignore the robot shooting the ball", " If there are no obstacles, return the center of the Segment and the shot angle", " If we have more than 1 Segment from the obstacle projection then we must", " combine overlapping ones to simplify analysis", " If there are no blocking Segments, just shoot at the center of the goal", " namespace Evaluation"], "deflect_off_enemy_target": [" The triangle formed by the enemy goalposts and the ball. Any robots in", " this triangle could block a chip/shot", " Finds the y value of the closest edge of the field (likely where the ball", " is)", " Find the enemy that's blocking a shot that's closest to the edge of the", " field", " want to shoot at the edge of a robot so the ball deflects towards the", " edge of the field", " choose point closest to edge of field", " namespace Evaluation"], "indirect_chip_test": ["", " distance from centre to end of field - goal width - inset"], "intercept_test": ["", " Test where the robot is just sitting on the path the ball is travelling along", " We should be able to find an intercept", " We expect that the best intercept is going to be somewhere between x=0 and x=2,", " The ball is travelling fast enough that we expect the best intercept to be", " somewhere between x=1.75 and x=2.25 (with some tolerance allowed because of how we", " do the optimisation here), with y = 0, and will occur sometime between 0 and", " 2/3 seconds in the future (the time for the ball to reach the robots initial", " position).", " This is the max speed the ball should ever be traveling at", " We should be able to find an intercept", " We expect that the best intercept is going to be somewhere between x=0 and x=2,", " The ball is travelling fast enough that we expect the best intercept to be", " somewhere between x=1.75 and x=2.25 (with some tolerance allowed because of how we", " do the optimisation here), with y = 0, and will occur sometime between 0 and", " 2/3 seconds in the future (the time for the ball to reach the robots initial", " position).", " Test where the robot is sitting just off to the side of the path the ball", " is travelling along", " We should be able to find an intercept", " We expect that the best intercept is going to be somewhere between x=0 and x=2.25,", " (with some extra tolerance because of how we do the optimisation)", " with y = 0, and will occur sometime between 0 and 2 seconds in the future", " (the time for the ball to reach the robot)", " Test where the ball starts ahead of the robot, but moving slowly so that", " the robot can catch up to it. Both the robot and the ball start at one", " end of the field moving towards the other end", " We should be able to find an intercept", " We expect the intercept will occur somewhere in x:[1,2], y:[1,2], t:[0, 3]", " Test where the robot is sitting just off to the side of the path the ball", " is travelling along", " We should be able to find an intercept", " We expect the intercept will occur somewhere in x:[1,2], y:[1,2], t:[0, 3]", " Test where the ball is not moving", " We should be able to find an intercept", " Since the ball is not moving, the only way to intercept it is to move to where", " it is (at the origin)", " The expected time is the time it will take the robot to move to the destination.", " This is dependent on robot constants, but should be in [0,5] seconds", " Test where the ball is moving very slowly", " We should be able to find an intercept", " Since the ball is not moving, the only way to intercept it is to move to where", " it is (at the origin)", " The expected time is the time it will take the robot to move to the destination.", " This is dependent on robot constants, but should be in [0,5] seconds", " Test where the robot has a timestamp that is significantly greater then that", " of the ball", " We should be able to find an intercept", " We expect that the best intercept is going to be somewhere between x=0 and x=2,", " with y = 0, and will take the robot about 2 seconds", " Test where the robot has a timestamp that is significantly greater then that", " of the ball", " We should be able to find an intercept", " We expect that the best intercept is going to be somewhere between x=0 and x=2,", " with y = 0, and will take the robot about 2 seconds", " Test where the robot has a timestamp that is significantly greater then that", " of the ball", " We should be able to find an intercept", " We expect that the best intercept is going to be somewhere between x=0 and x=2,", " with y = 0, and will take the robot about 2 seconds", " Test where we cannot get to the ball before it leaves the field, but if we ignore", " field boundaries we could eventually catch it", " We don't expect to be able to find an intercept"], "calc_best_shot_test": ["", " We expect to be able to find a shot", " We expect to be able to find a shot", " We expect to be able to find a shot", " We expect to be able to find a shot", " We expect to be able to find a shot", " We expect to be able to find a shot", " We should not be able to find a shot", " We should not be able to find a shot", " We should not be able to find a shot", " We should not be able to find a shot", " We should not be able to find a shot", " We should not be able to find a shot", " We should not be able to find a shot", " We should not be able to find a shot", " Create a complete line of obstacles", " Create a complete line of obstacles", " Create a complete line of obstacles", " Create a complete line of obstacles", " Using an obstacle radius of 0.1 passes, but 0.09 fails. Interesting...", " We do not expect to get a result", " We do not expect to get a result", " Create a complete line of obstacles", " Create a complete line of obstacles", " Blocking obstacles-", " Create a complete line of obstacles", " Blocking obstacles-", " We expect to get a result", " We expect to get a result"], "detect_threat": ["", " namespace Evaluation"], "possession_test": ["", " The ball is closer to robot0, but is moving towards robot1 so we expect robot1", " to be the baller", " robot0 is chasing the ball and is close enough to catching it we expect it to be", " the baller", " The ball is moving too fast to be caught by any robot within the field, so we", " expect robot1 to be the baller since it's the closest at this time."], "stp_test": [" Give an explicit seed to STP so that our tests are deterministic", " Put the ball where both its x and y coordinates are negative. Neither test Play", " is applicable in this case", " Only the HaltTestPlay should be applicable", " Both HaltTestPlay and MoveTestPlay should be applicable", " We expect a random selection of the plays that are applicable. This test should be", " deterministic because we have provided a seed for this test (in the setUp function)", " Test that we can successfully assign Plays when there is currently no Play assigned", " Only the HaltTestPlay should be applicable", " Only the HaltTestPlay should be applicable", " The HaltTestPlays invariant should no longer hold, and the MoveTestPlay should now", " be applicable", " Only the MoveTestPlay should be applicable", " Now only the HaltTestPlay should be applicable, and the MoveTestPlay's invariant", " no longer holds, so we expect the current play to become the HaltTestPlay", " TODO: Update this test when https://github.com/UBC-Thunderbots/Software/issues/396", " is completed. For now, we just check that the previous play remains assigned", " Only the HaltTestPlay should be applicable", " Put the ball where both its x and y coordinates are negative. Neither test Play", " is applicable in this case", " Only the HaltTestPlay should be applicable"], "stp": [" Try to get an intent from the tactic", " If we couldn't get an intent, we send the robot a StopIntent so", " it doesn't do anything crazy until it starts running a new Tactic", " This functions optimizes the assignment of robots to tactics by minimizing", " the total cost of assignment using the Hungarian algorithm", " (also known as the Munkres algorithm)", " https://en.wikipedia.org/wiki/Hungarian_algorithm", "", " https://github.com/saebyn/munkres-cpp is the implementation of the Hungarian", " algorithm that we use here", " Special handling for the Goalie tactics, since only one robot per team is permitted", " to act as the goalie", " Assign the goalie to the first goalie tactic", " Discard all goalie tactics, since we have already assigned the goalie robot (if", " there is one) to the first goalie tactic, and there should only ever be one goalie", " We do not have enough robots to assign all the tactics to. We \"drop\"", " (aka don't assign) the tactics at the end of the vector since they are", " considered lower priority", " The Matrix constructor will assert if the rows and columns of the matrix are", " not >= 1, so we perform that check first and return an empty vector of tactics.", " This represents the cases where there are either no tactics or no robots", " The rows of the matrix are the \"workers\" (the robots) and the columns are the", " \"jobs\" (the Tactics).", " Initialize the matrix with the cost of assigning each Robot to each Tactic", " capability requirements are satisfied, use real cost", " Apply the Munkres/Hungarian algorithm to the matrix.", " The Munkres matrix gets solved such that there will be exactly one 0 in every", " row and exactly one 0 in every column. All other values will be -1. The 0's", " indicate the \"workers\" and \"jobs\" (robots and tactics for us) that are most", " optimally paired together", "", " Example matrices:", "        -1, 0,-1,         and            0,-1,", "         0,-1,-1,                       -1, 0,", "        -1,-1, 0,", " Create a uniform distribution over the indices of the applicable_plays", " https://enreference.com/w/cpp/numeric/random/uniform_int_distribution", " Sort the tactics by the id of the robot they are assigned to, so we can report", " the tactics in order or robot id. This makes it much easier to read if tactics", " or robots change, since the order of the robots won't change"], "stp_tactic_assignment_test": ["", " Give an explicit seed to STP so that our tests are deterministic", "", " Both robots are now closest to move_tactic_1's destination. We do NOT want", " robot_0 to be assigned to move_tactic_1, because then robot_1 has to move all the", " way around to move_tactic_2. What we expect is that robot_0 will be assigned to", " move_tactic_2 and \"slide over\" to make room for robot_1", " move_tactic_1 should be the only Tactic assigned a robot, since stop_tactic_1 is a", " lower priority than move_tactic_1 so it should be dropped since there's only 1", " robot", " Test the case where it is \"obvious\" which robots should be assigned to each tactic", " Each robot is already close to one of the tactic's destinations, so it is trivial to", " see the optimal assignment is for each robot to be assigned to the tactic whose", " destination it's closest to", " Each robot is close to separate tactic destinations. They should each be trivially", " assigned to the tactic with the destination closest to their position", " Test a more complex case where each robot is closest to the same tactic destination.", " If robot0 were to be assigned to the tactic with dest1, robot1 would be forced to go", " all the way to dest2. This is what happened in our previous system that used greedy", " tactic assignment, and cause the robots to \"overlap\"", "", "     robot1", "                     robot0", "", "", "                     dest1             dest2", " Both robots are now closest to move_tactic_1's destination. We do NOT want", " robot_0 to be assigned to move_tactic_1, because then robot_1 has to move all the", " way around to move_tactic_2. What we expect is that robot_0 will be assigned to", " move_tactic_2 and \"slide over\" to make room for robot_1", " robot_2 should not be assigned since both robot_0 and robot_1 are more optimal", " to assign to the tactics. robot_2 is too far away", " If all costs are equal, the robots and tactics are simply paired in order", " The destination of the move_tactic is relatively close to the robot positions, so", " the cost of assigning any robot to the move_tactic should be less than the", " stop_tactics", " test that the robot that matches capability requirements is selected over the robot", " that doesn't even though the former has lower cost", " this robot has no capabilities", " Test that if there is no team goalie, the \"goalie\" tactic", " is not assigned a robot, even if there are enough robots", " Put two robots right in front of the friendly goal", " Test that only the robot set as the goalie on the team is assigned to the", " goalie tactic", " Put two robots right in front of the friendly goal", " default is all capabilities, if not specified otherwise", " Change the goalie and perform the same check in case we have a fluke bug", " default is all capabilities, if not specified otherwise"], "stp_refbox_game_state_play_selection_test": [" set up the friendly team", " to set restart reason, etc. properly", " enemy indirect free on both sides of the field", " INSTANTIATE_TEST_CASE_P(TestPositions,", " STPRefboxGameStatePlaySelectionTestWithPositions,", "                        ::testing::ValuesIn(test_params.begin(), test_params.end()));", " Give an explicit seed to STP so that our tests are deterministic", " TODO: replace the ball with real parameterized values", " INSTANTIATE_TEST_CASE_P(AllRefboxGameStates, STPRefboxGameStatePlaySelectionTest,", "                        ::testing::ValuesIn(all_refbox_game_states.begin(),", "                                            all_refbox_game_states.end()));"], "cherry_pick_tactic": ["", " Prefer robots closer to the target region", " Move the robot to be the best possible receiver for the best pass we can", " find (within the target region)"], "defense_shadow_enemy_tactic": [" Prefer robots closer to the enemy being shadowed", " We normalize with the total field length so that robots that are within the field", " have a cost less than 1", " try to steal the ball and yeet it away if the enemy robot has already", " received the pass"], "receiver_tactic_test": ["", " Since we're already setup to receive the pass, we should just be trying to move", " to our current position. We should continue to yield new Move Intents even though", " we're at the target position", " Test case where we can feasibly one-touch the ball into the net", " We should be trying to move into a position to properly deflect the ball into", " the net with a kick", " Test case where we can't feasibly one-touch the ball into the net because the", " deflection angle between the pass and shot would be way too large", " Since there's no reasonable way we could one-touch kick the pass into the net,", " we should be lining up to receive it", " Test case where we are facing right towards the goal, but it is blocked", " Since there's no reasonable way we could one-touch kick the pass into the net,", " we should be lining up to receive it", " Test where we have received the pass and the ball is now positioned in our dribbler", " Ball is travelling towards the robot", " We should yield one intent here", " Position the ball just in front of the robot dribbler", " Since we've received the ball, we shouldn't yield anything", " Test where we have just one-touch kicked the pass towards the goal", " The ball is travelling away from the origin towards the enemy net", " Since we've kicked the ball, we shouldn't yield anything", " Create a ball traveling from the specified position towards the robot", " Create a shot towards the enemy net", " Since the exact direction for one time shots is highly variable and depends a lot on", " physical tests, we check the exact angles, but we can at least test that they're in", " the right range", " Robot at the origin, ball coming at it from different directions", " Corner kicks, robot is roughly in the opposite corner of the goal crease to", " where the corner kick is coming from", " Corner kicks, robot is roughly in the same corner of the goal crease to", " where the corner kick is coming from", " Corner kick, robot is close to the goal and directly in front of it", "", " We just choose a moderate speed for these tests. Varying the speed won't change", " the results since it's treated as an \"ideal ball trajectory\" anyway", " We apply angular \"noise\" to the ball velocity vector to simulate imperfect passes", " Create a ball traveling from the specified position towards the robot", " Create a robot at the robot location with no velocity. The initial orientation", " does not matter.", " Create a best shot towards the center of the enemy goal", " The position where the ball should make contact with the receiver robot", " We check that the position the receiver tries to move to will cause the", " ball contact point to intersect with the ball's trajectory, meaning that we are", " in the correct position to make contact with the ball", " Robot x coordinate", " Robot y coordinate", " Ball x coordinate", " Ball y coordinate", " Angle deviation from ideal pass,", " in degrees"], "crease_defender_tactic_test": [" Check an action was returned (the pointer is not null)", " Check an action was returned (the pointer is not null)", " The robot's position should be one full robot diameter to the left,", " perpendicular to the shot vector, so that the goalie is allowed to block the", " shot in the middle and the crease defender isn't overlapping with the goalie", " Check an action was returned (the pointer is not null)", " The robot's position should be one full robot diameter to the right,", " perpendicular to the shot vector, so that the goalie is allowed to block the", " shot in the middle and the crease defender isn't overlapping with the goalie"], "goalie_tactic": ["           NW    pos_side   NE", "            +---------------+", "            |               |", "            |               |", "            |               |", "       +----+               |", "       |    |               |", "       |    |               |", " goal  |    |               | width", "       |    |               |", "       |    |               |", "       |    |               |", "       +----+               |", "            |               |", "            |               |", "            |               |", "           ++---------------+", "           SW    neg_side   SE", "", " Given the goalies desired position and the restricted area,", " first find the 3 intersections with each side of the restricted area", " (width, pos_side, neg_side) and the line from the desired position to the", " center of the friendly goal", " if the goalie restricted area already contains the point, then we are", " safe to move there.", " Due to the nature of the line intersection, its important to make sure the", " corners are included, if the goalies desired position intersects with width (see", " above), use those positions", " if either two sides of the goal are intercepted, then use those positions", " if there are no intersections (ex. ball behind net), then we are out of luck", " Update the world parameters stored by this Tactic", " We don't prefer any particular robot to be the goalie, as there should only", " ever be one robot that can act as the goalie", " Goalie Tactic", "", " The goalie tactic is responsible for blocking as many shots as it can, to the", " best of its ability. The tactic consists of 3 cases", "", " Case 1: The ball is moving towards the goal and has a speed that is concerning", "      Goalie moves onto the closest point on the oncoming line to stop the ball", "", " Case 2: The ball is moving at a slow speed and is inside the defense area", "      Goalie moves to the ball and chips it out of the defense area", "", " NOTE: If the ball is in the dont_chip_rectangle, then we prefer timeout,", " over scoring on ourselves", "", " Case 3: Any other case", "      Goalie blocks the cone to the net. (Cone being from the ball to either", "      goal post) The goalie also snaps to a rectangle inside the defense area,", "      to avoid leaving the defense area", "", " Create a segment along the goal line, slightly shortened to account for the", " robot radius so as we move along the segment we don't try run into the goal", " posts. This will be used in case3 as a fallback when we don't have an", " intersection with the crease lines", " compute intersection points from ball position and velocity", " Load DynamicParameter", " when should the goalie start panicking to move into place to stop the ball", " what should the final goalie speed be, so that the goalie accelerates faster", " how far in should the goalie wedge itself into the block cone, to block balls", " by how much should the defense are be decreased so the goalie stays close", " towards the net", " if the ball is in the don't chip rectangle we do not chip the ball", " as we risk bumping the ball into our own net trying to move behind", " the ball", " case 1: goalie should panic and stop the ball, its moving too fast towards the", " net", " the ball is heading towards the net, move to intercept the shot", " the final speed is a dynamic parameter so that if the goalie needs", " to dive for the shot instead of stop when reaching the intersection", " point it can do so.", " case 2: goalie does not need to panic and just needs to chip the ball out", " of the net", " if the ball is slow but its not safe to chip it out, don't.", " TODO finesse the ball out of the goal using the dribbler.", " for now we just stop https://github.com/UBC-Thunderbots/Software/issues/744", " if the ball is slow or stationary inside our defense area, and is safe", " to do so, chip it out", " case 3: ball does not have a clear velocity vector towards the goal, so", " position goalie in best position to block shot", " block the cone by default", " restrict the goalie to a semicircle inscribed inside the defense area", " restrict the point to be within the defense area", " compute angle between two vectors, negative goal post to ball and positive", " goal post to ball", " compute block cone position, allowing 1 ROBOT_MAX_RADIUS_METERS extra on", " either side", " we want to restrict the block cone to the friendly crease, also potentially", " scaled by a defense_area_deflation_parameter", " restrain the goalie in the deflated defense area, if the goalie cannot be", " restrained or if there is no proper intersection, then we safely default to", " center of the goal", " if the goalie could not be restrained in the deflated defense area,", " then the ball must be either on a really sharp angle to the net where", " its impossible to get a shot, or the ball is behind the net, in which", " case we snap to either post"], "move_tactic_test": [" Check an action was returned (the pointer is not null)", " We call the Action twice. The first time the Intent will always be returned to", " ensure the Robot is doing the right thing. In all future calls, the action will be", " done and so will return a null pointer"], "chip_tactic": [" update the world parameters stored by this tactic", " update the control parameters stored by this tactic", " the closer the robot is to a ball, the cheaper it is to perform the chip"], "goalie_tactic_test": [" The following tests will make sure the goalie stays in the requested", " deflated defense area when best positioning to defend the ball.", " The diagram below shows the requested position (R) by the goalie to where", " it should be defending, the restrain function returns the actual position (A)", " where the goalie is allowed to stay.", "", "", "    |", "    |defense", "    +-----------------+", "    |restrain         |", "    +-------+         |", " +--+       |         |", " |  |       |    R    |", " |  |      A|         |", " |  |       |         |", " |  |       |         |", " |  |       |         |", " |  |       |         |", " +--+       |         |", "    +-------+         |", "    |                 |", "    +-----------------+", "    |", "    |", " test to make sure that points given outside of the rectangle", " are constrained inside", " scaling the restrained position by a slight bit as containsPoint does not count", " the points right on the edge of the rectangle. For the purposes of the goalie", " we are okay if the point is right on the edge, or close enough.", " test to make sure that points given inside of the rectangle", " are not altered and are the same points", " are constrained inside.", " blow up rectangle to a huge amount, to contain all the points"], "shadow_enemy_tactic": [" Prefer robots closer to the enemy being shadowed", " We normalize with the total field length so that robots that are within the field", " have a cost less than 1", " If we think the enemy team can pass, and if we have identified a robot that can", " pass to the robot we are shadowing, we block the pass rather than block the", " net. Otherwise, we just block the net", " If the enemy robot already had the ball, try steal it and chip it away"], "passer_tactic_test": ["", " Robot is sitting at origin facing towards enemy goal", " We want to pass from the origin to 1 meter in the -y direction", " Robot should be offset from where the pass is supposed to start", " In this case we should be moving into position to kick the ball, since we're", " in front of it and need to get behind it", " Robot is sitting at {1,2} facing towards -y", " We want to pass from the origin to 1 meter in the -y direction", " Robot should be offset from where the pass is supposed to start", " In this case we should be moving into position to kick the ball, since we're", " in front of it and need to get behind it", " Robot is sitting at {-0.3,0.2} facing towards -y", " We want to pass from the origin to 1 meter in the -y direction. This means the", " robot needs to move around the ball to get toa point where it can kick", " Robot should be offset from where the pass is supposed to start", " In this case we should be moving into position to kick the ball, since we're", " in front of it and need to get behind it", " Robot is sitting just behind where we want to pass from, in the perfect", " position to just move forward a bit and take the kick", " We want to pass from the origin to 1 meter in the -y direction", " Robot should be offset from where the pass is supposed to start", " We're in the perfect position to kick, but pass hasn't started yet, so", " we should just be moving", " Robot is sitting just behind where we want to pass from, in the perfect", " position to just move forward a bit and take the kick", " Ball not moving initially", " We want to pass from the origin to 1 meter in the -y direction", " We should try to kick the ball", " Ball starts moving as if we've kicked it", " We need to try to get the next the intent to make the tactic finish", " The tactic should now be done"], "stop_tactic": [" Prefer all robots equally"], "move_tactic": [" Update the control parameters stored by this Tactic", " Prefer robots closer to the destination", " We normalize with the total field length so that robots that are within the field", " have a cost less than 1"], "passer_tactic": ["", " Prefer robots closer to the pass start position", " We normalize with the total field length so that robots that are within the field", " have a cost less than 1", " Move to a position just behind the ball (in the direction of the pass)", " until it's time to perform the pass", " We want to wait just behind where the pass is supposed to start, so that the", " ball is *almost* touching the kicker", " The angle between the ball velocity vector and a vector from the passer", " point to the receiver point", " We want the robot to move to the starting position for the shot and also", " rotate to the correct orientation to face the shot", " We want to keep trying to kick until the ball is moving along the pass", " vector with sufficient velocity"], "shadow_freekicker_tactic_test": [" The edge of the robot should be slightly more than 0.5m from the ball", " The robot should be just to the left of the line between the friendly net and", " the ball (from the POV of the friendly net)", " The edge of the robot should be slightly more than 0.5m from the ball", " The robot should be just to the right of the line between the friendly net and", " the ball (from the POV of the friendly net)"], "receiver_tactic": [" Prefer robots closer to the pass receive position", " We normalize with the total field length so that robots that are within the field", " have a cost less than 1", " Setup for the pass. We want to use any free time before the pass starts putting", " ourselves in the best position possible to take the pass", " We wait for the ball to start moving at least a bit to make sure the passer", " has actually started the pass", " If there is a feasible shot we can take, we want to wait for the pass at the", " halfway point between the angle required to receive the ball and the angle", " for a one-time shot", " If we do have a valid shot on net, orient the robot to face in between", " the pass vector and shot vector, so the robot can quickly orient itself", " to either receive the pass, or take the shot. Also, not directly facing", " where we plan on kicking may throw off the enemy AI", " We want the robot to move to the receiving position for the shot and also", " rotate to the correct orientation", " Vector from the ball to the robot", " The angle between the ball velocity and a vector from the ball to the robot", " Keep trying to shoot the ball while it's traveling roughly towards the robot", " (or moving slowly because we can't be certain of the velocity vector if it is)", " Calculations to check for termination conditions", " If we can't shoot on the enemy goal, just try to receive the pass as cleanly as", " possible", " Move into position with the dribbler on", " The lateral speed is roughly a measure of the lateral velocity we need to", " \"cancel out\" in order for our shot to go in the expected direction.", " The scaling factor of 0.3 is a magic number that was carried over from the old", " code. It seems to work well on the field.", " This kick speed is based off of the value used in the firmware `MovePrimitive` when", " autokick is enabled", " check which direction the ball is going in so we can decide which direction to", " apply the offset in", " need to go clockwise", " Check if we can shoot on the enemy goal from the receiver position", " Vector from the ball to the robot", " The angle the robot will have to deflect the ball to shoot", " The percentage of open net the robot would shoot on", " If we have a shot with a sufficiently large enough opening, and the deflection", " angle that is reasonable, we should one-touch kick the ball towards the enemy net", " Find the closest point to the ball contact point on the ball's trajectory", " The best position is determined such that the robot stays in the ideal", " orientation, but moves the shortest distance possible to put its contact point", " in the ball's path."], "stop_tactic_test": [" Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " We always expect the cost to be 0.5, because the StopTactic prefers all robots", " equally"], "shoot_goal_tactic_test": [" Check an intent was returned (the pointer is not null)", " The robot will start the shot since it can see enough of the net", " Check an intent was returned (the pointer is not null)", " The enemy has moved up to block more than 0.5 of the net, but since the net is not", " entirely blocked the robot will still try shoot", " Check an intent was returned (the pointer is not null)", " The net is now entirely blocked (but the enemy robot is not quite yet in danger of", " taking the ball), so the friendly robot just tries to line up to the ball", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)"], "tactic_test": ["", " Run the tactic several times", " This test is making sure we don't have any bugs with managing our coroutines that", " cause the tactic to end before we would expect", " Create a MoveTestTactic with the final destination very far from where the robot", " currently is, so that we know the tactic should not report done", " Run the Tactic several times, leaving the robot and parameters as is so the", " tactic should not approach a \"done\" state", " Check an action was returned (the pointer is not null)", " Create a MoveTestTactic that wants to move the Robot to where it already is.", " Therefore we expect the tactic to be done", " The tactic should always return an Action the first time it is run to make sure we", " are doing the right thing (and just don't happen to be in the \"done state\" at the", " time while actually doing something else)", " Subsequent calls should return a nullptr since the Tactic is done, and the", " tactic should also report done()", " Create a MoveTestTactic that wants to move the Robot to where it already is.", " Therefore we expect the tactic to be done", " Even though the Tactic should be done, we expect it to continue returning valid", " Actions because it will be constantly restarting"], "penalty_kick_tactic": ["", " We normalize with the total field length so that robots that are within the field", " have a cost less than 1", " If there is no goalie, the net is wide open", " The value of a penalty shot is proportional to how far away the enemy goalie is", " from the current shot of the robot", " We will make a penalty shot if the enemy goalie cannot accelerate in time to block", " it", " If we have an intersection, calculate if we have a viable shot", " Include the vision delay in our penalty shot", " calculations", " Based on constant acceleration -> // dX = init_vel*t + 0.5*a*t^2", "          dX - init_vel - (0.5*a*t)t", " If the position to block the ball is further than the enemy goalie can reach in", " the time required to score", " If a shot in our current direction will not end in a goal, don't shoot", " Evaluate if the goalie is closer to the negative or positive goalpost", " Return the center of the enemy goal", " We will need to keep track of time so we don't break the rules by taking too long", " A point behind the ball that leaves 5cm between the ball and kicker of the", " robot", " If we haven't approached the ball yet, get close"], "tactic_world_params_update_visitor": [" We disable clang-format here because it makes these lists borderline unreadable,", " and certainly way more difficult to edit", " clang-format off", " clang-format on"], "shoot_goal_tactic": [" If we can intercept the ball, use the distance to the intercept point.", " We normalize with the total field length so that robots that are within the", " field have a cost less than 1", " If we can't intercept the ball, just use the distance to the ball's current", " position. We normalize with the total field length so that robots that are", " within the field have a cost less than 1", " Our rectangle class does not have the concept of rotation, so instead", " we rotate all the robot positions about the origin so we can construct", " a rectangle that is aligned with the axis", " If we are in the middle of committing to a shot but an enemy is about to", " steal the ball we chip instead to just get over the enemy. We do not adjust", " the point we are targeting since that may take more time to realign to, and", " we need to be very quick so the enemy doesn't get the ball", " Once we have determined we can take a shot, continue to try shoot until the", " shot is entirely blocked", " If an enemy is about to steal the ball from us, we try chip over them to", " try recover the ball after, which is better than being stripped of the ball", " and directly losing possession that way", " A point behind the ball that leaves 5cm between the ball and kicker of the", " robot", " The default behaviour is to move behind the ball and face the net"], "crease_defender_tactic": [" Update the world parameters stored by this Tactic", " Prefer robots closer to the crease defender desired position", " We normalize with the total field length so that robots that are within the field", " have a cost less than 1", " Get the point on the crease path exactly between the two defenders", " Figure out how far away the ball is", " Find the best shot", " Figure out where the best shot intersects the path the", " crease defender must follow", " Return the segments that form the path around the crease that the", " defenders must follow. It's basically the crease inflated by one robot radius", " +x segment", " +y segment", " -y segment", " Draw a ray from the goalie out of the crease"], "tactic_world_params_update_visitor_test": [" ReceiverTactic doesnt update field", " ShadowFreeKickerTactic doesnt update field"], "tactic": [" require movement capability by default", " We call the getNextActionHelper before checking if we should loop forever", " so we can catch the tactic right when it's done. Since we do not want to return", " any nullptrs while a tactic is looping forever, we need to perform this", " check after running the logic and immediately restarting.", " Re-start the action sequence by re-creating it", " Yield a null pointer the very first time the function is called. This value will", " never be seen/used by the rest of the system.", " Anytime after the first function call, the calculateNextAction function will be", " used to perform the real logic. The calculateNextAction function will yield its", " values to the top of the coroutine stack, where they will be retrieved by", " getNextAction, so we do not need to yield or return the result of this function", " Check the coroutine status to see if it has any more work to do.", " Run the coroutine. This will call the bound calculateNextAction function", " Check if the coroutine is still valid before getting the result. This makes", " sure we don't try get the result after \"running out the bottom\" of the", " coroutine function", " Extract the result from the coroutine. This will be whatever value was", " yielded by the calculateNextAction function", " The Tactic is considered done once the next_action becomes a nullptr. This could", " either be because it was returned by the calculateNextAction function, or because", " the action_sequence coroutine is done and has no more work to do."], "patrol_tactic": [" If we already assigned a robot to this tactic, prefer reassigning", " that robot", " Prefer robots that are close to the current patrol point"], "move_test_tactic": [" Update the parameters stored by this Tactic", " Prefer robots closer to the destination", " We normalize with a constant factor so test results to not change based on any", " changes to World"], "goalie_test_tactic": [" Prefer all robots equally with a cost of 0.5", " Yield nothing"], "stop_test_tactic": [" Prefer all robots equally with a cost of 0.5"], "example_play_test": [" Make sure something was returned", " Make sure the expected number of tactics was returned", " Make sure each tactic is an ExampleTactic", " The result of the dynamic_cast will be a nullptr if the pointer does not", " actually point to a conrete type of MoveTactic"], "free_kick_play": [" Make sure we don't interfere with the cornerkick play", "", " Setup the goalie", " Setup crease defenders to help the goalie", " If the passing is coming from the friendly end, we split the cherry-pickers", " across the x-axis in the enemy half", " Otherwise, the pass is coming from the enemy end, put the two cherry-pickers", " on the opposite side of the x-axis to wherever the pass is coming from", " These two tactics will set robots to roam around the field, trying to put", " themselves into a good position to receive a pass", " This tactic will move a robot into position to initially take the free-kick", " Wait for a robot to be assigned to aligned to the ball to pass", " Set the passer on the pass generator", " Put the robot in roughly the right position to perform the kick", " We want the kicker to get into position behind the ball facing the center", " of the field", " Figure out where the fallback chip target is", " Commit to a pass", " TODO (Issue #636): We should stop the PassGenerator and Cherry-pick tactic here", "                    to save CPU cycles", " Perform the pass and wait until the receiver is finished", " Align the kicker to pass and wait for a good pass", " To get the best pass possible we start by aiming for a perfect one and then", " decrease the minimum score over time", " Register this play in the genericFactory"], "enemy_freekick_play": [" Init our goalie tactic", " Init a Crease Defender Tactic", " Init FreeKickShadower tactics (these robots will both block the enemy robot taking", " a free kick (at most we will have 2", " Init Shadow Enemy Tactics for extra robots", " Init Move Tactics for extra robots (These will be used if there are no robots to", " shadow)", " Create tactic vector (starting with Goalie)", " Get all enemy threats", " Add Freekick shadower tactics", " Add Crease defender tactic", " Assign ShadowEnemy tactics until we have every enemy covered. If there are not", " enough threats to shadow, move our robots to block the friendly net", " yield the Tactics this Play wants to run, in order of priority", " Register this play in the genericFactory"], "halt_play_test": [" Make sure something was returned", " Make sure the expected number of tactics was returned", " Make sure each tactic is an ExampleTactic"], "example_play": [" This play is never applicable so it will never be chosen during gameplay", " This play can be run for testing by using the Play override", " Create MoveTactics that will loop forever", " Continue to loop to demonstrate the example play indefinitely", " The angle between each robot spaced out in a circle around the ball", " Move the robots in a circle around the ball, facing the ball", " yield the Tactics this Play wants to run, in order of priority", " If there are fewer robots in play, robots at the end of the list will not be", " assigned", " Register this play in the genericFactory"], "halt_play": [" Create Stop Tactics that will loop forever", " yield the Tactics this Play wants to run, in order of priority", " Register this play in the genericFactory"], "penalty_kick_play": [" Move all non-shooter robots to the center of the field", " If we are setting up for penalty kick, move our robots to position", " Move all non-shooter robots to the center of the field", " yield the Tactics this Play wants to run, in order of priority", " Register this play in the genericFactory"], "kickoff_enemy_play": [" 3 robots assigned to shadow enemies. Other robots will be assigned positions", " on the field to be evenly spread out", " these positions are picked according to the following slide", " https://images.slideplayer.com/32/9922349/slides/slide_2.jpg", " since we only have 6 robots at the maximum, 3 robots will shadow threats", " up front, 1 robot is dedicated as the goalie, and the other 2 robots will defend", " either post (as show in the image)", "", " Positions 1,2 are the most important, 3,4,5 are a fallback", " if there aren't as many threats to shadow. Robots will be assigned", " to those positions in order of priority. The 5 positions shown below", " are in the same order as in the defense_position vector.", "", " \t\t+--------------------+--------------------+", " \t\t|                    |                    |", " \t\t|                    |                    |", " \t\t|                    |                    |", " \t\t+--+ 2            4  |                 +--+", " \t\t|  |                 |                 |  |", " \t\t|  |               +-+-+               |  |", " \t\t|  | 3             |   |               |  |", " \t\t|  |               +-+-+               |  |", " \t\t|  |                 |                 |  |", " \t\t+--+ 1            5  |                 +--+", " \t\t|                    |                    |", " \t\t|                    |                    |", " \t\t|                    |                    |", " \t\t+--------------------+--------------------+", " these move tactics will be used to go to those positions", " TODO: (Mathew): Minor instability with defenders and goalie when the ball and", " attacker are in the middle of the net", " keeps track of the next defense position to assign", " Assign the first 3 robots to shadow enemies, if the enemies exist", " Shadow with a distance slighlty more than the distance from the enemy", " robot to the center line, so we are always just on our side of the", " center line", " We shadow assuming the robots do not pass so we do not try block passes", " while shadowing, since we can't go on the enemy side to block the pass", " anyway", " Once we are out of enemies to shadow, or are already shadowing 3", " enemies, we move the rest of the robots to the defense positions", " listed above", " yield the Tactics this Play wants to run, in order of priority", " Register this play in the genericFactory"], "shoot_or_pass_play": ["", " Setup the goalie and crease defenders", " If the passing is coming from the friendly end, we split the cherry-pickers", " across the x-axis in the enemy half", " Otherwise, the pass is coming from the enemy end, put the two cherry-pickers", " on the opposite side of the x-axis to wherever the pass is coming from", " Have a robot keep trying to take a shot", " Start a PassGenerator that will continuously optimize passes into the enemy half", " of the field", " Wait for a good pass by starting out only looking for \"perfect\" passes (with a", " score of 1) and decreasing this threshold over time", " TODO: change this to use the world timestamp (Issue #423)", " This boolean indicates if we're ready to perform a pass", " Whether or not we've set the passer robot in the PassGenerator", " We're ready to pass if we have a robot assigned in the PassGenerator as the", " passer and the PassGenerator has found a pass above our current threshold", " If there is a robot assigned to shoot, we assume this is the robot", " that will be taking the shot", " If we've assigned a robot as the passer in the PassGenerator, we lower", " our threshold based on how long the PassGenerator as been running since", " we set it", " TODO (Issue #636): We should stop the PassGenerator and Cherry-pick tactic here", "                    to save CPU cycles", " If the shoot tactic has not finished, then we need to pass, otherwise we are", " done this play", " Commit to a pass", " Perform the pass and wait until the receiver is finished", " Register this play in the genericFactory"], "penalty_kick_enemy_play": [" goalie", " Move all non-shooter robots to the center of the field", " yield the Tactics this Play wants to run, in order of priority", " Register this play in the genericFactory"], "shoot_or_chip_play": ["", " Figure out where the fallback chip target is", " If we have any crease defenders, we don't want the goalie tactic to consider", " them when deciding where to block", " Update crease defenders", " Update tactics moving to open areas", " Face towards the ball", " Move a bit backwards to make it more likely we'll receive the chip", " Update chipper", " We want this second in priority only to the goalie", " If we can't do anything else then patrol?", " yield the Tactics this Play wants to run, in order of priority", " Register this play in the genericFactory"], "defense_play": [" If we have any crease defenders, we don't want the goalie tactic to consider", " them when deciding where to block", " Update crease defenders", " Assign ShadowEnemy tactics until we have every enemy covered. If there any", " extra friendly robots, have them perform a reasonable default defensive tactic", " yield the Tactics this Play wants to run, in order of priority", " somehow they have 0 robots", " Register this play in the genericFactory"], "corner_kick_play": ["", " Figure out if we're taking the kick from the +y or -y corner", " We want the two cherry pickers to be in rectangles on the +y and -y sides of the", " field in the +x half. We also further offset the rectangle from the goal line", " for the cherry-picker closer to where we're taking the corner kick from", " kick from neg corner", " This tactic will move a robot into position to initially take the free-kick", " These two tactics will set robots to roam around the field, trying to put", " themselves into a good position to receive a pass", " Setup two bait robots on the opposite side of the field to where the corner kick", " is taking place to pull enemies away from the goal", " Target any pass in the enemy half of the field, shifted up by 1 meter", " from the center line", " Wait for a robot to be assigned to align to take the corner", " Set the passer on the pass generator", " Put the robot in roughly the right position to perform the kick", " Align the kicker to take the corner kick and wait for a good pass", " To get the best pass possible we start by aiming for a perfect one and then", " decrease the minimum score over time", " Commit to a pass", " TODO (Issue #636): We should stop the PassGenerator and Cherry-pick tactic here", "                    to save CPU cycles", " Perform the pass and wait until the receiver is finished", " We want the kicker to get into position behind the ball facing the center", " of the field", " Register this play in the genericFactory"], "kickoff_friendly_play": [" Since we only have 6 robots at the maximum, the number one priority", " is the robot doing the kickoff up front. The goalie is the second most", " important, followed by 3 and 4 setup for offense. 5 and 6 will stay", " back near the goalie just in case the ball quickly returns to the friendly", " side of the field.", "", " \t\t+--------------------+--------------------+", " \t\t|                    |                    |", " \t\t|               3    |                    |", " \t\t|                    |                    |", " \t\t+--+ 5               |                 +--+", " \t\t|  |                 |                 |  |", " \t\t|  |               +-+-+               |  |", " \t\t|2 |               |1  |               |  |", " \t\t|  |               +-+-+               |  |", " \t\t|  |                 |                 |  |", " \t\t+--+ 6               |                 +--+", " \t\t|                    |                    |", " \t\t|               4    |                    |", " \t\t|                    |                    |", " \t\t+--------------------+--------------------+", "", " This is a two part play:", "      Part 1: Get into position, but don't touch the ball (ref kickoff)", "      Part 2: Chip the ball over the defender (ref normal start)", " the following positions are in the same order as the positions shown above,", " excluding the goalie for part 1 of this play", " Robot 1", " Robot 2", " Goalie positions will be handled by the goalie tactic", " Robot 3", " Robot 4", " Robot 5", " Robot 6", " move tactics to use to move to positions defined above", " specific tactics", " Part 1: setup state (move to key positions)", " set the requirement that Robot 1 must be able to kick and chip", " setup 5 kickoff positions in order of priority", " yield the Tactics this Play wants to run, in order of priority", " Part 2: not normal play, currently ready state (chip the ball)", " TODO This needs to be adjusted post field testing, ball needs to land exactly", " in the middle of the enemy field", " the robot at position 0 will be closest to the ball, so positions starting from", " 1 will be assigned to the rest of the robots", " yield the Tactics this Play wants to run, in order of priority", " Register this play in the genericFactory"], "stop_play": [" Robot assignments for the Stop Play", "  - 1 robot will be the goalie", "  - 2 robots will assist the goalie in blocking the ball, they will snap", "      to the best fit semicircle around the defense area", "  - 3 robots will stay within 0.5m of the ball, evenly spaced, also blocking the", "  goal", "", "  If x represents the ball and G represents the goalie, the following, also blocking", "  the goal diagram depicts a possible outcome of this play", "", " \t\t+--------------------+--------------------+", " \t\t|                    |                    |", " \t\t|         4  x       |                    |", " \t\t| 0       2          |                    |", " \t\t+--+ 1     3         |                 +--+", " \t\t|  |                 |                 |  |", " \t\t|G |               +-+-+               |  |", " \t\t|  |               |   |               |  |", " \t\t|  |               +-+-+               |  |", " \t\t|  |                 |                 |  |", " \t\t+--+                 |                 +--+", " \t\t|                    |                    |", " \t\t|                    |                    |", " \t\t|                    |                    |", " \t\t+--------------------+--------------------+", " we want to find the radius of the semicircle in which the defense area can be", " inscribed, this is so the robots can snap to that semicircle and not enter the", " defense area. The full derivation can be found in the link below", "", " http://www.stumblingrobot.com/2015/10/06/", " find-the-largest-rectangle-that-can-be-inscribed-in-a-semicircle/", " goalie tactic", " a unit vector from the center of the goal to the ball, this vector will be used", " for positioning all the robots (excluding the goalie). The positioning vector", " will be used to position robots tangent to the goal_to_ball_unit_vector", " goal_defense_point_center is a point on the semicircle around the friendly", " defense area, that can block the direct path from the ball to the net.", " position robots on either side of the \"goal defense point\"", " ball_defense_point_center is a point on the circle around the ball that the", " line from the center of the goal to the ball intersects. A robot will be placed", " on that line, and the other two will be on either side", " We add an extra robot radius as a buffer to be extra safe we don't break any", " rules by getting too close", " insert all the move tactics to the result", " Register this play in the genericFactory"], "play": [" If the coroutine \"iterator\" is done, the getNextTactics function has completed", " and has no more work to do. Therefore, the Play is done.", " Update the member variable that stores the world. This will be used by the", " getNextTacticsWrapper function (inside the coroutine) to pass the World data to", " the getNextTactics function. This is easier than directly passing the World data", " into the coroutine", " Check the coroutine status to see if it has any more work to do.", " Run the coroutine. This will call the bound getNextTactics function", " Check if the coroutine is still valid before getting the result. This makes", " sure we don't try get the result after \"running out the bottom\" of the", " coroutine function", " Extract the result from the coroutine. This will be whatever value was", " yielded by the getNextTactics function", " If the coroutine \"iterator\" is done, the getNextTactics function has completed", " and has no more work to do. Therefore, the Play is done so wereturn an empty", " optional", " Yield an empty vector the very first time the function is called. This value will", " never be seen/used by the rest of the system.", " Anytime after the first function call, the getNextTactics function will be", " used to perform the real logic. The calculateNextIntent function will yield its", " values to the top of the coroutine stack, where they will be retrieved by", " getNextAction, so we do not need to yield or return the result of this function", "", " The getNextTactics function is given the World as a parameter rather than using", " the member variable since it's more explicit and obvious where the World", " comes from when implementing Plays. The World is passed as a reference, so when", " the world member variable is updated the implemented Plays will have access", " to the updated world as well."], "halt_test_play": [" Register this play in the genericFactory"], "move_test_play": [" Register this play in the genericFactory"], "pivot_action_test": [" PivotAction should be yielding move_intents as the robot is too far away from orbit", " Check an intent was returned (the pointer is not null)", " PivotAction should be yielding pivot intents as the robot is close enough to the ball", " Check an intent was returned (the pointer is not null)", " PivotAction should be yielding move intents when far from the ball", " Check an intent was returned (the pointer is not null)"], "chip_action": [" How large the triangle is that defines the region where the robot is", " behind the ball and ready to chip.", " We want to keep the region small enough that we won't use the ChipIntent from too", " far away (since the ChipIntent doesn't avoid obstacles and we risk colliding", " with something), but large enough we can reasonably get in the region and chip the", " ball successfully.", " This value is 'X' in the ASCII art below", " ASCII art showing the region behind the ball", " Diagram not to scale", "", "                             X", "                      v-------------v", "", "                   >  B-------------C", "                   |   \\           /", "                   |    \\         /", "                   |     \\       /       <- Region considered \"behind ball\"", "                 X |      \\     /", "                   |       \\   /", "                   |        \\ /", "    The ball is    >         A", "    at A", "                             |", "                             V", "                     direction of chip", " A vector in the direction opposite the chip (behind the ball)", " The points below make up the triangle that defines the region we treat as", " \"behind the ball\". They correspond to the vertices labeled 'A', 'B', and 'C'", " in the ASCII diagram", " We make the region close enough to the ball so that the robot will still be", " inside it when taking the chip.", " The point in the middle of the region behind the ball", " If we're not in position to chip, move into position"], "stop_action_test": [" Check an intent was returned (the pointer is not null)", " We call the action twice. The first time the Intent will always be returned to", " ensure the Robot is doing the right thing. In all future calls, the action will be", " done and so will return a null pointer"], "action": [" The action is done if the coroutine evaluates to false, which means execution", " has \"dropped out\" the bottom of the function and there is no more work to do", " Check the coroutine status to see if it has any more work to do.", " Run the coroutine. This will call the bound calculateNextIntent function", " Check if the coroutine is still valid before getting the result. This makes", " sure we don't try get the result after \"running out the bottom\" of the", " coroutine function", " Extract the result from the coroutine. This will be whatever value was", " yielded by the calculateNextIntent function", " Yield a null pointer the very first time the function is called. This value will", " never be seen/used by the rest of the system.", " Anytime after the first function call, the calculateNextIntent function will be", " used to perform the real logic. The calculateNextIntent function will yield its", " values to the top of the coroutine stack, where they will be retrieved by", " getNextAction, so we do not need to yield or return the result of this function"], "intercept_ball_action_test": [" Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)"], "move_action": [" We use a do-while loop so that we return the Intent at least once. If the robot was", " already moving somewhere else, but was told to run the MoveAction to a destination", " while it happened to be crossing that point, we want to make sure we send the", " Intent so we don't report the Action as done while still moving to a different", " location"], "movespin_action": [" We use a do-while loop so that we return the Intent at least once. If the robot was", " already moving somewhere else, but was told to run the MoveSpinAction to a", " destination while it happened to be crossing that point, we want to make sure we", " send the Intent so we don't report the Action as done while still moving to a", " different location"], "dribble_action": [" We use a do-while loop so that we return the Intent at least once. If the robot was", " already moving somewhere else, but was told to run the DribbleAction to a", " destination while it happened to be crossing that point, we want to make sure we", " send the Intent so we don't report the Action as done while still moving to a", " different location"], "chip_action_test": [" Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " Check the MoveIntent is moving roughly behind the ball", " Check an intent was returned (the pointer is not null)", " Check the MoveIntent is moving roughly behind the ball", " Check an intent was returned (the pointer is not null)", " Check the MoveIntent is moving roughly behind the ball", " Check an intent was returned (the pointer is not null)", " Check the MoveIntent is moving roughly behind the ball"], "kick_action": [" How large the triangle is that defines the region where the robot is", " behind the ball and ready to kick.", " We want to keep the region small enough that we won't use the KickIntent from too", " far away (since the KickIntent doesn't avoid obstacles and we risk colliding", " with something), but large enough we can reasonably get in the region and kick the", " ball successfully.", " This value is 'X' in the ASCII art below", " ASCII art showing the region behind the ball", " Diagram not to scale", "", "                             X", "                      v-------------v", "", "                   >  B-------------C", "                   |   \\           /", "                   |    \\         /", "                   |     \\       /       <- Region considered \"behind ball\"", "                 X |      \\     /", "                   |       \\   /", "                   |        \\ /", "    The ball is    >         A", "    at A", "                             |", "                             V", "                     direction of kick", " A vector in the direction opposite the kick (behind the ball)", " The points below make up the triangle that defines the region we treat as", " \"behind the ball\". They correspond to the vertices labeled 'A', 'B', and 'C'", " in the ASCII diagram", " We make the region close enough to the ball so that the robot will still be", " inside it when taking the kick.", " The point in the middle of the region behind the ball", " If we're not in position to kick, move into position"], "action_test": ["", " The first time the Action runs it will always return an Intent to make sure we", " are doing the correct thing", " For subsequent calls, we expect the Action to be done (in this case)", " We make sure that when a nullptr is returned, the action also evaluates to \"done\"", " This is important since higher-level functionality relies on the Action::done()", " function but returning nullptr values out of sync with this done() function could", " cause problems"], "pivot_action": [" If we're not in position to pivot, move to grab the ball", " if the robot is close enough to the final position, call it a day"], "kick_action_test": [" Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " Check the MoveIntent is moving roughly behind the ball", " Check an intent was returned (the pointer is not null)", " Check the MoveIntent is moving roughly behind the ball", " Check an intent was returned (the pointer is not null)", " Check the MoveIntent is moving roughly behind the ball", " Check an intent was returned (the pointer is not null)", " Check the MoveIntent is moving roughly behind the ball"], "movespin_action_test": [" Check an intent was returned (the pointer is not null)", " We call the action twice. The first time the Intent will always be returned to", " ensure the Robot is doing the right thing. In all future calls, the action will be", " done and so will return a null pointer", " Run the Action several times", " Check an intent was returned (the pointer is not null)"], "dribble_action_test": [" Check an intent was returned (the pointer is not null)", " We call the action twice. The first time the Intent will always be returned to", " ensure the Robot is doing the right thing. In all future calls, the action will be", " done and so will return a null pointer", " Run the Action several times", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)"], "intercept_ball_action": [" This action tries to intercept and collect the ball on the field.", " We find the point on the Ray formed by the ball's velocity that is closest to", " the robot. If the time for the robot to get to that point is less than the time", " for the ball to get to that point, the robot moves to that point to intercept the", " ball. Once the robot is in the ball's path, it will move to a point just in", " front of the ball in order to meet it quicker, while staying in it's path.", "", " If the robot cannot reach the closest point on the ray before the ball, the robot", " will move to intercept the ball at the point it would leave the field. This", " generally causes the robot to move far enough ahead of the ball that it can switch", " to intercepting at the closest point on the ray like above.", "", " Finally, if the ball is moving slowly the robot will go directly to the ball.", " We add 1e-6 to avoid division by 0 without affecting the result significantly", " This is a fallback case that ideally should never be reached. We will only", " enter this case if the robot is not in front of the ball, and the ball is", " not within the field."], "move_action_test": [" Check an intent was returned (the pointer is not null)", " We call the action twice. The first time the Intent will always be returned to", " ensure the Robot is doing the right thing. In all future calls, the action will be", " done and so will return a null pointer", " Run the Action several times", " Check an intent was returned (the pointer is not null)", " Run the Action several times", " Check an intent was returned (the pointer is not null)", " Run the Action several times", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)", " Check an intent was returned (the pointer is not null)"], "move_test_action": [" We use a do-while loop so that we return the Intent at least once. If the robot was", " already moving somewhere else, but was told to run the MoveTestAction to a", " destination while it happened to be crossing that point, we want to make sure we", " send the Intent so we don't report the Action as done while still moving to a", " different location", " We don't call \"visitor.visit\" here because this class is just intended", " for testing and shouldn't be part of the visitor"], "navigator_test": [" The navigator under test", " Make sure we got exactly 1 primitive back", " Make sure we got exactly 1 primitive back", " Make sure we got exactly 1 primitive back", " Make sure we got exactly 1 primitive back", " Make sure we got exactly 1 primitive back", " Make sure we got exactly 1 primitive back", " Make sure we got exactly 1 primitive back", " Make sure we got exactly 1 primitive back", " Make sure we got exactly 1 primitive back", "    intents.emplace_back(", "        std::make_unique<MoveIntent>(0, Point(), Angle::quarter(), 0, 1));", " Make sure we got exactly 3 primitives back", " An arbitrary fixed point in time", " We use this fixed point in time to make the tests deterministic.", " Construct the world with arguments", " Make sure we got exactly 1 primitive back", " Construct the world with arguments", " Make sure we got exactly 1 primitive back", " case 1", " case 2", " case 1", " case 2", " case 1", " case 2"], "navigator": [" The cap style must be NOT be set to SquareCap. It can be set to anything else.", " Drawing a line of length 0 with the SquareCap style causes a large line to be", " drawn"], "velocity_obstacle_path_manager": [" Velocity obstacles used to avoid collisions.", " As we plan a path for each robot, a corresponding obstacle will be added", " to this list so that paths planned later do not collide with the path we just", " planned. Please see: https://en.wikipedia.org/wiki/Velocity_obstacle", " find path with relevant obstacles", " store path in managed_paths", " store velocity obstacle for current path", " We want to avoid the start of every other path, assuming that", " there is a robot moving along the path from the path's start"], "obstacle_test": [" obstacle with robot radius factor = 1, velocity projection factor = 1", " centred at (0,0) and with (0,0) velocity", " visually verified", " obstacle with robot radius factor = 1, velocity projection factor = 1", " centred at (1,2) and with (3,2) velocity", " visually verified", " obstacle with robot radius factor = 1.2, velocity projection factor = 1.4", " centred at (-1,-2) and with (-3,2) velocity", " visually verified", " obstacle with robot additional radius buffer = 0, additional velocity projection buffer", " = 0 centred at (1,2) and with (3,2) velocity", " visually verified", " obstacle with robot additional radius buffer = 0.4, additional velocity projection", " buffer = 1.8 centred at (-1,-2) and with (-3,2) velocity", " visually verified"], "obstacle": [" Add robot radius to account for path planning robot's size", " vector in the direction of the velocity and with the scaled size of the", " velocity", " velocity_cushion_vector should be at least as long as a robot width", " with an additional factor that is half of the average of intial speed and", " ROBOT_MAX_SPEED_METERS_PER_SECOND times the length_scaling", " left side of robot", " right side of robot", " right side velocity cushions", " left side velocity cushions", " vector in the direction of the velocity and with the scaled size of the", " velocity", " vector in the direction of the velocity and with the scaled size of the", " velocity", " TODO: using this for more then robots now, should probably rename", " This is a helper function to factor out some of the logic from the other functions", " left side of robot", " back left of robot", " back right of robot", " right side of robot", " right side velocity cushions", " left side velocity cushions", " force the robot to face in +x direction", " left side of robot", " back left of robot", " back right of robot", " right side of robot", " front right velocity cushions", " front left velocity cushions", " this is a helper function", " return radius cushion so that centre to side distance is at least double given", " radius so that two robots can pass by each other this is accomplished by", " doubling the radius and multiplying by 2/sqrt(3)"], "obstacle_factory": [" We extend the friendly defense area back by several meters to prevent", " robots going around the back of the goal", " We extend the enemy defense area back by several meters to prevent", " robots going around the back of the goal", " 0.3 is by definition what inflated means", " 0.5 represents half a metre radius"], "one_point_path_test_path_planner": [""], "theta_star_path_planner_test": [" If the path size is 1, just need to check that the point is not within the obstacle", " Check that no line segment on the path intersects the obstacle", " Test where we start in an obstacle. We should find the closest edge of", " the obstacle and start our path planning there", " Place a rectangle over our starting location", " Make sure the start and end of the path are correct", " Make sure the path does not exceed a bounding box", " Make sure the path does not go through any obstacles, except for the", " first point, which is in the obstacle blocking the start position", " Test where we try to end in an obstacle. We should navigate to the closest point", " on the edge of the destination", " Place a rectangle over our destination location", " The path should start at exactly the start point", " Make sure the path does not exceed a bounding box", " Make sure the path does not go through any obstacles", " Test where we need to navigate around a single obstacle along the x-axis", " Place a rectangle over our destination location", " The path should start at exactly the start point and end at exactly the dest", " Make sure the path does not exceed a bounding box", " Can't make sure the path does not go through any obstacles", " since start is blocked", " Test where we need to navigate around a single obstacle along the x-axis", " Place a rectangle over our destination location", " The path should start at exactly the start point and end at exactly the dest", " Make sure the path does not exceed a bounding box", " Can't make sure the path does not go through any obstacles", " since start is blocked", " Since there are no obstacles, there should be two path points, one at the start", " and one at the destination", " Test running theta star with no area to navigate in", " This test is disabled, it can be enabled by removing \"DISABLED_\" from the test name", " This test can be used to guage performance, and profiled to find areas for", " improvement"], "no_path_test_path_planner": [""], "theta_star_path_planner": ["", " Returns true if row number and column number", " is in range", " If we haven't checked this Coordinate for obstacles before, check it now", " We use the opposite convention to indicate blocked or not", " Return using the distance formula", " Leverage point class", " loop until parent is self", " Only process this CellHeuristic if this is a valid one", " If the successor is already on the closed", " list or if it is blocked, then ignore it.", " Else do the following", " If it isn\u2019t on the open list, add it to", " the open list. Make the current square", " the parent of this square. Record the", " f, and g costs of the square CellHeuristic", "             OR", " If it is on the open list already, check", " to see if this path to that square is better,", " using 'f' cost as the measure.", " Update the details of this CellHeuristic", " If the destination is the same as the current successor", " top level function", " Initialising the parameters of the starting node", " replace destination with actual destination", " replace src with actual start", " If the source is out of range", " If the destination is out of range", " The source is blocked", " The destination is blocked", " If the destination CellHeuristic is within one grid size of start", " Remove this vertex from the open list", " Add this vertex to the closed list", " When the destination CellHeuristic is not found and the open", " list is empty, then we conclude that we failed to", " reach the destination CellHeuristic. This may happen when the", " there is no way to destination CellHeuristic (due to blockages)", " spiral out from current_cell looking for unblocked cells", " expanding a circle to search for free points", " check for decision parameter", " and correspondingly", " update d, x, y", " account for robot radius", " account for robot radius", " Initialize member variables", " Reset data structures to path plan again"], "straight_line_path_planner": [""], "motion_constraint_manager_test": ["", " This namespace contains all the test parameters", " vector of pairs of Tactic and whitelists", " sets of motion constraints for each type of gamestate", " namespace"], "motion_constraint_manager": [" updates current_whitelisted_constraints", " Tactic didn't implement accept so don't add any more motion constraints", " We disable clang-format here because it makes these lists borderline unreadable,", " and certainly way more difficult to edit", " clang-format off", " clang-format on", " Is their penalty"], "pass_generator": [" We initialize the random number generator with a specific value to", " allow generated passes to be deterministic. The value used here has", " no special meaning.", " Generate the initial set of passes", " Start the thread to do the pass generation in the background", " The lambda expression here is needed so that we can call", " `continuouslyGeneratePasses()`, which is not a static function", " Take ownership of the updated world for the duration of this function", " Update the world", " Take ownership of the passer_point for the duration of this function", " Update the passer point", " Take ownershp of the passer robot id for the duration of this function", " If we're running deterministically, then we need to manually optimize the", " passes rather then assuming the optimization thread has done the work for us", " Take ownership of the best_known_pass for the rest of this function", " Take ownership of the target_region for the duration of this function", " Set this flag so pass_generation_thread knows to end (also making sure to", " properly take and give ownership of the flag)", " Join to pass_generation_thread so that we wait for it to exit before destructing", " the thread object. If we do not wait for thread to finish executing, it will", " call `std::terminate` when we deallocate the thread object and kill our whole", " program", " Take ownership of the in_destructor flag so we can use it for the conditional", " check", " Give up ownership of the in_destructor flag now that we're done the", " conditional check", " Yield to allow other threads to run. This is particularly important if we", " have this thread and another running on one core", " Take ownership of the `in_destructor` flag so we can use it for the conditional", " check", " Copy over the updated world and remove the passer robot", " Update the passer point for all the passes", " The objective function we minimize in gradient descent to improve each pass", " that we're optimizing", " Run gradient descent to optimize the passes to for the requested number", " of iterations", " NOTE: Parallelizing this `for` loop would probably be safe and potentially more", "       performant", " Sometimes the gradient descent algorithm could return an invalid pass, if", " so, we can just ignore it and carry on", " Sort the passes by decreasing quality", " Merge Passes That Are Similar", " We start by assuming that the most similar passes will be right beside each other,", " then iterate over the entire list, building a new list as we go by only adding", " elements when they are dissimilar enough from the last element we added", " NOTE: This flips the passes so they are sorted by increasing quality", " Check if we have no passes, or if this pass is too similar to the", " last pass we added to the list", " Replace the least promising passes", " Generate new passes to replace the ones we just removed", " Append our newly generated passes to replace the passes we just removed", " Take ownership of the best_known_pass for the duration of this function", " Sort the passes by decreasing quality", " We want to use the parameter value for this, but clamp it so that it is", " <= the number of passes we're optimizing", " We want to use the parameter value for this, but clamp it so that it is", " >= 1 so we are always optimizing at least one pass", " Take ownership of world, target_region, passer_robot_id for the duration of this", " function", " If the pass is invalid, just rate it as poorly as possible", " Take ownership of world for the duration of this function", " Take ownership of the world for the duration of this function", " Take ownership of the passer_point and world for the duration of this function", " Clamp the time to be >= 0, otherwise the TimeStamp will throw an exception"], "pass_generator_test": ["", "", " Run until the pass has converged with sufficient tolerance or the given", " time has expired, whichever comes first. We also check that the score", " is not small, otherwise we can get \"false convergence\" as the", " pass just starts to \"move\" towards the converged point", " Test that we can converge to a stable pass in a scenario where there is a", " fairly clear best pass.", " It is difficult to update all the timestamps in the world that the pass generator", " could use, so we don't, and hence this test does not really test convergence", " of pass start time.", " Find what pass we converged to", " Check that we keep converging to the same pass", " Test that the pass generator does not converge to use the robot set as the passer", " This would be the ideal robot to pass to", " This is a reasonable robot to pass to, but not the ideal", " We put a few enemies in to force the pass generator to make a decision,", " otherwise most of the field would be a valid point to pass to", " Wait until the pass stops improving or 30 seconds, whichever comes first", " Find what pass we converged to", " We expect to have converged to a point near robot 1. The tolerance is fairly", " generous here because the enemies on the field can \"force\" the point slightly", " away from the chosen receiver robot", " Test that we do not converge to a pass from the passer robot to itself", " The passer robot", " The potential receiver robot. Not in a great position, but the only friendly on", " the field", " We put a few enemies in to force the pass generator to make a decision,", " otherwise most of the field would be a valid point to pass to", " Wait until the pass stops improving or 30 seconds, whichever comes first", " Find what pass we converged to", " We expect to have converged to a point near robot 2. The tolerance is fairly", " generous here because the enemies on the field can \"force\" the point slightly", " away from the chosen receiver robot", " Test that changing the passer point is reflected in the optimized passes returned", " Put a friendly robot on the +y and -y sides of the field, both on the enemy half", " Put a line of enemies along the +x axis, \"separating\" the two friendly robots", " Set the passer point so that the only reasonable pass is to the robot", " on the +y side", " Wait for the pass to converge, or 30 seconds, whichever come first", " Find what pass we converged to", " We expect to have converged to a point near the robot in +y. The tolerance is", " fairly generous here because the enemies on the field can \"force\" the point", " slightly away from the chosen receiver robot", " Set the passer point so that the only reasonable pass is to the robot", " on the -y side", " Wait for the pass to converge, or 30 seconds, whichever come first", " Find what pass we converged to", " We expect to have converged to a point near the robot in +y. The tolerance is", " fairly generous here because the enemies on the field can \"force\" the point", " slightly away from the chosen receiver robot", " Test that when given a target region, the pass generator returns a pass", " with the receiver point in that target region", " Wait for the pass to converge, or 30 seconds, whichever come first", " With no target region set, the pass generator would like to pass more to", " the -y side of the field (away from the enemy and closer to the friendly).", " With a target region set, we expect the receiver point to be within the", " target region instead."], "cost_function": ["", " Rate all passes outside our target region as 0 if we have one", " Place strict limits on pass start time", " Place strict limits on the ball speed", " We ignore shoot pass quality if we're rating for a \"RECEIVE_AND_DRIBBLE\" pass", " TODO: You don't even use this first parameter, but stuff is hardcoded below", " Figure out the range of angles for which we have an open shot to the goal after", " receiving the pass", " Figure out what the maximum open angle of the goal could be from the receiver pos.", " Create the shoot score by creating a sigmoid that goes to a large value as", " the section of net we're shooting on approaches 100% (ie. completely open)", " Prefer angles where the robot does not have to turn much after receiving the", " pass to take the shot (or equivalently the shot deflection angle)", " Calculate a risk score based on the distance of the enemy robots from the receive", " point, based on an exponential function of the distance of each robot from the", " receiver point", " We want to rate a pass more highly if it is lower risk, so subtract from 1", " Return the highest risk for all the enemy robots, if there are any", " We estimate the intercept by the risk that the robot will get to the closest", " point on the pass before the ball, and by the risk that the robot will get to", " the reception point before the ball. We take the greater of these two risks.", " If the enemy cannot intercept the pass at BOTH the closest point on the pass and", " the the receiver point for the pass, then it is guaranteed that it will not be", " able to intercept the pass anywhere.", " Figure out how long the enemy robot and ball will take to reach the closest", " point on the pass to the enemy's current position", " Check for division by 0", " Figure out how long the enemy robot and ball will take to reach the receive point", " for the pass.", " Whether or not the enemy will be able to intercept the pass can be determined", " by whether or not they will be able to reach the pass receive position before", " the pass does. As such, we place the time difference between the robot and ball", " on a sigmoid that is centered at 0, and goes to 1 at positive values, 0 at", " negative values.", " Remove the passer robot from the friendly team before evaluating, as we assume", " the passer is not passing to itself", " We need at least one robot to pass to", " Special case where pass speed is 0", " Get the robot that is closest to where the pass would be received", " Figure out what time the robot would have to receive the ball at", " Figure out how long it would take our robot to get there", " Figure out what angle the robot would have to be at to receive the ball", " Figure out if rotation or moving will take us longer", " Create a sigmoid that goes to 0 as the time required to get to the reception", " point exceeds the time we would need to get there by", " This constant is used to determine how steep the sigmoid slopes below are", " The offset from the sides of the field for the center of the sigmoid functions", " Make a slightly smaller field, and positive weight values in this reduced field", " Add a negative weight for positions closer to our goal", " Add a strong negative weight for positions within the enemy defense area, as we", " cannot pass there"], "cost_function_test": ["", " We get these values here so we can make these tests robust to change", " This test does not assert anything. Rather, It can be used to guage how", " fast ratePass is running, and can be profiled in order to find areas", " of improvement for ratePass", " At the time of this tests creation, ratePass ran at an average 0.105ms", " in debug on an i7", "    std::cout << \"Took \"", "              <<", "              std::chrono::duration_cast<std::chrono::microseconds>(duration).count()", "              /", "                     1000.0", "              << \"ms to run, average time of \"", "              << std::chrono::duration_cast<std::chrono::microseconds>(avg).count()", "              /", "                     1000.0", "              << \"ms\" << std::endl;", " A pass from halfway up the +y side of the field to the origin.", " There is an enemy defender right on the pass trajectory", " A pass from halfway up the +y side of the field to the origin.", " There is a defender closely marking one friendly robot on the field, but the", " friendly robot at the origin is free.", " A pass from the +y side of the field to the -y side of the field, roughly 1/2 way", " up the enemy half of the field. There is a defender closely marking the only", " friendly robot on the field.", " A pass from the +y side of the field to the -y side of the field,", " roughly 1/2 way up the enemy half of the field. There is a defender somewhat close", " to the pass, but not close enough to get there in time.", " A pass from the +y side of the field to the -y side of the field,", " roughly 1/2 way up the enemy half of the field, with a goalie in the net, but off", " to the positive side. We also pass as soon as we can", " A pass from the +y side of the field to the -y side of the field,", " roughly 1/2 way up the enemy half of the field", " A pass from the positive enemy corner to a robot at the center of the field with", " no enemies", " A corner kick from the +x, +y corner of the field to a robot on the +x axis part", " way up the enemy half of the field. The receiver friendly is marked by an enemy,", " but it has enough space that it should be able to break away from it's marker in", " time to make space to receive the pass and one-time shoot it into the net.", " Robot doing corner kick", " Robot at center field", " Enemy goalie", " Enemy marking friendly in the center", " This should be a really good pass, and since there is no target region it should", " be highly scored", " This should be a really good pass, but it's outside our target region, so it", " should be rate poorly", " We should very poorly rate a pass that has occurred in the past", " We update the the ball state because that's what is used as a reference for the", " current time by the evaluation function", " TODO (Issue #423): Change this to use the `World` timestamp when `World` has one", " We update the the ball state because that's what is used as a reference for the", " current time by the evaluation function", " TODO (Issue #423): Change this to use the `World` timestamp when `World` has one", " If there is only a passer on the field, no pass is possible", " Test that a pass which does NOT result in a good shot on goal is rated", " highly if we are rating it as a pass which is intended to be received", " Since we're passing from the origin to a point directly in front of the goal,", " the receiving robot would have to turn 180 degrees to take a shot after", " receiving the ball", " No robots on the field, we receive the pass and are directly facing the goal", " and are right in front of it", " No robots on the field, we receive the pass and are facing directly away from the", " goal", " Robots on field, but none that are in the way of us shooting after the pass", " Test rating a pass that results in no open shot to goal", " Robot directly in front of the pass position", " As we decrease the open angle to the goal, the shot score should also decrease", " Test with an enemy team that has several robots, the first of which is close to", " the pass trajectory", " Test with an enemy team that has several robots, the last of which is close to", " the pass trajectory", " Test calculating the intercept risk for a robot that is located directly", " along the trajectory of the pass", " Test calculating the intercept risk for a robot that is located just off to the", " side of the pass trajectory, but close enough that it will be able to move onto", " the pass trajectory and intercept it", " Test calculating the intercept risk for a robot that is located far enough away", " from the pass trajectory that there is no way it will be able to intercept it", " Test passing across the enemy end of the field, with an enemy robot over in the", " friendly end of the field. The enemy robot should not be able to intercept the pass", " An enemy robot moving towards the pass from far away should not be able to", " intercept it", " Test where the enemy is a fair distance off the pass trajectory, but the pass", " doesn't start for a few seconds, so the enemy would have time to move to", " intercept before the pass has started", " An enemy robot moving towards the pass from far away should not be able to", " intercept it", " Test a pass that the enemy robot should just barely be able to intercept, starting", " from a stop", " x = u*t + 1/2*at^2, u=0, t=1", " If there are no robots on the team, then there is no way we can receive a pass", " If there are no robots on the team, then there is no way we can receive a pass", " Test getting friendly capability for a team with two robots, one near the pass", " reception point and the other far away", " There should be a very high probability that we can receive this pass", " Test getting friendly capability with two friendly robots:", " - one robot in the perfect position to receive the pass, but it's the passer", "   robot, so we should ignore it", " - one robot fairly far away from the pass receive point, so it won't be able to", "   receive the pass in time", " The net result should be a poor friendly capability, as we can only pass to the", " one robot that can't get to the pass reception point in time", " Test case where there are lots of robots far away from the reception point and", " there *is not* enough time for them to get to the reception point", " Test case where there are lots of robots far away from the reception point, but", " when *there is* enough time for them to reach the receive point", " Test case where this is one robot, but it is turned in the wrong direction and", " will not be able to turn in time to receive the pass", " Test case where the receiver is already lined up to receive the pass", " Check that the static quality is basically 0 at the edge of the field", " Check that we have a static quality of almost 0 near our goal", " Check that we have a large static quality near the enemy goal", " But we should have basically 0 static quality too close to the enemy goal,", " as there is a defense area around the net that we cannot pass to"], "intent_test": [""], "move_intent_test": ["", " For equality operators, we only check for cases not covered in the Primitive tests,", " since Intents inherit from Primitives"], "movespin_intent_test": ["", " For equality operators, we only check for cases not covered in the Primitive tests,", " since Intents inherit from Primitives"], "chip_intent_test": ["", " For equality operators, we only check for cases not covered in the Primitive tests,", " since Intents inherit from Primitives"], "stop_intent_test": ["", " For equality operators, we only check for cases not covered in the Primitive tests,", " since Intents inherit from Primitives"], "direct_velocity_intent_test": ["", " For equality operators, we only check for cases not covered in the Primitive tests,", " since Intents inherit from Primitives"], "intent": [" Implement concrete functions shared by all intents"], "pivot_intent_test": ["", " For equality operators, we only check for cases not covered in the Primitive tests,", " since Intents inherit from Primitives"], "direct_wheels_intent_test": ["", " For equality operators, we only check for cases not covered in the Primitive tests,", " since Intents inherit from Primitives"], "dribble_intent_test": ["", " For equality operators, we only check for cases not covered in the Primitive tests,", " since Intents inherit from Primitives"], "kick_intent_test": ["", " For equality operators, we only check for cases not covered in the Primitive tests,", " since Intents inherit from Primitives"], "catch_intent_test": ["", " For equality operators, we only check for cases not covered in the Primitive tests,", " since Intents inherit from Primitives"], "team": [" Set the size of the Timestamp history buffer", " Update the robots, checking that there are no duplicate IDs in the given data", " The second value of the pair that is returned indicates whether or not the", " value was already present in the set. We use this to detect duplicate robots", " The robot already exists on the team. Find and update the robot", " This robot does not exist as part of the team yet. Add the new robot", " Update the state of all robots to their predicted state", " Check to see if any Robots have \"expired\". If it more time than the expiry_buffer", " has passed, then remove the robot from the team", " Check if the timestamp buffer is empty", " Check that the new timestamp is not older than the most recent timestamp", " Don't update if the timestamp is the same as the most recent already assigned", " to Team"], "field_test": [" The field was already constructed in the test setup, so we only need to check", " values here", " Test that the timestamp history is saved when the Field is updated", " point around centre", " First make sure we have a timestamp > 0"], "game_state": [" it has to be a restart for it to be our restart", " Robots must be in position for a restart", " One of our robots can kick the ball", " Our robots must stay on our half of the field", " Our robots (except the penalty kicker) must stay a set distance behind the penalty line", " apologies for this monster switch statement", " Save the ball state so we can tell once it moves", " Once the ball has moved enough, the restart is finished"], "world_test": [" An arbitrary fixed point in time", " We use this fixed point in time to make the tests deterministic.", " Construct the world with arguments", " Check that objects used for construction are returned by the accessors", " Check that objects used for construction are returned by the accessors", " Test that getMostRecentTimestamp functions properly", " Test that most recent timestamp from member objects works", " Test that the timestamp history is accurate"], "game_state_test": [" tuple of start state, update state, end state, our_restart, restart reason", "", " transitions to HALT", " transitions to STOP", " transitions from STOP to a restart state", " a restart state transitioning to NORMAL_START should not clear the restart. We", " should do that ourselves either when the ball starts moving, or when we kick", " the ball.", " transitions to a GOAL state", " transition to FORCE_START", "", " PLAYING state must be manually set after a transition from a restart state to", " NORMAL_START", " isOurRestart tested above already", " PREDICATE_TEST(", "    isSetupRestart, RefboxGameState::PREPARE_KICKOFF_US,", "    RefboxGameState::PREPARE_KICKOFF_THEM, RefboxGameState::BALL_PLACEMENT_US,", "    RefboxGameState::BALL_PLACEMENT_THEM,", "    // NORMAL_START is a ready state until the restart is cleared when the ball moves", "    RefboxGameState::NORMAL_START, RefboxGameState::PREPARE_PENALTY_US,", "    RefboxGameState::PREPARE_PENALTY_THEM)", " canKick needs to be tested with a proper restart sequence", " STOP -> restart_type is how restarts occur during games", " verify game_state is in the correct state", " restart_type -> NORMAL_START happens next", " verify state again", " restart state is cleared when the ball is kicked, enter regular", " playing state", " STOP -> restart_type is how restarts occur during games", " verify game_state is in the correct state", " restart_type -> NORMAL_START happens next", " verify state again", " restart state is cleared when the ball is kicked, enter regular", " playing state", " STOP -> restart_type is how restarts occur during games", " verify game_state is in the correct state", " restart_type -> NORMAL_START happens next", " verify state again", " restart state is cleared when the ball is kicked, enter regular", " playing state", " STOP -> restart_type is how restarts occur during games", " verify game_state is in the correct state", " restart_type -> NORMAL_START happens next", " verify state again", " restart state is cleared when the ball is kicked, enter regular", " playing state"], "team_test": [" The goalie assignment should not be affected by the prediction"], "world": [" Set the default Timestamp as this parameter is not caught when using the World", " contructor", " Store a small buffer of previous refbox game states so we can filter out noise", " Grab the most recent timestamp from all of the members used to update the world", " Check if the timestamp buffer is empty", " Check that the new timestamp is not older than the most recent timestamp", " Take the consensus of the previous refbox messages", " Intit to 0.0. This way we will always get a larger or equal timestamp from one of", " the members", " Add all member timestamps to a list", " Return the max"], "ball_test": [" An arbitrary fixed point in time.", " We use this fixed point in time to make the tests deterministic.", " A small distance to check that values are approximately equal", " A small distance to check that values are approximately equal", " A small distance to check that values are approximately equal"], "field": [" The addEllipse function does not center the ellipse at the given coordinates, so it", " is slightly easier to define the bounding rect within which the ellipse is drawn"], "visualizer_wrapper": [" Call the Application in a threadsafe manner.", " https://stackoverflow.com/questions/10868946/am-i-forced-to-use-pthread-cond-broadcast-over-pthread-cond-signal-in-order-to/10882705#10882705", " We use raw pointers to have explicit control over the order of destruction.", " For some reason, putting the QApplication and Visualizer on the stack does", " not work, despite theoretically having the same order of destruction", " Run the QApplication and all windows / widgets. This function will block", " until \"quit\" is called on the QApplication, either by closing all the", " application windows or calling the destructor of this class", " NOTE: The visualizer MUST be deleted before the QApplication. The QApplication", " manages all the windows, widgets, and event loop so must be destroyed last", " Let the system know the visualizer has shut down once the application has", " stopped running"], "geometry_conversion": [" In Qt's default coordinate system, (0, 0) is the \"top-left\" of the screen, and y", " increases downwards. This means the \"top-left\" corner of a rectangle is the", " corner with the most negative x and y coordinate, and \"bottom-right\" is positive", " x and positive y"], "zoomable_qgraphics_view": [" Do a mouse-wheel based zoom about the cursor position", " See https://stackoverflow.com/a/44422044"], "robot_status": [" The column count must be set before the labels are set"], "world_view": [" Performance optimizations", " https://stackoverflow.com/questions/43826317/how-to-optimize-qgraphicsviews-performance", " Using an OpenGL widget with the view should help make use of the graphics card", " rather than doing CPU drawing, which should take some load off the CPU and make", " things faster", " Invert the y-coordinates of the view.", " We do this because Qt's default coordinate system for drawing is:", " * positive x = \"right\"", " * positive y = \"down\"", " Our coordinate system defines positive y as being \"up\", so we invert the coordinate", " system so all our draw calls can follow our coordinate convention. This also fixes", " the orientation convention, so \"positive\" rotation is counterclockwise in the view", " (rotating from +x, to +y, to -x, to -y)"], "ai_control": [" TODO: Set this up using factory values like the play override once a factory of", " these values is available", " See issue #811 for getting these value from an enum / factory", " TODO: Confirm how East and West map to positive and negative sides", " TODO: Confirm how East and West map to positive and negative sides", " Sort the entries in alphabetical order from a-z", " Create a new list with all the play names converted to QStrings"], "robot_status_table": [" no increment ", " Resize the number of rows to only have as many rows as we have messages. This will", " automatically delete any extra rows / messages for us, and then we overwrite the", " existing rows with new messages"], "main_widget": [" Handles all the setup of the generated UI components and adds the components", " to this widget", " StrongFocus means that the MainWidget will more aggressively capture focus when", " clicked. Specifically, we do this so that when the user clicks outside of the", " QLineEdits used for Parameters, the QLineEdit will lose focus.", " https://www.qtcentre.org/threads/41128-Need-to-implement-in-place-line-edit-unable-to-get-lose-focus-of-QLineEdit", " This is a trick to force the initial width of the ai control tabs to be small,", " and the initial width of the ai view to be large. This sets the sizes of the", " widgets in the splitter to be unrealistically small (1 pixel) so that the", " size policies defined for the widgets will take over and grow the widgets to", " their minimum size, and then distribute the rest of the space according to the", " policies.", " See https://doc.qt.io/archives/qt-4.8/qsplitter.html#setSizes", " Update to make sure all layout changes apply nicely"], "parameters": [" We block signals while setting the state of the checkbox so that we don't", " trigger the `on_checkbox_value_changed` function, which would set the", " parameter value again and deadlock on the parameter's internal mutex", " TODO: Get range from parameter", " QSpinBox has 2 \"valueChanged\" signals that each provide different info (string vs", " int), so we need to static_cast to specify the integer version", " We block signals while setting the value of the spinbox so that we don't", " trigger the `on_spinbox_value_changed` function, which would set the", " parameter value again and deadlock on the parameter's internal mutex", " TODO: Get range from parameter", " QDoubleSpinBox has 2 \"valueChanged\" signals that each provide different info", " (string vs int), so we need to static_cast to specify the integer version", " We block signals while setting the value of the spinbox so that we don't", " trigger the `on_spinbox_value_changed` function, which would set the", " parameter value again and deadlock on the parameter's internal mutex", " This event will only fire when \"Enter\" is pressed or the LineEdit loses focus,", " rather than every time a character changes in the LineEdit.", " https://doc.qt.io/archives/qt-4.8/qlineedit.html#editingFinished", " We block signals while setting the text of the LineEdit so that we don't", " trigger the `on_line_edit_text_changed` function, which would set the", " parameter value again and deadlock on the parameter's internal mutex"], "parameter_exists_test": [" vectors to store the parameters fetched from the registry", " how long to wait for before running the tests, allowing time for the node to spawn", " msg to display before the name of the paramter that is not found", " namespace", " fixture used to run paramterized int32_t existance test", " fixture used to run paramterized double existance test", " fixture used to run paramterized bool existance test", " fixture used to run paramterized string existance test", " setup all test cases for the 4 XmlRpc types", " grab parameters of each type from its respective registry", " run tests"], "parameter_test": [" This callback will set the test_value (by reference) to the given value", " This callback will set the test_value (by reference) to the given value"], "config_test": [" More info on why this is needed here", " https://enreference.com/w/cpp/utility/variant/visit", " this is loaded from bazel data", " this creates an internal representation of the yaml files similar", " to how generate_parameters creates its internal dictionary", " before generating the required code.", " stores the yaml that should have the same structure", " as the config generated", " make sure the default value matches, accessing the yaml node with an", " invalid key will fail the test by default", " check to see if the options have been loaded correctly if they exist", " This creates a shared ptr pointing to a ThunderbotsConfig which can be mutated", " This creates an immutable ThunderbotsConfig w/ proper const correctnesss", " This creates a shared ptr pointing to a ThunderbotsConfig which can be mutated", " This creates an immutable ThunderbotsConfig w/ proper const correctnesss"], "dynamic_parameters": [" in c++ const by default has internal linkage, so we prefix extern to specify", " external linkage, and every file that needs DynamicParameters will grab the", " instance created here TODO remove this as part of", " https://github.com/UBC-Thunderbots/Software/issues/960", " namespace Util"], "gradient_descent_test": ["", " f = x^2", " f = -x^2", " Note that we halve the weight for \"y\" here to make sure", " gradient descent can see the function in a more homogenous way.", " See the GradientDescentOptimizer class javadoc comment for more details.", " f = x^2 + 2*y^2 + 20", " Note that we halve the weight for \"y\" here to make sure", " gradient descent can see the function in a more homogenous way.", " See the GradientDescentOptimizer class javadoc comment for more details.", " f = (x+5)^2 + 2*(y-4)^2 + 20", " f = 1 / (1 + exp(2-2x))", " We expect that the gradient descent will make it over the", " main part of the \"S\" in the sigmoid", " This test can be used to judge if the performance of gradient descent", " has decreased, as we here we are checking if it took _exactly_ the number", " of iterations to get past the main \"S\" part of a sigmoid", " f = 1 / (1 + exp(2-2x))", " We expect that the gradient descent will make it over the main part of", " the \"S\" in the sigmoid within the given number of iterations"], "math_functions_test": [" Check that value in the rectangle center is basically 1", " Check that value in the rectangle center is basically 1", " Check that values off in x are basically 0", " Check that values off in y are basically 0", " Check that values off in x and y are basically 0", " Check that values off in x are basically 0", " Check that values off in y are basically 0", " Check that values off in x and y are basically 0", " Test the value at sig_width/2 is 0.982", " Test the value at -sig_width/2 is 0.018", " Test that the value at 0 is 0.5 if no offset", " Test that the value at the offset is 0.5", " Test that negating sig_width inverts the sigmoid"], "math_functions": ["", " Created by roark on 28/03/19.", "", " namespace Util", " For both x and y here we use two sigmoid functions centered at the positive and", " negative edge of the rectangle respectively", " Calculate how far the point is from the circle center", " This is factor that changes how quickly the sigmoid goes from 0 to 1 it. We", " divide 8 by it because that is the distance a sigmoid function centered about 0", " takes to go from 0.018 to 0.982 (and that is what the `sig_width` is, as per", " the javadoc comment for this function)"], "grsim_backend": [" Update GrSim if we have all the information we need", " Register this play in the genericFactory"], "radio_backend": [" Send the world to the robots directly via radio", " Register this play in the genericFactory"], "simulator_backend": [" Start the thread to do the simulation in the background", " The lambda expression here is needed so that we can call", " `runSimulationLoop()`, which is not a static function", " Set this flag so the simulation_thread knows to end (also making sure to", " properly take and give ownership of the flag)", " Join to simulation_thread so that we wait for it to exit before destructing", " the thread object. If we do not wait for thread to finish executing, it will", " call `std::terminate` when we deallocate the thread object and kill our whole", " program", " Take ownership of the in_destructor flag so we can use it for the conditional", " check", " Give up ownership of the in_destructor flag now that we're done the", " conditional check", " Calculate how much wall-clock time has passed since we last published a", " world, and sleep for as much time as necessary for it to have been", " world_time_increment seconds in wall-clock time since the last world was", " published.", " Yield to allow other threads to run. This is particularly important if we", " have this thread and another running on one core", " TODO: Simulate the primitives", " https://github.com/UBC-Thunderbots/Software/issues/768", " Take ownership of the `in_destructor` flag so we can use it for the conditional", " check", " Register this play in the genericFactory"], "mrf_primitive_visitor": [" If we've never visited a primitive (and so have never populated the", " `radio_prim`) then throw an exception", " For this primitive, we don't divide the RPM"], "dongle": [" Different configs for the dongle, to allow for communication over", " different PANs and/or channels", " milliseconds", " The dongle's MAC address", " Used for sorting by robot ID", " namespace", " Sanity-check the dongle by looking for an interface with the appropriate", " subclass and alternate settings with the appropriate protocols.", " While doing so, discover which interface number is used for the radio and", " which alternate settings are for configuration-setting and normal // operation.", " Move the dongle into configuration 1 (it will nearly always already be", " there).", " Claim the radio interface.", " Switch to configuration mode and configure the radio parameters.", " Switch to normal mode.", " Prepare the available message IDs for allocation.", " Submit the message delivery report transfers.", " Attempt to receive at most 8 bytes from endpoint 1", " Submit the received message transfers.", " Attempt to receive at most 105 bytes from endpoint 2", " Submit the estop transfer.", " Mark USB device as shutting down to squelch cancelled transfer warnings.", " Connect signal to beep dongle when annunciator requests it.", " Only handle if there are more than 2 bytes in the transfer.", " These messages are critical enough that the dongle should continuously beep", " while the conditions are true.", " Assume all robots don't have valid position at the start", " Initialize pointer to start at location of storing ball data. First 2", " bytes are for mask and flag vector", " Add Ball x position", " Add Ball Y position", " Sort robots in ascending order by ID", " For the number of robot for which data was passed in, assign robot ids to", " mask vector and position/angle data to camera packet", " Write out the timestamp", " Mask and Flag Vectors should be fully initialized by now. Assign them to", " the packet", " Create and submit USB transfer with camera packet", " Update annunciator with detected bots for dead bot detection", " Connect signal to beep dongle when annunciator requests it.", " More than 1 prim.", " All robots are present. Build a full-size packet with all the", " robots\u2019 data in index order.", " Only some robots are present. Build a reduced-size packet", " with robot indices prefixed.", " Submit drive_packet when possible.", " Visit the primitive.", " Encode the parameter words.", " Encode the movement primitive number.", " Encode charge state", " Robots are always charged if the estop is in RUN state; otherwise discharge them.", " Discharge`", " Charge", " Encode extra data plus the slow flag.", " Convert the words to bytes."], "send_reliable_message_operation": [" namespace"], "mrf_primitive_visitor_test": [""], "annunciator": ["", "", "", " Received Signal Strength Indicator ", " Corresponding decibel value ", " Table of conversions from RSSI to decibels", "", " Struct to keep track of previously published messages for a robot", " Because vision updates and status updates occur from different", " threads, a mutex is used to prevent race conditions.", " Previously published status for this robot", " Map of message to timestamp for edge-triggered messages", " Timestamp of when this bot last sent a status update", " Map of robot number to their previously published messages", " namespace", " Initialize messages with the correct robot ID", " Guard robot status state for this bot", " General robot status update", " Warn if battery voltage is too low", " Warn if capacitor voltage is too low", " Warn if board temperature too high", " Robot logger status", " SD card messages", " Decode extensions.", " Error bits.", " Handling of level-triggered messages.", "", " Build IDs.", " LPS data. WARNING: unused, do not delete until", " it's removed from firmware", " Autokick fired", " Robot has ball", " Robot does not have ball", " Edge-triggered messages: keep sending message for ET_MESSAGE_KEEPALIVE_TIME seconds", " Beep the dongle if there were new messages since the last update", " Add the latest robot and dongle status messages", " Update previous message state", " Update last communicated time", " Send out robot status", " If there is a new message that wasn't present in the previous status update, beep", " the dongle", " Guard robot status state for this bot", " Check if robot is dead, publish old status update with dead message if so", " Beep dongle if this is a recent event", " Update and publish latest status"], "devicehandle": [" namespace"], "libusb": [" namespace", " Init libusb", " Init event handling thread", " Terminate event thread", " Close all devices", " This wakes up libusb_handle_events, now let the thread join", " Cleanup libusb"], "transfer": [" The transfer is submitted.", " Initiate transfer cancellation.", " Instead of waiting for cancellation to complete, \"disown\" the", " transfer object.", " It will be freed by the trampoline.", "", " There is a libusb bug where cancelling transfers sometimes makes", " the endpoint completely unresponsive in future.", " It\u2019s not a USB bug; libusb actually never submits future", " transfers for that endpoint!", " We should show a warning if a transfer is cancelled.", " However, cancelling transfers at shutdown would result in", " unnecessary spam, so squelch those.", " The transfer is not submitted and therefore can safely be freed.", " This happens if the Transfer object has been destroyed but the", " transfer was submitted at the time.", " The disowned libusb_transfer needs to be allowed to finish", " cancelling before being freed.", " libusb is C code, so exception cannot safely propagate through it", " doing a normal stack unwind.", " Save the exception in the main loop and do a normal return, which", " will let libusb unwind itself properly before the exception continues", " unwinding."], "errors": [" namespace"], "grsim_output_test": [" Create the packet we expect.", " Protobuf packets do not have a standard equality operator, so we need to use", " the protobuf MessageDifferencer", " Create the packet we expect.", " Protobuf packets do not have a standard equality operator, so we need to use", " the protobuf MessageDifferencer", " Create the packet we expect.", " Protobuf packets do not have a standard equality operator, so we need to use", " the protobuf MessageDifferencer", " Create the packet we expect.", " Protobuf packets do not have a standard equality operator, so we need to use", " the protobuf MessageDifferencer", " Create the packet we expect.", " Protobuf packets do not have a standard equality operator, so we need to use", " the protobuf MessageDifferencer", " Create the packet we expect.", " Protobuf packets do not have a standard equality operator, so we need to use", " the protobuf MessageDifferencer", " Create the packet we expect.", " Protobuf packets do not have a standard equality operator, so we need to use", " the protobuf MessageDifferencer", " Create the packet we expect.", " Protobuf packets do not have a standard equality operator, so we need to use", " the protobuf MessageDifferencer"], "grsim_output": [" Creates a struct which inherits all lambda function given to it and uses their", " Ts::operator(). This can be passed to std::visit to easily write multiple different", " lambdas for each type of motion controller commands below. See", " https://enreference.com/w/cpp/utility/variant/visit for more details.", " TODO: Can't replace this timestamp as part of issue #228 because the Timestamp", " class doesn't support absolute \"wall time\". This function will need to be", " changed to make use of the timestamps stored with the robots", " https://github.com/UBC-Thunderbots/Software/issues/279", "", " initial timestamp for bang-bang set as current time", " send the velocity data via grsim_packet", " timestamp of when the motion controller was last run (to be used for calculating", " delta_time in the future)", " We set a robot velocity, not individual wheel velocities", " veltangent moves the robot forward and backward", " velnormal strafes the robots left and right", " The vertical component of kicks (used to create chips) are applied separately. We", " use the same value as the kick speed to get a chip angle of roughly 45 degrees", " grSim_Replacement* replacement          = packet.mutable_replacement();", " grSim_BallReplacement* ball_replacement = replacement->mutable_ball();", " ball_replacement->set_x(destination.x());", " ball_replacement->set_y(destination.y());", " ball_replacement->set_vx(velocity.x());", " ball_replacement->set_vy(velocity.y());"], "grsim_command_primitive_visitor": [" Calculate the theoretical catch point based on the robots's distance to the ball", " and how fast the robot is moving.", " If Robot is not moving, estimate position based on a standard velocity of 1", " Get unit vectors in the direction the ball is moving.", " This allows the interceptor margin to be applied in the correct direction.", " Robot should be facing in the opposite direction the ball in moving to have ball", " hit its dribbler.", " If ball is far enough way from robot, add extra margin of error to ensure robot", " gets in line with the ball correctly. In addition, if the robot is not yet facing", " the ball move away to give it time to adjust.", " If current robot position is in line with the shot (i.e. less than two robot radius", " within the line in the direction of the shot), can go for the shot", " If robot is not in line, move to the closest point on the line from the current", " position", " TODO: https://github.com/UBC-Thunderbots/Software/issues/286", " get current robot position and orientation(angle)", " create linear velocity vector from direct velocity primitive", " transfer velocity into global coordinate by rotating the vector in robot", " coordinates by the angle of robot", " final destination is the parameter that can control the robot to", " move in the direction of velocity vector from current robot position", " final orientation is the parameter that can control the robot to rotate in the", " direction of angular velocity from current robot orientation, clamp the angular", " velocity between [-pi/2,pi/2]", " TODO: https://github.com/UBC-Thunderbots/Software/issues/98", " If current robot position is in line with the shot (i.e. less than two robot radius", " within the line in the direction of the shot), can go for the shot", " If robot is not in line, move to the closest point on the line from the current", " position", " compute final position", " get current vector from pivot point to robot position", " get a vector in the tangential direction", " get collinear point on orbit, between the robot and the pivot point, used", " to maintain orbit", " the robot can take go to two tangential points on the nex call", " based on which one is closer to the final destination", " comparing the magnitude of vector from the two possible next positions to the final", " position, will tell the robot which way to move. The shorter magnitude is the", " shorter path on orbit. since this is resolved every time this function is called,", " if pivot overshoots, it will rotate the other way", " get displacement to final robot position, if the robot were to move there linearly.", " This value is used to scale the tangential vector added to the collinear point to", " allow for rotation.", " always move to collinear point on orbit, plus a portion in the tangential direction", " based on how much linear displacement is left from the current and final position", " NOTE: Scaling the displacement by a half, ensures that the robot slows down more", " aggressively", " intentionally leaving out the option to coast until later"], "motion_controller": ["", "en.wikipedia.org/wiki/Bang%E2%80%93bang_control for more info", " Creates a struct which inherits all lambda function given to it and uses their", " Ts::operator(). This can be passed to std::visit to easily write multiple different", " lambdas for each type of motion controller commands below. See", " https://enreference.com/w/cpp/utility/variant/visit for more details.", " Calculate the angular difference between us and a goal", " Calculate our desired additional turn rate based on a sqrt-esque profile", " This allows us to rapidly bring the velocity to zero when we're near the", " target angle", " Cap our angular velocity at the robot's physical limit", " Figure out the maximum acceleration the robot is physically capable of", " Compute the final velocity by taking the minimum of the physical max additional", " turn rate and our desired additional turn rate", " Figure out the maximum (physically possible) velocity we can add to the robot", " Calculate a unit vector from the robot to the destination", " Calculate the vector of our velocity perpendicular to the vector toward the", " destination", " Use the \"remaining\" velocity (based on physical limits) to move us along the vector", " towards the destination", " The resulting additional velocity to apply to the robot is the velocity required to", " counteract our movement perpendicular to the vector towards the destination, with", " the \"remaining\" velocity pushing us along the vector to the destination", " Clamp the new robot velocity to the minimum of the physical maximum velocity and", " a square root-esque function of the distance to the destination. This allows us to", " bring the robot velocity to zero as we approach the destination", " https://github.com/UBC-Thunderbots/Software/issues/270", " Check for the case where we are moving away from the target AND the additional", " velocity is greater in magnitude than the current velocity, as the above", " function will increase in magnitude as the distance to the destination increases", " Translate velocities into robot coordinates"], "motion_controller_test": [" GrSim motion controller test file.", " Functional unit tests for the controller are located here.", " set up test class to keep deterministic time", " An arbitrary fixed point in time", " We use this fixed point in time to make the tests deterministic.", " We use a custom MAX_ANGULAR_SPEED value because if this value is too high, the", " controller will always try decelerate because it thinks it will overshoot its", " orientation target at the current velocity. Using a lower value lets us actually", " hit the maximum and test that case", " Expect getting robot velocities to throw", " We use a lower MAX_ANGULAR_SPEED threshold here so it's easier to check the final", " value (since it will just hit the maximum)", " expect -4 because of angular speed cap", " We use a lower MAX_ANGULAR_SPEED threshold here so it's easier to check the final", " value (since it will just hit the maximum)", " expect 4 because of angular speed cap", " basic sanity test to make sure we don't continue accelerating in the wrong", " direction when we accelerate slightly in the opposite direction of the destination", " https://github.com/UBC-Thunderbots/Software/issues/270", " we need to test the case that we have a small velocity away from the destination", " while we are trying to accelerate toward the destination", " if the destination is on the +x side of the robot, the velocity should always have", " x > 0", " same as above, test with a large initial velocity this time", " if the destination is on the +x side of the robot, the velocity should always have", " x > 0"], "simulator_ball": [" TODO: Make sure all objects de-allocated properly", " See issue https://github.com/UBC-Thunderbots/Software/issues/1128", " TODO: implement me", " TODO: implement me", " TODO: implement me", " TODO: implement me"], "simulator_robot_test": [" This is a temporary tests to validate that the SimulatorRobotSingleton works as", " expected when binding and switching robots behind the scenes. It will be replaced with", " a better test once its functions are implemented properly"], "simulator_robot": [" TODO: Make sure all objects de-allocated properly", " See issue https://github.com/UBC-Thunderbots/Software/issues/1128", " Temporary implementation for testing", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " Return a somewhat arbitrary \"room temperature\" temperature.", " This is an ideal simulation so the dribbler will not overheat", " Do nothing", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me", " TODO: Implement me"], "physics_simulator_test": [" very small step", " medium step", " small step"], "box2d_util": [" Box2D already asserts that Polygons are not degenerate (have < 3 vertices) when", " they are created, so we do not need to check for that here.", " Using the shoelace formula / algorithm from", " https://www.geeksforgeeks.org/area-of-a-polygon-with-given-n-ordered-vertices/", " This requires that the vertices are given in order, either clockwise or", " counter-clockwise."], "physics_ball": [" All the BodyDef must be defined before the body is created.", " Changes made after aren't reflected", " The ball can potentially move relatively quickly, so treating it as a \"bullet\"", " helps prevent tunneling and other collision problems", " See the \"Breakdown of a collision\" section of:", " https://www.iforce2d.net/b2dtut/collision-anatomy", " Calculate the density the fixture / ball must have in order for it to have the", " desired mass. The density is uniform across the shape.", " These restitution and friction values are somewhat arbitrary. Because this is an", " \"ideal\" simulation, we can approximate the ball as having perfectly elastic", " collisions and no friction. Because we also do not generally depend on specific", " behaviour when the ball collides with something, getting these values to perfectly", " match reality isn't too important.", " Examples for removing bodies safely from", " https://www.iforce2d.net/b2dtut/removing-bodies"], "physics_field": [" createFieldBody must be called before the setup functions, so that the b2Body is", " instantiated before fixtures are added to it.", " Examples for removing bodies safely from", " https://www.iforce2d.net/b2dtut/removing-bodies", " All the BodyDef must be defined before the body is created.", " Changes made after aren't reflected", " Note that the body shape is defined relative to the body position. Setting the", " body position to (0, 0) makes it easy to add the shape using the standard field", " interface, since field coordinates are also relative to (0, 0)", " https://www.iforce2d.net/b2dtut/fixtures", " Collisions with the field boundary are perfectly elastic and have", " no friction", " Collisions with the enemy goal are perfectly elastic and have no friction", " Collisions with the friendly goal are perfectly elastic and have no friction"], "physics_robot_test": [" Once we leave the above scope the robot is destroyed, so it should have been", " removed from the world", " Roll the ball along the left side of the robot just outside of the robot radius", " and check it does not collide", " The ball should pass right next to the robot without colliding, so should not", " change direction", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " Roll the ball along the left side of the robot just inside of the robot radius", " and check it does collide", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " Roll the ball along the right side of the robot just outside of the robot radius", " and check it does not collide", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " Roll the ball along the right side of the robot just inside of the robot radius", " and check it does collide", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " Roll the ball along the back side of the robot just outside of the robot radius", " and check it does not collide", " The ball should pass right next to the robot without colliding, so should not", " change direction", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " Roll the ball along the back side of the robot just inside of the robot radius", " and check it does collide", " The ball should pass right next to the robot without colliding, so should not", " change direction", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " Roll the ball along the front side of the robot just in front of the chicker", " and check it does not collide", " The ball should pass right next to the robot without colliding, so should not", " change direction", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " Roll the ball along the front side of the robot just behind the chicker", " and check it does collide", " The ball should pass right next to the robot without colliding, so should not", " change direction", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds"], "physics_field_test": [" There is only 1 body that represents the entire field", " Once we leave the above scope the field is destroyed, so it should have been", " removed from the world", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds"], "physics_ball_test": [" Once we leave the above scope the ball is destroyed, so it should have been", " removed from the world", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " Perfectly elastic collisions and no friction", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds", " Create a box angled 45 degrees so the ball is deflected downwards", " The box is slightly raised in the y-axis so the ball doesn't perfectly", " hit the corner", " Perfectly elastic collisions and no friction", " We have to take lots of small steps because a significant amount of accuracy", " is lost if we take a single step of 1 second", " 5 and 8 here are somewhat arbitrary values for the velocity and position", " iterations but are the recommended defaults from", " https://www.iforce2d.net/b2dtut/worlds"], "physics_robot": [" createRobotPhysicsBody must be called before the setup functions, so that the", " b2Body is instantiated before fixtures are added to it.", " Examples for removing bodies safely from", " https://www.iforce2d.net/b2dtut/removing-bodies", " All the BodyDef must be defined before the body is created.", " Changes made after aren't reflected", " This is a somewhat arbitrary value. Collisions with robots are not perfectly", " elastic. However because this is an \"ideal\" simulation and we generally don't care", " about the exact behaviour of collisions, getting this value to perfectly match", " reality isn't too important.", " Create a very thin rectangle where the dribbler and chicker are on the", " flat face of the robot", " We don't want this shape to contribute to the mass of the overall robot, so density", " is 0", " restitution and friction are somewhat arbitrary values. Collisions with the chicker", " are generally very damped, and friction along the dribbler is high since the", " dribbler is designed to have high friction with the ball. However because this is", " an \"ideal\" simulation and we generally don't care about the exact behaviour of the", " ball colliding or rolling along the chicker / dribbler, getting these values to", " perfectly match reality isn't too important.", " To create a polygon that approximates the shape of a robot, we find", " one of the points at the edge of the flat face at the front of the robot,", " and sweep around the back of the robot evenly distributing vertices until", " we reach the other edge of the flat face.", " Shapes are defined relative to the body they are added to, so we do everything", " relative to the centre of the robot body, which is treated as (0, 0)"], "network_client": [" Set up our connection over udp to receive vision packets", " LOG(FATAL) will terminate this process", " Set up our connection over udp to receive gamecontroller packets", " LOG(FATAL) will terminate this process", " Start the thread to run the io_service in the background", " Stop the io_service. This is safe to call from another thread.", " https://stackoverflow.com/questions/4808848/boost-asio-stopping-io-service", " This MUST be done before attempting to join the thread because otherwise the", " io_service will not stop and the thread will not join", " Join the io_service_thread so that we wait for it to exit before destructing the", " thread object. If we do not wait for the thread to finish executing, it will call", " `std::terminate` when we deallocate the thread object and kill our whole program", " We analyze the first 60 packets we receive to find the \"real\" starting time.", " The real starting time is the smaller value of the ones we receive", " We pass all packets without a detection to the logic (since they are likely", " geometry packet). Packets with detection timestamps are compared to the last", " valid timestamp to make sure they are close enough before the data is passed", " along. This ensures we ignore any of the garbage packets grsim sends that", " are thousands of seconds in the future.", " We invert the field side if we explicitly choose to override the values", " provided by refbox. The 'defending_positive_side' parameter dictates the side", " we are defending if we are overriding the value", " TODO remove as part of https://github.com/UBC-Thunderbots/Software/issues/960"], "ssl_vision_client": [" Throw this exception up to top-level, as we have no valid", " recovery action here", " Join the multicast group.", " Start listening for data asynchronously", " See here for a great explanation about asynchronous operations:", " https://stackoverflow.com/questions/34680985/what-is-the-difference-between-asynchronous-programming-and-multithreading", " Once we've handled the data, start listening again", " Start listening again to receive the next data"], "ssl_gamecontroller_client": [" Throw this exception up to top-level, as we have no valid", " recovery action here", " Join the multicast group.", " Start listening for data", " Once we've handled the data, start listening again", " Start listening again to receive the next data"], "ssl_protobuf_reader": [" We can initialize the field_state with all zeroes here because this state will never", " be accessed by an external observer to this class. the getFieldData must be called to", " get any field data which will update the state with the given protobuf data", " We can't guarantee the order that any geometry elements are passed to us in, so", " We map the name of each line/arc to the actual object so we can refer to them", " consistently", " Circular arcs", "", " Arc names:", " CenterCircle", " Field Lines", "", " Line names:", " TopTouchLine", " BottomTouchLine", " LeftGoalLine", " RightGoalLine", " HalfwayLine", " CenterLine", " LeftPenaltyStretch", " RightPenaltyStretch", " RightGoalTopLine", " RightGoalBottomLine", " RightGoalDepthLine", " LeftGoalTopLine", " LeftGoalBottomLine", " LeftGoalDepthLine", " LeftFieldLeftPenaltyStretch", " LeftFieldRightPenaltyStretch", " RightFieldLeftPenaltyStretch", " RightFieldRightPenaltyStretch", " Check that CenterCircle exists before using it", " Extract the data we care about and convert all units to meters", " Check that LeftFieldLeftPenaltyStretch exists before using it", " We arbitraily use the left side here since the left and right sides are identical", " Check that LeftPenaltyStretch exists before using it", " We arbitraily use the left side here since the left and right sides are identical", " Convert all data to meters and radians", " TODO remove Util::DynamicParameters as part of", " https://github.com/UBC-Thunderbots/Software/issues/960", " Collect all the visible robots from all camera frames", " TODO remove Util::DynamicParameters as part of", " https://github.com/UBC-Thunderbots/Software/issues/960", " SSL Referee proto messages' `Command` fields map to `RefboxGameState` data", " structures", " this maps a protobuf Referee_Command enum to its ROS message equivalent", " this map is used when we are on the blue team", " this maps a protobuf Referee_Command enum to its ROS message equivalent", " this map is used when we are on the yellow team", " this maps a protobuf Referee_Stage enum to its RefboxStage equivalent"], "robot_filter": [" add up all data points for this robot and then average it", " to get the latest timestamp of all data points in case there is no data for", " this robot id", " if there is no data the duration of expiry_buffer_duration after previously", " recorded robot state, return null. Otherwise remain the same state", " update data by returning filtered robot data", " velocity = position difference / time difference", " angular_velocity = orientation difference / time difference", " update current_robot_state"], "ball_filter_test": ["", " Initialize the time", " Use a constant seed to results are deterministic", "", "", " Check for division by 0", " Calculate how many simulation steps to take, given the ball's velocity and the", " time step in order for the ball to reach the end of the given segment.", "", " Create the distrubutions we use to generate noise when sampling the ball", " Generate the noise that will be added to the position and time step to", " simulate imperfect data", " Calculate the current time and add noise", " We make sure the applied noise doesn't cause the timestamp to be larger", " than expected on the last iteration so the ball's final position is close", " to what's expected by the caller of this function", " Take the time difference from the start time and calculate the ball's", " current position based on it's velocity and the elapsed time", " Apply noise to the ball's position to simulate measurement noise", " Create the detection that would have been seen by the vision system", " Get the filtered result given the new detection information", " Only check the velocity once we have more than 1 data entry in the filter", " since the filter can't return a realistic velocity with only a single", " detection", " Check the direction of the velocity", " Check the magnitude of the velocity", " Make sure the timestamps are always increasing", " When the ball is sitting still, the velocity could be any direction so we do", " not use a strict tolerance for this test. We only really care about the", " magnitude of the velocity to make sure it's small enough", " When the ball is sitting still, the velocity could be any direction so we do", " not use a strict tolerance for this test. We only really care about the", " magnitude of the velocity to make sure it's small enough", " test the inverse regression", " Check the lines are pointing in the same direction"], "robot_team_filter": [" Add filters for any robot we haven't seen before", " Get the filtered data for each robot from the robot filters. The robot filters", " handle robot expiry (robots disappearing after not being detected for a while),", " so we ignore any expired robots", " Using the most recent timestamp for the team, remove any robots that have not", " been detected for a while", " TODO: Mathew - The RobotFilter and Team are both handling expiry now?", " Just the filter probably should"], "ball_filter": [" Sort the detections in increasing order before processing. This places the oldest", " detections (with the smallest timestamp) at the front of the buffer, and the most", " recent detections (largest timestamp) at the end of the buffer.", " Ignore any detections that are not anywhere within the field", " Ignore any data from the past, and any data that is as old as the oldest", " data in the buffer since it provides no additional value. This also", " prevents division by 0 when calculating the estimated velocity", " We determine if the detection is noise based on how far it is from a ball", " detection in the buffer. From this, we can calculate how fast the ball", " must have moved to reach the new detection position. If this estimated", " velocity is too far above the maximum allowed velocity, then there is a", " good chance the detection is just noise and not the real ball. In this", " case, we ignore the new \"noise\" data", " Make the maximum acceptable velocity a bit larger than the strict limits", " according to the game rules to account for measurement error, and to be a", " bit on the safe side. We don't want to risk discarding real data", " If we determine the data to be noise, remove an entry from the buffer.", " This way if we have messed up and now the ball is too far away for the", " buffer to track, the buffer will rapidly shrink and start tracking the", " ball at its new location once the buffer is empty.", " We sort the vector in decreasing order first so that we can always", " ensure any elements that are ejected from the end of the buffer are the", " oldest data", " We sort the vector in decreasing order first so that we can always", " ensure any elements that are ejected from the end of the buffer are the", " oldest data", " If there is no data in the buffer, we always add the new data", " Sort the detections in increasing order before processing. This places the oldest", " detections (smallest timestamp) at the front of the buffer, and the most recent", " detections (with the largest timestamp) at the end of the buffer", " Avoid division by 0. If we have adjacent detections with the same timestamp", " the velocity cannot be calculated", " Snap the detection positions to the regression line if it was provided", " Sort the detections in decreasing order before processing. This places the most", " recent detections (with the largest timestamp) at the front of the buffer, and the", " oldest detections (smallest timestamp) at the end of the buffer", " Use the average of the min and max velocity magnitudes in the buffer. We use this", " rather than the average so we can quickly respond to drastic changes in the ball", " velocity, such as when the ball goes from being stationary to moving quickly (like", " when it's kicked). If the buffer is large, then it will take more time for the mean", " speed to increase enough to start shrinking the buffer. However, the average of the", " min and max values will immediately increase if the ball starts moving, so the", " buffer can start shrinking more quickly and increase the filter response time to", " these sorts of changes.", " Between the min and max velocity magnitudes, we linearly scale the size of the", " buffer", " Sort the detections in increasing order before processing. This places the oldest", " detections (smallest timestamp) at the front of the buffer, and the most recent", " detections (with the largest timestamp) at the end of the buffer", " Construct matrix A and vector b for linear regression. The first column of A", " contains the bias variable, and the second column contains the x coordinates of the", " ball. Vector b contains the y coordinates of the ball.", " This extra column of 1's is the bias variable, so that we can regress with a", " y-intercept", " Perform linear regression to find the line of best fit through the ball positions.", " This is solving the formula Ax = b, where x is the vector we want to solve for.", " How to calculate the error is from", " https://eigen.tuxfamily.org/dox/group__TutorialLinearAlgebra.html", " norm() is L2 norm", " Find 2 points on the regression line that we solved for, and use this to construct", " our own Line class", " Sort the detections in decreasing order before processing. This places the most", " recent detections (with the largest timestamp) at the front of the buffer, and the", " oldest detections (smallest timestamp) at the end of the buffer", " Linear regression cannot fit a vertical line. To get around this, we fit two lines,", " one with x and y swapped, so any vertical line becomes horizontal. Then we take the", " line of the two that fit the best.", " Because we swapped the coordinates of the input, we have to swap the coordinates of", " the output to get back to our expected coordinate space", " We use the regression from above with the least error", " Take the position of the most recent ball position and project it onto the line of", " best fit. We do this because we assume the ball must be travelling along its", " velocity vector, and this allows us to return more stable position values since the", " line of best fit is less likely to fluctuate compared to the raw position of a ball", " detection", " Project the velocity so it also lies along the line of best fit calculated", " above. Again, this gives more stable values because the line of best fit is", " more robust to fluctuations in ball position, so will not vary as much as using", " the \"raw\" ball velocity", " If there is only 1 entry in the buffer, we can't calculate a velocity so", " just set it to 0"], "robot_filter_test": [""], "network_filter": [" We can initialize the field_state with all zeroes here because this state will never", " be accessed by an external observer to this class. the getFieldData must be called to", " get any field data which will update the state with the given protobuf data", " We can't guarantee the order that any geometry elements are passed to us in, so", " We map the name of each line/arc to the actual object so we can refer to them", " consistently", " Circular arcs", "", " Arc names:", " CenterCircle", " Field Lines", "", " Line names:", " TopTouchLine", " BottomTouchLine", " LeftGoalLine", " RightGoalLine", " HalfwayLine", " CenterLine", " LeftPenaltyStretch", " RightPenaltyStretch", " RightGoalTopLine", " RightGoalBottomLine", " RightGoalDepthLine", " LeftGoalTopLine", " LeftGoalBottomLine", " LeftGoalDepthLine", " LeftFieldLeftPenaltyStretch", " LeftFieldRightPenaltyStretch", " RightFieldLeftPenaltyStretch", " RightFieldRightPenaltyStretch", " Extract the data we care about and convert all units to meters", " We arbitraily use the left side here since the left and right sides are identical", " We arbitraily use the left side here since the left and right sides are identical", " Convert all data to meters and radians", " TODO remove Util::DynamicParameters as part of", " https://github.com/UBC-Thunderbots/Software/issues/960", " Collect all the visible robots from all camera frames", " TODO remove Util::DynamicParameters as part of", " https://github.com/UBC-Thunderbots/Software/issues/960", " Collect all the visible robots from all camera frames", " this maps a protobuf Referee_Command enum to its ROS message equivalent", " this map is used when we are on the blue team", " this maps a protobuf Referee_Command enum to its ROS message equivalent", " this map is used when we are on the yellow team"], "polynomial_test": [" 1 + 2x + 3x^2", " 1 + 2x + 3x^2", " 1 + 2x + 3x^2", " 1 + 2x + 3x^2", " 1 + 2x + 3x^2", " 2 + 4.5x + 6x^2 + 8x^3", " 0 + 3x + 6x^2 + 9.2x^3 + 12x^4", " 2 + 4.5x + 6x^2 + 8x^3", " 0 + 3x + 6x^2 + 9.2x^3 + 12x^4", " 2 + 4.5x + 6x^2 + 8x^3", " 0 + 3x + 6x^2 + 9.2x^3 + 12x^4", " 4 + 2.3x + 1x^2 + 6x^3 + 2x^4", " 7 + 2x + 3x^2 + 8.3x^3 + 1x^4 + 5x^5", " 4 + 2.3x + 1x^2 + 6x^3 + 2x^4", " 7 + 2x + 3x^2 + 8.3x^3 + 1x^4 + 5x^5", " 4 + 2.3x + 1x^2 + 6x^3 + 2x^4", " 7 + 2x + 3x^2 + 8.3x^3 + 1x^4 + 5x^5"], "polynomial": [" Zero polynomial treated as an order zero polynomial", " Horner's Method:", " https://www.geeksforgeeks.org/horners-method-polynomial-evaluation/"], "line_test": [" -0.5x + y - 2.5 = 0", " -1.5x + y - 3 = 0", " -1.5x + y + 6 = 0", " x = 1", " -0.5x + y - 2.5 = 0"], "rectangle": [" Ensures rectangle cannot be shrunk to less than a point"], "convex_polygon": [" From:", " https://math.stackexchange.com/questions/1743995/determine-whether-a-polygon-is-convex-based-on-its-vertices", " Calculate sign flips using the next edge vector (\"next_to_curr\"),", " recording the first sign", " Find out the orientation of this pair of edges and ensure it does not differ", " from previous ones", " Final sign flips", " Concave polygons have two sign flips along each axis", " Algorithm taken from http://mathwords.com/a/area_convex_polygon.htm", "", " A = (1/2) * [(x1*y2 + x2y3 + x3y4 + ... + xny1) - (y1x2 + y2x3 + y3x4 + ... +", " ynx1)] Coordinates must be taken in counterclockwise order around the polygon,", " beginning and ending in the same point."], "polygon": [" This algorithm is from https://stackoverflow.com/a/16391873", " but does not include the bounding boxes.", "", " A quick description of the algorithm (also from the same post) is as follows:", " \"I run a semi-infinite ray horizontally (increasing x, fixed y) out from the test", " point, and count how many edges it crosses. At each crossing, the ray switches", " between inside and outside. This is called the Jordan curve theorem.\"", "", " NOTE: This algorithm will treat boundaries on the bottom-left of the polygon", " different from the boundaries on the top-right of the polygon. This small", " inconsistency does not matter for our use cases, and actually has the benefit that", " should two distinct polygons share an edge, any point along this edge will be", " located in one and only one polygon.", " add a segment between consecutive points, but wrap index", " to draw a segment from the last point to first point."], "polygon_test": [" check that all of the points are in the polygon", " check that the correct segments are in the polygon", " check that all of the points are in the polygon", " check that the correct segments are in the polygon", " Hexagon centered at origin with the following points", " top vertex", " top right vertex", " bottom right vertex", " bottom vertex", " bottom left vertex", " top left vertex", " on right edge, see NOTE on Polygon::contains", " on left edge", " the bottom left vertex of the hexagon", " Self intersecting polygon, each asterisk on the diagram is a point making up the", " polygon", " on a \"right\" edge, see NOTE on Polygon::contains", " on a \"right\" edge, see NOTE on Polygon::contains", " on a top edge, see NOTE on Polygon::contains", " on a top edge, see NOTE on Polygon::contains", " Self intersecting polygon, each asterisk on the diagram is a point making up the", " polygon", " on a \"right\" edge, see NOTE on Polygon::contains", " on a \"right\" edge, see NOTE on Polygon::contains", " on a top edge, see NOTE on Polygon::contains", " on a top edge, see NOTE on Polygon::contains", " on a \"right\" edge, see NOTE on Polygon::contains", " on a top edge, see NOTE on Polygon::contains", " on a \"top\" edge, see NOTE on Polygon::contains", " on a \"right\" edge, see NOTE on Polygon::contains", " Self intersecting polygon, each asterisk on the diagram is a point making up the", " polygon", " on a right edge, see NOTE on Polygon::contains", " inner right edge should be contained", " on a top edge, see NOTE on Polygon::contains", " inner top edge should be contained", " in the hole of the polygon, not contained", " in the hole of the polygon, not contained", " All of the below are what's known as \"white box tests\". That means these tests are", " written with knowledge of how the function is implemented, to test certain internal", " edge cases. These tests are written with the knowledge that the", " 'Polygon::contains(Point)' function uses a ray that is shot in the +x direction"], "angle_test": [" We require a slightly larger tolerance for this test to pass"], "convex_polygon_test": [" check that all of the points are in the convex polygon", " check that the correct segments are in the convex polygon", " check that all of the points are in the convex polygon", " check that the correct segments are in the polygon", " Self intersecting polygon, each asterisk on the diagram is a point making up the", " polygon", " Self intersecting polygon, each asterisk on the diagram is a point making up the", " polygon"], "distance": [" similar code", " Calculate the distance from the point to each edge"], "intersection_test": [" Ray at origin pointing upwards", " Ray up and to the right that points right", " Ray positioned at origin pointing down", " Ray positioned NW of ray1 pointing left", " Ray positioned at origin pointing up"], "intersection": ["", "en.wikipedia.org/wiki/Line%E2%80%93line_intersection#Given_two_points_on_each_line", "", " If there exists a single intersection, and it exists on the ray and within the", " segment", " If no intersection was found and the ray and segment are parallel, and collinear", " Check if ray passes through both segment start and end", " Ray origin within the segment, return the ray start position and the segment", " endpoint in the ray's direction", " The ray and segment do not intersect at all", " Lines are parallel", " Calculate if an intersection exists between line representations of the rays", " Check if the intersection exits along the direction of both rays"], "sensor_fusion": [" TODO: incorporate robot_status into world and update world", " https://github.com/UBC-Thunderbots/Software/issues/1149"], "simulated_tests_test": ["", " NOTE: All these tests use validation functions that assert various things about the", " timestamp of the world. There is no physics directly involved in these tests, they are", " as simple as possible and only test the behavior of the validation functions and", " test pipeline", " Because the EXPECT_NONFATAL_FAILURE macro only captures a single failure, we have", " to write this failing function in such a way that it will only fail once during the", " test. To do this we check the timestamp very close to the test timeout", " This test is basically the same as", " test_gtest_expect_statement_in_continuous_validation_function_causes_test_to_fail but", " exists because there was a bug with the FunctionValidator and", " ContinuousFunctionValidator that caused only the last validation_function in the", " vectors to be run, so we re-order the validation_functions in this test to catch future", " failures of this type", " Because the EXPECT_NONFATAL_FAILURE macro only captures a single failure, we have", " to write this failing function in such a way that it will only fail once during the", " test. To do this we check the timestamp very close to the test timeout"], "simulated_test_fixture": [" The world_state_observer observes the World from the backend, and then the ai", " observes the World from the WorldStateObserver. Because we know the AI will not", " run until it gets a new World, and the SimulatorBackend will not pubish another", " world until it has received primitives, we can guarantee that each step in the", " test pipeline will complete before the next. The steps are:", " 1. Simulate and publish new world", " 2. Validate World", " 3. AI makes decisions based on new world", " Overall this makes the tests deterministic because one step will not asynchronously", " run way faster than another and lose data.", " The XDG_RUNTIME_DIR environment variable must be set in order for the", " Visualizer to work properly. If it's not set, the Visualizer initialization", " will fail with an error like \"qt.qpa.screen: QXcbConnection: Could not", " connect to display\" In order for this environment variable to be set", " correctly these test targets MUST be run with 'bazel run' rather than", " 'bazel test'", " We mock empty argc and argv since we don't have access to them when running", " tests These arguments do not matter for simply running the Visualizer", " Simulate in realtime if we are using the Visualizer so we can actually see", " things at a reasonably realistic speed"], "continuous_function_validator": [" We need to provide the world and validation_function in the coroutine function", " binding so that the wrapper function has access to the correct variable context,", " otherwise the World inside the coroutine will not update properly when the", " pointer is updated, and the wrong validation_function may be run.", " Check the coroutine status to see if it has any more work to do.", " Re-start the coroutine by re-creating it", " Run the coroutine. This will call the bound executeAndCheckForFailuresWrapper", " function", " Yield the very first time the function is called, so that the validation_function", " is not run until this coroutine / wrapper function is called again by", " executeAndCheckForFailures", " Anytime after the first function call, the validation_function will be", " used to perform the real logic."], "function_validator_test": [" This validation function will only pass if the ball's x-coordinate becomes positive", " before the ball's y-coordinate becomes positive", " This shows an example of using GoogleTest statements within a validation function.", " Just like regular unit tests, if the condition is not met the test will fail.", " Unfortunately we can't have an example of a failing tests since GoogleTest doesn't", " have a way of expecting a test to fail, so we just have an example of a passing", " test."], "function_validator": [" We need to provide the world and validation_function in the coroutine function", " binding so that the wrapper function has access to the correct variable context,", " otherwise the World inside the coroutine will not update properly when the", " pointer is updated, and the wrong validation_function may be run.", " Yield the very first time the function is called, so that the validation_function", " is not run until this coroutine / wrapper function is called again by", " executeAndCheckForSuccess", " Anytime after the first function call, the validation_function will be", " used to perform the real logic.", " Check the coroutine status to see if it has any more work to do.", " Run the coroutine. This will call the bound executeAndCheckForSuccessWrapper", " function", " The validation_function is done if the coroutine evaluates to false, which means", " execution has \"dropped out\" the bottom of the function and there is no more work to", " do. If this is the case then the validation_function has passed successfully"], "world_state_validator": [" The pointer to the world that will be shared with all the function validators", " After we have validated the world state, send it to other Observers", " We update the value of the existing pointer rather than making a new pointer", " because we have shared this pointer with the function validators, and need", " the pointer to stay the same for values to be shared properly"], "continuous_function_validator_test": [" This validation_functions uses exceptions as a way for the test to observe it's", " internal state", " Check one more time without updating the world", " This validation_functions uses exceptions as a way for the test to observe it's", " internal state The exception will not be reached until the 3rd function call"], "test_util_test": [" Check that the field has the correct dimensions for a", " SSL Division B field according to the rules", " only way to test this getAllRefboxGameStates() without a literal copy-paste", " of the implementation", " note that this array does not contain RefboxGameState::REFBOX_GAME_STATE_COUNT,", " this is intentional"], "test_util": [" Using the dimensions of a standard Division B SSL field", " namespace Test"], "threaded_observer_test": [" The value should have been updated by the thread running", " in the ThreadedObserver", " Because the destructor has to manage the internal thread to make sure it", " finishes, this test ensures that it actually can succeed"], "observer_test": [" Create a seperate thread to grab the value for us", " Send the value over", " Wait for the thread to successfully get the value"], "thread_safe_buffer_test": [" This \"popLeastRecentlyAddedValue\" call should block until something is \"pushed\"", " Wait for the popLeastRecentlyAddedValue to complete", " This \"popLeastRecentlyAddedValue\" call should block until something is \"pushed\"", " Wait for the popMostRecentlyAddedValue to complete", " We should have overwritten the least recently added value"], "generic_factory_test": [" Create and register two test generics with the factory here", " Make sure we get the names we are expecting"]}, "code_comments_python": {"constants": ["######################################################################", "                              Constants                              #", "######################################################################", " the weird espace charecters at the front change the color to red when ", " printed in a terminal, the espace charecter at the end clears and resets", " back to the original color. More info can be found here:", " https://stackoverflow.com/questions/287871/print-in-terminal-with-colors", " the working directory is set to the current folder in CMakeLists", "######################################################################", "                              Parameter                              #", "######################################################################", "######################################################################", "                               Config                                #", "######################################################################", "pragma once"], "generate_parameters_v2": ["!/usr/bin/env python", "######################################################################", "                              Load Yaml                              #", "######################################################################", " parse yaml and create parameter dictionaries", "######################################################################", "                              Parameter                              #", "######################################################################", " python stores booleans as True and False, but we need them to be", " lowercase for c++", " min max will only be in a parameter if it is of type int", " or float, the rest of the parameters will be nullopt", " NOTE: we either have both min/max or no bounds at all", " load both min and max", " any parameter can provide options, which is a list of valid", " values the parameter can take", " the type of the parameter", " the variable name", " we need to add additional quotes around the value if it is a string", " so the quotes are formatted here", " the parameter name (different from variable name)", " min and max", " the parameter takes in a vector of options", " which is generated here", " the default value of the parameter", "######################################################################", "                            CPP Generator                            #", "######################################################################", " stores all the configurations in a \"flat\" structure", " globally to print all the classes and their", " forward declarations", " if the dictionary has type/value in the values, then it must", " be a parameter, so create one", " otherwise this config has a nested config so create that that", " add to local and global lsit", "###############", " Acquire Data #", "###############", " constructor entries: The constructor of a config class initializes", " all parameters and nested configs as well as the mutable/immutable parameterlists", " which contain a list of all parameters and configs", " mutable parameter list initialization", " immutable parameter list initialization", " public section of the config class is where all the accessors reside", " for each param and nested config", " private section of the config class", "#################", " Generate Class #", "#################", " the config name is the name of the configuration class", " the entries that will go into the constructor of the config", " class excluding the parameter_list initialization", " parameter list initialization with all the parameters and configs", " that are a part of this class, without the const pointer cast", " parameter list initialization with all the parameters and configs", " that are a part of this class, with the const pointer cast", " public members of the config class", " private members of the config class", "######################################################################", "                                MAIN                                 #", "######################################################################", " create config", " header", " forward declarations", " all the classes", " main ThunderbotsConfig class"]}}
,{"git_repo_name": "jsk_robot", "code_comments_file_names": ["camera_info_fixer", "sanity_check_of_joint_trajectory_action_server", "initialize_baxter", "xdisplay_image_topic", "sanity_check_of_head_action_server", "check_driver_boards", "warning", "safe_tilt_head", "roslaunch_depends", "imu_corrector", "boot_sound", "odom_corrector", "battery_warning", "nav_speak", "time_signal", "correct_position", "roslaunch_depends", "check_openni_node", "plane_reflect_cloud", "publish_empty_cloud", "__init__", "image_snapshot", "image_gui", "joy_controller", "image_snapshot_joy", "fullbody_action_node", "pr2_reset_motors", "battery_visualization", "battery_warning", "battery_logger", "mongodb_log", "transform_utils", "visualize_objectdetection", "visualize_move_base", "visualization_utils", "pr2_base_trajectory_action_controller_node", "pr2_base_trajectory_action_controller", "spline_test", "teleop_nao_keyboard", "play_audio_stream", "take_wakeup_pose", "play_audio_stream_node", "list_up_ros_node", "roslaunch_depends", "nao_laser", "roseus_bridge", "test", "roseus_command_sender", "marker_msg_from_indigo_to_kinetic", "setup", "joint_states_throttle_node", "message_store_singleton", "lightweight_logger_nodelet", "odometry_utils", "__init__", "IIRFilter", "OdometryOffset", "CalculateOdomInitToBaseLinkTransform", "OdometryIIRFilter", "EKFGPFOdometry", "OdometryFeedbackWrapper", "ParticleOdometry", "__init__", "transformations", "mongo_record", "base_trajectory_logger", "logger_base", "tf_logger", "object_detection_logger", "action_logger", "mongo_record", "base_trajectory_logger", "tf_logger", "periodic_replicator_client", "object_detection_logger", "action_logger", "odom_feedback_wrapper", "ConstantHeightFramePublisher", "ekf_gpf_odometry", "calculate_init_to_base_link_transform", "auto_reset_slam", "particle_odometry", "odometry_iir_filter", "SlamMapTfToOdometry", "OdometryTfManager", "ImuRootlinkCalculator", "auto_reset_heightmap", "OdometryTfBroadcaster", "odometry_offset", "OdometryIntegrator", "OdomDiffTransformPublisher", "CameraToBaseOffset", "mux_selector", "start_launch_sound", "mongod_kill_watcher", "finish_launch_sound"], "md_file_names": ["README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "show_webview", "get_show_image_folder_path", "show_app", "hide_image", "set_show_image_folder_path", "show_image", "simulator", "connect_to_wifi", "disable_autonomous_life_from_ros_service", "control_multiple_robots_in_one_pc", "README", "README", "README", "set_master_volume", "servo_off", "set_move_arms_enabled", "fade_leds", "start_grasp", "speak_action", "enable_life", "set_background_movement_enabled", "get_background_movement_enabled", "get_life", "go_pos", "reset_leds", "get_move_arms_enabled", "speak", "go_velocity", "set_language", "play_audio_file", "get_defined_pose_list", "get_master_volume", "stop_grasp", "get_language", "servo_on", "get_take_picture_folder_path", "error_vector", "set_body_pose_with_speed", "get_basic_awareness_enabled", "disable_life", "set_external_collision_protection_status", "get_external_collision_protection_status", "set_basic_awareness_enabled", "take_picture", "animated_speak", "set_take_picture_folder_path", "README", "README", "README", "README"], "md_contents": {"README": ["jsk_robot_startup/lifelog\n", "===\n", "\n", "## mongodb.launch\n", "\n", "Launch file for logging data of robots.\n", "\n", "### setup\n", "\n", "#### specify robot identifier\n", "\n", "- set param for your own robot identifier:\n", "\n", "```bash\n", "rosparam set robot/name pr1012 # pr1040, baxter, pepper, etc...\n", "```\n", "\n", "- include `launch/mongodb.launch` in your robot startup launch file.\n", "\n", "## action_logger\n", "\n", "Save action goal, result and feedback to database\n", "\n", "### Parameters\n", "\n", "* `~update_cycle` (Double, default: `1.0`)\n", "\n", "  spin rate\n", "  \n", "* `~white_list` (dict)\n", "\n", "  White list of logging action. Topics are specified with `name` or `type`\n", "  \n", "  e.g.:\n", "\n", "```yaml\n", "name:\n", "- /r_arm_controller/follow_joint_trajectory/result\n", "type:\n", "- JointTrajectoryActionGoal\n", "- JointTrajectoryActionResult\n", "- JointTrajectoryActionFeedback\n", "- PointHeadActionGoal\n", "- PointHeadActionResult\n", "```\n", "\n", "* `~black_list` (dict)\n", "\n", "  Black list of logging action. Topics are specified with `name` or `type`\n", "\n", "  see `~white_list` for example.\n", "\n", "## base_trajectory_logger\n", "\n", "Save base trajectory to database\n", "\n", "### Parameters\n", "\n", "* `~update_cycle` (Double, default: `1.0`)\n", "\n", "  spin rate\n", "\n", "* `~map_frame` (String, default: `map`)\n", "\n", "  base static tf frame\n", "  \n", "* `~robot_frame` (String, default: `base_link`)\n", "\n", "  robot base tf frame\n", "  \n", "## object_detection_logger\n", "\n", "Save object detection result to database\n", "\n", "### Parameters\n", "\n", "* `~update_cycle` (Double, default: `1.0`)\n", "\n", "  spin rate\n", "\n", "* `~map_frame` (String, default: `map`)\n", "\n", "  base static tf frame\n", "  \n", "* `~robot_frame` (String, default: `base_footprint`)\n", "\n", "  robot base tf frame\n"], "show_webview": ["## :show-webview `url` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Display the webview on the tablet and load the url.\n", "\n", "### Parameters\n", "\n", "`url`: url of the web page (str)\n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/tablet.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALTabletService::showWebview](http://doc.aldebaran.com/2-5/naoqi/core/altabletservice-api.html#ALTabletService::showWebview__ssCR)  \n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_bridge/pull/52)\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :show-webview \"http://www.jsk.t.u-tokyo.ac.jp/index-j.html\"\n", "```\n"], "get_show_image_folder_path": ["## :get-show-image-folder-path (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Get the current path of a file which you want to show on the tablet.  \n", "\n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_bridge/pull/52)\n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/tablet.launch`  \n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :get-show-image-folder-path\n", "\"/home/nao/.local/share/PackageManager/apps/img/html/\"\n", "```\n"], "show_app": ["## :show-app `app` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Start new application on tablet and shows it. The index.html file of the app should be in `/home/nao/.local/share/PackageManager/apps/<app>/html/`. 'app' is a parameter of this method.\n", "\n", "### Parameters\n", "\n", "`app`: app name (str)\n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/tablet.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALTabletService::loadApplication](http://doc.aldebaran.com/2-5/naoqi/core/altabletservice-api.html#ALTabletService::loadApplication__ssCR)  \n", "[ALTabletService::showWebview](http://doc.aldebaran.com/2-5/naoqi/core/altabletservice-api.html#altabletservice-showwebview1)  \n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_bridge/pull/52)\n", "\n", "### Sample\n", "\n", "```\n", "; create app named 'img' under /home/nao/.local/share/PackageManager/apps/img/html/\n", "send *ri* :show-app \"img\"\n", "```\n"], "hide_image": ["## :hide-image (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Hide image currently displayed. This method deletes every image, app, webview and shows Pepper's bubbles.  \n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/tablet.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALTabletService::hideImage](http://doc.aldebaran.com/2-5/naoqi/core/altabletservice-api.html?highlight=altablet#ALTabletService::hideImage)  \n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_bridge/pull/52)\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :hide-image\n", "```\n"], "set_show_image_folder_path": ["## :set-show-image-folder-path `name` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Change the path of a file which you want to show on the tablet. This method changes the part of `Folder path` in `/home/nao/.local/share/PackageManager/apps/<Folder path>/html/`.  \n", "\n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_bridge/pull/52)\n", "\n", "### Parameters\n", "\n", "`name`: directory name (str, default is `img`)  \n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/tablet.launch`  \n", "\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :set-show-image-folder-path \"aaa/bbb\"\n", "#<naoqi_bridge_msgs::setfolderpathresponse #X9b1c660>\n", "\n", "; put 'test.jpg' under /home/nao/.local/share/PackageManager/apps/aaa/bbb/html/\n", "; (send *ri* :get-show-image-folder-path) will return \"/home/nao/.local/share/PackageManager/apps/aaa/bbb/html/\"\n", "\n", "send *ri* :show-image \"test.jpg\"\n", "```\n"], "show_image": ["## :show-image `file` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Show an image on the tablet, using the cache. The image should be under `/home/nao/.local/share/PackageManager/apps/<Folder path>/html/` inside a robot.  \n", "(Default is \"/home/nao/.local/share/PackageManager/apps/img/html/\")  You can change 'Folder path' by using `:set-show-image-folder-path name`.\n", "\n", "### Parameters\n", "\n", "`file`: file name (str)\n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/tablet.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALTabletService::showImage](http://doc.aldebaran.com/2-5/naoqi/core/altabletservice-api.html#ALTabletService::showImage__ssCR)  \n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_bridge/pull/52)\n", "\n", "### Sample\n", "\n", "```\n", "; put 'test.jpg' under /home/nao/.local/share/PackageManager/apps/img/html/\n", "send *ri* :show-image \"test.jpg\"\n", "\n", "; The ip of the robot from the tablet is 198.18.0.1, and this parent service actually calls ALTabletService::showImage(\"http://198.18.0.1/img/test.jpg\").\n", "```\n"], "simulator": ["# How to controll NAO/ Pepper with a gazebo simulator + roseus?\n", "\n", "## NAO\n", "\n", "For environment setup, please refer to [here](https://github.com/ros-naoqi/nao_virtual/tree/master/nao_gazebo_plugin).  \n", "```\n", "roslaunch nao_gazebo_plugin nao_gazebo_plugin_H25.launch\n", "roseus nao-interface.l\n", "(nao-init)\n", "```\n", "\n", "## Pepper\n", "\n", "For environment setup, please refer to [here](https://github.com/ros-naoqi/pepper_virtual/tree/master/pepper_gazebo_plugin).  \n", "```\n", "roslaunch pepper_gazebo_plugin pepper_gazebo_plugin_Y20.launch\n", "roseus pepper-interface.l\n", "(pepper-init) \n", "```\n", "## How to move the joint angle of robots?\n", "\n", "Same as when we controll real robots.\n", "\n", "```\n", "(send *pepper* :head :neck-p :joint-angle 10)\n", "(send *ri* :angle-vector (send *pepper* :angle-vector))\n", "```\n", "[Joints of NAO](https://github.com/jsk-ros-pkg/jsk_robot/blob/master/jsk_naoqi_robot/naoeus/README#joints-of-nao)\n", "[Joints of Pepper](https://github.com/jsk-ros-pkg/jsk_robot/blob/master/jsk_naoqi_robot/peppereus/README#joints-of-pepper)\n", "\n", "## Current issues\n", "\n", "[Pepper in falling down & go-velocity](https://github.com/ros-naoqi/pepper_robot/pull/31)  \n", "[go-pos](https://github.com/jsk-ros-pkg/jsk_robot/pull/685)"], "connect_to_wifi": ["# Connect a robot to wifi\n", "\n", "## Introduction\n", "\n", "In order to use a real robot, you have to connect your robot and your PC to same network.\n", "\n", "You can choose wired / wireless network.  \n", "\n", "## How to know IP address of a robot?\n", "\n", "A robot speaks IP address when you push a chest button once.  \n", "\n", "![NAO's chest button](img/NAO_button.jpg)\n", "![Pepper's chest button](img/Pepper_button.jpg)\n", "\n", "If a robot says no network is connected, you have to connect a robot to wired LAN first.  \n", "\n", "## How to connect a robot to wired LAN?\n", "\n", "NAO's port is located in back of NAO's head.  \n", "\n", "![NAO's wired LAN port](img/NAO_lan.jpg)\n", "\n", "Pepper's port is also located in back of Pepper's head.  \n", "You have to take off Pepper's head cover with a special key.  \n", "\n", "1. The special key is located in here. Please remove this cover.  \n", "\n", "![Location of a special key](img/Pepper_lan1.jpg)\n", "\n", "2. Insert this key into two holes in Pepper's head. Then, you can remove head cover.\n", "\n", "![How to use a key](img/Pepper_lan2.jpg)\n", "\n", "3. You can see Pepper's port. \n", "\n", "![Pepper's wired LAN port](img/Pepper_lan3.jpg)\n", "\n", "After connecting a wired LAN cable, please push a chest button once. A robot will speak IP address.  \n", "\n", "## How to connect a robot to wireless LAN?\n", "\n", "After connecting your robot to wired network, you have to access to a robot web page.  \n", "\n", "For further details, please refer to [here (for NAO)](http://doc.aldebaran.com/2-4/nao/webpage.html#access-webpage-nao), [here (for Pepper)](http://doc.aldebaran.com/2-4/family/pepper_user_guide/webpage.html#accessing-the-pepper-web-page).  \n", "\n", "Then, you will see a robot web page.  \n", "\n", "Select a button like a shape of the earth and move to Network Settings.\n", "\n", "![Network Settings](img/robot_webpage.jpg)\n", "\n", "Finally, you can connect your robot to wireless network.  \n", "\n", "For further details, please refer to [here](http://doc.aldebaran.com/2-4/nao/nao-connecting.html#standard-wifi-connection).  \n", "\n", "## (Pepper Only) How to access to a robot web page via Pepper's tablet?\n", "\n", "First of all, please touch Pepper's tablet and select \"Setting\".  \n", "\n", "![Tablet top page](img/Pepper_tablet1.jpg)\n", "\n", "Then, Pepper starts loading setting.  \n", "\n", "![Setting is loaded](img/Pepper_tablet2.jpg)\n", "\n", "Select a button like a shape of the earth. Other steps are same as above.  \n", "\n", "![Network Setting](img/Pepper_tablet3.jpg)\n", "\n", "After finishing setting network, please exit this page. That is because Pepper keeps taking same pose like this picture.  \n", "\n", "![Pepper keeps some pose unless you exit setting](img/Pepper_tablet6.jpg)\n", "\n", "![How to exit (1)](img/Pepper_tablet4.jpg)\n", "\n", "![How to exit (2)](img/Pepper_tablet5.jpg)"], "disable_autonomous_life_from_ros_service": ["# Disable AutonomousLife from ROS service\n", "\n", "## NAO\n", "\n", "Please execute this after you [launch jsk_nao_startup.launch](https://github.com/jsk-ros-pkg/jsk_robot/tree/master/jsk_naoqi_robot/jsk_nao_startup#running-startup-program).\n", "\n", "`rosservice call /nao_robot/pose/life/disable`\n", "\n", "## Pepper\n", "\n", "Please execute this after you [launch jsk_pepper_startup.launch](https://github.com/jsk-ros-pkg/jsk_robot/tree/master/jsk_naoqi_robot/jsk_pepper_startup#running-startup-program).\n", "\n", "`rosservice call /pepper_robot/pose/life/disable`\n", "\n", "Or please push a gear mark button of NAOqi dashboard and select `Disable Life`.\n", "\n"], "control_multiple_robots_in_one_pc": ["# Control multiple robots in one PC\n", "\n", "## When is this feature useful?\n", "\n", "When creating one *ri* instance in one file, and communicate with each other using topics. Currently, we can't create multiple *ri* instances in one file. \n", "\n", "## Requirements\n", "\n", "Please use following packages from source:\n", "- jsk_pepper_startup (master branch)\n", "- naoqi_driver [(kochigami-develop branch)](https://github.com/kochigami/naoqi_driver/tree/kochigami-develop)\n", "\n", "[Especially, related change is stored in this branch](https://github.com/kochigami/naoqi_driver/tree/add-group-name-to-subscribe-topic-name)  \n", "\n", "([allow group-name for subscribing topics](https://github.com/kochigami/naoqi_driver/commit/b752dd8c0559987f77f597d4a0f94894db686000#diff-25d902c24283ab8cfbac54dfa101ad31) + [enable to change the name of boot_config.json](https://github.com/kochigami/naoqi_driver/commit/923310e0520943588cc5bcccaeaea413f1016581#diff-25d902c24283ab8cfbac54dfa101ad31))\n", "\n", "```\n", "cd catkin_ws/src\n", "wstool set naoqi_driver --git http://github.com/ros-naoqi/naoqi_driver\n", "wstool update\n", "cd naoqi_driver\n", "git remote add kochigami https://github.com/kochigami/naoqi_driver.git\n", "git fetch kochigami\n", "git checkout -b kochigami-develop kochigami/kochigami-develop\n", "\n", "catkin build -c\n", "```\n", "\n", "## Sample1 (How topics are covered with group name)\n", "\n", "```\n", "roscore\n", "roseus nao-interface.l ; roseus pepper-interface.l\n", "; \"robot1\" is a group name\n", "nao-init t \"robot1\" ; pepper-init t \"robot1\"\n", "```\n", "\n", "NAO\n", "\n", "```\n", "/dummy_state\n", "/joint_states\n", "/nao_dcm/LeftHand_controller/command\n", "/nao_dcm/RightHand_controller/command\n", "/robot1/animated_speech\n", "/robot1/cmd_vel\n", "/robot1/move_base_simple/goal\n", "/robot1/nao_robot/pose/joint_angles\n", "/robot1/nao_robot/pose/joint_stiffness_trajectory/cancel\n", "/robot1/nao_robot/pose/joint_stiffness_trajectory/feedback\n", "/robot1/nao_robot/pose/joint_stiffness_trajectory/goal\n", "/robot1/nao_robot/pose/joint_stiffness_trajectory/result\n", "/robot1/nao_robot/pose/joint_stiffness_trajectory/status\n", "/robot1/nao_robot/pose/joint_trajectory/cancel\n", "/robot1/nao_robot/pose/joint_trajectory/feedback\n", "/robot1/nao_robot/pose/joint_trajectory/goal\n", "/robot1/nao_robot/pose/joint_trajectory/result\n", "/robot1/nao_robot/pose/joint_trajectory/status\n", "/robot1/speech\n", "/robot_interface_marker_array\n", "/rosout\n", "/rosout_agg\n", "/tf\n", "/tf_static\n", "```\n", "\n", "Pepper\n", "\n", "```\n", "rostopic list\n", "/dummy_state\n", "/joint_states\n", "/pepper_dcm/LeftHand_controller/command\n", "/pepper_dcm/RightHand_controller/command\n", "/robot1/animated_speech\n", "/robot1/cmd_vel\n", "/robot1/move_base_simple/goal\n", "/robot1/pepper_robot/pose/joint_angles\n", "/robot1/pepper_robot/pose/joint_stiffness_trajectory/cancel\n", "/robot1/pepper_robot/pose/joint_stiffness_trajectory/feedback\n", "/robot1/pepper_robot/pose/joint_stiffness_trajectory/goal\n", "/robot1/pepper_robot/pose/joint_stiffness_trajectory/result\n", "/robot1/pepper_robot/pose/joint_stiffness_trajectory/status\n", "/robot1/pepper_robot/pose/joint_trajectory/cancel\n", "/robot1/pepper_robot/pose/joint_trajectory/feedback\n", "/robot1/pepper_robot/pose/joint_trajectory/goal\n", "/robot1/pepper_robot/pose/joint_trajectory/result\n", "/robot1/pepper_robot/pose/joint_trajectory/status\n", "/robot1/speech\n", "/robot_interface_marker_array\n", "/rosout\n", "/rosout_agg\n", "/tf\n", "/tf_static\n", "```\n", "\n", "### Note\n", "\n", "Topics which are used in `robot-interface` are not covered with group name.\n", "\n", "For example, `/joint_states`, `/tf`, `/tf_static`, `/dummy_state`, `/robot_interface_marker_array`.  \n", "\n", "[related issue](https://github.com/jsk-ros-pkg/jsk_robot/issues/1012)\n", "\n", "\n", "## Sample2 (Two robots speak respectively in one PC)\n", "\n", "Robot1: Pepper, Robot2: NAO  \n", "Confirmed with Ubuntu 16.04, ROS kinetic, NAO 2.4.3, Pepper 2.5.5.5\n", "\n", "- Put `boot_config.json` with new name under `naoqi_driver/share` as much as the number of robots you want to control. Change `group_name` of `subscribers` group. See examples of [json file1](https://github.com/jsk-ros-pkg/jsk_robot/blob/master/jsk_naoqi_robot/sample/control_multiple_robots/boot_config1.json) and [json file2](https://github.com/jsk-ros-pkg/jsk_robot/blob/master/jsk_naoqi_robot/sample/control_multiple_robots/boot_config2.json).\n", "\n", "- Set value of `boot_config_file_name` and `nao_ip` (ex. NAO_IP -> NAO_IP1) like [launch file1](https://github.com/jsk-ros-pkg/jsk_robot/blob/master/jsk_naoqi_robot/sample/control_multiple_robots/sample1.launch) and [launch file2](https://github.com/jsk-ros-pkg/jsk_robot/blob/master/jsk_naoqi_robot/sample/control_multiple_robots/sample2.launch). \n", "\n", "```\n", "roslaunch sample1.launch network_interface:=<network>\n", "roseus sample1.l\n", "; Pepper subscribes `/robot1/speech` and speak\n", "```\n", "\n", "```\n", "roslaunch sample2.launch network_interface:=<network>\n", "roseus sample2.l\n", "; NAO subscribes `/robot2/speech` and speak\n", "```\n", "\n", "- Pepper will say \"hello NAO\" and NAO will say \"Hello Pepper\" respectively in one PC\n"], "set_master_volume": ["## :set-master-volume `volume` (naoqi_driver [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Sets the overall output volume of the system.  \n", "\n", "### Parameters\n", "\n", "`volume`: volume (int 0-100)\n", "\n", "### Location\n", "\n", "`launch/naoqi_driver.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALAudioDeviceProxy::setOutputVolume](http://doc.aldebaran.com/2-5/naoqi/audio/alaudiodevice-api.html#alaudiodevice-api)  \n", "\n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_driver/pull/110) and [here](https://github.com/jsk-ros-pkg/jsk_robot/pull/814).  \n", "Related commit is [here](https://github.com/kochigami/naoqi_driver/commit/9839964110eb25ba316213b65908715863e8ca94#diff-fd6c3751bab04f0ce69992cda4034458R974).\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :set-master-volume 30 ; set master volume as 30 (0~100)\n", "```\n"], "servo_off": ["## :servo-off (naoqi_bridge [`master`])\n", "\n", "### What is this?\n", "\n", "A robot sets motor off and takes a reset pose.  \n", "\n", "### Location\n", "\n", "`naoqi_pose/launch/pose_manager.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALMotionProxy::rest](http://doc.aldebaran.com/2-5/naoqi/motion/control-stiffness-api.html#ALMotionProxy::rest)\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :servo-off\n", "```\n"], "set_move_arms_enabled": ["## :set-move-arms-enabled `status` `&optional (arm :arms)` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Enable shaking arms movement while moving\n", "\n", "### Parameters\n", "\n", "`status`: t/ nil (bool)  \n", "`arm` (optional): `:rarm`, `:larm`, `:arms` (default: `:arms`)   \n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/locomotion_control.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALMotion::setMoveArmsEnabled](http://doc.aldebaran.com/2-5/naoqi/motion/control-walk-api.html#ALMotionProxy::setMoveArmsEnabled__bCR.bCR)  \n", "\n", "Related commit is [here](https://github.com/kochigami/naoqi_bridge/commit/5d36e3d1a7e13095d62831ca4568f44a43f7bc37#diff-e9b6c21fdccdb01cff79b583fc7ad7d2)\n", "\n", "### Sample\n", "\n", "```\n", "; move arms while moving\n", "send *ri* :set-move-arms-enabled t\n", "\n", "; do not move right arm while moving\n", "send *ri* :set-move-arms-enabled nil :rarm\n", "```\n"], "fade_leds": ["## :fade-leds `led_name` `r` `g` `b` `sec` (naoqi_driver [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Sets the color of an RGB led using RGB color code.  \n", "\n", "### Parameters\n", "\n", "`led_name`: name of the RGB LED or Group. (string, please refer to [here](http://doc.aldebaran.com/2-5/naoqi/sensors/alleds.html#groups-short-names-and-names).)  \n", "`r`: intensity of red channel (float 0-1)  \n", "`g`: intensity of green channel (float 0-1)  \n", "`b`: intensity of blue channel (float 0-1)  \n", "`d`: time used to fade in seconds (int/ float)  \n", "\n", "### Location\n", "\n", "`launch/naoqi_driver.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALLeds::fadeRGB with RGB color code](http://doc.aldebaran.com/2-5/naoqi/sensors/alleds-api.html#alleds-api)  \n", "\n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_driver/pull/100) and [here](https://github.com/jsk-ros-pkg/jsk_robot/pull/999)\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :fade-leds \"FaceLeds\" 0.5 0.5 0 1 ;; Robot's eyes become yellow in a 1 sec.\n", "```"], "start_grasp": ["## :start-grasp `&optional (angle-ratio 0.0) (arm :arms)` (naoqi_bridge [`master`])\n", "\n", "### What is this?\n", "\n", "Start grasping.\n", "\n", "### Parameters\n", "\n", "`angle-ratio`: ratio of grasping (float, 0.5-1.0 (default 0.0))  \n", "`arm`: grasping arm type (str, `:larm`, `:rarm`, `:arms` (default `:arms`))  \n", "\n", "### Location\n", "\n", "`naoqi_pose/launch/pose_manager.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALMotion:setAngles](http://doc.aldebaran.com/2-5/naoqi/motion/control-joint-api.html#ALMotionProxy::setAngles__AL::ALValueCR.AL::ALValueCR.floatCR)  \n", "\n", "### Sample\n", "\n", "```\n", "; angle-ratio: 0.0, arms: :arms\n", "send *ri* :start-grasp\n", "\n", "; angle-ratio: 0.3, arms: :rarm\n", "send *ri* :start-grasp 0.3 :rarm\n", "```\n"], "speak_action": ["## :speak-action `str` `&optional (wait 60)` (naoqi_driver [`master`] and naoqi_apps [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "This is a speak action. It waits and returns `t` after speaking a sentence finishes.\n", "\n", "This method uses [ALTextToSpeech/Status](http://doc.aldebaran.com/2-5/naoqi/audio/altexttospeech-api.html#ALTextToSpeech/Status) to know when speaking a sentence finishes. This is defined in naoqi_apps/speech.launch [`kochigami-develop`].  \n", "\n", "The figure below is a flow of this method.\n", "\n", "![](img/speak_action_flow.png)\n", "\n", "### Parameters\n", "\n", "`str`: speech sentence (str)\n", "\n", "`wait`: max wait time [sec] while speaking a sentence (float (default 60))\n", "\n", "### Location\n", "\n", "`naoqi_driver/launch/naoqi_driver.launch`\n", "\n", "`naoqi_apps/launch/speech.launch`\n", "\n", "### NAOqi API\n", "\n", "[ALTextToSpeechProxy::say](http://doc.aldebaran.com/2-5/naoqi/audio/altexttospeech-api.html#ALTextToSpeechProxy::say__ssCR)\n", "\n", "[ALTextToSpeech/Status](http://doc.aldebaran.com/2-5/naoqi/audio/altexttospeech-api.html#ALTextToSpeech/Status)\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :speak-action \"Hello, my name is Hop. Nice to meet you. I like Sukiyaki. How about you?\"\n", "[ INFO] [1547277401.665943347]: subscribing speech_status\n", "[ INFO] [1547277402.165140869]: subscribing speech_status\n", "[ INFO] [1547277402.665047236]: subscribing speech_status\n", "[ INFO] [1547277403.165137494]: subscribing speech_status\n", "[ INFO] [1547277403.665055341]: subscribing speech_status\n", "[ INFO] [1547277404.165135809]: subscribing speech_status\n", "[ INFO] [1547277404.665330840]: subscribing speech_status\n", "[ INFO] [1547277405.165178278]: subscribing speech_status\n", "[ INFO] [1547277405.665018189]: subscribing speech_status\n", "[ INFO] [1547277406.165078145]: subscribing speech_status\n", "[ INFO] [1547277406.664587612]: subscribing speech_status\n", "[ INFO] [1547277407.165133282]: subscribing speech_status\n", "[ INFO] [1547277407.665196644]: subscribing speech_status\n", "t ; t returns after saying a sentence \n", "```"], "enable_life": ["## :enable-life (naoqi_bridge [`master`])\n", "\n", "### What is this?\n", "\n", "Enable AutonomousLife.  \n", "\n", "### Location\n", "\n", "`naoqi_pose/launch/pose_manager.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALAutonomousLife::setState](http://doc.aldebaran.com/2-5/naoqi/interaction/autonomouslife-api.html#ALAutonomousLifeProxy::setState__ssCR)  \n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :enable-life\n", "```\n"], "set_background_movement_enabled": ["## :set-background-movement-enabled `status` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Enable or disable the background movements. For further details on background movement, please refer to [here](http://doc.aldebaran.com/2-5/naoqi/interaction/autonomousabilities/albackgroundmovement.html#albackgroundmovement).   \n", "\n", "### Parameters\n", "\n", "`status`: t/ nil (bool)  \n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/background_movement.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALBackgroundMovement::setEnabled](http://doc.aldebaran.com/2-5/naoqi/interaction/autonomousabilities/albackgroundmovement-api.html#ALBackgroundMovementProxy::setEnabled__b)  \n", "\n", "Related commit is [here](https://github.com/ros-naoqi/naoqi_bridge/pull/82)\n", "\n", "### Sample\n", "\n", "```\n", "; enable background movement\n", "send *ri* :set-background-movement-enabled t\n", "```\n"], "get_background_movement_enabled": ["## :get-background-movement-enabled (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Return whether the background movements are enabled. For further details on background movement, please refer to [here](http://doc.aldebaran.com/2-5/naoqi/interaction/autonomousabilities/albackgroundmovement.html#albackgroundmovement).\n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/background_movement.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALBackgroundMovement::isEnabled](http://doc.aldebaran.com/2-5/naoqi/interaction/autonomousabilities/albackgroundmovement-api.html#ALBackgroundMovementProxy::isEnabled)  \n", "\n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_bridge/pull/82)\n", "\n", "### Sample\n", "\n", "```\n", "; get background movement status\n", "send *ri* :get-background-movement-enabled\n", "t\n", "```\n"], "get_life": ["## :get-life (naoqi_bridge [`master`])\n", "\n", "### What is this?\n", "\n", "Return AutonomousLife state. (\"solitary\", \"interactive\", \"safeguard\", \"disabled\")\n", "\n", "### Location\n", "\n", "`naoqi_pose/launch/pose_manager.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALAutonomousLife::getState](http://doc.aldebaran.com/2-5/naoqi/interaction/autonomouslife-api.html#ALAutonomousLifeProxy::getState)  \n", "For further details of AutonomousLife state, please refer to [here](http://doc.aldebaran.com/2-5/ref/life/state_machine_management.html#autonomouslife-states).\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :get-life\n", "\"disabled\"\n", "```\n"], "go_pos": ["## :go-pos `x` `y` `theta` (naoqi_driver [`master`])\n", "\n", "### What is this?\n", "\n", "Move to a specified distance.  \n", "\n", "### Parameters\n", "\n", "`x`: distance along the X axis [m] (int, float)  \n", "`y`: distance along the Y axis [m] (int, float)  \n", "`theta`: rotation around the Z axis [degree] (int)\n", "\n", "### Location\n", "\n", "`launch/naoqi_driver.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALMotion::moveTo](http://doc.aldebaran.com/2-5/naoqi/motion/control-walk-api.html#almotionproxy-moveto1)  \n", "\n", "### Sample\n", "\n", "```\n", "; move to x=0.1 y=0.1 and rotate 30 degree \n", "send *ri* :go-pos 0.1 0.1 30\n", "```\n"], "reset_leds": ["## :reset-leds `led_name` (naoqi_driver [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Set a LED or Group of LEDs to their default state.  \n", "\n", "### Parameters\n", "\n", "`led_name`: name of the RGB LED or Group. (string, please refer to [here](http://doc.aldebaran.com/2-5/naoqi/sensors/alleds.html#groups-short-names-and-names).)  \n", "\n", "### Location\n", "\n", "`launch/naoqi_driver.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALLedsProxy::reset](http://doc.aldebaran.com/2-5/naoqi/sensors/alleds-api.html#alleds-api)  \n", "\n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_driver/pull/100) and [here](https://github.com/jsk-ros-pkg/jsk_robot/pull/999)\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :reset-leds \"FaceLeds\" ;; Pepper's eye becomes clear\n", "```"], "get_move_arms_enabled": ["## :get-move-arms-enabled `&optional (arm :arms)` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Get the status of whether shaking arms movement is enabled while moving.  \n", "\n", "### Parameters\n", "\n", "`arm` (optional): `:rarm`, `:larm`, `:arms` (default: `:arms`)   \n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/locomotion_control.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALMotion::getMoveArmsEnabled](http://doc.aldebaran.com/2-5/naoqi/motion/control-walk-api.html#ALMotionProxy::getMoveArmsEnabled__ssCR)  \n", "\n", "Related commit is [here](https://github.com/kochigami/naoqi_bridge/commit/5d36e3d1a7e13095d62831ca4568f44a43f7bc37#diff-e9b6c21fdccdb01cff79b583fc7ad7d2)\n", "\n", "### Sample\n", "\n", "```\n", "; get the status of arms while moving\n", "send *ri* :get-move-arms-enabled\n", "t\n", "\n", "; get the status of right arm while moving\n", "send *ri* :get-move-arms-enabled :rarm\n", "nil\n", "```\n"], "speak": ["## :speak `str` (naoqi_driver [`master`])\n", "\n", "### What is this?\n", "\n", "Speak a sentence.\n", "\n", "### Parameters\n", "\n", "`str`: speech sentence (str)\n", "\n", "### Location\n", "\n", "`launch/naoqi_driver.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALTextToSpeechProxy::say](http://doc.aldebaran.com/2-5/naoqi/audio/altexttospeech-api.html#ALTextToSpeechProxy::say__ssCR)  \n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :speak \"Hello. Nice to meet you.\"\n", "```\n"], "go_velocity": ["## :go-velocity `x` `y` `d` `&optional (msec 1000)` `&key (stop t)` (naoqi_driver [`master`])\n", "\n", "### What is this?\n", "\n", "Move in a specified velocity.  \n", "\n", "### Parameters\n", "\n", "`x`: velocity along the X axis [m/s] (int, float (-1 ~ 1))  \n", "`y`: velocity along the Y axis [m/s] (int, float (-1 ~ 1))  \n", "`d`: velocity around the Z axis [rad/s] (int, float (-1 ~ 1))  \n", "`msec` (optional): how long a robot keeps moving (int, enable if `:stop t`)  \n", "`stop`(key value): determines whether a robot stops after moving for some time\n", "\n", "### Location\n", "\n", "`launch/naoqi_driver.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALMotion::move](http://doc.aldebaran.com/2-5/naoqi/motion/control-walk-api.html#almotionproxy-move1)  \n", "\n", "### Sample\n", "\n", "```\n", "; move vx=0.2 m/s, vy=0.3 m/s and rotate 0.1 rad/s \n", "send *ri* :go-velocity 0.2 0.3 0.1\n", "\n", "; move vx=0.2 m/s, vy=0.3 m/s and rotate 0.1 rad/s, a robot keeps moving forever \n", "send *ri* :go-velocity 0.2 0.3 0.1 :stop nil\n", "\n", "; move vx=0.2 m/s, vy=0.3 m/s and rotate 0.1 rad/s, a robot keeps moving for 2 sec\n", "send *ri* :go-velocity 0.2 0.3 0.1 2000\n", "```"], "set_language": ["## :set-language `language` (naoqi_driver [`master`])\n", "\n", "### What is this?\n", "\n", "Set a language which a robot speaks.  \n", "\n", "### Parameters\n", "\n", "`language`: language (str)  \n", "\n", "### Location\n", "\n", "`launch/naoqi_driver.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALTextToSpeech::setLanguage](http://doc.aldebaran.com/2-5/naoqi/audio/altexttospeech-api.html#ALTextToSpeechProxy::setLanguage__ssCR)  \n", "\n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_driver/pull/87)\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :set-language \"Japanese\" ; \"English\"\n", "```\n"], "play_audio_file": ["## :play-audio-file `file` (naoqi_driver [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Play audio file inside a robot.  \n", "\n", "### Parameters\n", "\n", "`file`: path to your audio file (str)  \n", "Please locate mp3, wav file under `/home/nao/`. Then, set a path to your audio file to `file`.  \n", "\n", "### Location\n", "\n", "`launch/naoqi_driver.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALAudioPlayer::playFile](http://doc.aldebaran.com/2-5/naoqi/audio/alaudioplayer-api.html#ALAudioPlayerProxy::playFile__ssCR)  \n", "\n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_driver/pull/109)\n", "\n", "### Sample\n", "\n", "This is an example of how to play test.mp3 file from `/home/nao/audio_file/test.mp3` path.  \n", "\n", "```\n", "; ssh nao@<robot IP> \n", "; then, create audio_file folder and put test.mp3 file\n", "; scp test.mp3  nao@<robot IP>:/home/nao/audio_file/\n", "\n", "send *ri* :play-audio-file \"/audio_file/test.mp3\"\n", "```\n"], "get_defined_pose_list": ["## :set-body-pose-with-speed (naoqi_pose [`master`])\n", "\n", "### What is this?\n", "\n", "Returns defined pose list which can be available in `:set-body-pose-with-speed` method. \n", "\n", "### Location\n", "\n", "`naoqi_pose/launch/pose_manager.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALRobotPosture::getPostureList](http://doc.aldebaran.com/2-4/naoqi/motion/alrobotposture-api.html#alrobotposture-api)\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :get-defined-pose-list\n", "\"Crouch LyingBack LyingBelly Sit SitOnChair SitRelax Stand StandInit StandZero\"\n", "```"], "get_master_volume": ["## :get-master-volume (naoqi_driver [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Gets the overall output volume of the system.  \n", "\n", "### Location\n", "\n", "`launch/naoqi_driver.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALAudioDevice::getOutputVolume](http://doc.aldebaran.com/2-5/naoqi/audio/alaudiodevice-api.html#alaudiodevice-api)\n", "\n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_driver/pull/110) and [here](https://github.com/jsk-ros-pkg/jsk_robot/pull/814).  \n", "Related commit is [here](https://github.com/kochigami/naoqi_driver/commit/9839964110eb25ba316213b65908715863e8ca94#diff-fd6c3751bab04f0ce69992cda4034458R962).\n", "\n", "### Sample\n", "\n", "```\n", "2.irteusgl$ send *ri* :get-master-volume\n", "30 ; master volume is set as 30\n", "```"], "stop_grasp": ["## :stop-grasp `&optional (angle-ratio 1.0) (arm :arms)` (naoqi_bridge [`master`])\n", "\n", "### What is this?\n", "\n", "Stop grasping.  \n", "\n", "### Parameters\n", "\n", "`angle-ratio`: ratio of grasping (float, 0.5-1.0 (default 1.0))  \n", "`arm`: grasping arm type (str, `:larm`, `:rarm`, `:arms` (default `:arms`))  \n", "\n", "### Location\n", "\n", "`naoqi_pose/launch/pose_manager.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALMotion:setAngles](http://doc.aldebaran.com/2-5/naoqi/motion/control-joint-api.html#ALMotionProxy::setAngles__AL::ALValueCR.AL::ALValueCR.floatCR)  \n", "\n", "### Sample\n", "\n", "```\n", "; angle-ratio: 1.0, arms: :arms\n", "send *ri* :stop-grasp\n", "\n", "; angle-ratio: 0.6, arms: :larm\n", "send *ri* :stop-grasp 0.6 :larm\n", "```\n"], "get_language": ["## :get-language (naoqi_driver [`master`])\n", "\n", "### What is this?\n", "\n", "Get a language which a robot speaks.  \n", "\n", "### Location\n", "\n", "`launch/naoqi_driver.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALTextToSpeech::getLanguage](http://doc.aldebaran.com/2-5/naoqi/audio/altexttospeech-api.html#ALTextToSpeechProxy::getLanguage)  \n", "\n", "Related PR is [here](https://github.com/ros-naoqi/naoqi_driver/pull/87)\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :get-language\n", "\"Japanese\"\n", "```\n"], "servo_on": ["## :servo-on (naoqi_bridge [`master`])\n", "\n", "### What is this?\n", "\n", "A robot sets motor on takes an initial pose.  \n", "\n", "### Location\n", "\n", "`naoqi_pose/launch/pose_manager.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALMotionProxy::wakeUp](http://doc.aldebaran.com/2-5/naoqi/motion/control-stiffness-api.html#ALMotionProxy::wakeUp)  \n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :servo-on\n", "```\n"], "get_take_picture_folder_path": ["## :get-take-picture-folder-path (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Gets a file path to store a photo taken by a robot by using `:take-picture`.\n", "\n", "As a default, photo will be stored in `/home/nao/.local/share/PackageManager/apps/img/html/`.\n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/photo_capture.launch`\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :get-take-picture-folder-path\n", "\n", "\"/home/nao/.local/share/PackageManager/apps/img/html/\"\n", "\n", "send *ri* :set-take-picture-folder-path \"test\"\n", "send *ri* :get-take-picture-folder-path\n", "\n", "\"/home/nao/.local/share/PackageManager/apps/test/html/\"\n", "```"], "error_vector": ["## :error-vector (naoqi_driver [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Return the difference of reference joint angle and sensored joint angle.\n", "\n", "Related PR is [here](https://github.com/kochigami/naoqi_driver/pull/6)  \n", "\n", "Related original PR (for naoqi_driver_py) is [here](https://github.com/ros-naoqi/naoqi_bridge/pull/37)  \n", "\n", "### Location\n", "\n", "`naoqi_driver/launch/naoqi_driver.launch`  \n", "`naoqi_driver/src/converters/joint_states`  \t   \n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :error-vector\n", "#f(3.201651e-07 -0.087846 9.562265e-05 -2.561321e-06 2.049057e-05 -1.707547e-06 0.527356 -0.755197 -0.439454 0.816019 1.16013 0.0 0.0 0.0 0.027345 -0.351577 -0.755204 0.0 0.0 0.0)\n", "```\n"], "set_body_pose_with_speed": ["## :set-body-pose-with-speed (naoqi_pose [`master`])\n", "\n", "### What is this?\n", "\n", "A robot takes a defined pose.  \n", "\n", "### Location\n", "\n", "`naoqi_pose/launch/pose_manager.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALRobotPosture::goToPosture](http://doc.aldebaran.com/2-4/naoqi/motion/alrobotposture-api.html#alrobotposture-api)\n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :set-body-pose-with-speed \"Stand\"\n", "```"], "get_basic_awareness_enabled": ["## :get-basic-awareness-enabled (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Return whether basic awareness is enabled. For further details on basic awareness, please refer to [here](http://doc.aldebaran.com/2-5/naoqi/interaction/autonomousabilities/albasicawareness.html#albasicawareness).\n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/basic_awareness.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALBasicAwareness::isEnabled](http://doc.aldebaran.com/2-5/naoqi/interaction/autonomousabilities/albasicawareness-api.html#ALBasicAwarenessProxy::isEnabled)    \n", "\n", "Related commits are [here](https://github.com/kochigami/naoqi_bridge/commit/f91bb1ed5598d19d5be4f6186b0710c5b69a5a3d#diff-a526e4a93ddc5f0149214c25d7f13988) and [here](https://github.com/kochigami/naoqi_bridge/commit/8344b35a79e3e465cd43ffc1457254f3b13c6ef1#diff-a526e4a93ddc5f0149214c25d7f13988).  \n", "\n", "### Sample\n", "\n", "```\n", "; get basic awareness status\n", "send *ri* :get-basic-awareness-enabled\n", "t\n", "```"], "disable_life": ["## :disable-life (naoqi_bridge [`master`])\n", "\n", "### What is this?\n", "\n", "Disable AutonomousLife.  \n", "\n", "### Location\n", "\n", "`naoqi_pose/launch/pose_manager.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALAutonomousLife::setState](http://doc.aldebaran.com/2-5/naoqi/interaction/autonomouslife-api.html#ALAutonomousLifeProxy::setState__ssCR)  \n", "\n", "### Sample\n", "\n", "```\n", "send *ri* :disable-life\n", "```\n"], "set_external_collision_protection_status": ["## :set-external-collision-protection-status `type` `status` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Enable/disable external collision protection of a robot on the given name.  \n", "\n", "### Parameters\n", "\n", "`type`: body parts type of a robot (int)  \n", "\n", "```\n", "All:  0\n", "Move: 1\n", "Arms: 2\n", "Larm: 3\n", "Rarm: 4 \n", "```\n", "\n", "`status`: t/ nil (bool)  \n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/external_collision_avoidance.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALMotion::setExternalCollisionProtectionEnabled](http://doc.aldebaran.com/2-5/naoqi/motion/reflexes-external-collision-api.html#ALMotionProxy::setExternalCollisionProtectionEnabled__ssCR.bCR)  \n", "\n", "Related commit is [here](https://github.com/kochigami/naoqi_bridge/commit/7655dea24e26df3c0c2fae3fda20b6e96111d898#diff-e9b6c21fdccdb01cff79b583fc7ad7d2)\n", "\n", "### Sample\n", "\n", "```\n", "; disable external collision protection for Move part\n", "send *ri* :set-external-collision-protection-status 1 nil\n", "```\n"], "get_external_collision_protection_status": ["## :get-external-collision-protection-status `type` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Check if the external collision protection is activated on the given name.  \n", "\n", "### Parameters\n", "\n", "`type`: body parts type of a robot (int)  \n", "\n", "```\n", "All:  0\n", "Move: 1\n", "Arms: 2\n", "Larm: 3\n", "Rarm: 4 \n", "```\n", "### Location\n", "\n", "`naoqi_apps/launch/external_collision_avoidance.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALMotion::getExternalCollisionProtectionEnabled](http://doc.aldebaran.com/2-5/naoqi/motion/reflexes-external-collision-api.html#ALMotionProxy::getExternalCollisionProtectionEnabled__ssCR)  \n", "\n", "Related commit is [here](https://github.com/kochigami/naoqi_bridge/commit/7655dea24e26df3c0c2fae3fda20b6e96111d898#diff-e9b6c21fdccdb01cff79b583fc7ad7d2)\n", "\n", "### Sample\n", "\n", "```\n", "; get status of external collision protection for Move part\n", "send *ri* :get-external-collision-protection-status 2 \n", "t\n", "```\n"], "set_basic_awareness_enabled": ["## :set-basic-awareness-enabled `status` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Enable or disable basic awareness. For further details on basic awareness, please refer to [here](http://doc.aldebaran.com/2-5/naoqi/interaction/autonomousabilities/albasicawareness.html#albasicawareness).   \n", "\n", "### Parameters\n", "\n", "`status`: t/ nil (bool)  \n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/basic_awareness.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALBasicAwareness::setEnabled](http://doc.aldebaran.com/2-5/naoqi/interaction/autonomousabilities/albasicawareness-api.html#ALBasicAwarenessProxy::setEnabled__b)  \n", "\n", "Related commits are [here](https://github.com/kochigami/naoqi_bridge/commit/f91bb1ed5598d19d5be4f6186b0710c5b69a5a3d#diff-a526e4a93ddc5f0149214c25d7f13988) and [here](https://github.com/kochigami/naoqi_bridge/commit/8344b35a79e3e465cd43ffc1457254f3b13c6ef1#diff-a526e4a93ddc5f0149214c25d7f13988).  \n", "\n", "### Sample\n", "\n", "```\n", "; enable basic awareness\n", "send *ri* :set-basic-awareness-enabled t\n", "```"], "take_picture": ["## :take-picture `file-name` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Takes one picture and store it in PC of Naoqi robot.\n", "\n", "### Parameters\n", "\n", "`file-name`: file name (str)\n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/photo_capture.launch`\n", "\n", "### NAOqi API\n", "\n", "[ALPhotoCaptureProxy::takePicture](http://doc.aldebaran.com/2-5/naoqi/vision/alphotocapture-api.html#ALPhotoCaptureProxy::takePicture__ssCR.ssCR)\n", "\n", "Related commit is [here](https://github.com/kochigami/naoqi_bridge/pull/8)\n", "\n", "### Sample\n", "\n", "```\n", "; nao.jpg is stored in `/home/nao/.local/share/PackageManager/apps/img/html/test.jpg`\n", "\n", "send *ri* :take-picture \"nao\"\n", "```"], "animated_speak": ["## :animated-speak `str` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Speak a sentence and animate it.  \n", "\n", "### Parameters\n", "\n", "`str`: speech sentence (str)\n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/animated_speech.launch`  \n", "\n", "### NAOqi API\n", "\n", "[ALAnimatedSpeech::say](http://doc.aldebaran.com/2-5/naoqi/audio/alanimatedspeech-api.html#ALAnimatedSpeechProxy::say__ssCR)  \n", "\n", "Related commit (not a PR to master) is [here](https://github.com/kochigami/naoqi_bridge/tree/add-animated-speak)\n", "\n", "### Sample\n", "\n", "```\n", "; Robot speaks the sentence with some gesture.\n", "send *ri* :animated-speak \"Hello. Nice to meet you.\"\n", "```\n"], "set_take_picture_folder_path": ["## :set-take-picture-folder-path `name` (naoqi_bridge [`kochigami-develop`])\n", "\n", "### What is this?\n", "\n", "Changes a file path which a photo taken by a robot by using `:take-picture` is stored\n", "\n", "As a default, a photo will be stored in `/home/nao/.local/share/PackageManager/apps/img/html/`.\n", "\n", "This method will change <folder name> of `/home/nao/.local/share/PackageManager/apps/<folder name>/html/`.\n", "\n", "### Parameters\n", "\n", "`name`: directory name (str, default is `img`)\n", "\n", "### Location\n", "\n", "`naoqi_apps/launch/photo_capture.launch`  \n", "\n", "### Sample\n", "\n", "```\n", "; As a default, 1.jpg will be stored in `/home/nao/.local/share/PackageManager/apps/img/html/`\n", "\n", "send *ri* :take-picture \"1\"\n", "\n", "; In this sample, 2.jpg taken by a NAOqi robot will be stored in /home/nao/.local/share/PackageManager/apps/test/html/\n", "\n", "send *ri* :set-take-picture-folder-path \"test\"\n", "send *ri* :take-picture \"2\"\n", "```\n", "\n"]}, "code_comments_c++": {"pr2_base_trajectory_action_controller_node": [" -*- mode: c++ -*-", "*******************************************************************"], "pr2_base_trajectory_action_controller": [" -*- mode: c++ -*-", "*******************************************************************", " auto_start = ", " check joint names", " send cancel to current active goal", " validate points", " stop", " set new trajectory", " for feedback msg", " calc error", " P gain: 1.0", " publish feedback", " check if goal reached", " check if new commands violates the max velocity", " publish command velocity", " function update", " first, append previous trajectory to new traecjtory", " look up table", " calc rotational align from previous trajectory", " calc spline from trajectory", " debugging", " commit new active trajectory", " namespace"], "teleop_nao_keyboard": [" Author: Kevin Watts", " get the console in raw mode", " Setting a new line, then end of file", " get the next event from the keyboard", " Walking", " Running"], "joint_states_throttle_node": [" -*- mode: C++ -*-", "*******************************************************************", " the joint is on blacklist", " the joint is not on the last message"], "message_store_singleton": [" -*- mode: C++ -*-", "*******************************************************************", " lifelog", " jsk_robot_startup"], "lightweight_logger_nodelet": [" -*- mode: C++ -*-", "*******************************************************************", " settings for database", " settings for buffering logged messages", " settings for blocking/non-blocking message insertion", " settings for diagnostics", " start logger thread", " stop logger thread", " deinit message store object", " The message store object is initialized here, since the object waits for connection", " until the connection to the server is established.", " After message store object is initialized, this thread is re-used for", " lazy document insertion.", " check interruption", " lazy document insertion", " subscriber for message_store/insert does not exists", " lifelog", " jsk_robot_startup"]}, "code_comments_python": {"camera_info_fixer": ["!/usr/bin/env python", " https://github.com/ros-perception/vision_opencv/blob/8216fb5df7eb262601f12ac4b0c9415477717514/image_geometry/src/pinhole_camera_model#L149"], "sanity_check_of_joint_trajectory_action_server": ["!/usr/bin/env python", " Modified work: Copyright (c) 2017, JSK Lab.", " Original work of Trajectory by:", " -----------------------------------------------------------------------------", " Copyright (c) 2013-2015, Rethink Robotics", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions are met:", "", " 1. Redistributions of source code must retain the above copyright notice,", "    this list of conditions and the following disclaimer.", " 2. Redistributions in binary form must reproduce the above copyright", "    notice, this list of conditions and the following disclaimer in the", "    documentation and/or other materials provided with the distribution.", " 3. Neither the name of the Rethink Robotics nor the names of its", "    contributors may be used to endorse or promote products derived from", "    this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"", " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE", " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE", " ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE", " LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR", " CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF", " SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS", " INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN", " CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)", " ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", " -----------------------------------------------------------------------------"], "initialize_baxter": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", "", " enable robot", " joint action server"], "xdisplay_image_topic": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " JSK baxter's xdisplay is 1920x1200.", " But default baxter's xdisplay is 1024x600.", " resize image", " centerize image"], "sanity_check_of_head_action_server": ["!/usr/bin/env python", " Modified work: Copyright (c) 2017, JSK Lab.", " Original work of HeadClient:", " -----------------------------------------------------------------------------", " Copyright (c) 2013-2015, Rethink Robotics", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions are met:", "", " 1. Redistributions of source code must retain the above copyright notice,", "    this list of conditions and the following disclaimer.", " 2. Redistributions in binary form must reproduce the above copyright", "    notice, this list of conditions and the following disclaimer in the", "    documentation and/or other materials provided with the distribution.", " 3. Neither the name of the Rethink Robotics nor the names of its", "    contributors may be used to endorse or promote products derived from", "    this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"", " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE", " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE", " ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE", " LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR", " CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF", " SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS", " INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN", " CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)", " ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", " -----------------------------------------------------------------------------", " Wait 10 Seconds for the head action server to start or exit"], "check_driver_boards": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " mainboard", " l_wheel", " r_wheel", " torso_lift", " head_pan", " heal_tilt", " 35,   # ?? cart_dock_mcb", " shoulder_pan", " shoulder_lift", " upperarm_roll", " elbow_flex", " forearm_roll", " wrist_flex", " wrist_roll", " 81,   # ?? mcb Base motor test stand", " 82,   # ?? mcb Base motor test stand", " charger", " gripper"], "warning": ["!/usr/bin/env python", "# http://stackoverflow.com/questions/323972/is-there-any-way-to-kill-a-thread-in-python", " \"\"\"if it returns a number greater than one, you're in trouble,", " and you should call it again with exc=NULL to revert the effect\"\"\"", " ignore error status if the error already occured in the latest 10 minites", " we can ignore \"Joystick not open.\"", "", "", "", "", "", "# warn when cmd_vel is issued while the robot is charning", " play builtin sound Boom!", "#", "#", "#", "# check if this comes from /robot_driver", " when RunStopped, ignore message from *_mcb and *_breaker", " error_status is not []", " make sure that diagnostics_speak_thread is None, when the thread is terminated", " run new thread", " store error status and time of the error in the latest 10 minites"], "safe_tilt_head": ["!/usr/bin/env python", " Copyright (c) 2017 JSK Robotics Lab.", " Copyright (c) 2015 Fetch Robotics Inc.", " Copyright (c) 2013-2014 Unbounded Robotics Inc. ", " All right reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions are met:", "", "   * Redistributions of source code must retain the above copyright", "     notice, this list of conditions and the following disclaimer.", "   * Redistributions in binary form must reproduce the above copyright", "     notice, this list of conditions and the following disclaimer in the", "     documentation and/or other materials provided with the distribution.", "   * Neither the name of Unbounded Robotics Inc. nor the names of its ", "     contributors may be used to endorse or promote products derived ", "     from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND", " ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED", " WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE", " DISCLAIMED. IN NO EVENT SHALL UNBOUNDED ROBOTICS INC. BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT", " LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA,", " OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF", " LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE", " OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF", " ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.", "", " Tilt head for navigation obstacle avoidance.", "", " Note:", " This file is originally copied from", " https://github.com/fetchrobotics/fetch_ros/blob/0.7.12/fetch_navigation/scripts/tilt_head", " and modified to integrate with safe teleoperation.", "", " pose and lock", " get the goal", " look ahead one meter", " transform to base_link", " update"], "roslaunch_depends": [" Software License Agreement (BSD License)", "", " Copyright (c) 2008, Willow Garage, Inc.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of Willow Garage, Inc. nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", " process group, include, node, and test tags from launch file", "descend group tags as they can contain node tags", " Check if an empty file is included, and skip if so.", " This will allow a default-empty <include> inside a conditional to pass", " determine package dependency for included file", " recurse", " we actually want to include the package itself if that's referenced", "if launch_file_pkg != pkg:", " https://github.com/ros/ros_comm/pull/1455", " for verbose output we print extra source information", "cannot determine package", " print out list of package dependencies", " print space-separated to be friendly to rosmake", "cannot determine package", " for catkin packages consider the run dependencies instead", " else not released packages will not appear in the dependency list", " since rospkg  does uses rosdep to decide which dependencies to return", " make sure we don't count ourselves as a dep"], "imu_corrector": ["!/usr/bin/env python"], "boot_sound": ["!/usr/bin/env python", " https://www.youtube.com/watch?v=HM-xG0qXaeA&&", " ffmpeg -i R2D2\\ all\\ Sounds\\ -\\ Star\\ Wars\\ free\\ sounds.mp4 -ss 48 -t 10 R2D2.wav", " ???", " play sound", " make sure to topic is going out", " notify ip address", " make sure to topic is going out"], "odom_corrector": ["!/usr/bin/env python"], "battery_warning": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>", " speak", " param", " Pick first 4 characters as a keyword instead of using whole sentence", " because sentence can have variables like 100%, 90%, etc."], "nav_speak": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " speak japanese by default", " speak japanese"], "time_signal": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " 130010 is tokyo. See http://weather.livedoor.com/forecast/rss/primary_area.xml", " time signal", " weather forecast"], "correct_position": ["!/usr/bin/env python"], "check_openni_node": ["!/usr/bin/env python", " 3. usbreset...", " it should be like Bus 002 Device 013: ID 045e:02ad Microsoft Corp. Xbox NUI Audio", " 1. kill nodelet manager", " 2. pkill", " 3 restarting"], "plane_reflect_cloud": ["!/usr/bin/env python"], "publish_empty_cloud": ["!/usr/bin/env python", "# Hz", " x rotation", "            x = max_range * math.cos(i*0.005)", "            y = max_range * math.sin(i*0.005) * math.cos(j * 0.005)", "            z = -1 * max_range * math.sin(i*0.005) * math.sin(j * 0.005)", " y rotation"], "__init__": ["# do nothing"], "image_snapshot": ["!/usr/bin/env python", "#", "#", " Give QObjects reasonable names", " Process standalone plugin command-line arguments", " Add argument(s) to the parser.", " Create a container widget and give it a layout", " Add a button for ....", " self._step_run_button.setStyleSheet('QPushButton {color: black}')", "go = rospy.ServiceProxy('/head_snap/snapshot', std_srvs.srv.Empty)", "go()", "go = rospy.ServiceProxy('/lhand_snap/snapshot', std_srvs.srv.Empty)", "go()", "go = rospy.ServiceProxy('/rhand_snap/snapshot', std_srvs.srv.Empty)", "go()"], "image_gui": ["!/usr/bin/env python"], "joy_controller": ["!/usr/bin/env python"], "image_snapshot_joy": ["!/usr/bin/env python"], "fullbody_action_node": ["!/usr/bin/env python", " -*- mode: python -*-", " list of JointTrajectory", " controllers", " action methods"], "pr2_reset_motors": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>", " By default, motor will be reset 3 times maximum in 5 minutes"], "battery_visualization": ["!/usr/bin/env python"], "battery_logger": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>", " if file does not exist, any file is writable there", " write index", " aggregate", " log"], "mongodb_log": ["!/usr/bin/python", "##########################################################################", "  mongodb_log - Python based ROS to MongoDB logger (multi-process)", "", "  Created: Sun Dec 05 19:45:51 2010", "  Copyright  2010-2012  Tim Niemueller [www.niemueller.de]", "             2010-2011  Carnegie Mellon University", "             2010       Intel Labs Pittsburgh", "##########################################################################", "  This program is free software; you can redistribute it and/or modify", "  it under the terms of the GNU General Public License as published by", "  the Free Software Foundation; either version 2 of the License, or", "  (at your option) any later version.", "", "  This program is distributed in the hope that it will be useful,", "  but WITHOUT ANY WARRANTY; without even the implied warranty of", "  MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the", "  GNU Library General Public License for more details.", "", "  Read the full text in the LICENSE.GPL file in the doc directory.", " make sure we aren't using floor division", " import roslib; roslib.load_manifest(PACKAGE_NAME)", " for msg_to_document", "from rviz_intel.msg import TriangleMesh", " if use_processes:", " else:", " from threading import Lock, Condition, Event", " from Queue import Queue", " def Value(t, val, lock=None):", " return val", "from rospy import Time, Duration", " print \"Creating process %s\" % self.name", " self.process = Thread(name=self.name, target=self.run)", " print \"created %s\" % self.process", " print \"started %s\" % self.process", " clear signal handlers in this child process, rospy will handle signals for us", " print \"Calling init_node with %s from process %s\" % (worker_node_name, mp.current_process())", " run the thread", " free connection", " self.mongoconn.end_request()", "print(\"SHUTDOWN %s qsize %d\" % (self.name, self.queue.qsize()))", "print(\"JOIN %s qsize %d\" % (self.name, self.queue.qsize()))", "self.queue.put((topic, data, current_time or datetime.now()))", " Anticipate Ctrl-C", "print(\"Quit W1: %s\" % self.name)", "print(self.sep + threading.current_thread().getName() + \"@\" + topic+\": \")", "pprint.pprint(doc)", " switched to use inserted_at to match message_store", " meta[\"recorded\"] = ctime or datetime.now()", "print(\"Quit W2: %s\" % self.name)", " we must make sure to clear the queue before exiting,", " or the parent thread might deadlock otherwise", "print(\"Quit W3: %s\" % self.name)", "self.str_fn = roslib.message.strify_message", "'\\033[2J\\033[;H'", " print \"existing topics %s\" % self.topics", " print \"subscribing to topics %s\" % topics", " although the collections is not strictly necessary, since MongoDB could handle", " pure topic names as collection names and we could then use mongodb[topic], we want", " to have names that go easier with the query tools, even though there is the theoretical", " possibility of name clashes (hence the check)", " the following code makes sure we run once per STATS_LOOPTIME, taking", " varying run-times and interrupted sleeps into account", "print(\"Shutdown %s\" % name)", "print(\"Size: %d  RSS: %s  Stack: %s\" % (size, rss, stack))"], "transform_utils": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>"], "visualize_objectdetection": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>"], "visualize_move_base": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>", " days"], "visualization_utils": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>", "rospy.Time.now()", "t_first.child_frame_id", " make line strip", "rospy.Time.now()", "t_first.child_frame_id"], "play_audio_stream": ["! /usr/bin/env python", " -*- coding: utf-8 -*-", " nodelist_tmp: ('/pepper_1556630474468299832\\n/rosout\\n', None)", " nodelist: '/pepper_1556630474468299832\\n/rosout\\n'", " nodelist: ['/pepper_1556630474468299832', '/rosout', '']"], "take_wakeup_pose": ["! /usr/bin/env python", " -*- coding: utf-8 -*-", " pub", " reference: https://github.com/ros-naoqi/nao_robot/blob/master/nao_apps/scripts/test_joint_angles", " Creates the SimpleActionClient, passing the type of the action", " Waits until the action server has started up and started", " listening for goals.", " Sends the goal to the action server.", " Waits for the server to finish performing the action.", " Prints out the result of executing the action", " Creates a goal to send to the action server.", " http://doc.aldebaran.com/2-5/family/pepper_technical/bodyparts_pep.html", " Creates a goal to send to the action server.", " http://doc.aldebaran.com/2-5/family/pepper_technical/bodyparts_pep.html", " check current AutonomousLife status", " set AutonomousLife disabled", " servo on", " speak", " stretch", " speak", " speak"], "play_audio_stream_node": ["! /usr/bin/env python", " -*- coding: utf-8 -*-", "!topic/ros-sig-aldebaran/M7Q3P51Akv8", " instantiate PyAudio", " open stream", " reference https://github.com/ros-naoqi/naoqi_driver/blob/master/src/event/audio#L168", " reference https://github.com/ros-naoqi/naoqi_driver/blob/master/src/event/audio#L167", " start the stream", " create audio topic subscriber", " reference: https://github.com/ros-naoqi/naoqi_bridge/blob/master/naoqi_sensors_py/src/naoqi_sensors/naoqi_microphone#L116-L117", " reference: https://github.com/ros-naoqi/naoqi_bridge/blob/master/naoqi_sensors_py/src/naoqi_sensors/naoqi_microphone#L111-L112", " stop stream", " close PyAudio"], "list_up_ros_node": ["! /usr/bin/env python", " -*- coding: utf-8 -*-", " execute timer_callback every 10 sec", " nodelist_tmp: ('/pepper_1556630474468299832\\n/rosout\\n', None)", " nodelist: '/pepper_1556630474468299832\\n/rosout\\n'", " nodelist: ['/pepper_1556630474468299832', '/rosout', '']", " If '/pepper_robot' node is killed, need to kill jsk_pepper_startup.launch by killing another required node (see https://github.com/jsk-ros-pkg/jsk_robot/issues/1077)", " play_audio_stream_node is highlighted because this node needs to take care of people's privacy", " display camera node as \"/pepper_robot/camera\" because there are a lot of camera nodes", " ignore ''"], "nao_laser": ["! /usr/bin/env python", " for measureddata", " for rangedata", " distance = []", " print \"i = \", i, \", angrate = \", angrate", " interpolation", " distance.append(laserdata[i][0])", " distance.append(laserdata[i][0])", " print \"laserdata[\", i_pre, \"][0] = \", laserdata[i_pre][0]", " print \"laserdata[\", i_pre, \"][1] = \", laserdata[i_pre][1]", " print \"cnt = \", cnt", " self.laserscan.angle_increment = (maxangle - minangle) / cnt"], "roseus_bridge": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>"], "test": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>"], "roseus_command_sender": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>"], "marker_msg_from_indigo_to_kinetic": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Detail of visualization_msgs/msg/Marker.msg of Indigo and that of Kinetic are", " a little bit different, so checksums of them are different of course.", " That means on Kinetic you cannot subscribe the topic of which type is", " visualization_msgs/Marker published on  Indigo.", " Use this script on Kinetic when you want to subscribe the topic of which type", " is visualization_msgs/MarkerArray published on Indigo.", " By executing this script, you can subscribe converted topics", " whose content is the same with visualization_msgs/MarkerArray", " published on Indigo.", " clean old topics", " subscribe topics subscribed", " unsubscribe topics unsubscribed"], "setup": ["# ! DO NOT MANUALLY INVOKE THIS setup, USE CATKIN INSTEAD", " fetch values from package.xml"], "odometry_utils": ["! /usr/bin/env python", " twist transformation", " pose calculation", " calculate current pose as integration", " angular is assumed to be global", " quaternion calculation", " normalize", " covariance calculation", " twist is assumed to be local", " trust \"completely stopping\" state", " covariance should be singular", " make matirx from covariance array", " jacobian matrix", " elements in pose and twist are assumed to be independent on global coordinates", " covariance calculation", " update covariances as array type (twist is same as before)", " tf broadcast", " mathmatical tools    ", " scipy.stats.multivariate_normal only can be used after SciPy 0.14.0", " input: x(array), mean(array), cov_inv(matrix) output: probability of x", " covariance has to be inverted to reduce calculation time", " determinant of inverse matrix is reciprocal", " tf.transformations.euler_from_quaternion is slow because the function calculates matrix inside.", " prev_euler expects previous [roll, pitch, yaw] angle list and fix ret_euler ", " cf. https://en.wikipedia.org/wiki/Conversion_between_quaternions_and_Euler_angles", " singularity check", " use tf.transformations.euler_from_quaternion only at singularity points", " zero check", " epsilon for testing whether a number is close to zero", " consider arctan/arcsin range", " TODO: This solution is not fundamental because it does not consider ununiqueness of euler angles", " roll: arctan2 is in range of [-pi, pi]"], "IIRFilter": [" Infinite Impulse Filter", " y[n] = sum(0, dim, ff[i] * x[n - i]) + sum(1, dim, fb[i] * y[n - i])", " dimensioon: dimension of filter", " cutoff_per_sampling: cutoff freq [Hz] / sampling freq [Hz]", " remove oldest value"], "OdometryOffset": ["! /usr/bin/env python", " execute rate", " tf parameters", " for filter (only used when use_twist_filter is True)", " to overwrite probability density function (only used when overwrite_pdf is True)", " init_transform is assumed to be transform of init_odom -> base_link", " tf relationships: init_odom -> source_odom -> body_link <- init_odom", " offset_odom is init_odom -> source_odom", " TODO: check timestamps of base_odom and source_odom and fix if necessary", " source_odom -> body_link", " T(init->src) * T(src->body) = T(init->body)", " base_odom -> init_odom", " use median filter to cancel spike noise of twist when use_twist_filter is true", " overwrite twist covariance when calculate_covariance flag is True", " shift twist according to error mean when moving (stopping state is trusted)", " calculate twist covariance according to standard diviation", " trust stopping state", " offset coords", " initial covariance is assumed to be constant", " only offset pose covariance", " publish", " filter_buffer has at least 1 member"], "CalculateOdomInitToBaseLinkTransform": ["! /usr/bin/env python", " execute rate", " init_transform is assumed to be transform of base_odom -> init_odom", " tf relationships: init_odom <- base_odom -> base_link", " offset_odom is init_odom -> base_link", " TODO: check timestamps of base_odom and source_odom and fix if necessary", " base_odom -> body_link", " base_odom -> init_odom", " offset is not initialized"], "OdometryIIRFilter": ["! /usr/bin/env python", " parameters", " must be larger than nyquist frequency", " tf", " pub/sub"], "EKFGPFOdometry": ["! /usr/bin/env python", " execute sampling every time topic is subscribed when this value is not larger than 0", " EKF", " update current_odom (only update pose, stamp and twist are copied from source_odom)", "# particle filter functions", " sampling poses from EKF result (current_pose_with_covariance)", " sampling", " weighting", " resampling", " estimate new pdf ", " wait next measurement", " use only important particels", " [(p0, w0), (p1, w1), ..., (pN, wN)] -> [(sorted_p0, sorted_w0), (sorted_p1, sorted_w1), ..., (sorted_pN', sorted_wN')] -> [(sorted_p0, ..., sorted_pN'), (sorted_w0, ..., sorted_wN')]", " estimate gaussian distribution for Odometry msg ", " overwrite pose pdf", " refrect source_odom informations", " diagnostics", " update prev_rpy to prevent jump of angles", " main functions", " call update() when control input is subscribed"], "OdometryFeedbackWrapper": ["! /usr/bin/env python", " This script only calculate offset caused by odometry feedback and do not consider initial offset.", " Initial offset should be calculated by OdometryOffset (source_odom is assumed to be offseted already) ", " if max_feedback_time <= 0, feedback is not occurs by time", " determined from frequency of feedback_odom", " belief of this wrapper", " check distribution accuracy", " get neaerest odom from feedback_odom referencing timestamp", " get approximate pose at feedback_odom timestamp (probably it is past) of nearest_odom", " update feedback_odom to approximate odom at current timestamp using previsous velocities", " adjust timestamp of self.feedback_odom to current self.odom", " update pose and twist according to the history", " update feedback_odom according to twist of hist", " update covariance", " integrate feedback_odom and current odom", " update self.odom according to the result of integration", " update offset", " Hnew = Hold * T -> T = Hold^-1 * Hnew", " self.odom.header.stamp is assumed to be same as self.source_odom.header.stamp", " 6d column vector", " Calculate new state by most likelihood method:", " sigma_new = (sigma_0^-1 + sigma_1^-1)^-1", " x_new = sigma_new * (sigma_0^-1 * x_0 + sigma_1^-1 * x_1)", " Less inverse form (same as above):", " sigma__new = sigma_1 - sigma_1 * (sigma_1 + sigma_2)^-1 * sigma_1", " x_new = x1 + sigma_1*(sigma_1+sigma_2)^-1*(x_2-x_1)", " cf. \"Distributed sensor fusion for object position estimation by multi-robot systems\"", " return list", " consider only pose because twist is local and copied from source_odom", " calculate pose (use odometry source)", " calculate pose covariance (do not use odometry source)", " do not use source_odom covariance in pose", " initial covariance of pose is defined as same value of source_odom"], "ParticleOdometry": ["! /usr/bin/env python", "# initialize", " init node", " instance valiables", " select valid_particle_num particles in ascending weight sequence when estimating normal distributions", " z error probability from source. z is assumed not to move largely from source odometry", " referenced only when use_imu is True", " roll error probability from imu. (referenced only when use_imu is True)", " pitch error probability from imu. (referenced only when use_imu is True)", " yaw error probability from imu. (referenced only when use_imu and use_imu_yaw are both True)", " tf", " publisher", " histogram", " subscriber", " imu is assumed to be in base_link_frame relative coords", " init_transform is assumed to be transform of init_odom -> base_link", " init", "# particle filter functions", " input: particles(list of pose), source_odom(control input)  output: list of sampled particles(pose)", " make sampeld velocity at once because multivariate_normal calculates invert matrix and it is slow", " input: particles(list of pose), min_weight(float) output: list of weights", " use uniform weights when measure_odom has not been subscribed yet", " adjust timestamp of pose in measure_odom to source_odom", " assuming dt is small and measure_odom.twist is do not change in dt", " calculate inverse matrix first to reduce computation cost", " if all([x == min_weight for x in weights]):", "     rospy.logwarn(\"[%s] likelihood is too small and all weights are limited by min_weight.\", rospy.get_name())", " normalization and each weight is assumed to be larger than 0", " consider difference from ideal z height to prevent drift", " input: list of particles, list of weights output: list of particles", " for i in range(int(self.particle_num)):", "# probability functions", " input: u(twist), u_cov(twist.covariance)  output: sampled velocity", " rvs = Random Varieties Sampling", " input: x(pose), mean(array), cov_inv(matrix), output: pdf value for x", " pdf = Probability Dencity Function", " w ~ p(z(t)|x(t))", " ~ p(x(t)|z(t))", " return scipy.stats.norm.pdf(z_error, loc = 0.0, scale = self.z_error_sigma) # scale is standard divasion", " standard pdf", " multiply 1.0 make no effects to weight", " imu is assumed to be in base_link relative and imu_rotation is base_link->particle_odom transformation", " roll_pitch_pdf = scipy.stats.norm.pdf(prt_euler[0] - imu_euler[0], loc = 0.0, scale = self.roll_error_sigma) * scipy.stats.norm.pdf(prt_euler[1] - imu_euler[1], loc = 0.0, scale = self.pitch_error_sigma)", " std pdf: Z = (X - mu) / sigma", " input: init_pose(pose), output: initial distribution of pose(list of pose)", "# top odometry calculations ", " sampling", " weighting", " resampling", " wait next measurement", " relfect source_odom information", " use only important particels", " [(p0, w0), (p1, w1), ..., (pN, wN)] -> [(sorted_p0, sorted_w0), (sorted_p1, sorted_w1), ..., (sorted_pN', sorted_wN')] -> [(sorted_p0, ..., sorted_pN'), (sorted_w0, ..., sorted_wN')]", " estimate gaussian distribution for Odometry msg ", " update prev_rpy to prevent jump of angles", " diagnostics", "# callback functions", " raise measurement flag", " cannot calculate imu_rotation", " base_link -> particle_odom", " main functions", " call update() when control input is subscribed", "# utils", " particles_lst = [self.convert_pose_to_list(prt) for prt in particles]", " mean = numpy.mean(particles_lst, axis = 0)", " cov = numpy.cov(particles_lst, rowvar = 0)", " particles_list = [numpy.array(self.convert_pose_to_list(prt)) for prt in particles]", " mean = None", " cov = None", " w2_sum = 0.0", " mean = numpy.average(particles_list, axis = 0, weights = weights)", " for prt, w in zip(particles_list, weights):", "     if cov is None:", "         cov = w * numpy.vstack(prt - mean) * (prt - mean)", "     else:", "         cov += w * numpy.vstack(prt - mean) * (prt - mean)", "     w2_sum += w ** 2", " cov = (1.0 / (1.0 - w2_sum)) * cov # unbiased covariance", " calculate weighted mean and covariance (cf. https://en.wikipedia.org/wiki/Weighted_arithmetic_mean#Weighted_sample_covariance)        ", " array of x - mean", " sum(w * (x - mean).T * (x - mean))", " unbiased covariance", " initialize", " count", " [(x_data), (y_data), ..., (yaw_data)]", " TODO: check particles", " check weights"], "transformations": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>", " NOQA  # for stamped message conversion"], "mongo_record": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: furushchev <furushchev@jsk.imi.i.u-tokyo.ac.jp>", " spawn by roslaunch", " spawn by command"], "base_trajectory_logger": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>"], "logger_base": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>"], "tf_logger": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>"], "object_detection_logger": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>", "", " Store the ObjectDetection message", ""], "action_logger": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " Author: Yuki Furuta <furushchev@jsk.imi.i.u-tokyo.ac.jp>", "", " This script stores actionlib goals, results and feedbacks by MongoDB"], "periodic_replicator_client": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " parameters", " default: 1 day", " database to be replicated", " network monitoring", " database interface", " advertise service", " first replicate persistent data without removal", " then replicate all data with removal"], "odom_feedback_wrapper": ["! /usr/bin/env python"], "ConstantHeightFramePublisher": ["! /usr/bin/env python", " license removed for brevity", " [Hz]", " [m]", " transformation: (x, y): same as parent, z: equal to height", " rotation: (x, y): same as /odom, z: same as parent ", " publish tf"], "ekf_gpf_odometry": ["! /usr/bin/env python"], "calculate_init_to_base_link_transform": ["! /usr/bin/env python"], "auto_reset_slam": ["!/usr/bin/env python", " automatically reset slam as robot put on the ground"], "particle_odometry": ["! /usr/bin/env python"], "odometry_iir_filter": ["! /usr/bin/env python"], "SlamMapTfToOdometry": ["! /usr/bin/env python", " self.base_frame = rospy.get_param(\"~base_frame\", \"BODY\")", " 10hz", " current map->base_odom transform", " base_odom -> body", " map -> base_odom", " map -> body", " calculate covariance", " use covariance of base_odom.pose and only transform it to new coords from tf", " TODO: calc covariance in correct way, but what is that ...?", " twist is local and transform same as covariance"], "OdometryTfManager": ["! /usr/bin/env python", " 10hz", " current map->base transform"], "ImuRootlinkCalculator": ["! /usr/bin/env python", " tf parameters", " wait to update odom_init frame", " gyrometer->body", " gyrometer->body", " todo: convert covariance", " publish"], "auto_reset_heightmap": ["!/usr/bin/env python", " automatically reset heightmap integration as robot put on the ground"], "OdometryTfBroadcaster": ["! /usr/bin/env python", " Make publisher for tfMessage because tf.broadcaster in python cannot receive transfomation msg list", " It seems that transformations in tfMessage needs to be sorted by timestamp"], "odometry_offset": ["! /usr/bin/env python"], "OdometryIntegrator": ["! /usr/bin/env python", " license removed for brevity", " input assumption:", " pose is described in each odom coordinate", " twist is described in base_link_frame coordinate same as ~base_link_frame param", " tf of each odom to base_link_frame is enabled", " [sec]", " check initialization", " check timestamp", " adjust timestamps of odom sources", " self.odoms.sort(cmp = lambda x, y: cmp(x.header.stamp, y.header.stamp))", " make state vector and covariance matrix for pose and twist from odometry source", " 6d column vector", " 6d column vector", " assumed to be described in each odom frame", " assumed to be described in base_link_frame", " publish integrated odometry", " Calculate new state by most likelihood method:", " sigma_new = (sigma_0^-1 + sigma_1^-1)^-1", " x_new = sigma_new * (sigma_0^-1 * x_0 + sigma_1^-1 * x_1)", " Less inverse form (same as above):", " sigma__new = sigma_1 - sigma_1 * (sigma_1 + sigma_2)^-1 * sigma_1", " x_new = x1 + sigma_1*(sigma_1+sigma_2)^-1*(x_2-x_1)", " cf. \"Distributed sensor fusion for object position estimation by multi-robot systems\"", " todo: lookup odom.header.stamp"], "OdomDiffTransformPublisher": ["! /usr/bin/env python", " license removed for brevity", " 30hz"], "CameraToBaseOffset": ["! /usr/bin/env python", " execute rate", " tf parameters", " wait to update odom_init frame", " calculate camera transform", " base_link transformation in camera coords", " calculate offseted odometry", " make odometry msg. twist is copied from source_odom", " publish", " camera -> base_link"], "mux_selector": ["!/usr/bin/env python", " setting triggers", " parse arguments", " ros node initialization", " loop"], "start_launch_sound": ["!/usr/bin/env python", " topic --> /robotsound or /robotsound_jp", " sleep to wait for connection"], "mongod_kill_watcher": ["!/usr/bin/env python", " -*- coding: utf-8 -*-", " when this node is killed, kill mongod. "], "finish_launch_sound": ["!/usr/bin/env python", " topic --> /robotsound or /robotsound_jp", " sleep to wait for connection"]}}
,{"git_repo_name": "autorally", "code_comments_file_names": ["setup", "autorally_controller", "ground_truth_republisher", "joystickControlMain", "JoystickControl", "autorally_plant", "status_monitor", "param_getter", "lap_stats", "track_generator", "track_converter", "gpsWaypoint", "ConstantSpeedController", "setup", "__init__", "chronyStatus", "RingBuffer", "Diagnostics", "ImageRepublisher", "RunStop", "ImageMaskEntry", "main_window", "main", "DiagnosticsEntry", "qnode", "SerialSensorInterface", "SerialInterfaceThreaded", "SerialCommon", "systemStatus", "__init__", "wheel_odometry", "StateEstimator", "GPSHemisphere", "CameraTrigger", "AutoRallyChassis", "CameraAutoBalancePtGrey", "CameraAutoBalanceFLIR", "FlycaptureAdjuster", "CameraAutoBalance", "SpinnakerAdjuster", "XbeeNode", "XbeeInterface", "XbeeCoordinator", "SafeSpeed", "serialSensorInterfaceTest", "diagnosticsTest", "pololuMicroMaestroTest"], "md_file_names": ["README", "LICENSE", "README", "README", "LICENSE"], "md_contents": {"README": ["This folder contains the parameters for the AutoRally dynamics models used by MPPI. All of the models take as input 4 (roll, longitudenal velocity, lateral velocity, heading rate) state variables and \n", "the commanded steering and throttle, and they output the time derivative of the state variables.\n", "\n", "## autorally_nnet_09_12_2018.npz \n", "This is a neural network with 2 hidden layers and tanh non-linearities, which means that the total configuration of the network is 6-32-32-4. This network is meant to be used by the class neural_net_model.cuh, which takes the 6-32-32-4 shape as a template parameter. Within neural_net_model.cuh, the model is loaded in by the function \"loadParams(std::string model_path)\", where model path is the path to this file. This network was trained on real world data collected at CCRF on the beta chassis. It was initially\n", "trained to minimize one-step prediction error, and then fine-tuned using back-prop through time in order to minimize multi-step prediction error. For both phases of training stochastic gradient descent with ADAM was used.\n", "\n", "## basis_function_09_12_2018.npz \n", "This model predicts the time derivative of the state as a linear combination of a set of pre-defined basis functions. The basis functions that are used are defined \n", "in the file car_bfs.cuh. This model is meant to be used by the class generalized_linear.cuh, which takes the basis functions defined by car_bfs.cuh as a template parameter. Within\n", "generalized_linear.cuh, the model is loaded in by \"loadParams(std::string model_path)\" where model_path is the path to this file.\n", "\n", "## gazebo_nnet_09_12_2018.npz \n", "This is an old neural network based on the ROS indigo 2.x version of Gazebo. It has the exact same format as autorally_nnet.npz This model should not be used except to compare with previously published results. The paper \"Robust Sampling Based Model Predictive Control with Sparse Objective Information\" presented at RSS 2018 used this model with Gazebo 2.x. Note that with Gazebo 7+ the physics are vastly improved and the model trained on real-world data performs better than this network.\n"], "LICENSE": ["Apache License\n", "Version 2.0, January 2004\n", "http://www.apache.org/licenses/\n", "\n", "TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION\n", "\n", "1. Definitions.\n", "\n", "\"License\" shall mean the terms and conditions for use, reproduction, and\n", "distribution as defined by Sections 1 through 9 of this document.\n", "\n", "\"Licensor\" shall mean the copyright owner or entity authorized by the copyright\n", "owner that is granting the License.\n", "\n", "\"Legal Entity\" shall mean the union of the acting entity and all other entities\n", "that control, are controlled by, or are under common control with that entity.\n", "For the purposes of this definition, \"control\" means (i) the power, direct or\n", "indirect, to cause the direction or management of such entity, whether by\n", "contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the\n", "outstanding shares, or (iii) beneficial ownership of such entity.\n", "\n", "\"You\" (or \"Your\") shall mean an individual or Legal Entity exercising\n", "permissions granted by this License.\n", "\n", "\"Source\" form shall mean the preferred form for making modifications, including\n", "but not limited to software source code, documentation source, and configuration\n", "files.\n", "\n", "\"Object\" form shall mean any form resulting from mechanical transformation or\n", "translation of a Source form, including but not limited to compiled object code,\n", "generated documentation, and conversions to other media types.\n", "\n", "\"Work\" shall mean the work of authorship, whether in Source or Object form, made\n", "available under the License, as indicated by a copyright notice that is included\n", "in or attached to the work (an example is provided in the Appendix below).\n", "\n", "\"Derivative Works\" shall mean any work, whether in Source or Object form, that\n", "is based on (or derived from) the Work and for which the editorial revisions,\n", "annotations, elaborations, or other modifications represent, as a whole, an\n", "original work of authorship. For the purposes of this License, Derivative Works\n", "shall not include works that remain separable from, or merely link (or bind by\n", "name) to the interfaces of, the Work and Derivative Works thereof.\n", "\n", "\"Contribution\" shall mean any work of authorship, including the original version\n", "of the Work and any modifications or additions to that Work or Derivative Works\n", "thereof, that is intentionally submitted to Licensor for inclusion in the Work\n", "by the copyright owner or by an individual or Legal Entity authorized to submit\n", "on behalf of the copyright owner. For the purposes of this definition,\n", "\"submitted\" means any form of electronic, verbal, or written communication sent\n", "to the Licensor or its representatives, including but not limited to\n", "communication on electronic mailing lists, source code control systems, and\n", "issue tracking systems that are managed by, or on behalf of, the Licensor for\n", "the purpose of discussing and improving the Work, but excluding communication\n", "that is conspicuously marked or otherwise designated in writing by the copyright\n", "owner as \"Not a Contribution.\"\n", "\n", "\"Contributor\" shall mean Licensor and any individual or Legal Entity on behalf\n", "of whom a Contribution has been received by Licensor and subsequently\n", "incorporated within the Work.\n", "\n", "2. Grant of Copyright License.\n", "\n", "Subject to the terms and conditions of this License, each Contributor hereby\n", "grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free,\n", "irrevocable copyright license to reproduce, prepare Derivative Works of,\n", "publicly display, publicly perform, sublicense, and distribute the Work and such\n", "Derivative Works in Source or Object form.\n", "\n", "3. Grant of Patent License.\n", "\n", "Subject to the terms and conditions of this License, each Contributor hereby\n", "grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free,\n", "irrevocable (except as stated in this section) patent license to make, have\n", "made, use, offer to sell, sell, import, and otherwise transfer the Work, where\n", "such license applies only to those patent claims licensable by such Contributor\n", "that are necessarily infringed by their Contribution(s) alone or by combination\n", "of their Contribution(s) with the Work to which such Contribution(s) was\n", "submitted. If You institute patent litigation against any entity (including a\n", "cross-claim or counterclaim in a lawsuit) alleging that the Work or a\n", "Contribution incorporated within the Work constitutes direct or contributory\n", "patent infringement, then any patent licenses granted to You under this License\n", "for that Work shall terminate as of the date such litigation is filed.\n", "\n", "4. Redistribution.\n", "\n", "You may reproduce and distribute copies of the Work or Derivative Works thereof\n", "in any medium, with or without modifications, and in Source or Object form,\n", "provided that You meet the following conditions:\n", "\n", "You must give any other recipients of the Work or Derivative Works a copy of\n", "this License; and\n", "You must cause any modified files to carry prominent notices stating that You\n", "changed the files; and\n", "You must retain, in the Source form of any Derivative Works that You distribute,\n", "all copyright, patent, trademark, and attribution notices from the Source form\n", "of the Work, excluding those notices that do not pertain to any part of the\n", "Derivative Works; and\n", "If the Work includes a \"NOTICE\" text file as part of its distribution, then any\n", "Derivative Works that You distribute must include a readable copy of the\n", "attribution notices contained within such NOTICE file, excluding those notices\n", "that do not pertain to any part of the Derivative Works, in at least one of the\n", "following places: within a NOTICE text file distributed as part of the\n", "Derivative Works; within the Source form or documentation, if provided along\n", "with the Derivative Works; or, within a display generated by the Derivative\n", "Works, if and wherever such third-party notices normally appear. The contents of\n", "the NOTICE file are for informational purposes only and do not modify the\n", "License. You may add Your own attribution notices within Derivative Works that\n", "You distribute, alongside or as an addendum to the NOTICE text from the Work,\n", "provided that such additional attribution notices cannot be construed as\n", "modifying the License.\n", "You may add Your own copyright statement to Your modifications and may provide\n", "additional or different license terms and conditions for use, reproduction, or\n", "distribution of Your modifications, or for any such Derivative Works as a whole,\n", "provided Your use, reproduction, and distribution of the Work otherwise complies\n", "with the conditions stated in this License.\n", "\n", "5. Submission of Contributions.\n", "\n", "Unless You explicitly state otherwise, any Contribution intentionally submitted\n", "for inclusion in the Work by You to the Licensor shall be under the terms and\n", "conditions of this License, without any additional terms or conditions.\n", "Notwithstanding the above, nothing herein shall supersede or modify the terms of\n", "any separate license agreement you may have executed with Licensor regarding\n", "such Contributions.\n", "\n", "6. Trademarks.\n", "\n", "This License does not grant permission to use the trade names, trademarks,\n", "service marks, or product names of the Licensor, except as required for\n", "reasonable and customary use in describing the origin of the Work and\n", "reproducing the content of the NOTICE file.\n", "\n", "7. Disclaimer of Warranty.\n", "\n", "Unless required by applicable law or agreed to in writing, Licensor provides the\n", "Work (and each Contributor provides its Contributions) on an \"AS IS\" BASIS,\n", "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied,\n", "including, without limitation, any warranties or conditions of TITLE,\n", "NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are\n", "solely responsible for determining the appropriateness of using or\n", "redistributing the Work and assume any risks associated with Your exercise of\n", "permissions under this License.\n", "\n", "8. Limitation of Liability.\n", "\n", "In no event and under no legal theory, whether in tort (including negligence),\n", "contract, or otherwise, unless required by applicable law (such as deliberate\n", "and grossly negligent acts) or agreed to in writing, shall any Contributor be\n", "liable to You for damages, including any direct, indirect, special, incidental,\n", "or consequential damages of any character arising as a result of this License or\n", "out of the use or inability to use the Work (including but not limited to\n", "damages for loss of goodwill, work stoppage, computer failure or malfunction, or\n", "any and all other commercial damages or losses), even if such Contributor has\n", "been advised of the possibility of such damages.\n", "\n", "9. Accepting Warranty or Additional Liability.\n", "\n", "While redistributing the Work or Derivative Works thereof, You may choose to\n", "offer, and charge a fee for, acceptance of support, warranty, indemnity, or\n", "other liability obligations and/or rights consistent with this License. However,\n", "in accepting such obligations, You may act only on Your own behalf and on Your\n", "sole responsibility, not on behalf of any other Contributor, and only if You\n", "agree to indemnify, defend, and hold each Contributor harmless for any liability\n", "incurred by, or claims asserted against, such Contributor by reason of your\n", "accepting any such warranty or additional liability.\n", "\n", "END OF TERMS AND CONDITIONS\n", "\n", "APPENDIX: How to apply the Apache License to your work\n", "\n", "To apply the Apache License to your work, attach the following boilerplate\n", "notice, with the fields enclosed by brackets \"[]\" replaced with your own\n", "identifying information. (Don't include the brackets!) The text should be\n", "enclosed in the appropriate comment syntax for the file format. We also\n", "recommend that a file or class name and description of purpose be included on\n", "the same \"printed page\" as the copyright notice for easier identification within\n", "third-party archives.\n", "\n", "   Copyright [yyyy] [name of copyright owner]\n", "\n", "   Licensed under the Apache License, Version 2.0 (the \"License\");\n", "   you may not use this file except in compliance with the License.\n", "   You may obtain a copy of the License at\n", "\n", "     http://www.apache.org/licenses/LICENSE-2.0\n", "\n", "   Unless required by applicable law or agreed to in writing, software\n", "   distributed under the License is distributed on an \"AS IS\" BASIS,\n", "   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n", "   See the License for the specific language governing permissions and\n", "   limitations under the License.\n"]}, "code_comments_c++": {"joystickControlMain": ["********************************************"], "JoystickControl": ["********************************************", "toggle runstop if a runstop toggle button changed from 0 to 1", "can enable/disable throttle control with L2 on game pad, only toggle if button changed from 0 to 1", "can enable/disable steering control with R2 on game pad, only toggle if button changed from 0 to 1"], "autorally_plant": ["********************************************", "Initialize the publishers.", "Initialize the subscribers.", "Timer callback for path publisher", "Initialize auxiliary variables.", "Initialize yaw derivative to zero", "Debug image display signaller", ".clear();", "Update the timestamp", "Set activated to true --> we are receiving state messages.", "Update position", "Grab the quaternion", "Update euler angles. These use the 1-2-3 Euler angle convention.", "Don't allow heading to wrap around", "Update the quaternion", "Update the world frame velocity", "Update the body frame longitudenal and lateral velocity", "Update the minus yaw derivative.", "Interpolate and publish the current control", "Just publish the computed open loop controls", "Compute the error between the current and actual state and apply feedback gains", "Copy network structure into description", "Compute total number of weights", "/< Autorally control message initialization.", "Publish the steering and throttle commands", "Nan control publish zeros and exit.", "No use trying to recover, quitting is the best option.", "Publish the computed control input.", "Everything is good.", "Shutdown timers, subscribers, and dynamic reconfigure", "server_.clearCallback();", "namespace autorally_control"], "status_monitor": ["********************************************"], "param_getter": ["********************************************"], "gpsWaypoint": ["********************************************", "    m_poseSub = m_nh.subscribe(\"Pose\", 1, &GpsWaypoint::Posecb, this);", "    m_paramTimer = m_nh.createTimer(ros::Rate(1),", "                   &GpsWaypoint::paramCallback, this);", " Get our heading from the message", " Now we have all the latest data, do some maths", " Are we at the next waypoint?", " Get the next wp", "ROS_INFO(\"Hit a waypoint\");", " UTM is a ENU system", " imugps node uses a local ENU system", " so our heading is measured from the positive x axis, meaning 0 is pointing east", " and this lets a normal x-y axis system drawn on paper represent our system with x pointing up.", "m_imMask.lines[0].end.x = 256 - (100 * cos((command.steering * PI / 2.0) + PI/2.0));", "m_imMask.lines[0].end.y = 320 - (100 * sin((command.steering * PI / 2.0) + PI/2.0));", " std::cout << \" Error \" << error << \" Steering \" << command.steering;", " std::cout << \"At theta \" << theta << \" bearing \" << bearing;", " std::cout << \" x \" << x << \" y \" << y << std::endl;", " std::cout << \" xn \" << xn << \" yn \" << yn << std::endl;", " std::cout << \" dx \" << deltaX<< \" dy \" << deltaY << std::endl;", "  void GpsWaypoint::Posecb(sensor_msgs::Imu pose)", "  {", "    m_lock.lock();", "    m_pose = pose;", "    m_lock.unlock();", "  }", "void GpsWaypoint::paramCallback(const ros::TimerEvent& time)", "{", "  m_nh.param(\"HeadingP\", m_headingP, 2.0);", "}", "ROS_INFO(\"Publish markers at %f %f and %f %f\", x, y, xwp, ywp);", "ros::NodeHandle n;"], "ConstantSpeedController": ["********************************************", "m_accelerationProfile = generateAccelerationProfile(100);", "m_backWheelsSpeed = 0.2*m_backWheelsSpeed + 0.4*(msg->lbSpeed + msg->rbSpeed);", " NODELET_INFO(\"interp %f, command %f\",p, command->throttle);"], "RingBuffer": ["********************************************", "already have entry from that time", "do not perform extrapolation", "  std::cout << \"Comparing:\" << value << \" to:\";", "    std::cout << buffIt->second << \" \";", "      std::cout << std::endl;", "std::cout << \"Interpolating key between(\" << buffIt->first << \":\" << (buffIt-1)->first <<", "             \")  for value\" << value << std::endl;", "do not perform extrapolation", "std::cout << \"Comparing:\" << key << \" to:\";", "std::cout << buffIt->first << \" \";", "std::cout << std::endl;", "std::cout << std::endl;"], "Diagnostics": ["********************************************", "can retrieve a global diagnosticsFrequency parameter if diagnostics should", "be published at a differenc frequency than 1.0 second", "time", "force the publishing of a diagnostics array based on the desired frequency", "add current overall diagnostic level and message", "Frequency messages are added to diagnotics only if tick() is being called", "remove all tick counts older than 15 seconds", "sum all ticks in the window", "add a diagnostic message with the publishing freq over the sliding window", "strs << sum/((n-mapItF->second.front().second).toSec());", "add new tick entry to vector", "add all queued diganostic messages, clear the queues"], "ImageRepublisher": [" Limit frame rate"], "RunStop": ["********************************************", "publish runsto pat 10Hz into system", "leftfront, rightfront, leftback, rightback, servo, camera", "frame data, and parse if an entire message is waiting", "std::cout << startPosition << \" \" << endPosition << std::endl;", "std::cout << \"message:\" << message.c_str() << std::endl;", "time", "get out all the messages", "std::cout << \".\" << std::endl;", "if no recent message, runstop is false"], "ImageMaskEntry": ["", "pick a random color from", "{Qt::red, Qt::green, Qt::blue, Qt::cyan, Qt::magenta, Qt::yellow}"], "main_window": ["", " Calling this incidentally connects all ui's triggers to on_...() callbacks in this class.", " qApp is a global variable for the application", "ui.backBrakeBar->setFormat(\"Back Brake: %v\");", "automatically connect into ROS system on startup", "ROS_INFO(\"%f\",(time-m_startTime).toSec());", "index", "set image", "set image", "std::cout << warnVal << \" \" << critVal << \" \" << val << std::endl;"], "main": ["", "***************************************************************************", "***************************************************************************"], "DiagnosticsEntry": ["", "newMessage << new QStandardItem(\"1\");", "go through each DiagnosticStatus in the array", "ROS_INFO(\"Looking at %s\", diagIt->name.c_str());", "find the entry in the diagnostics model, otherwise add a new one", "add new item for the sender", "int count;", "bool ok = false;", "QString num;", "update the message just received", "ROS_INFO(\"%s -%s-\", data.key.c_str(), data.value.c_str());", "if its a normal diagnostic message set the text to the value,", "otherwise it is an auto_rally diagnostic that has a level associated", "count = diagMsg->child(i,2)->text().toInt(&ok) + 1;", "ROS_INFO(\"count %d\", count);", "if(ok && diagMsg->child(i,2))", "{", "num.setNum(count);", "ROS_INFO(\"%s\", diagMsg->child(i,2)->text().toStdString().c_str());", "ROS_INFO(\"num [%s]\", QString::number(count).toStdString().c_str());", "diagMsg->child(i,2)->setText(QString::number(count));", "ROS_INFO(\"after\");", "} else", "{", "  ROS_ERROR(\"Bad conversion\");", "}", "ROS_INFO(\"end count %d\", count);", "ROS_INFO(\"updateKeyValue halfway\");", "if it is a new message from the sender, add it", "set the number of messages for the sender", "ROS_INFO(\"updateKeyValue done\");", "remove the row that was clicked on", "set number of messages for parent entry", "go through each nodes diagnostics messages", "go through each message", "remove that entry by index", "only update the times if the model has time data associated with it", "this allows non auto_rally diagnostic messages to be not colored", "consider message stale if a new one has not been received for a while,", "color part of it magenta as well as part of the parent", "there are no key-value pairs with priority, reset bkgnd color"], "qnode": ["", "register my data types so I can pass them around in signals and slots", "qRegisterMetaType<autorally_msgs::servoMSGConstPtr>", "                (\"autorally_msgs::servoMSGConstPtr\");", " explicitly needed since we use ros::start();", " Add your ros communications here.", "\tm_servoCommandTimer = n.createTimer(ros::Duration(0.1), &QNode::ssTimerCallback, this);", "\tm_servoCommandTimer.stop();", "used to signal the gui to shutdown (useful to roslaunch)", "add new item for the sender", "update the runstop", "found more than one sender with the same name", "  if(m_sendServoCommand)", "set colors for stale", " Swap R & B channels", " Copy G channel directly", " get declared transports", "qDebug(\"ImageView::updateTopicList() declared transport '%s'\", it->c_str());", " strip prefix from transport name"], "SerialSensorInterface": ["********************************************", "std::cout << \"Shutting down \" << m_port.c_str() << \" \" << close(fileDescriptor()) << std::endl;", "get current node name to allow access to the serial parameters", "specific to this node", "set timer to be able to pull 25% more data off serial port than possible", "get up to 100 bytes from the com port, add it to the data buffer", "std::cout<<\"true\";", "time", "get up to 100 bytes from the com port, add it to the data buffer", "ROS_INFO(\"Polling\");", "ROS_INFO(\"RECIEVED\");", "data[received]='\\0';", "time", "queue up a status messages", "diag_warn(\"No data within previous second\");"], "SerialInterfaceThreaded": ["********************************************", "clearDataCallback();", "if the serial thread isnt dead yet, wait for it to close", "std::cout << \"Shutting down \" << m_port.c_str() << \" \" << close(fileDescriptor()) << std::endl;", "get current node name to allow access to the serial parameters", "specific to this node", "std::string nName = nodeName;//+((portHandle.length()>0)?\"/\"+portHandle:\"\");", "std::cout << portName+((portHandle.empty())?\"\":\"/\"+portHandle) << std::endl;", "start worker in separate thread", " Watch stdin (fd 0) to see when it has input. ", " Wait up to one seconds. ", " Don't rely on the value of tv now! ", " FD_ISSET(0, &rfds) will be true. ", "callback triggered within same thread", "catch this exception for cleaner shutdown", "condition can notify (wake) other threads waiting for data", "        m_waitCond.notify_all();", "since ros is shutdown and ROS diag messages wouldnt go anywhere", "void SerialInterfaceThreaded::waitForData()", "{", "  boost::unique_lock<boost::mutex> lock(m_waitMutex);", "  m_waitCond.wait(lock);", "}", "bool SerialInterfaceThreaded::waitForData(const long& timeMS)", "{", "  boost::unique_lock<boost::mutex> lock(m_waitMutex);", "  return m_waitCond.timed_wait(lock, boost::posix_time::milliseconds(timeMS));", "}", "time", "queue up a status messages"], "SerialCommon": ["********************************************", "init in Diagnostics", "m_fd = open(port.c_str(), O_WRONLY | O_NOCTTY | O_NDELAY);", "ioctl(m_fd, USBDEVFS_RESET, 0);", "close(m_fd);", "std::cout << port << \" reset\" << std::endl;", "std::cout << port << \" open attempted\" << std::endl;", " structure to store the port settings in", "Get the current options for the port...", "tcgetattr(m_fd, &m_old_port_settings);", "fcntl(m_fd, F_SETFL, 0);", "fcntl(m_fd, F_SETFL, FNDELAY);", "std::cout << port << \" got attributes\" << std::endl;", " set baud rates", " set 8N1", " no parity bit", " even parity", " enable parity", " even parity", " enable parity", " odd parity", " only one stop bit", " two stop bits", "port_settings.c_cflag |= ~CSIZE;  // clear data bit number", " set 5 data bits", " set 6 data bits", " set 7 data bits", " set 8 data bits", " hardware flow control", " software flow control", "this part is important", " enable reading and ignore control lines", "set raw input mode (not canonical)", "  disable pre-processing of input data", " wait for at least 1 character (read doesn't block)", " 0.5 seconds read timeout", "std::cout << baud << std::endl;", "std::cout << port << \" setting attributes\" << std::endl;", " apply the settings to the port", "  wait for connection to be negotiated", "  found this length through experimentation", "std::cout<<(char*)data.c_str();", "ROS_INFO(\"%s\",\"write() failed!\");", "ROS_INFO(\"%s\",\"write() failed!\");"], "wheel_odometry": ["", " debug mode publishes a different message and subscribes to state estimator for easy visualization", " time_delay parameter is measured in seconds - only used in debug mode", " must be transformed to a number of messages (from /wheelSpeeds) to delay calculations of angular velocity", " /wheelSpeeds publish frequency is 70Hz", " initialize with 0.02s as time step", " the /pose_estime does not conform to usual ROS standard of twist in local frame", " X velocity in local frame", " Y velocity in local frame", " Initialize x, y, and heading to match state estimator", " mapping servo values to their corresponding steering angle", " Servo values are negative for left turns, steering angle is positive for left turns", " correct for values to high and too low", "Simulator steering is ideal", " For first timestep, use .02 which is approximately the timestep between wheelSpeeds messages", " approximately straight steering - turn radius +inf", " Delay this node's angular velocity estimate to account for system delays", " useful for lining up state estimator values and odometry values for data validation", " only run in debug mode", " shift buffer to remove old measurement", " add the new measurements to their buffers", " take the next element for current measurements", " update x and y positions in meters", " Two estimations, based on left and right front wheels", " these are the two error metrics published", " velocity_x_var currently is a constant 0.0569", " function for error_velocity_theta_: -0.6398 * exp(-5.1233 * error_velocity_theta_) + 0.7541", " the pose is relative to the header.frame_id reference published", " the twist is relative to the child_fram_id", " debug mode publishes data for visualization purposes", " Row-major representation of the 6x6 covariance matrix - all covariances that follow take same form", " The orientation parameters use a fixed-axis representation.", " In order, the parameters are:", " (x, y, z, rotation about X axis, rotation about Y axis, rotation about Z axis)", " use delayed time for angular z velocity", " covariance matrix takes same form as above", " covariance matrix takes same form as above", " assume instantaneous y velocity is 0", " covariance matrix takes same form as above"], "StateEstimator": ["********************************************", " Convenience for named keys", " GPS pose", " macro for getting the time stamp of a ros message", " temporary variables to retrieve parameters", " Use an ENU frame", " prior on the first pose", " Add velocity prior", " Add bias prior", " we're choosing this as the origin", " we are given an origin", " Add prior factors on pose, vel and bias", "Factor for imu->gps translation", " add prior values on pose, vel and bias", "Read IMU measurements up to the first GPS measurement", "If we only pop one, we need some dt", " add IMU measurements", " adding the integrated IMU measurements to the factor graph", " Predict forward to get an initial estimate for the pose and velocity", " add GPS measurements that are not ahead of the imu messages", " this is a gps message for a factor", " check if the GPS message is close to our expected position", " if only using odom with no GPS, then remove old messages from queue", " if available, add any odom factors that are not ahead of the imu messages", " if we processed imu - then we can optimize the state", " if we haven't added gps data for 2 message (0.2s) then change status", "ros::Time before = ros::Time::now();", " Push the IMU measurement to the optimization thread", " Each time we get an imu measurement, calculate the incremental pose from the last GTSAM pose", "Grab the most current optimized state", " haven't optimized first state yet", "We need to reset integration and iterate through all our IMU measurements", " ROS_INFO(\"IMU time %f, dt %f\", (*it)->header.stamp.toSec(), dt_temp);", " ROS_INFO(\"Resetting Integration, %d measurements integrated, %d discarded\", numMeasurements, numImuDiscarded);", "Just need to add the newest measurement, no new optimized pose", " ROS_INFO(\"Integrating %f, dt %f\", m_lastImuT, dt);", " predict next state given the imu measurements", "ros::Time after = ros::Time::now();", " publish the status of the estimate - set in the gpsHelper thread", " the local frame velocities", " update the relative position from the initial", "time", "Don't do anything", "diag_info(\"Test\");", "ros::NodeHandle n;"], "GPSHemisphere": ["********************************************", "", "default values reasonable for a crappy gps", "  m_refLocTimer = nh.createTimer(ros::Duration(60.0),", "                    &GPSHemisphere::updateReferenceLocationCallback,", "                    this);", "set real high covariances for now", "since this is only done once, the published utc time messages will not", "be correct if the code is run overnight receiving GPGSA or GPGGA for timing", "make sure data is framed (we expect only NMEA 0183 messages here)", "remove $ at beginning and trailing \\r\\n before further processing", "erase through \\r\\n at end of message", "if a complete message was found, process it", "make sure data is framed", "ROS_WARN_STREAM(\"Not Framed\");", "std::cout << \"Discarding:\" << m_portB.m_data.substr(0, start).size() <<", "  \" Leading with:\" << (unsigned int)(m_portB.m_data[0]&0xff) << std::endl;", "printMessage(m_portB.m_data);", "process if there is enough data to read the header and message type", "printMessage(m_portB.m_data);", "ROS_WARN_STREAM(\"Buffer len:\" << m_portB.m_data.length() <<", "                \" Payload len:\" << len << \" msg type:\" << type);", "record type of message seen in diagnostics", "fill in structure to send message", "std::cout << \"\\t new B Len:\" << m_portB.m_data.length() << std::endl;", "quality token", "std::cout << (double)((int)(ros::Time::now().toSec() + m_gpsTimeOffset) / 86400) << \"Week\" << messageTime << time << std::endl;", "std::cout << (ros::Time::now().toSec()) << std::endl;", " Abandon our timestamp if its too far off", "navigational status should be unsafe when no fix", "std::cout << (double)((int)(ros::Time::now().toSec() + m_gpsTimeOffset) / 86400) << \"Week\" << messageTime << time << std::endl;", "std::cout << (ros::Time::now().toSec()) << std::endl;", " Abandon our timestamp if its too far off", "ignore since its a reply", "only use this if there isn't a better source of covariance information", "and the fix is valid", "choose ideal measurmenet error based on fix type", "use DOP*ideal measurement error for std dev estimates", "HDOP used for lat and lon", "VDOP", "val = boost::lexical_cast<double>(tokens[5])*multiplier;", "check to see better variance source is available, and the message has data", "UTC time", "Token 2 = RMS of std dev of range inputs", "Token 3 = Standard deviation of semi-major axis of error ellipse, meters", "Token 4 = Standard deviation of semi-minor axis of error ellipse, meters", "Token 5 = Error in semi major axis origination, in decimal degrees, true north", "Std dev of latitude error, in meters", "Std dev of longitude error, in meters", "Std dev of altitude error, in meters", "course over ground/ground speed", "detailed UTC time information", "Token 1 = UTC", "Token 2 = UTC day", "Token 3 = UTC month", "Token 4 = UTC year", "Token 5 = Local zone hours", "Token 6 = Local zone minutes", "Minimum message with no satelite info in it.", " Iterate through all of the satellites", "We got complete info", "std::cout << \"lat \" << lat << std::endl;", "std::cout << \"lon \" << lon << std::endl;", "time", "query the current RTK transmission status", "if there are no recent RTK corrections, switch to satellite augmentation", "  if((ros::Time::now()-m_mostRecentRTK).toSec() > 120 && m_rtkEnabled)", "  {", "    unsigned char mode[14] = \"$JDIFF,WAAS\\r\\n\";", "    m_portA.writePort(cmd,14);", "    m_rtkEnabled = false;", "    m_portA.diag_ok(\"Switching to WAAS corrections\");", "  } else if((ros::Time::now()-m_mostRecentRTK).toSec() < 5 && !m_rtkEnabled)", "  {", "    unsigned char mode[16] = \"$JDIFF,BEACON\\r\\n\";", "    m_portA.writePort(cmd,16);", "    m_rtkEnabled = true;", "    m_portA.diag_ok(\"Switching to RTK corrections\");", "  }", "time", "if the unit has augmented position data, update the current reference", "location"], "CameraTrigger": ["********************************************", "set up dynamic_reconfigure server", "make sure data is framed", "try to pull out a full message", "std::cout << \"Looking at^\" << m_port.m_data << \"^\" << std::endl;", "remove # at beginning and trailing \\r\\n before further processing", "erase through \\r\\n at end of message", "level", "NODELET_ERROR_STREAM(\"Triggering FPS \" << m_triggerFPS);  ", "m_port.diag(\"Requested triggering FPS\", std::to_string(m_triggerFPS));", "send new FPS to arduino"], "AutoRallyChassis": ["********************************************", "need entry for each escDataFailCounter_actuator read from RC receiver to keep track of pulse statistics", "callback for serial data from chassis", "subscribe to a one topic for every chassis commander listed in the chassis commander priorities file", "Any variables accessed in here and in other places in the code need to be mutex'd as this fires in a different", "thread than the main thread. This is also a pretyt long callback, and ROS can shutdown underneath us, so check", "if ROS system is still running any time anytseparatedhing ROS is used", "parse all messages from chassis", "look for start and end of message", "pull message out of buffer if start and end are found", "frame data if not framed", "cut out and erase mescDataFailCounter_essage from queue", "process a complete messsage from the chassis with start ('#'), message type, and end ('\\n') characters removed", "look for another message if we haven't looked at all data available yet", "ROS_INFO_STREAM(msgType << \":\" << msg);", "wheel speeds data as comma separated doubles, units in m/s", " Convert from rotations per second to m/s", "Actuator controls from RC input, as comma separated us pulse width, currentl frontBrake is not controlled by RC", "std::cout << std::stoi(data[0]) << \" \" << std::stoi(data[1]) << std::endl;", " setting to zero to make sure brake is neutral", "this line is in here for compatibility with the old servoInterface", "this value can be 0 or 1", "Castle Link ESC data, stored as 9, 2-byte shorts in message", "Expected 18 bytes of ESC data, instead received \" + std::to_string(msg.length()));", "std::cout << msg.length() << std::endl;", "std::cout << escRegisterData_[i].second << \" \" << escRegisterData_[i].first << \" \" <<", "             (((unsigned int)(msg[2*i]&0xFF))<<8) << \" \" << (int)(msg[2*i+1]&0xFF) << std::endl;", "error message as an ASCII string", "check if motion is enabled (all runstop message runstopMotionEnabled = true)", "find highest priority (lowest valuemostRecentRc_) command message for each actuator across all valid actuator commands", "valid throttle commands are on [-1,1], only set throttle value if runstop is enabled", "valid steeringBrake commands are on [-1,1]", "valid frontBrake commands are on [0,1]", "send actuator commands down to chassis, sets to calibrated neutral if no valid commander", "send diagnostic info about who is in control of each actuator", "if we're in autonomous mode, set all the information apppropriately ", "if we're in manual mode, send the most recentl RC command received from the chassis", "publish state message", "assemble send command message for chassis", "steering", "throttle", "frontBrake", "message end signal", "convert actuator command message to raw PWM pulse width in us using the actuator config", "don't need to check if actuatorValue is on [-1, 1] because it was already done", " flip range but still keep it in [0,1]", " flip entire range for throttle and steering", "convert PWM pulse width in us back to actuator command message using the actuator config", "if us value is outside normal servo ranges, complain and don't try to convert", "we've gone 2 cycles without a valid reading, disable RC control of this actuator", "if we only get one invalid pulse width in a row, just use the previous one", "only increment invalid pulses when we get one in a row, not continuously", "NODELET_ERROR_STREAM(getName() << \" RC \" << actuator << \" pulse width out of valid range 900-2100ms (\" <<", "                     pulseWidth << \")\");", "save most recent valid actuator command    ", "read in actuator settings from paramter server that were loaded from the launch file", "add an entry for each actuator (steering, throttle, front brake)", "read in chassisCommandPriorities from the parameter server that were loaded by the launch file", "add entry in priority queue and command map", "sort the loaded commanders according to their priority"], "CameraAutoBalancePtGrey": [""], "CameraAutoBalanceFLIR": [""], "FlycaptureAdjuster": [" namespace autorally_core"], "CameraAutoBalance": ["", " namespace autorally_core"], "SpinnakerAdjuster": [" get camera by serial number from the camera list", " flir_camera_driver handles initializing and de-initing the cameras.", " Attempting to do it here sometimes causes errors and/or race conditions.", " namespace autorally_core"], "XbeeNode": ["********************************************", "until a runstop is received from rf, it will publish runstops", "with this name", "fill out space for incoming RTCM3 message sequences  ", "time", "dont send until we read our own node identifier", "std::cout << \"SENDING:\" << sendData << std::endl;", "once we know the address of the coordinator, start sending periodic info to it", "time", "time", "networkAddress", "std::cout << msg << std::endl;", "ROS_INFO_STREAM(\"Xbee NODE receive:\" << data << \" -\" << msg << \"-\" << m_coordinatorAddress);", "ROS_ERROR(\"XbeeNode: Received pose estimate\");", "std::cout << \"RS:\" << ss << std::endl;", "if I'm receiving targeted xbee runstop messages, ignore broadcast xbee", "runstop messages", "just received first packet of new RTCM3 message  ", "check to make sure there is space in the packet vector (+1 since packets #s start at 1)", "actual RTCM payload data packets start at 1", "clear message data immediately so it can't be accidentally used again", "allocate new message, fill it in", "publish correction into ros", "These will be received but are only needed by coordinator", "time", "ROS_WARN_STREAM(\"Sending position:\" << data);  ", "ROS_WARN_STREAM(\"Received:\" << message << \" from:\" << sender);"], "XbeeInterface": ["Create function pointers to call based on what type of message is", "create vector of all periodically update diagnostic info", "AT command", "frame id", "0x41;", "0x50;", "call appropritate callback", "catch this exception for cleaner shutdown", "append incoming message to vector, stripped of", "start delimiter, length, checksum", "AT command reply byte", "frameid", "Check no error code", "sometimes these AT responses fail (specifically NI request) for some reason,", "and I can't figure out why but they are just debug info, so I send the message", " to debug insted of raising an error", "m_port.diag_error(\"Xbee AT response \" + message.substr(2,2) +", "                  \" error code:\" + std::to_string(message[4]));", "AT command reply byte", "frameid", "Check no error code", "check the message is an AT command reply for the desired command", "AT command reply byte", "frameid", "frame delimiter", "Transmit command", "Random selection", "5-12 64bit address", "broadcast radius set to 0", "multicast set to 0 (unicast)", "while(ros::Time::now()-m_mostRecentXbeeXmit < ros::Duration(0.05))", "{", "usleep(5000);", "ROS_INFO(\"sleepString\");", "}", "m_mostRecentXbeeXmit = ros::Time::now();", "frame delimiter", "Transmit command", "Random selection", "5-12 64bit address", "broadcast radius set to 0", "multicast set to 0 (unicast)", "while(ros::Time::now()-m_mostRecentXbeeXmit < ros::Duration(0.02))", "{", "  usleep(5000);", "  ROS_INFO(\"sleepVec\");", "}", "m_mostRecentXbeeXmit = ros::Time::now();", "time", "time", "allocate space in string", "ROS_ERROR_STREAM(\"Converted:\" << (int)input[i] << \" to:\" << toReturn.substr(2*i,2));"], "XbeeCoordinator": ["networkAddress", "broadcast", "give 5 extra seconds to complete startup before the node is stale", "coordinator doesnt do anything with received odom msgs from nodes right now", "coordinator doesnt do anything with received runstop or GPS correction msgs from another coordinator", "if(data.length() == 62)", "{", "  processXbeeOdom(data, sender);", "}", "else", "  ROS_ERROR(\"XbeeNode: Received incorrect length(%d) odom message \\\"%s\\\"\", (int)data.length(),data.c_str());", "wait to start sending these until we actually get the node identifier from the Xbee", "ros::Time now = ros::Time::now();", "std::map<std::string, RobotState>::const_iterator mapIt;", "if state has not been received from a node in > 2 seconds, send a", "runstop = 0.0 to that node (overriding the broadcast runstop),", "regardless of what overall system runstop is", "for(mapIt = m_robotInfos.begin(); mapIt != m_robotInfos.end(); mapIt++)", "{", "if we received a hearbeat in the last 2 sec from xbee", "if( (ros::Time::now()-mapIt->second.lastHeartbeat) < ros::Duration(2.0) )", "{", "ROS_WARN(\"No recent heartbeat from %s\", mapIt->first.c_str());", "sendData = \"RS \" + msg->sender + \" 0.00\";", "m_xbee.sendTransmitPacket(sendData, mapIt->second.address);", "}", "}", "xbee packet has max len of 72 bytes", "size_t bytesSent = 0;", "each msg gets a unique character to identify it", "this system will break down if more than 27 GPS RTCM msgs are being sent per second", "send a header packet with identifier, msg count, label from the MultiByteArray", "std::string msgHeader = \"GC\" + boost::lexical_cast<std::string>(m_rtkCount) + boost::lexical_cast<std::string>(numMsgs);", "ROS_INFO_STREAM(\"Sending gps correction len \" << correction->data.size() << ", "                \" in \" << numMsgs << \" xbee packets\");", "ROS_INFO_STREAM(msgHeader + boost::lexical_cast<std::string>(msgNum) +", "                            correction->layout.dim.front().label);", "msg payload is 67 bytes of data appended", "correctionSubstr.clear();", "ROS_INFO_STREAM(\"GC\" << m_rtkCount << std::to_string(numMsgs) << ", "                std::to_string(msgNum) << \" positions \" << (msgNum-1)*payloadSize << \":\" <<", "                std::min<int>((msgNum)*payloadSize, correction->data.size()));", "ROS_WARN_STREAM(\"Received:\" << message << \" from:\" << sender);"], "SafeSpeed": ["********************************************", "keep 15 most recent speed values", "update SafeSpeed from sender, and timstamp assosiated with it", "if there is not yet an entry to sender, add it", "if the SafeSpeed is still considered valid", "check if safeSpeed can give up control (if it's in control)", "calculate acceleration", "if all is good, let the throttle do whatever", "NODELET_WARN_STREAM(\"Speed:\" << m_vehicleSpeeds.back().speed << \" Acc:\" << acceleration << \" SafeSpeed:\" << safeSpeed); ", "+acceleration", " cut throttle, act as a speed governer", "compute safeThrottle", "if(!m_throttleMappings.interpolateKey(safeSpeed, safeThrottle))", "{", "  safeThrottle = 0.0;", "  NODELET_WARN_STREAM(", "            \"SafeSpeed: couldn't interpolate a safeThrottle from safeSpeed:\"", "            << safeSpeed);", "}", "ros::NodeHandle nhPvt = getPrivateNodeHandle();"], "serialSensorInterfaceTest": ["********************************************", "", " virtual void TearDown() {}", "", "", ""], "diagnosticsTest": ["********************************************", "", " virtual void TearDown() {}", "", "", "set overall level", "force diagnostic publication", "check overall status is unchanged, then change it", "", "force diagnostic message to be sent", "make sure queue is now empty", "", "force diagnostic message to be sent", "make sure queue is now empty", "", "force diagnostic message to be sent", "make sure queue is now empty", "", "force diagnostic message to be sent", "make sure queue is now empty", "", "force diagnostic message to be sent", "make sure queue is now empty", ""], "pololuMicroMaestroTest": ["********************************************", ""]}, "code_comments_python": {"setup": [" Software License Agreement (BSD License)", " Copyright (c) 2013, Georgia Institute of Technology", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions are met:", "", " 1. Redistributions of source code must retain the above copyright notice, this", " list of conditions and the following disclaimer.", " 2. Redistributions in binary form must reproduce the above copyright notice,", " this list of conditions and the following disclaimer in the documentation", " and/or other materials provided with the distribution.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"", " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE", " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE", " DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE", " FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL", " DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR", " SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,", " OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE", " OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.", "data_files=['src/systemStatus/systemStatus'],", "scripts=['src/systemStatus/systemStatus'],"], "autorally_controller": ["!/usr/bin/env python", " Parameters", " Wheels", " Shock absorbers", " Command timeout", " Publishing frequency", " _last_cmd_time is the time at which the most recent Ackermann", " driving command was received.", " Last steering angle", " Left steering joint angle", " Right steering joint angle", " Last acceleration limit", " Axle angular velocities", " _joint_dist_div_2 is the distance between the steering joints,", " divided by two.", " Front center position", " Rear center position", " Inverse of _wheelbase", "self.lastCmdTime = rospy.get_time()", "load chassis commander priorities", "runstop information", "self.rear_axle_reverse_percent = 0.25 # percent of max_effort applied when reversing", "self.rear_axle_reverse_effort = self.rear_axle_max_effort*self.rear_axle_reverse_percent", " Publishers and subscribers", "don't set up callback until params are initialized", "self.sub = rospy.Subscriber('/autorally_platform/gazebo/link_states', ModelStates, self.callback)", " Too much time has elapsed since the last command. Stop the", " vehicle.", "rospy.logwarn(\"looking for chassis commander %s with priority %d\", cmd, priority)", "rospy.loginfo(\"%s in control of steering\", cmd);", "rospy.loginfo(\"%s in control of throttle\", cmd);", "the brake acts to slow any movement", " Publish the steering and axle joint commands.", "rospy.loginfo()", "self.lastCmdTime = rospy.get_time()", " Get front wheel parameters. Return a tuple containing the steering", " link name, steering controller name, axle controller name (or None),", " and inverse of the circumference.", " Get rear wheel parameters. Return a tuple containing the link name,", " axle controller name, and inverse of the circumference.", " Get parameters used by the front and rear wheels. Return a tuple", " containing the axle controller name (or None) and the inverse of the", " circumference.", " Return the position of the specified link, relative to the right", " rear wheel link.", " Control the steering joints.", " Compute theta, the virtual front wheel's desired steering angle.", " Limit the steering velocity.", " Compute the desired steering angles for the left and right front", " wheels.", " Control the axle joints.", " Compute veh_speed, the vehicle's desired speed.", " Limit the vehicle's acceleration.", " Compute the desired angular velocities of the wheels.", " Front", " Rear", "return data.twist[idx].angular.y * (dia)/2.0 #if data is from linkState message", "print data", "published speeds can't be negative so data mimics the physical platform", " Default wheel diameter. Unit: meter.", " Default equilibrium position. Unit: meter.", " Default command timeout. Unit: second.", " Default publishing frequency. Unit: hertz.", " end _AutoRallyCtrlr", " Wait for the specified controller to be in the \"running\" state.", " Commands can be lost if they are published before their controller is", " running, even if a latched publisher is used.", " Create an axle command publisher.", " Create a command publisher.", " Return the desired steering angle for a front wheel.", " main"], "ground_truth_republisher": ["!/usr/bin/env python", "set frame to be the same as state estimator output", "print msg.pose.pose.position.x, msg.pose.pose.position.y", "rotate position 90 deg around z-axis", "rotate orientation 90 deg around z-axis", "rotate linear velocity 90 deg around z-axis"], "lap_stats": ["!/usr/bin/env python", "Import message types", "Slope, Offset, X min, X max", "Using the 1-2-3 euler angle convention", "Yaw is heading", "Get the pose from the message", "Process the pose to get statistics", "Check if we've completed the last", "Read the launch params"], "track_generator": ["Rotate the image so that the origin is in the top left corner.", "Cast image to numpy array", "Save data to numpy array, each channel is saved individually as an array in row major order."], "track_converter": ["Save data to numpy array, each channel is saved individually as an array in row major order."], "chronyStatus": ["!/usr/bin/env python", " Software License Agreement (BSD License)", " Copyright (c) 2016, Georgia Institute of Technology", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions are met:", "", " 1. Redistributions of source code must retain the above copyright notice, this", " list of conditions and the following disclaimer.", " 2. Redistributions in binary form must reproduce the above copyright notice,", " this list of conditions and the following disclaimer in the documentation", " and/or other materials provided with the distribution.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"", " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE", " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE", " DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE", " FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL", " DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR", " SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,", " OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE", " OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.", "split on first : to separate data field name from value because some values can have : in them", "M = tok[0][0]", "S = tok[0][1]", "all is good if we are synchronizing to a source", "print M, S", " query and publish chrony information once every 5 seconds", "chronyMinVersion = 1.29", "publish error and exit if chronyMinVersion is not satisfied", "if chronyVersion < chronyMinVersion:", "  rospy.logerr('ChronyStatus requires chrony version ' + str(chronyMinVersion) + \\", "               ' or greater, version ' + str(chronyVersion) + ' detected, exiting')", "else:"], "systemStatus": ["!/usr/bin/env python", " Software License Agreement (BSD License)", " Copyright (c) 2013, Georgia Institute of Technology", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions are met:", "", " 1. Redistributions of source code must retain the above copyright notice, this", " list of conditions and the following disclaimer.", " 2. Redistributions in binary form must reproduce the above copyright notice,", " this list of conditions and the following disclaimer in the documentation", " and/or other materials provided with the distribution.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"", " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE", " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE", " DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE", " FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL", " DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR", " SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,", " OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE", " OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.", "# @package systemStatus", "  Gets the wireless signal strength, power status, and CPU temperature. This information is published in the form of ROS messages.", "", "import roslib; roslib.load_manifest('autorally_msgs')", " This shared library is only importable when a GPU is installed", " https://docs.nvidia.com/deploy/nvml-api/group__nvmlDeviceQueries.html#group__nvmlDeviceQueries_1g90843d79066e66430ecb5929c698ce09", "# WirelessStatus.", "", "  Uses iwconfig to retrieve wireless signal strength and then publishes it.", "#  Initializes wirelessSignalStatusMSG", "#  Retrieves wireless signal strength and stores it in the MSG format.", "# PowerStatus.", "", "  Uses acpi to retrieve battery status and then publishes it.", "#  Initializes powerStatusMSG", "#  Retrieves battery status and stores it in the MSG format.", "            print outputString[percentageLocation-2:pPubercentageLocation]", "# M4ATXPowerStatus", "", "  Uses M4API to check compute box battery status and power supply diagnostics", " Battery max voltage 25, fully depleted 19, 6 volt span", "# TempStatus.", "", "  Uses sensors to retrieve CPU temperature and then publishes it.", "#  Initializes tempStatusMSG", "#  Retrieves CPU temperature and fan speed and stores it in the MSG format.", "only try to query GPU if nvml was sucessfully init", " assumes only 1 GPU installed, at index 0          ", "convert reading in milliwatt to W", "uncomment line below to disable m4ATX status updates", "1Hz", " WiFi status is not currently published by our driver", "get available dick space in /media/data", "remove extra spaces and split on remaning/media/data spaces", "check disc usage %              ", "only add part of the df -h output to diagnostics              "]}}
,{"git_repo_name": "jackal_robot", "code_comments_file_names": ["jackal_base", "jackal_hardware", "jackal_diagnostic_updater", "simple_joy_node", "setup", "__init__", "navsat_rtk_relay", "Receiver", "__init__", "network", "Sender", "daemonize"], "md_file_names": ["README"], "md_contents": {"README": ["jackal_robot\n", "============\n", "\n", "Robot packages for Jackal\n"]}, "code_comments_c++": {"jackal_base": ["", " Calculate monotonic time elapsed", " Initialize ROS node.", " Create the serial rosserial server in a background ASIO event loop.", " Background thread for the controls callback.", " Create diagnostic updater, to update itself on the ROS thread.", " Foreground ROS spinner for ROS callbacks, including rosserial, diagnostics"], "jackal_hardware": ["", " Realtime publisher, initializes differently from regular ros::Publisher", "", " TODO(mikepurvis): determine this from amperage data.", "", " Update the feedback message pointer to point to the current message. Block", " until the control thread is not using the lock.", " namespace jackal_base"], "jackal_diagnostic_updater": ["", " The arrival of this message runs the update() method and triggers the above callbacks.", " These message frequencies are reported on separately.", " Publish whether the wireless interface has an IP address every second.", " Fresh data from the MCU, publish a diagnostic update.", " Get system structure of interface IP addresses.", " Iterate structure looking for the wireless interface.", " Free structure, publish result message.", " namespace jackal_base"], "simple_joy_node": ["", " When deadman button is released, immediately send a single no-motion command", " in order to stop the robot.", " namespace jackal_teleop"]}, "code_comments_python": {"navsat_rtk_relay": [" Software License Agreement (BSD) ", "", " @author    Mike Purvis <mpurvis@clearpathrobotics.com>", " @copyright (c) 2015, Clearpath Robotics, Inc., All rights reserved.", "", " Redistribution and use in source and binary forms, with or without modification, are permitted provided that", " the following conditions are met:", " * Redistributions of source code must retain the above copyright notice, this list of conditions and the", "   following disclaimer.", " * Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the", "   following disclaimer in the documentation and/or other materials provided with the distribution.", " * Neither the name of Clearpath Robotics nor the names of its contributors may be used to endorse or", "   promote products derived from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED", " WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A", " PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR", " ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED", " TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION)", " HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING", " NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", " This loop is necessary for when the script starts with ROS on the local-filesystems", " event, it can run before the network devices are established."], "Receiver": ["!/bin/env python"], "network": ["!/bin/env python", "An ugly hack to account for different ifreq sizes on", "different architectures", "Get the list of all network interfaces", "Get ip addresses for each interface"], "Sender": ["!/bin/env python"], "daemonize": ["!/usr/bin/env python", " Do first fork.", " Exit first parent.", "1 failed: (%d) %s\\n\" % (e.errno, e.strerror) )", " Decouple from parent environment.", " Do second fork.", " Exit second parent.", "2 failed: (%d) %s\\n\" % (e.errno, e.strerror) )", " Now I am a daemon!", " Redirect standard file descriptors."]}}
,{"git_repo_name": "pandora_ros_pkgs", "code_comments_file_names": ["pose_estimation_node", "pose_estimation", "pandora_slam_2d", "pandora_slam_2d_node", "laser_scan_to_point_cloud_converter", "laser_scan_to_point_cloud_converter_node", "pandora_icp_slam_3d_kinect", "pandora_icp_slam_3d_kinect_node", "pandora_icp_slam_3d_laser", "pandora_icp_slam_3d_laser_node", "pandora_icp_slam_3d_kinect_map_node", "pandora_icp_slam_3d_kinect_map", "pandora_icp_slam_3d_laser_map_node", "pandora_icp_slam_3d_laser_map", "setup", "test_flow", "test_move_end_effector_server", "test_effector_clients", "test_move_end_effector_server", "test_client_factory", "command_mapping_dict", "client_factory", "__init__", "effector_clients", "move_end_effector_server", "move_eef_script", "topics", "client_dict", "client_list", "end_effector_controller_node", "states", "mock_end_effector_planner", "__init__", "goal_maker", "action_servers", "setup", "stabilizer_control_node", "stabilizer_control", "test_pandora_stabilizer_node", "setup", "sensor_orientation_controller", "__init__", "__init__", "move_kinect_script", "move_head_script", "setup", "linear_actuator_controller", "__init__", "__init__", "move_linear_actuator_script", "motors_keyop", "motors_keyop_node", "motors_joyop", "keyop", "joyop", "setup", "__init__", "__init__", "dataset_utils", "motion_reward", "experiment", "kinodynamic_control", "params", "navigation_environment", "navigation_task", "utils", "__init__", "linear_fusion", "goal_cost", "trajectory_cost", "fuse_cost_node", "__init__", "fusion_strategy", "cost_node", "move_base", "move_base_node", "mock_local_patcher", "static_patch", "setup", "__init__", "__init__", "move_base", "setup", "range_to_point_cloud_converter", "point_cloud_cropper", "mock_data_fusion", "hard_obstacle_patcher", "tururu", "mock_params", "obstacle_test", "map_utils_test", "__init__", "obstacle", "map_utils", "map_patch_params", "map_patch", "setup", "co2_widget", "widget_info", "message_data_model", "__init__", "battery_widget", "pandora_gui", "console", "save_mission_client", "probability_info", "rpc_client", "console_widget", "sonars_widget", "temp_widget", "standar_widget", "main_widget", "gui_state_client", "victim_found_server", "__init__", "rqt_gui", "listener", "victim_action_client", "talker", "victim_propabilities", "pandora_rqt_gui", "pointcloud_to_image_converter", "discrete_wavelet_transform", "discrete_wavelet_transform_test", "victim_hole_preprocessor", "victim_hole_processor", "victim_node", "victim_handler", "victim_parameters", "victim_vj_detector", "victim_image_processor", "victim_image_preprocessor", "victim_postprocessor", "rgb_feature_extraction", "edge_orientation_extractor", "channels_statistics_extractor", "depth_feature_extraction", "sift_extractor", "histogram_extractor", "feature_extraction", "haralickfeature_extractor", "hog_extractor", "color_angles_extractor", "mean_std_dev_extractor", "dft_coeffs_extractor", "dominant_color_extractor", "neural_network_validator", "random_forests_validator", "validator_factory", "neural_network_classifier", "abstract_validator", "victim_training_node", "rgbd_svm_validator", "svm_classifier", "abstract_classifier", "random_forests_classifier", "classifier_factory", "rgb_random_forests_classifier", "rgbd_svm_classifier", "svm_validator", "feature_extraction_utilities", "principal_component_analysis", "bag_of_words_trainer", "file_utilities", "platt_scaling", "accuracy_test", "victim_benchmark_test", "haralickfeature_extractor_test", "sift_extractor_test", "histogram_extractor_test", "edge_orientation_extractor_test", "dominant_color_test", "mean_std_dev_test", "color_angles_test", "random_dataset_creator", "check_annotations_file", "transform_annotations_to_full_frame", "benchmark_tests_automation", "rename_dataset", "training_automation", "qrcode_detector", "qrcode_processor", "qrcode_preprocessor", "qrcode_node", "qrcode_handler", "qrcode_postprocessor", "accuracy_test", "qrcode_benchmark_test", "qrCode_detector_test", "obstacle_postprocessor", "obstacle_preprocessor", "hard_obstacle_handler", "hard_obstacle_postprocessor", "dummy_processor", "hard_obstacle_node", "hard_obstacle_preprocessor", "traversability_mask", "dummy_main", "hard_obstacle_detector", "hard_obstacle_processor", "barrel_handler", "barrel_processor", "barrel_node", "fast_symmetry_detector", "barrel_detector", "parameters", "soft_obstacle_handler", "soft_obstacle_detector", "soft_obstacle_processor", "soft_obstacle_node", "barrel_benchmark_test", "rename_bag_topic", "barrel_detector_test", "fast_symmetry_detector_test", "traversability_mask_test", "soft_obstacle_detector_test", "setup", "image_saver_by_topic", "enhanced_image_shower", "rgb_to_enhanced", "__init__", "__init__", "vision_benchmark_test_base", "pkg.develspace.context.pc", "pkg.installspace.context.pc", "setup", "annotator_controller", "annotator_connector", "annotator_node", "annotator_loader", "annotator_application", "annotator_tools", "__init__", "images_to_bag", "split_bag", "motion_preprocessor", "motion_postprocessor", "motion_handler", "motion_processor", "motion_node", "motion_detector", "dbscan", "motion_detector_test", "landoltc_postprocessor", "landoltc_preprocessor", "landoltc_node", "landoltc_handler", "landoltc_detector", "landoltc_parameters", "landoltc3d_parameters", "landoltc3d_detection", "landoltc3d_node", "landoltc3d_detector", "accuracy_test", "landoltc_benchmark_test", "landoltc_detector_test", "landoltc3d_detector_test", "datamatrix_node", "datamatrix_detector", "datamatrix_preprocessor", "datamatrix_postprocessor", "datamatrix_handler", "datamatrix_processor", "datamatrix_detector_test", "color_processor", "color_handler", "color_preprocessor", "color_node", "color_postprocessor", "color_detector", "color_detector_test", "predator_node", "predator", "orb_detector", "feature_matching_detector", "hazmat_postprocessor", "sift_detector", "hazmat_handler", "planar_object_detector", "hazmat_processor", "detector_factory", "hazmat_node", "hazmat_preprocessor", "surf_detector", "image_signature", "surf_trainer", "factory", "sift_trainer", "hazmat_trainer_node", "planar_pattern_trainer", "orb_trainer", "accuracy_test", "hazmat_benchmark_test", "feature_matching_test", "trainer_test", "image_signature_test", "thermal_node", "thermal_hole_detector", "thermal_cropper", "thermal", "thermal_cropper_node", "noise_elimination", "holes_conveyor", "histogram", "blob_vector", "outline_discovery", "image_matching", "wavelets", "visualization", "bounding_box_detection", "edge_detection", "blob_detection", "morphological_operators", "message_conversions", "parameters", "hole_filters", "rgb", "rgb_hole_detector", "noise_elimination", "holes_conveyor", "histogram", "blob_vector", "outline_discovery", "image_matching", "wavelets", "visualization", "bounding_box_detection", "edge_detection", "blob_detection", "morphological_operators", "message_conversions", "parameters", "hole_filters", "timer", "filters", "planes_detection", "hole_fusion", "hole_merger", "hole_validation", "rgb_filters", "filters_resources", "depth_filters", "hole_uniqueness", "noise_elimination", "holes_conveyor", "histogram", "blob_vector", "outline_discovery", "image_matching", "wavelets", "visualization", "bounding_box_detection", "edge_detection", "blob_detection", "morphological_operators", "message_conversions", "parameters", "hole_filters", "depth_hole_detector", "depth", "noise_elimination", "holes_conveyor", "histogram", "blob_vector", "outline_discovery", "image_matching", "wavelets", "visualization", "bounding_box_detection", "edge_detection", "blob_detection", "morphological_operators", "message_conversions", "parameters", "hole_filters", "pc_thermal_synchronizer", "hole_detector_test", "hole_benchmark_test", "hole_detector_test", "holes_conveyor_test", "message_conversions_test", "morphological_operators_test", "noise_elimination_test", "wavelets_test", "outline_discovery_test", "edge_detection_test", "blob_vector_test", "visualization_test", "hole_filters_test", "bounding_box_detection_test", "hole_merger_test", "rgb_filters_test", "hole_validation_test", "hole_uniqueness_test", "filters_test", "filters_resources_test", "depth_filters_test", "planes_detection_test", "hole_detector_test", "rgb_depth_thermal_synchronizer", "interface_tester", "tf_monitor", "interfaces_xml_parser", "node_diagnostics", "generic_diagnostic", "interface_diagnostics_node", "interface_diagnostics", "bounds_check", "bounds_check_subscriber", "overall_main_motor_control_checker", "main_motor_state_checker", "butterfly_checker", "irs_checker", "mlx_checker", "sonars_checker", "co2_checker", "tpa_checker", "compass_checker", "overall_controllers_checker", "xmega_hardware_interface", "xmega_hardware_interface_node", "battery_controller", "range_sensor_controller", "encoder_sensor", "test", "range_sensor", "battery_sensor", "xmega_serial_interface", "linear_actuator_hardware_interface_node", "linear_actuator_hardware_interface", "firgelli_com_interface", "jrk_com_interface", "jrk_communicator", "thermal_sensor_controller", "battery_controller", "co2_sensor_controller", "range_sensor_controller", "arm_hardware_interface_node", "arm_hardware_interface", "arm_usb_interface", "arm_usb_interface_demo", "imu_hardware_interface", "imu_hardware_interface_node", "imu_rpy_controller", "ahrs_com_interface", "trax_ahrs_configuration_node", "imu_com_interface", "cpu_temperature_monitor", "battery_monitor", "state_indicator", "serial_epos2_handler", "epos2_test", "epos_serial_gateway", "Utils", "serial_epos_handler", "test", "abstract_epos_handler", "error_codes_test", "epos2_gateway", "motor_hardware_interface", "motor_hardware_interface_node", "skid_steer_velocity_controller", "skid_steer_torque_controller", "leddar_hardware_interface", "leddar_hardware_interface_node", "Leddar", "leddar_serial_interface_demo", "OS", "leddar_serial_interface", "Modbus", "leddar_usb_interface_demo", "leddar_usb_interface", "leddar_sensor_controller", "joint_states_wrapper", "gio_gazebo_interface", "pandora_wheel_physics_plugin", "pandora_fdir_plugin", "pandora_differential_plugin", "pandora_microphone_plugin", "pandora_co2_plugin", "pandora_sonar_plugin", "pandora_thermal_plugin", "pandora_p3d_plugin", "pandora_imu_stabilizer_plugin", "setup", "end", "init", "sensor_hold", "identification", "fusion_validation", "victim_deletion", "operator_validation", "exploration", "fsm_framework", "utilities", "world_model", "navigator", "effector", "explorer", "data_fusion", "gui", "victim_validator", "mocks", "agent_standalone", "__init__", "topics", "target", "agent", "config", "utils", "__init__", "navigator", "effector", "explorer", "data_fusion", "gui", "__init__", "msgs", "action_servers", "publishers", "__init__", "transition", "machine", "state", "event", "agent_end_effector_test", "data_fusion_agent_test", "agent_explorer_test", "hole_data_fusion_test", "setup", "__init__", "processing", "setup", "__init__", "capture", "monitor", "record", "transport_image_topics", "setup", "state_server", "state_client", "state_client_nodelet", "state_changer", "state_manager_test", "__init__", "state_client", "test_client", "sensor_processor_test", "dummy_handler", "dummy_processor", "dummy_preprocessor", "dummy_processor_node", "dummy_postprocessor", "setup", "bag_player_for_tests", "customized_player", "map_loader", "__init__", "dummy_node", "test_dummy_node", "__init__", "bcolors", "mocksubscriber", "moxcomparators", "messageInfoParser", "generic_mock", "__init__", "dummy_node", "test_dummy_node", "__init__", "test_base", "alert_delivery", "integration_tester", "utils", "watchdog", "watchdog_monitor", "mutex_guard", "standalone_mutex", "remote_mutex", "kinect_movement_filter", "parse_extra_files", "download_checkmd5", "exploration_controller", "exploration_controller_node", "navfn_frontier_path_generator", "navfn_service_frontier_path_generator", "map_frontier_search", "frontier_goal_selector", "distance_cost_function", "visited_cost_function", "alignment_cost_function", "size_cost_function", "frontier_selector_test", "exploration_caller", "map_frontier_search_test", "costmap_tools_test", "setup", "__init__", "__init__", "explorer", "surface_checker", "sensor_coverage", "main", "sensor", "utils", "coverage_checker", "sensor_planner", "sensor_planner_node", "interactive_command_publisher_marker", "interactive_tf_publisher_marker", "temprature_visualization", "data_fusion_object_visualization", "pandora_qr_csv_node", "qr_csv_creator", "objects_srv", "save_csv", "server", "creator", "pandora_geotiff_node", "objects_srv", "utilities", "geotiff_creator_test", "save_mission_client", "talker", "utils", "ros_tf_listener", "utils_test", "pandora_alert_handler_node", "object_factory", "alert_handler", "landoltc", "motion", "obstacle", "visual_victim", "qr", "sound", "co2", "soft_obstacle", "hard_obstacle", "hole", "hazmat", "thermal", "victim", "barrel", "data_matrix", "filter_model", "victim_handler", "victim_clusterer", "object_handler", "victim_list", "obstacle_list", "subscriber_test", "mass_alert_publisher", "alert_handler_test", "test_base", "alert_handler_static_test", "object_list_test", "object_factory_test", "victim_clusterer_test", "victim_test", "objects_test", "victim_list_test", "clusterer", "thermal_node", "co2_processor", "co2_node", "utils", "thermal_processor", "co2_processor_test", "test_base", "thermal_processor_test", "clusterer_test", "utils_test", "pose_finder", "pose_finder_test", "keypoint_transformer", "view_pose_finder", "roi_transformer", "frame_matcher_node", "frame_matcher", "matcher_processor", "enhanced_image_postprocessor", "candidate_hole_postprocessor", "enhanced_image_preprocessor", "frame_matcher_functional"], "md_file_names": ["README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README", "README"], "md_contents": {"README": ["pandora_data_fusion [![Build Status](http://jenkins.pandora.ee.auth.gr/buildStatus/icon?job=test-pandora_data_fusion/hydro-devel)](http://jenkins.pandora.ee.auth.gr/job/test-pandora_data_fusion/branch/hydro-devel/)\n", "===================\n", "\n", "Data and victim fusion implementation for pandora UGV.\n"]}, "code_comments_c++": {"pose_estimation_node": ["*******************************************************************"], "pose_estimation": ["*******************************************************************", " Initialize exponential decay filter", " Maybe it's something else relatively to /map frame", "DEBUG z", "DEBUG z --> Publish IMU RPY", "MultiArrayDimension", "float", "float", "float", " Get frame flat", " Get difference in x and y", " Find difference in z", " TODO(lynx): interpolation steps as parameter", " Update previousOrigin", " Broadcast updated footprint transform", "tf::Vector3 translationZ(0, 0, final_z);", " For testing purposes: keep z in internal state without affecting others", "DEBUG z", "MultiArrayDimension", "float", "float", "float", "float", "float", " Broadcast updated base stabilized", " base_stabilized -> base_link", "Measure exec time and INFO rate", "", " Newest measurements at the front of the queue!", " Accumulators", "Leave 1 element in queue as starting point for next loop", "TODO(lynx): exp filter IMU", "", "", "the 0.9 factor might help reduce quantization error?", " namespace pandora_pose_estimation"], "pandora_slam_2d": ["*******************************************************************", "", "", " namespace pandora_slam_2d"], "pandora_slam_2d_node": ["*******************************************************************", "!< Main function of the node"], "pandora_icp_slam_3d_kinect": ["Inverse"], "pandora_icp_slam_3d_kinect_node": [" Use 4 threads", " spin() will not return until the node has been shutdown"], "pandora_icp_slam_3d_laser": ["Inverse"], "pandora_icp_slam_3d_laser_node": [" Use 4 threads", " spin() will not return until the node has been shutdown"], "pandora_icp_slam_3d_kinect_map_node": [" Use 4 threads", " spin() will not return until the node has been shutdown"], "pandora_icp_slam_3d_kinect_map": ["Inverse"], "pandora_icp_slam_3d_laser_map_node": [" Use 4 threads", " spin() will not return until the node has been shutdown"], "pandora_icp_slam_3d_laser_map": ["Inverse"], "stabilizer_control_node": ["*******************************************************************"], "stabilizer_control": ["*******************************************************************", " namespace", " Invert commands in order to stabilize", " Convert degs to rads", " Add offsets", " Check commands' limits", " Publish roll command", " Publish pitch command", " namespace pandora_control"], "sensor_orientation_controller": ["*******************************************************************", " namespace", " get params from param server", " set the action state to aborted", " Invert command in order to stabilize", " Convert degs to rads", " set the action state to succeeded", " namespace pandora_control"], "linear_actuator_controller": ["*******************************************************************", " get params from param server", " set the action state to aborted", " Parse robot description", " Get current link and its parent", " Step could be a param", " set the action state to succeeded", " set the action state to preempted", " set the action state to succeeded", " set the action state to preempted", " set the action state to succeeded", " set the action state to succeeded", " set the action state to preempted", " set the action state to preempted", " set the action state to succeeded", " set the action state to preempted", " set the action state to succeeded", " namespace pandora_control"], "motors_keyop": ["*******************************************************************", " get the console in raw mode", " Setting a new line, then end of file", " get the next event from the keyboard", " ~ linear_=angular_=0;", " namespace pandora_teleop"], "motors_keyop_node": ["*******************************************************************"], "move_base": ["*******************************************************************", "get some parameters that will be global to the move base node", "set up plan triple buffer", "set up the planner's thread", "for comanding the base", "we'll provide a mechanism for some people to send goals as PoseStamped messages over a topic", "they won't get any useful information back about its status, but this is useful for tools", "like nav_view and rviz", "we'll assume the radius of the robot to be consistent with what's specified for the costmaps", "create the ros wrapper for the planner's costmap... and initializer a pointer we'll use with the underlying map", "initialize the global planner", "check if a non fully qualified name has potentially been passed in", "if we've found a match... we'll get the fully qualified name and break out of the loop", "create the ros wrapper for the controller's costmap... and initializer a pointer we'll use with the underlying map", "create a local planner", "check if a non fully qualified name has potentially been passed in", "if we've found a match... we'll get the fully qualified name and break out of the loop", " Start actively updating costmaps based on sensor data", "advertise a service for getting a plan", "advertise a service for clearing the costmaps", "if we shutdown our costmaps when we're deactivated... we'll do that now", "load any user specified recovery behaviors, and if that fails load the defaults", "initially, we'll need to make a plan", "we'll start executing recovery behaviors at the beginning of our list", "we're all set up now so we can start the action server", "The first time we're called, we just want to make sure we have the", "original configuration", "if someone sets restore defaults on the parameter server, prevent looping", "initialize the global planner", "check if a non fully qualified name has potentially been passed in", "if we've found a match... we'll get the fully qualified name and break out of the loop", " wait for the current planner to finish planning", " Clean up before initializing the new planner", "create a local planner", "check if a non fully qualified name has potentially been passed in", "if we've found a match... we'll get the fully qualified name and break out of the loop", " Clean up before initializing the new planner", "we need to be able to publish velocity commands", "update feedback to correspond to our curent position", "push the feedback out", "check to see if we've moved far enough to reset our oscillation timeout", "if our last recovery was caused by oscillation, we want to reset the recovery index", "check that the observation buffers for the costmap are current, we don't want to drive blind", "if we have a new plan then grab it and give it to the controller", "make sure to set the new plan flag to false", "do a pointer swap under mutex", "ABORT and SHUTDOWN COSTMAPS", "disable the planner thread", "make sure to reset recovery_index_ since we were able to find a valid plan", "the move_base state machine, handles the control logic for navigation", "if we are in a planning state, then we'll attempt to make a plan", "if we're controlling, we'll attempt to find valid velocity commands", "check to see if we've reached our goal", "disable the planner thread", "check for an oscillation condition", "make sure that we send the velocity command to the base", "check if we've tried to find a valid control for longer than our time limit", "we'll move into our obstacle clearing mode", "otherwise, if we can't find a valid control, we'll go back to planning", "enable the planner thread in case it isn't running on a clock", "we'll try to clear out space with any user-provided recovery behaviors", " Fix me (tsompania)", "we'll invoke whatever recovery behavior we're currently on if they're enabled", "we at least want to give the robot some time to stop oscillating after executing the behavior", "we'll check if the recovery behavior actually worked", "update the index of the next recovery behavior that we'll try", "disable the planner thread", "disable the planner thread", "we aren't done yet", " Not used inside move_base", "clear the costmaps", " Not used inside move_base", "make sure we have a costmap for our planner", "if the user does not specify a start pose, identified by an empty frame id, then use the robot's pose", "update the copy of the costmap the planner uses", "if we have a tolerance on the goal point that is greater", "than the resolution of the map... compute the full potential function", "copy the plan into a message to send out", " This is used for nav_view and rviz", "clear the planner's costmap", "clear the controller's costmap", "make sure to set the plan to be empty initially", "since this gets called on handle activate", "get the starting pose of the robot", " planner_ is ptr to a GlobalPlanner object", "if the planner fails or returns a zero length plan, planning failed", " plan will be filled with the calculated", "first we need to check if the quaternion has nan's or infs", "next, we need to check if the length of the quaternion is close to zero", "next, we'll normalize the quaternion and check that it transforms the vertical vector correctly", " takes the goal msg pose data and set them to the goal pose", "just get the latest available transform... for accuracy they should send", "goals in the frame of the planner", " Can throw InvalidArgument if quaternion is malformed or LookupException", " (Lookup exception) The most common reason for this is that the frame is not being published,", " or a parent frame was not set correctly causing the tree to be broken.", "check if we should run the planner (the mutex is locked)", "if we should not be running the planner then suspend this thread", "time to plan! get a copy of the goal and unlock the mutex", " planner_goal_ is a poseStamped message", "run planner", " planner_plan is a ptr to a vector of poseStamped messages(each vector is a plan)", "pointer swap the plans under mutex (the controller will pull from latest_plan_)", "make sure we only start the controller if we still haven't reached the goal", "if we didn't get a plan and we are in the planning state (the robot isn't moving)", "check if we've tried to make a plan for over our time limit", "we'll move into our obstacle clearing mode", "take the mutex for the next iteration", "we will try our best to find a valid plan, by moving the given goal", "we have a goal so start the planner", "we want to make sure that we reset the last time we had a valid plan and control", "if we're active and a new goal is available, we'll accept it, but we won't shut anything down", "we will try our best to find a valid plan, by moving the given goal", "we'll make sure that we reset our state for the next execution cycle", "we have a new goal so make sure the planner is awake", "publish the goal point to the visualizer", "make sure to reset our timeouts", "if we've been preempted explicitly we need to shut things down", "notify the ActionServer that we've successfully preempted", "we'll actually return from execute after preempting", "we also want to check if we've changed global frames because we need to transform our goal pose", "we want to go back to the planning state for the next execution cycle", "we have a new goal so make sure the planner is awake", "publish the goal point to the visualizer", "make sure to reset our timeouts", "for timing that gives real time even in simulation", "the real work on pursuing a goal is done here", "if we're done, then we'll return from execute", "check if execution of the goal has completed in some way", "make sure to sleep for the remainder of our cycle time", "wake up the planner thread so that it can exit cleanly", "if the node is killed then we'll abort and return", "check for recovery behaviors with the same name", "if we've made it to this point, we know that the list is legal so we'll create all the recovery behaviors", "check if a non fully qualified name has potentially been passed in", "if we've found a match... we'll get the fully qualified name and break out of the loop", "shouldn't be possible, but it won't hurt to check", "initialize the recovery behavior with its name", "if no recovery_behaviors are specified, we'll just load the defaults", "if we've made it here... we've constructed a recovery behavior list successfully", "we'll load our default recovery behaviors here", "we need to set some parameters based on what's been passed in to us to maintain backwards compatibility", "first, we'll load a recovery behavior to clear the costmap", "next, we'll load a recovery behavior to rotate in place", "next, we'll load a recovery behavior that will do an aggressive reset of the costmap", "we'll rotate in-place one more time", "if we shutdown our costmaps when we're deactivated... we'll do that now", " converts the goal coordinates from world coordinates to map coordinates", " returns True if conversion was successful", "if cell is free, nothing to do", "try to find a valid cell, we will accept NO_INFORMATION cells also", "costmap_2d::CIRCUMSCRIBED_INFLATED_OBSTACLE", "update goal"], "move_base_node": ["ros::MultiThreadedSpinner s;"], "range_to_point_cloud_converter": ["*******************************************************************", " x", " y", " z", " namespace pandora_navigation"], "point_cloud_cropper": ["*******************************************************************", "stop pcl from spamming", "ROS_INFO(\"cb\");", " remove NaN", "ROS_INFO(\"withoutNan\");", "apply VoxelGrid filter", "ROS_INFO(\"transformed\");", " apply outlier removal (takes a lot of time)", "ROS_INFO(\"withoutOutliers\");", " filter points", "ROS_INFO(\"cropped\");", " publish final cloud", " namespace pandora_costmap"], "pointcloud_to_image_converter": ["*******************************************************************", " Prepare the output image", " For the depth image", " if element is nan make it a zero", " For the rgb image", " namespace pandora_vision"], "discrete_wavelet_transform": ["*******************************************************************", " namespace pandora_vision_common", " namespace pandora_vision"], "discrete_wavelet_transform_test": ["*******************************************************************", " namespace pandora_vision_common", " namespace pandora_vision"], "victim_hole_preprocessor": ["*******************************************************************", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_hole_processor": ["*******************************************************************", "", "  * input->getDepth() + (input->getRegions().size() > 0) + 1;", "/ Message alert creation", " if (final_victims[i]->getClassLabel() == 1)", " {", " counter_++;", "/ Debug purposes", " }", "/ Debug image", " Convert the image into a message", " Publish the image message", "", " || detectionMode == GOT_RGB", " SVM mask merging", " Combine rgb & depth probabilities", "/ Weighted mean", " Only rgb svm probabilities", " if (detectionMode == GOT_HOLES )  // || detectionMode == GOT_RGB", " {", " for (unsigned int i = 0 ; i < rgb_svm_probabilities.size(); i++)", " {", " VictimPOIPtr temp(new VictimPOI);", " if (rgb_svm_probabilities[i]->getClassLabel() == 1)", " {", " counter_++;", " temp->setProbability(rgb_svm_probabilities[i]->getProbability() *", " paramsPtr_->rgb_svm_weight);", " temp->setPoint(rgb_svm_probabilities[i]->getPoint());", " temp->setSource(RGB_SVM);", " temp->setWidth(rgb_svm_probabilities[i]->getWidth());", " temp->setHeight(rgb_svm_probabilities[i]->getHeight());", " final_probabilities.push_back(temp);", " }", " else", " counter_--;", " }", " } ", "", "/ Interpolated depth image publishing", " Convert the image into a message", " Publish the image message", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_node": ["*******************************************************************"], "victim_handler": ["*******************************************************************", "", " Escape if it is already visited", " Escape if it has only a hazmat", "", "", "", "", "//////////////////////////////////////////////////////////////////////////////", "", "", "", "", "", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_parameters": ["*******************************************************************", "!< Dynamic reconfigure parameters", "/ The dynamic reconfigure (depth) parameter's callback", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_vj_detector": ["*******************************************************************", "", " ROS_ERROR(\"%s\", cascade_path.c_str());", "", "", "/ Clear vector of faces before using it for the current frame", "", "", " Normalize probability to [-1,1]", " Normalize probability to [0,1]", "", "/ Find the faces in the frame:", "/ Process face by face:", "/ Add every element created for each frame, to the total amount of faces", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_image_processor": ["*******************************************************************", "/ Message alert creation", "/ Debug purposes", "/ Debug image", " Convert the image into a message", " Publish the image message", " VictimPOIPtr temp(new VictimPOI);", " center of frame???", " center of frame???]", " ......", " vector??", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_image_preprocessor": ["*******************************************************************", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_postprocessor": ["*******************************************************************", " namespace pandora_vision_victim", " namespace pandora_vision"], "rgb_feature_extraction": ["*******************************************************************", "", "", " TO DO(Vassilis Choutas) : Change to ROS_BREAK().", "", "", "/ Clear feature vector", "/ Extract Color Statistics features from RGB image", "/ Append Color Statistics features to RGB feature vector.", "/ Extract Edge Orientation features from RGB image", "/ Append Edge Orientation features to RGB feature vector.", "/ Extract Haralick features from RGB image", "/ Append Haralick features to RGB feature vector.", "/ Extract SIFT features from RGB image", "/ Append SIFT features to RGB feature vector.", "/ Extract HOG features from RGB image", "/ Append HOG features to RGB feature vector.", " Plot the features if the visualization flag is true.", " namespace pandora_vision_victim", " namespace pandora_vision"], "edge_orientation_extractor": ["*******************************************************************", "", " ROS_INFO(\"ENTER find edge features\");", "/ Block size", " ROS_INFO_STREAM(\"vector's size\"<< edgeFeatures->size() );", " ROS_INFO_STREAM(\"EdgeFeatures= \");", " for (int ii = 0; ii < edgeFeatures.size(); ii++)", " ROS_INFO_STREAM( \" \" << edgeFeatures[ii]);", "", " ROS_INFO(\"ENTER PARTITION\");", " std::vector<double> edgeFeatures;", "!< Do stuff with subblock here", "", " ROS_INFO(\"ENTER FIND LOCAL EDGE\");", "/ Build a vector of the same size of the image and 5 dimensions", "/ to save the gradients", "/  Define the Scharr filters for the 5 types of edges", "/ Iterate over the posible directions and apply the filters", "/ Calculate the max sobel gradient and save the type of the orientation", "/ Detect the edges", "/ multiply against the types of orientations detected by the Sobel masks", "/ Establish the number of bins", "/ Set the range", "/ save the final edgeFeatures for the 5 types of oriented gradients", " std::vector<double> edgeFeatures(5);", " (*localEdgeFeatures)[ii-1]=hist.at<float>(ii) / (data.rows *data.cols);", "", " cv::Point anchor(kernel.cols - kernel.cols / 2 - 1,", "                 kernel.rows - kernel.rows / 2 - 1);", " cv::flip(kernel,kernel, -1);", "", "/ visualize each bin", " namespace pandora_vision_victim", " namespace pandora_vision"], "channels_statistics_extractor": ["*******************************************************************", "", "/ Transform it to HSV", "/ Preprocess current image to find histograms in HSV planes.", "/ Separate the image in 3 single-channel matrices, one for each of the", "/ Hue, Saturation and Value components.", "/ Set the ranges for each color component.", "/ Compute the histograms for every color component.", "/ Find the mean value and standard deviation value of every color", "/ component.", "/ Find the dominant color component and their density values", "/ Compute the first 6 Fourier Transform coefficints of the", "/ Hue and Saturation color components.", "/ Compute the colour angles of the R, G, B color components.", "/ Append all features to the output feature vector.", "", "/ Set the histogram ranges.", "/ Compute the histograms for every color component.", "/ Find the mean and standard deviation value of the image.", "/ Find the dominant color and its density value.", "/ Compute the first 6 Fourier Transform coefficints of the image.", "/ Append all features to the output feature vector.", " namespace pandora_vision_victim", " namespace pandora_vision"], "depth_feature_extraction": ["*******************************************************************", "", "", " TO DO(Vassilis Choutas) : Change to ROS_BREAK().", "", "", "/ Clear feature vector", "/ Extract Color Statistics features from Depth image", "/ Append Color Statistics features to Depth feature vector.", "/ Extract Edge Orientation features from Depth image", "/ Append Edge Orientation features to Depth feature vector.", "/ Extract Haralick features from Depth image", "/ Append Haralick features to Depth feature vector.", "/ Extract SIFT features from Depth image", "/ Append SIFT features to Depth feature vector.", "/ Extract HOG features from Depth image", "/ Append HOG features to Depth feature vector.", " namespace pandora_vision_victim", " namespace pandora_vision"], "sift_extractor": ["*******************************************************************", "", "", "", "", "", " cv::Mat imageWithKeyPoints;", " cv::drawKeypoints(inImage, keyPoints, imageWithKeyPoints, cv::Scalar::all(-1),", " cv::DrawMatchesFlags::DEFAULT);", " cv::imshow(\"Image Keypoints\", imageWithKeyPoints);", " cvWaitKey(0);", " namespace pandora_vision_victim", " namespace pandora_vision"], "histogram_extractor": ["*******************************************************************", "", "", " Copy the channel vector.", " Get the histogram dimensions.", " Copy the histogram size in each dimension.", " Copy the range of the histogram for each channel.", " Convert the input color code to an OpenCV compliant format.", " Flag that specifies whether a joint histogram will be used.", "", " Go through the node", " Go through the node", "", " If no successful comparison was made the return a negative code", " so as to inform the feature extractor that no conversion should be", " made.", "", " The image that will be processed to produced the histogram features.", " Convert the image to another color space if necessary.", " Split the image into separate channels.", " The final vector that will contain the histograms.", " Define the ranges for the histogram.", " Calculate the histogram for the current channel.", " Normalize the histogram to convert it to a probability", " distribution.", " Store the resulting histogram.", " Concatenate the histograms so as to form a compact feature vector.", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "feature_extraction": ["*******************************************************************", "", "", "", "", "", "", "", "", "", "", "", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "haralickfeature_extractor": ["*******************************************************************", "", "", "", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(sum[0]);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(sum);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(sum);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(variance);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(corr);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(temp);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(totalSum[0]);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " double f7 = _haralickFeatures[6];", " _haralickFeatures.push_back(sum);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(sum);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(f10);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(sum);", "", "murphylab.web.cmu.edu/publications/boland/boland_node26.html", " _haralickFeatures.push_back(f12);", " _haralickFeatures.push_back(f13);", "", " ROS_INFO(\"ENTER FIND HARALICK\");", " namespace pandora_vision_victim", " namespace pandora_vision"], "hog_extractor": ["*******************************************************************", "", "", "", "", " TODO(Miltos/Vassilis) Check if HOG works with RGB image.", " TODO(Miltos/Vassilis) Check proper size.", " namespace pandora_vision_victim", " namespace pandora_vision"], "color_angles_extractor": ["*******************************************************************", "", "", "", "/ Separate the image in 3 matrices, one for each of the R, G, B channels", "/ Compute the average pixel value of each r,g,b color component", "/ Obtain zero-mean colour vectors r0, g0 and b0 by subtracting the", "/ corresponding average pixel value of each original color vector", " */", "/ Compute the dot product of the RGB color components", " */", "/ Compute the lengh of the color angle vector", " */", " */", " */", "/ Compute the color angles", " */", "/ Normalised intensity standard deviation", "/ Transform the src image to grayscale", "/ Compute the mean intensity value", "/ Find the maximum intensity value", "/ Construct the final feature vector", " namespace pandora_vision_victim", " namespace pandora_vision"], "mean_std_dev_extractor": ["*******************************************************************", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "dft_coeffs_extractor": ["*******************************************************************", "", "", "", "/ Expand input image to optimal size", "/ On the border add zero values", "/ Add to the expanded another plane with zeros", "/ This way the result may fit in the source matrix", "/ Normalize the dft coeffs", "/ Compute the magnitude", " planes[0] = Re(DFT(I), planes[1] = Im(DFT(I))", "/ planes[0] = magnitude", " namespace pandora_vision_victim", " namespace pandora_vision"], "dominant_color_extractor": ["*******************************************************************", "", "", "", " */", "/ Image contains the image histogram, not the actual image.", " namespace pandora_vision_victim", " namespace pandora_vision"], "neural_network_validator": ["*******************************************************************", "", "", "", "", " const CvMat* layerSizes = neuralNetworkValidator_.get_layer_sizes();", " std::cout << layerSizes-><int>(0,0) << std::endl;", " namespace pandora_vision_victim", " namespace pandora_vision"], "random_forests_validator": ["*******************************************************************", "", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "validator_factory": ["*******************************************************************", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "neural_network_classifier": ["*******************************************************************", "", " Iterate over the parameter YAML file to get the size for each layer", " of the ANN.", " Get the parameters of  the sigmoid function.", " Parse the learning rate parameter", " Get the maximum number of iterations for the training of the network.", " Get the maximum number of iterations for the training of the network.", " TO DO(Vassilis Choutas): Add RLProp parameters", " If the training algorithm is not the back propagation algorithm", " then we must get the rest of the parameters for RPROP algorithm.", " Initialize the training algorithm's termination criteria.", " Initialize the pointer to the Neural Network Classifier object.", " Create the Neural Network with the specified topology.", " End of NeuralNetworkClassifier Constructor", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "abstract_validator": ["*******************************************************************", "", " Make features matrix a row vector.", "/ Normalize the data", " Make features matrix a row vector.", "/ Normalize the data", " namespace pandora_vision_victim", " namespace pandora_vision"], "victim_training_node": ["*******************************************************************"], "rgbd_svm_validator": ["*******************************************************************", "", "", "", "", "", " Normalize probability to [-1,1]", " Normalize probability to [0,1]", " namespace pandora_vision_victim", " namespace pandora_vision"], "svm_classifier": ["*******************************************************************", "", "!< POLY", "!< POLY/RBF/SIGMOID", "!< POLY/SIGMOID", "!< CV_SVM_C_SVC, CV_SVM_EPS_SVR, CV_SVM_NU_SVR", "!< CV_SVM_NU_SVC, CV_SVM_ONE_CLASS, CV_SVM_NU_SVR", "!< CV_SVM_EPS_SVR", "!< CV_SVM_C_SVC", " CvParamGrid CvParamGrid_C(pow(2.0,-5), pow(2.0,15), pow(2.0,2));", " CvParamGrid CvParamGrid_gamma(pow(2.0,-20), pow(2.0,3), pow(2.0,2));", " if (!CvParamGrid_C.check() || !CvParamGrid_gamma.check())", " std::cout << \"The grid is NOT VALID.\" << std::endl;", "", "", "", " uncomment for ONE_CLASS SVM", " for (int ii = 0; ii < results.rows; ii++)", " for (int jj = 0; jj < results.cols; jj++)", " if(results.at<float>(ii, jj) == 0)", " results.at<float>(ii, jj) = -1;", " namespace pandora_vision_victim", " namespace pandora_vision"], "abstract_classifier": ["*******************************************************************", "", " + \"/Training_Images\";", " const std::string trainingDatasetPath = datasetPath_ + \"/Training_Images\";", " + \"/Test_Images\";", " const std::string testDatasetPath = datasetPath_ + \"/Test_Images\";", "", "", "", "", "", "", "", " Start Training Process", " namespace pandora_vision_victim", " namespace pandora_vision"], "random_forests_classifier": ["*******************************************************************", "", " const float priors[] = {1, 1};", " Initialize the pointer to the Random Forests Classifier object.", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "classifier_factory": ["*******************************************************************", "", " Structs for calculating elapsed time.", " Train the system", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "rgb_random_forests_classifier": ["*******************************************************************", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "rgbd_svm_classifier": ["*******************************************************************", "", "!< POLY", "!< POLY/RBF/SIGMOID", "!< POLY/SIGMOID", "!< CV_SVM_C_SVC, CV_SVM_EPS_SVR, CV_SVM_NU_SVR", "!< CV_SVM_NU_SVC, CV_SVM_ONE_CLASS, CV_SVM_NU_SVR", "!< CV_SVM_EPS_SVR", "!< CV_SVM_C_SVC", " CvParamGrid CvParamGrid_C(pow(2.0,-5), pow(2.0,15), pow(2.0,2));", " CvParamGrid CvParamGrid_gamma(pow(2.0,-20), pow(2.0,3), pow(2.0,2));", " if (!CvParamGrid_C.check() || !CvParamGrid_gamma.check())", " std::cout << \"The grid is NOT VALID.\" << std::endl;", "", "", "", "", " uncomment for ONE_CLASS SVM", " for (int ii = 0; ii < results.rows; ii++)", " for (int jj = 0; jj < results.cols; jj++)", " if(results.at<float>(ii, jj) == 0)", " results.at<float>(ii, jj) = -1;", "", " Start Training Process", " std::cout << \"results\" << results.size() << std::endl << results <<std::endl <<std::endl;", " namespace pandora_vision_victim", " namespace pandora_vision"], "svm_validator": ["*******************************************************************", "", "", "", "", "", " Normalize probability to [-1,1]", " Normalize probability to [0,1]", " namespace pandora_vision_victim", " namespace pandora_vision"], "feature_extraction_utilities": ["*******************************************************************", "", "", "", "", "", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "principal_component_analysis": ["*******************************************************************", "", " namespace pandora_vision_victim", " namespace pandora_vision"], "bag_of_words_trainer": ["*******************************************************************", "", "", "", "", "", "", "", "", "", " Initialize the window where the histogram will be displayed.", " Initialize the window dimensions.", " Create the canvas where the descriptor/histogram of visual words", " will be drawn.", " namespace pandora_vision_victim", " namespace pandora_vision"], "file_utilities": ["*******************************************************************", "", "", "", "", "", "", "", "", " if the file was not found, then file is 0, i.e. !file=1 or true", " the file was not found", " if the file was found, then file is non-0", " the file was found", "", "", " */", "", " namespace file_utilities", " namespace pandora_vision_victim", " namespace pandora_vision"], "platt_scaling": ["*******************************************************************", " Maximal number of iterations", " Minimal step taken in line search", " For numerically strict PD of Hessian", " Initial Point and Initial Fun Value", " Update Gradient and Hessian (use H' = H + sigma I)", " numerically ensures strict PD", " Stopping Criteria", " Finding Newton direction: -inv(H') * g", " Line Search", " New function value", " Check sufficient decrease", " namespace pandora_vision_victim", " namespace pandora_vision"], "haralickfeature_extractor_test": ["*******************************************************************", "", "/ Sets up images needed for testing", " Construct a black image", " set the blackGLCM matrix", " std::cout << \"blackGLCM= \" << std::endl << \" \" << blackGLCM << std::endl << std::endl;", " Construct a white image", " std::cout << \"white= \" << std::endl << \" \" << white << std::endl << std::endl;", " set the whiteGLCM matrix", " std::cout << \"whiteGLCM= \" << std::endl << \" \" << whiteGLCM << std::endl << std::endl;", " Construct a horizontal edge image", " Construct a vertical edge image", " Image Dimensions", " Images that will be used for testing", "/ Tests HaralickFeaturesExtractor::calculateGLCM()", " The output image", " std::cout << \"out= \" << std::endl << \" \" << out << std::endl << std::endl;", " The output image", " std::cout << \"out= \" << std::endl << \" \" << out << std::endl << std::endl;", " The output feature", " std::cout << \"out= \" << std::endl << \" \" << out << std::endl << std::endl;", " compute angular second moment", " The output feature", " std::cout << \"out= \" << std::endl << \" \" << out << std::endl << std::endl;", " compute angular second moment", " namespace pandora_vision_victim", " namespace pandora_vision"], "sift_extractor_test": ["*******************************************************************", "/ The image used for testingg purposes.", "/ A pointer to the extractor siftExtractorTestFixture_ that will be tested.", "/ The pointer the keypoint detector that produces the correct results.", "/ The pointer to the feature extractor that produces the correct", "/ results.", " Create the SIFT siftExtractorTestFixture_", " Create the SIFT keypoint detector.", " Create the SIFT feature extractor.", " Check that the image was read successfully.", " Convert the image to gray scale.", " End of SiftTest", " Convert the image to gray scale.", " End of DenseSiftTest", " namespace pandora_vision_victim", " namespace pandora_vision"], "histogram_extractor_test": ["*******************************************************************", " Initialize the ranges for the BGR color space.", " Initialize the ranges for the BGR color space.", " Initialize the ranges for the BGR color space.", " Initialize the ranges for the BGR color space.", " Get all the possible channel permutations.", " Store all the possible 2-permutations of the image channels.", " Store all the possible 3-permutations of the image channels.", " outputImage->setTo(static_cast<short unsigned int>(", " (range.first + range.second) / 2));", "", "/ The width_ of the test images.", "/ The height_ of the test images.", " Iterate over all the possible channel combinations.", " For each channel in the current configuration:", " Store the number of histogram bins that correspond to the current", " permutation of the image channels.", " Do the same for the range of values of each channel of the", " current color space. The resulting vector has size equal to two", " times the number of channels we want for our histogram. The even", " values are the lower bounds and the odd values are the upper bounds", " for each channel.", " Create the correct extractor for this configuration.", " Check that the histogram feature extractor has been created.", " Set the valid channels flag to add values only to the channels that", " will be tested in this iteration.", " If only one channel is tested then set the corresponding value.", " Set all the necessary channel flags.", " Create all possible combinations for the histogram range values", " for the current channel permutation.", " Calculate the true feature vector size.", " Iterate over all the above created values.", " Create a new test image by assigning non-zero values only to the", " designated channels in the provided ranges.", " Check that the returned vector has the size we expect.", " For each channel of the image that will be included in the", " histogram:", " Check if it is included.", " Get the position of the non-zero values for the histogram", " by finding the bin that corresponds to the values we assigned", " during the image creation.", " Add an offset so as to get to the correct block of the feature", " vector(the block that corresponds to the current channel).", " Update the offset by the number of bins.", " Clear the vectors so as to use them to set up the test for", " the next iteration.", " End of BGR color histogram extractor test.", " Iterate over all the possible channel combinations.", " For each channel in the current configuration:", " Store the number of histogram bins that correspond to the current", " permutation of the image channels.", " Do the same for the range of values of each channel of the", " current color space. The resulting vector has size equal to two", " times the number of channels we want for our histogram. The even", " values are the lower bounds and the odd values are the upper bounds", " for each channel.", " Create the correct extractor for this configuration.", " Check that the histogram feature extractor has been created.", " Set the valid channels flag to add values only to the channels that", " will be tested in this iteration.", " If only one channel is tested then set the corresponding value.", " Set all the necessary channel flags.", " Create all possible combinations for the histogram range values", " for the current channel permutation.", " Calculate the true feature vector size.", " Iterate over all the above created values.", " Create a new test image by assigning non-zero values only to the", " designated channels in the provided ranges.", " Check that the returned vector has the size we expect.", " For each channel of the image that will be included in the", " histogram:", " Check if it is included.", " Get the position of the non-zero values for the histogram", " by finding the bin that corresponds to the values we assigned", " during the image creation.", " Add an offset so as to get to the correct block of the feature", " vector(the block that corresponds to the current channel).", " Update the offset by the number of bins.", " Clear the vectors so as to use them to set up the test for", " the next iteration.", " End of HSV color histogram extractor test.", " Iterate over all the possible channel combinations.", " For each channel in the current configuration:", " Store the number of histogram bins that correspond to the current", " permutation of the image channels.", " Do the same for the range of values of each channel of the", " current color space. The resulting vector has size equal to two", " times the number of channels we want for our histogram. The even", " values are the lower bounds and the odd values are the upper bounds", " for each channel.", " Create the correct extractor for this configuration.", " Check that the histogram feature extractor has been created.", " Set the valid channels flag to add values only to the channels that", " will be tested in this iteration.", " If only one channel is tested then set the corresponding value.", " Set all the necessary channel flags.", " Create all possible combinations for the histogram range values", " for the current channel permutation.", " Calculate the true feature vector size.", " Iterate over all the above created values.", " Create a new test image by assigning non-zero values only to the", " designated channels in the provided ranges.", " Check that the returned vector has the size we expect.", " For each channel of the image that will be included in the", " histogram:", " Check if it is included.", " Get the position of the non-zero values for the histogram", " by finding the bin that corresponds to the values we assigned", " during the image creation.", " Add an offset so as to get to the correct block of the feature", " vector(the block that corresponds to the current channel).", " Update the offset by the number of bins.", " Clear the vectors so as to use them to set up the test for", " the next iteration.", " End of YCrCb color histogram extractor test.", " Iterate over all the possible channel combinations.", " For each channel in the current configuration:", " Store the number of histogram bins that correspond to the current", " permutation of the image channels.", " Do the same for the range of values of each channel of the", " current color space. The resulting vector has size equal to two", " times the number of channels we want for our histogram. The even", " values are the lower bounds and the odd values are the upper bounds", " for each channel.", " Create the correct extractor for this configuration.", " Check that the histogram feature extractor has been created.", " Set the valid channels flag to add values only to the channels that", " will be tested in this iteration.", " If only one channel is tested then set the corresponding value.", " Set all the necessary channel flags.", " Create all possible combinations for the histogram range values", " for the current channel permutation.", " Calculate the true feature vector size.", " Iterate over all the above created values.", " Create a new test image by assigning non-zero values only to the", " designated channels in the provided ranges.", " Check that the returned vector has the size we expect.", " For each channel of the image that will be included in the", " histogram:", " Check if it is included.", " Get the position of the non-zero values for the histogram", " by finding the bin that corresponds to the values we assigned", " during the image creation.", " Add an offset so as to get to the correct block of the feature", " vector(the block that corresponds to the current channel)", " Update the offset by the number of bins.", " Clear the vectors so as to use them to set up the test for", " the next iteration.", " End of CIELab color histogram extractor test.", " namespace pandora_vision_victim", " namespace pandora_vision"], "edge_orientation_extractor_test": ["*******************************************************************", "", "/ Sets up images needed for testing", " Construct a black image", " Construct a white image", " Construct a horizontal edge image", " Construct a vertical edge image", " Construct a 135-degree diagonal edge image", " Construct a 45-degree diagonal edge image", " Construct an image with a circle", " Construct a noisy image", "        cv::imshow(\"noisy\", noisy);", "cv::waitKey(0);", "/ Image Dimensions", "/ Images that will be used for testing", "/ Tests EdgeOrientationExtractor::findEdgeFeatures", " The output vector", " The output vector", " uncomment to visualize", " The output vector", " uncomment to visualize", " The output vector", " uncomment to visualize", " The output vector", " uncomment to visualize", " The output vector", " uncomment to visualize", " The output vector", "uncomment to vizualize", " The output vector", "uncomment to vizualize", " namespace pandora_vision_victim", " namespace pandora_vision"], "dominant_color_test": ["*******************************************************************", "", "/ Sets up images needed for testing", " Construct a black histogram", " Construct a white histogram", " Construct an ascending histogram", " Construct a descending histogram", "/ The histograms bins", "/ Image Dimensions", "/ Images that will be used for testing", "/ Tests DominantColorExtractor::extract", " The output vector", " namespace pandora_vision_victim", " namespace pandora_vision"], "mean_std_dev_test": ["*******************************************************************", "", "/ Sets up images needed for testing", " Construct a black image", " Construct a white image", " Construct a half black - half white image", "/ The image dimensions", "/ Images that will be used for testing", "/ Tests MeanStdDevExtractor::extract", " The output vector", " namespace pandora_vision_victim", " namespace pandora_vision"], "color_angles_test": ["*******************************************************************", "", "/ Sets up images needed for testing", " Construct a blue image", " Construct a green image", " Construct a red image", "/ Tests ColorAnglesExtractor::extract", " The output vector", " std::vector<double> out;", " ColorAnglesExtractor c1(&blue);  // , c2(&green), c3(&red);", " out = c1.extract();", " EXPECT_EQ(0, out[0]);", " EXPECT_EQ(0, out[1]);", " EXPECT_EQ(0, out[2]);", " EXPECT_EQ(0, out[3]);", " out = c2.extract();", " EXPECT_EQ(255, out[0]);", " EXPECT_EQ(0, out[1]);", " out = c3.extract();", " EXPECT_EQ(127.5, out[0]);", " EXPECT_EQ(127.5, out[1]);", " namespace pandora_vision_victim", " namespace pandora_vision"], "qrcode_detector": ["*******************************************************************", "", " Initiliaze the zbar scanner", "", "", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "qrcode_processor": ["*******************************************************************", "", "", " Get the image debug view flag.", "/ Get the buffer size parameter if available", "/ Get the difference threshold parameter if available", " Initiliaze the QR code detector.", "/ The dynamic reconfigure parameter's callback", "", "", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "qrcode_preprocessor": ["*******************************************************************", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "qrcode_node": ["*******************************************************************"], "qrcode_handler": ["*******************************************************************", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "qrcode_postprocessor": ["*******************************************************************", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "qrCode_detector_test": ["*******************************************************************", "", "", "/ Tests QrCodeDetector::detectQrCode", " there shouldn't be any qrcodes", " neither when 3 channels are used", " there shouldn't be any qrcodes", " Vertically concatenated", " there shouldn't be any qrcodes", " there shouldn't be any qrcodes", " there shouldn't be any qrcodes", " namespace pandora_vision_qrcode", " namespace pandora_vision"], "obstacle_postprocessor": ["*******************************************************************", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "obstacle_preprocessor": ["*******************************************************************", " ros::shutdown();", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "hard_obstacle_handler": ["*******************************************************************", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "hard_obstacle_postprocessor": ["*******************************************************************", "", " Get robot base footprint transform", " convert cells to meters", " transform from bottom-left corner of traversability map to base", " footprint", " transform from base footprint to map", " transform from map to bottom-left corner of slam map", " convert meters from bottom-left corner of slam map to coordinates", " obstacleDilation(output, 2, coords_map);", " That's foreground", " Check for all adjacent", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "dummy_processor": ["*******************************************************************", " namespace sensor_processor"], "hard_obstacle_node": ["*******************************************************************"], "hard_obstacle_preprocessor": ["*******************************************************************", " Convert the input Point Cloud to a local elevation map", " in the form of a occupancy Grid Map", " Find the known areas in the map.", " Normalize only the map elements that correspond to known cells.", " Set all unknown areas to 0 so that they appear as black.", "cv::imshow(\"Elevation Map Image\", colorMapImg);", "", " converting PointCloud2 msg format to pcl pointcloud format in order to read the 3d data", " Create the output Elevation Map", " Check if the current point has any NaN value.", " Check if the point is in the allowed distance range.", " Check if the z coordinate is within the specified range.", " If the current point is located higher that the higher point of the corresponding cell", " then substitute it.", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "traversability_mask": ["*******************************************************************", " Create the robot height mask.", " Calculate the values for the size of the robot parts.", " Initialize the mask of the robot.", " Assign the values for the motors of the robots.", " Top Left Barrels", " Top Right Barrels", " robotGeometryMask_->at<double>(i + wheelSize, j) = description_->barrelH;", " Top Right Barrel Height", " Bottom Left Barrels.", " Bottom Right Barrels.", " Robot sidelines.", " Robot Main body.", "", " Calculate the values for the size of the robot parts.", " Initialize the mask of the robot.", " Assign the values for the motors of the robots.", " Top Left Barrels", " Top Right Barrels", " robotGeometryMask_->at<double>(i + wheelSize, j) = description_->barrelH;", " Top Right Barrel Height", " Bottom Left Barrels.", " Bottom Right Barrels.", " Robot sidelines.", " Robot Main body.", "", " Calculate the current position of the Upper Left Wheel.", " Calculate the current position of the Lower Left Wheel.", " Calculate the current position of the Lower Right Wheel.", " Calculate the number of valid wheels.", " Get the mask for the left side of the robot", " Initialize the transformed map by creating a deep copy of the original.", " TODO(Vassilis Choutas): Check return values", " If no wheel position is know then mark the current point as unknown.", " else if (validWheelNum == 2) ", " {", " if (upperLeftWheelValid && upperRightWheelValid)", " {", " MatPtr tempMapPtr(new cv::Mat(*updatedMaskPtr,", " cv::Rect(0, 0, updatedMaskPtr->cols - 1, wheelSize)));", " // Get the mask for the top side of the robot.", " bool traversabilityFlag = findElevatedTopBottom(tempMapPtr, upperLeftWheelMeanHeight,", " upperRightWheelMeanHeight, wheelCenterDist);", " // If the return value is false then it that point is not traversible.", " if (!traversabilityFlag)", " return occupiedArea;", " validAreaWidth += updatedMaskPtr->cols - 1;", " validAreaHeight += wheelSize;", " // Get the Position of the the barrels that are located below the forward wheels.", " cv::Point leftBarrelPos(", " metersToSteps(center_.x - description_->robotD / 2 - description_->barrelD", " - description_->wheelD),", " metersToSteps(center_.y - description_->robotD / 2 - description_->barrelD));", " cv::Point rightBarrelPos(", " metersToSteps(center_.x + description_->robotD / 2 + description_->barrelD),", " metersToSteps(center_.y - description_->robotD / 2 - description_->barrelD));", " double upperLeftBarrelMeanHeight, upperLeftBarrelStdDev;", " bool upperLeftBarrelValid = findHeightOnWheel(leftBarrelPos, &upperLeftBarrelMeanHeight,", " &upperLeftBarrelStdDev);", " double upperRightBarrelMeanHeight, upperRightBarrelStdDev;", " bool upperRightBarrelValid = findHeightOnWheel(rightBarrelPos, &upperRightBarrelMeanHeight,", " &upperRightBarrelStdDev);", " if (upperLeftBarrelValid && upperRightBarrelValid)", " {", " // Update the values for the elevated mask for the barrel area.", " tempMapPtr.reset(new cv::Mat(*updatedMaskPtr,", " cv::Rect(0, wheelSize, updatedMaskPtr->cols - 1, barrelSize)));", " traversabilityFlag = findElevatedTopBottomBody(tempMapPtr, upperLeftBarrelMeanHeight,", " upperRightBarrelMeanHeight, wheelCenterDist);", " if (!traversabilityFlag)", " return occupiedArea;", " validAreaHeight += barrelSize;", " // Get the Position of the upper half of the robot body located below .", " cv::Point leftBodyPartPos(", " metersToSteps(center_.x - description_->robotD / 2 - description_->barrelD", " - description_->wheelD),", " metersToSteps(center_.y - description_->robotD / 2));", " cv::Point rightBodyPartPos(", " metersToSteps(center_.x + description_->robotD / 2 + description_->barrelD),", " metersToSteps(center_.y - description_->robotD));", " double upperLeftBodyPartMeanHeight, upperLeftBodyPartStdDev;", " bool upperLeftBodyPartValid = findHeightOnWheel(leftBodyPartPos, &upperLeftBodyPartMeanHeight,", " &upperLeftBodyPartStdDev);", " double upperRightBodyPartMeanHeight, upperRightBodyPartStdDev;", " bool upperRightBodyPartValid = findHeightOnWheel(rightBodyPartPos, &upperRightBodyPartMeanHeight,", " &upperRightBodyPartStdDev);", " // Check that the upper half parts of the robot are within a known area of the elevation map", " if (upperLeftBodyPartValid && upperRightBodyPartValid)", " {", " tempMapPtr.reset(new cv::Mat(*updatedMaskPtr,", " cv::Rect(0, wheelSize + barrelSize, updatedMaskPtr->cols - 1, robotDSize / 2)));", " traversabilityFlag = findElevatedTopBottomBody(tempMapPtr, upperRightWheelMeanHeight,", " lowerRightWheelMeanHeight, wheelCenterDist);", " // If the upper half of the main robot body is not located in a valid area", " // then mark the point as occupied.", " if (!traversabilityFlag)", " return occupiedArea;", " validAreaHeight += robotDSize / 2;", " }", " }", " // Extract the elevation map area that corresponds to the valid part of the mask.", " cv::Mat validElevationMapOverlap =", " (*elevationMapPtr_)(cv::Rect(center_.x - robotDSize / 2 - barrelSize - wheelSize,", " center_.y -  - robotDSize / 2 - barrelSize - wheelSize, validAreaWidth, validAreaHeight));", " // Create a shallow copy of the valid region of the transformed robot height mask.", " cv::Mat validMask = (*updatedMaskPtr)(cv::Rect(validAreaTopLeftX, validAreaTopLeftY,", " validAreaWidth, validAreaHeight));", " cv::Mat diff = validMask - validElevationMapOverlap;", " cv::Mat result = diff <= 0 & validElevationMapOverlap != unknownArea;", " if (cv::countNonZero(result) > 0)", " return occupiedArea;", " else", " {", " if (cv::countNonZero(validElevationMapOverlap == - std::numeric_limits<double>::max()) == 0)", " return freeArea;", " else", " return unknownArea;", " }", " }  // End_if : Only top wheels on known elevation.", " if (lowerLeftWheelValid && lowerRightWheelValid)", " {", " }", " if (upperLeftWheelValid && lowerLeftWheelValid)", " {", " }", " if (upperRightWheelValid && lowerRightWheelValid)", " {", " }", " }", " else if (validWheelNum == 3)", " {", " } ", " If all the wheels are on a known area of the elevation Map.", " Calculate the mask for the left side of the robot.", " Get the mask for the right side of the robot.", " Get the mask for the top side of the robot.", " Get the mask for the bottom side of the robot.", " Decide about binary traversability", " Extract the elevation map area that corresponds to the valid part of the mask.", " Create a shallow copy of the valid region of the transformed robot height mask.", " End of findTraversability", "", "", "", " Interpolate the mask values to get the robot's local estimated elevation.", "", " Convert the size of the wheel from distance units to the number of cells", " it corresponds using the current elevation map resolution.", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", " Find the wheel that is located higher", " Convert the size of the wheel from distance units to the number of cells", " it corresponds using the current elevation map resolution.", " Find the wheel that is located higher", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", " Convert the size of the wheel from distance units to the number of cells", " it corresponds using the current elevation map resolution.", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", " Find the wheel that is located higher", " Convert the size of the wheel from distance units to the number of cells", " it corresponds using the current elevation map resolution.", " Find the wheel that is located higher", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", " Iterate over the section of the mask for the current pair of wheels", " and update their corresponding values.", " Reject slopes greater than the maximum possible angle.", "", " Copy the region of the elevation map that corresponds to the current wheel.", "if ()", "{", "  }", "else", "{", "}", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "hard_obstacle_detector": ["*******************************************************************", " Minimum acceptable value for the process to work properly", " Load the robot's description and create it's 2d Elevation Mask.", " ROS_INFO(\"Finished loading robot description and creating robot mask!\");", " Check if input type is CV_64FC1", " Show the input image", " *elevationMapPtr_ = inputImage;", " Pass the unknown areas in edges image.", " Pass the robot mask on the complete area that was made.", "", " Initialize the output traversability map", " Set all of it's cells to unknown.", " Iterate over the map", " Check that we are on a valid cell.", "", " Initialize the output traversability map", " Set all of it's cells to unknown.", " Iterate over the map", " this is y", " this is x", " for (int ii = local_radius; ii < nonTraversableRowPoints.rows - local_radius; ++ii) {", " for (int jj = local_radius; jj < nonTraversableRowPoints.cols - local_radius; ++jj) {", " if (static_cast<int8_t>(nonTraversableRowPoints.at<uchar>(ii, jj)) == occupiedArea)", " (static_cast<int8_t>(nonTraversableRowPoints.at<uchar>(ii, jj)) == freeArea))", "       { ", " double maxHeight = -std::numeric_limits<double>::max();", " double minHeight = std::numeric_limits<double>::max();", " double mean = 0.0;", " int count = 0;", " for (double theta = 0; theta < 2 * CV_PI; theta += 0.2) {", " int iic = ii + static_cast<int>(cos(theta) * local_radius);", " int jjc = jj + static_cast<int>(sin(theta) * local_radius);", " double height = inputImage.at<double>(iic, jjc);", " if (height != -std::numeric_limits<double>::max())", " {", " mean += height;", " count++;", " if (height > maxHeight) maxHeight = height;", " if (height < minHeight) minHeight = height;", " }", " }", " // Escape if information is not considered sufficient", " if (count < static_cast<int>((2 * CV_PI / 0.2) / 2))", " continue;", " mean /= count;", " double heightDiff = inputImage.at<double>(ii, jj) - mean;", " // Escape if edge point does not lie in high ground... (error)", " if (heightDiff <= 0)", " continue;", " if (heightDiff <= height_diff_)", " {", " traversabilityMap->at<int8_t>(ii, jj) = freeArea;", " continue;", " }", " // Escape if max is smaller than min", " if (maxHeight < minHeight)", " continue;", " double grad = maxHeight - minHeight;", " if (grad >= grad_diff_)", " {", " traversabilityMap->at<int8_t>(ii, jj) = freeArea;", " // continue;", " }", " // Edge is definetely a hard obstacle", " // occupiedPoints.push_back(cv::Point(jj ,ii));", " }", " }", " }", " for (int ii = local_radius; ii < nonTraversableColPoints.rows - local_radius; ++ii) {", " for (int jj = local_radius; jj < nonTraversableColPoints.cols - local_radius; ++jj) {", " if ((static_cast<int8_t>(nonTraversableColPoints.at<uchar>(ii, jj)) == rampArea) ||", " (static_cast<int8_t>(nonTraversableColPoints.at<uchar>(ii, jj)) == freeArea))", " {", " double maxHeight = -std::numeric_limits<double>::max();", " double minHeight = std::numeric_limits<double>::max();", " double mean = 0.0;", " int count = 0;", " for (double theta = 0; theta < 2 * CV_PI; theta += 0.2) {", " int iic = ii + static_cast<int>(cos(theta) * local_radius);", " int jjc = jj + static_cast<int>(sin(theta) * local_radius);", " double height = inputImage.at<double>(iic, jjc);", " if (height != -std::numeric_limits<double>::max())", " {", " mean += height;", " count++;", " if (height > maxHeight) maxHeight = height;", " if (height < minHeight) minHeight = height;", " }", " }", " // Escape if information is not considered sufficient", " if (count < static_cast<int>((2 * CV_PI / 0.2) / 2))", " continue;", " mean /= count;", " double heightDiff = inputImage.at<double>(ii, jj) - mean;", " // Escape if edge point does not lie in high ground... (error)", " if (heightDiff <= 0)", " continue;", " if (heightDiff <= height_diff_)", " continue;", " // Escape if max is smaller than min", " if (maxHeight < minHeight)", " continue;", " double grad = maxHeight - minHeight;", " if (grad >= grad_diff_)", " continue;", " // Edge is definetely a hard obstacle", " traversabilityMap->at<int8_t>(ii, jj) = occupiedArea;", " // occupiedPoints.push_back(cv::Point(jj ,ii));", " }", " }", "   } ", "***************************************************************************", " If value is negative, make it green for visualization", "cv::imshow(title, scaledImage);", " If the map value is unknown then paint it black.", " Paint the occupied Areas red", " Paint the free areas blue", "cv::imshow(\"Traversability Map\", traversabilityVisualization);", "", " Use opencv function for visualization", " Convert CV_8UC1 to CV_8UC3", " use Opencv function for visualization", " If value is negative give color", " Check the probability of the pixel and give color for visualization", " Give Red color", " Give Yellow color", " Give Blue color", "cv::imshow(title, scaledImage);", "***************************************************************************", " Pass from the input mat the negative values as our policy dictates.", " If negative values in the input image, convert them to -1.", " Visualization of unknown areas based on their optimistic probabilities", " After convolution there might be negative values, so we need", " to set them to -1.", "***************************************************************************", " Reduce the noise of the input Image", " Detect edges with canny", " Reduce the noise of the input image", " Gradient X", "        src, dst, ddepth, 1, 0, scale, delta, border_type", " Gradient Y", "        src, dst, ddepth, 1, 0, kernelSize, scale, delta, border_type", " Total Gradient (approximate)", " Reduce the noise of the input image", " Gradient X", "        src, dst, ddepth, 1, 0, kernelSize, scale, delta, border_type", " Gradient Y", "        src, dst, ddepth, 1, 0, kernelSize, scale, delta, border_type", " Total Gradient (approximate)", " Apply threshold to the edges", " Convert the type of the output image to CV_64FC1.", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "hard_obstacle_processor": ["*******************************************************************", " Debug show parameters", " Edge detection parameters", " Canny parameters", " NODELET_INFO(\"[%s] In process\", this->getName().c_str());", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "barrel_handler": ["*******************************************************************", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "barrel_processor": ["*******************************************************************", " ROS_INFO(\"Starting bag read\");", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "barrel_node": ["*******************************************************************"], "fast_symmetry_detector": ["*******************************************************************", " Pre calculate rotation matrices from -90 deg to 90 deg (actually to 89 deg) ", "", " Get the cos and sin values from our pre-calculated rotation matrices ", " Reset our row pointers to start of each row in rotated edges matrix ", " Now append the corresponding rho values of the rotated edges ot rotated edges matrix ", "", " Make sure that we reset the accumulation matrix and rotated edges matrix ", " Find all the pixels of the edges ", " Translate them in relation to center of the image ", " For each degree of rotation ", " Rotate edge to that degree ", " Ignore edges that have smaller number of pairings ", " Vote for Hough matrix ", "", "", " Make sure that we have appropriate peaks ", " Pre-set the size of the neighbors ", " Find the peak from the Hough accumulation matrix ", " Convert from Hough space back to x-y space ", " Try to zero out the peak and the neighborhood of the peak, so that ", " we can move on to find the second highest peak ", " Handles the edge case that wraps around the matrix ", "", " return pair<Point, Point> { p0, p1, };", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "barrel_detector": ["*******************************************************************", "", " Determine the shape of Hough accumulationmatrix ", " temp.convertTo(depth8UC3, CV_8UC3, 255);", " Find the edges ", " Vote for the accumulation matrix ", " Draw the symmetrical line ", " float len1 = std::sqrt(result[i].first.x * result[i].first.x + result[i].first.y * result[i].first.y);", " float len2 = std::sqrt(result[i].second.x * result[i].second.x + result[i].second.y * result[i].second.y);", " float dot = result[i].first.x * result[i].second.x + result[i].first.y * result[i].second.y;", " float a = dot / (len1 * len2);", " float angle;", " if (a >= 1.0)", "   angle = 0.0;", " else if (a <= -1.0)", "   angle = 3.14;", " else", "   angle = std::acos(a); //  0..PI", " angle = angle * 180 / 3.14;", " cv::line(depth8UC3, result[i].first, result[i].second, cv::Scalar(0, 0, 255), 2);", " cv::rectangle(depth8UC3,", "     cv::Point(result[i].second.x - maxDist / 2, result[i].second.y),", "     cv::Point(result[i].first.x + maxDist / 2, result[i].first.y),", "     cv::Scalar(255, 0, 0),", "     2);", "  cv::line(temp, s3, s2, cv::Scalar(0, 255, 0), 2);", " Visualize the Hough accum matrix ", " cv::Mat accum = detector.getAccumulationMatrix();", " accum.convertTo(accum, CV_8UC3);", " cv::applyColorMap(accum, accum, cv::COLORMAP_JET);", " cv::resize(accum, accum, cv::Size(), 2.0, 0.5);", " /* Draw lines based on cursor position */", " if (accumIndex.x != -1 && accumIndex.y != -1)", " {", "   std::pair<cv::Point, cv::Point> pointPair = detector.getLine(accumIndex.y, accumIndex.x);", "   cv::line(depth8UC3, pointPair.first, pointPair.second, CV_RGB(0, 255, 0), 2);", " }", " Show the original and edge images ", "  cv::Mat appended = cv::Mat::zeros(depth8UC3.rows + accum.rows, depth8UC3.cols * 2, CV_8UC3);", "  depth8UC3.copyTo(cv::Mat(appended, cv::Rect(0, 0, depth8UC3.cols, depth8UC3.rows)));", "  cv::cvtColor(edge, cv::Mat(appended, cv::Rect(depth8UC3.cols, 0, edge.cols, edge.rows)), CV_GRAY2BGR);", "  accum.copyTo(cv::Mat(appended, Rect(0, depth8UC3.rows, accum.cols, accum.rows)));", "  cv::imshow(\"Candidate Barrel\", appended);", "", "  Validate based on variance in RGB ROI", " (*valid) = false;", "  Validate that through the symmetry line we have almost", "  constant depth", " (*valid) = false;", "  Rotate vector 90 degrees clockwisely", "  A point on the symmetry line", " ROS_INFO(\"%f, %f\", slope.x, slope.y);", "  In order to calculate circularity place points of the perpendicular", "  line into a vector", "  Ignore values at the border", " Used to spot extreme values, in order to remove them from calculations", "  calculate differentiation of depth values, through the perpendicular", "  line(s) for the left side of the barrel and the right side of the", "  barrel. Calculate avg of differentiation for left and right side", "  separately.", " avgLeftLinePoint = sumLeftLine;", " avgRightLinePoint = sumRightLine;", "  We expect that starting from the left side of the barrel,", "  we have a decreasing depth up to the peak of the barrel", "  (negative differential avg), and then increasing depth.", " (*valid) = false;", "  We must have a symmetry between the differential avgs of the", "  left and right sides of the barrel.", " (*valid) = false;", " Check if some of the points belong to a circle curve", " Firstly get an approximation of the center of the curve, thus", " approximate radius", " s1 is the coordinates of the center (this point is located on the symmetry line)", " so approximate radius as the difference of this point (on a barrel this point", " will have the smallest depth, same as all points on the symmetry line) and the", " point of the biggest depth inside the roi, hopefully it will be a point on the", " wall, but there is no problem if it is on the barrel.", " (*valid) = false;", " Eliminate corners with Harris Corner Detector", " cv::cvtColor(rgbImage, gray, CV_BGR2GRAY);", " dst = cv::Mat::zeros(rgbImage.size(), CV_32FC1);", " Detecting corners", " Normalizing", " (*valid) = false;", " Validation based on specific barrels' color", " convert RGB image into HSV image", " cv::inRange(hImage, iLowH, iHighH, binary);", " For RED define one second threshold", " cv::inRange(hImage, iLowH, iHighH, binaryTemp);", " (*valid) = false;", " cv::inRange(hsvImage, cv::Scalar(iLowH, iLowS, iLowV), cv::Scalar(iHighH, iHighS, iHighV), binary);  // red*/", "", " Calculate unit normal vector for the circle's plane. Consider", " third coordinate zero based on the assumption that the depth", " between two points on the symmetry line remains constant", " Calculate unit vector from center to a point on the circle, consider", " this point to be at the center of the symmetry line, thus having same", " x, y coordinates as the center point", " Calculate cross product of N and U", " Check if point belongs to the circle equation", " Find the avg error between the point and the equation", "/ Find depth distance", "", "", " Find the depth distance of the soft obstacle", " ROS_INFO(\"barrel found\");", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "parameters": ["*******************************************************************", "", "////////////////// Blob detection - specific parameters ////////////////////", "/////////////////////// Debug-specific parameters //////////////////////////", " Publish the enhanced Images", " Show the depth image that arrives in the depth node", " Show the thermal image that arrives in the thermal node", " Show the rgb image that arrives in the rgb node", " Show the holes that each of the depth and RGB nodes transmit to the", " hole fusion node, on top of their respective origin images", " Show all valid holes, from either the Depth or RGB source, or", " the merges between them", " The product of this package: unique, valid holes", " In the terminal's window, show the probabilities of candidate holes", " Show the texture's watersheded backprojection", "///////////////// Parameters specific to the Depth node ////////////////////", " The interpolation method for noise removal", " 0 for averaging the pixel's neighbor values", " 1 for brushfire near", " 2 for brushfire far", "//////////////// Parameters pecific to the Thermal node ////////////////////", " The thermal detection method", " If set to 0 process the binary image acquired from temperatures MultiArray", " If set to 1 process the sensor/Image from thermal sensor", " The probability extraction method", " 0 for Gaussian function", " 1 for Logistic function", " Gausian variables", " Logistic variables", "/////////// Parameters of acceptable temperature for threshold /////////////", "//////////////////// Parameters of the thermal image ///////////////////////", "/////////////////// Edge detection specific parameters /////////////////////", " canny parameters", " The opencv edge detection method:", " 0 for the Canny edge detector", " 1 for the Scharr edge detector", " 2 for the Sobel edge detector", " 3 for the Laplacian edge detector", " 4 for mixed Scharr / Sobel edge detection", " Threshold parameters", " When mixed edge detection is selected, this toggle switch", " is needed in order to shift execution from one edge detector", " to the other.", " 1 for the Scharr edge detector,", " 2 for the Sobel edge detector", "/////////////////////  Histogram related parameters ////////////////////////", "//////////////////////// Filters-related parameters ////////////////////////", " DepthDiff", " 0 for binary probability assignment on positive depth difference", " 1 for gaussian probability assignment on positive depth difference", " The mean stardard deviation for the normal distribution", " incorporated in the depth diff filter.", " Min difference in depth between the inside and the outside of a hole", " Max difference in depth between the inside and the outside of a hole", " DepthArea", " DepthHomogeneity", " RectanglePlaneConstitution", " IntermediatePointsPlaneConstitution", " ColourHomogeneity", " LuminosityDiff", " TextureDiff", " The threshold for texture matching regarding the intermediate points", " The threshold for texture matching reagrding the points inside the hole", " TextureBackprojection", "///////////////////// HoleFusion-specific parameters ///////////////////////", "-------------------------------- Validation --------------------------------", " The holes' validation process identifier", " When depth analysis is applicable", " When depth analysis is not applicable, we can only rely", " on RGB analysis", " Plane detection parameters", " Option to enable or disable the merging of holes", " Holes connection - merger", " Merger parameters", " The inflation size of holes' bounding rectangles", "//////////////// Image representation specific parameters //////////////////", " The depth sensor's horizontal field of view in rads", " The depth sensor's vertical field of view in rads", " Fallback values. See the input point cloud callback of the", " synchronizer node", " Depth and RGB images' representation method.", " 0 if image used is used as obtained from the image sensor", " 1 through wavelet analysis", " Method to scale the CV_32F image to CV_8UC1", " Term criteria for segmentation purposes", "///////////////// Outline discovery specific parameters ////////////////////", " The detection method used to obtain the outline of a blob", " 0 for detecting by means of brushfire", " 1 for detecting by means of raycasting", " When using raycast instead of brushfire to find the (approximate here)", " outline of blobs, raycast_keypoint_partitions dictates the number of", " rays, or equivalently, the number of partitions in which the blob is", " partitioned in search of the blob's borders", " Loose ends connection parameters", "////////////////// Parameters specific to the RGB node /////////////////////", " RGB image segmentation parameters", " Selects the method for extracting a RGB image's edges.", " Choices are via segmentation and via backprojection", " The threshold applied to the backprojection of the RGB image", " captured by the image sensor", " Parameters specific to the pyrMeanShiftFiltering method", " True to posterize the product of the segmentation", " FloodFill options regarding minimum and maximum colour difference", " Watershed-specific parameters", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "soft_obstacle_handler": ["*******************************************************************", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "soft_obstacle_detector": ["*******************************************************************", " First erode image to eliminate noise and then dilate", "/ Perform Hough Transform", "/ Keep only vertical lines", "!< The point that the line intersects with the x-axis", "/ If line is almost vertical and not close to image borders", " Add each point of the line to list of Points", "/ Calculate ROI probability", " The point inside this Rect is the roi center, now it is the", " upper left point in order to visualize", " Image should be continuous in order to be reshaped", " Get one sorted row of depth values", " Remove the zero values", " X coordinate of start and end point", "/ Find the position of the line in the list with the minimum and", "/ maximum x coordinate", " Find the line closest to the middle of the bounding box", " Y coordinate of start and end point", " First and Third point", " Second and Forth point", " Split vertically ROI to four parts", " not used", " Convert rgb image to grayscale", " Apply Histogram Equalization", " Blur image using Gaussian filter", " Perform DWT", " Normalize image [0, 255]", " Convert image to binary with Otsu thresholding", " Dilate Image", " Perform Hough Transform to detect lines (keep only vertical)", " Detect bounding box that includes the vertical lines", " Examine whether the points of the bounding box have difference in depth", " distance", " Find the new depth distance of the soft obstacle", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "soft_obstacle_processor": ["*******************************************************************", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "soft_obstacle_node": ["*******************************************************************"], "barrel_detector_test": ["*******************************************************************", "", "", "", "", " The images' width and height", " The images under processing", "", " Fill the inside of the desired rectangle with the @param rgbIn provided", "", " Fill the inside of the desired rectangle with the @param depthIn provided", "", " float step = 2 * (depthUpper - depthLower) / x;", " for (int rows = upperLeft.y; rows < upperLeft.y + y; rows++)", " {", "   // First decrement depth", "   for (int cols = upperLeft.x; cols < upperLeft.x + (x / 2); cols++)", "   {", "     image->at< float >(rows, cols) = depthUpper - (cols - upperLeft.x) * step;", "   }", "   // Then increment depth", "   for (int cols = upperLeft.x + (x / 2); cols < upperLeft.x + x; cols++)", "   {", "     image->at< float >(rows, cols) = depthLower + (cols - upperLeft.x - (x / 2)) * step;", "   }", " }", " ! Tests BarrelDetector::getSymmertyObject", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the depthImage to constant value", " Construct two vertical parallel symmetrical lines", " Construct a square", " cv::Mat square = cv::Mat::zeros(HEIGHT, WIDTH, CV_32FC1);", " BarrelDetectorTest::generateDepthRectangle", "  (cv::Point2f (WIDTH - 350, HEIGHT - 350),", "    310,", "    310,", "    0.9,", "    &square);", " depthImage += square;", " It is expected that the bounding box surrounds the square", " ! Tests BarrelDetector::validateROI", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the depthImage to constant value", " Construct the rgbImage. The entire image is at a colour of", " value approximate the the colour value of the images of walls", " Red", " Green", " Blue", " Construct a symmetric square with firstly decreasing and then increasing", " depth", " Construct the homogeneous RGB square", " It is expected that this object is verified as positive", " namespace pandora_vision"], "fast_symmetry_detector_test": ["*******************************************************************", "", "", "", " The images' width and height", " The image under processing", "", " Fill the inside of the desired rectangle with the @param rgbIn provided", "", " Fill the inside of the desired rectangle with the @param depthIn provided", " ! Tests FastSymmetryDetector::rotateEdges", " ! Tests FastSymmetryDetector::getMaxDistance", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the depthImage to constant value", " Determine the shape of Hough accumulationmatrix ", " edge.copyTo(temp1);", " Find the edges ", " Vote for the accumulation matrix ", " Get the symmetrical line ", " It is expected that the maximum distance will be zero, because no", " object has been found", " And the symmetric lines are also zero", " Construct a square", " edge.copyTo(temp1);", " Find the edges ", " Vote for the accumulation matrix ", " Get the symmetrical line ", " It is expected that the maximum distance between symmetric lines will", " be equal to the square's width or height", " It is expected that points of the symmetry line are at the center of", " the square (either vertically either horizontally)", " namespace pandora_vision"], "traversability_mask_test": ["*******************************************************************", " Set the robot dimensions.", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "soft_obstacle_detector_test": ["*******************************************************************", " Considering that a pixel has width and height equal to 1", " namespace pandora_vision_obstacle", " namespace pandora_vision"], "image_saver_by_topic": ["*******************************************************************", "", " The folder for the images to be saved", " The width for the image to be resized", " The height of the image to be resized", "! Initialization of the static members", "! Static initialization of the counter", "", " user press left button ", " user drag the mouse ", "img->copyTo(imgCopy);", " user release left button ", "! Cast counter to string", "! Produce image path", "! Resize if requested by the user", "! Save the image", "", "!< Current frame to be processed", "! Show the image", "~ cv::rectangle(current_frame, point, cv::Point(xx, yy), CV_RGB(255, 0, 0), 3, 8, 0);", "! Catch key presses in the opencv window  ", "! Saves the image", "! Cast counter to string", "! Produce image path", "! Resize if requested by the user", "! Save the image", "! Starts counting from 0", "", "! Check the arguments. If 3 no resizing is requested.", "! Argument parsing", "!< If arguments were 5 the resize operation was requested", "! Topic subscription"], "enhanced_image_shower": ["*******************************************************************", "", "!< Current frame to be processed", " cv::cvtColor(rgb_msg->image, temp, CV_BGR2RGB);", "", "! Argument parsing", "! Topic subscription"], "annotator_controller": ["****************************************************************************", "", "", "", "", "", "", "", "", "", "", "", "", " Load all messages", "", "", "", "loader_.statusLabel->setText(QString(img_name.c_str()));", "", "", "", "cv::cvtColor(in_msg->image, temp, CV_BGR2RGB); // cvtColor Makes a copt, that what i need", " enforce deep copy, see documentation", "", "", ",", "sensor_msgs::image_encodings::TYPE_8UC3);", "ROS_INFO_STREAM(\"enc\" << in_msg->encoding);", " enforce deep copy, see documentation", "", " namespace pandora_vision"], "annotator_connector": ["****************************************************************************", "", " Event filter for the image area", "loader_.scrollArea->installEventFilter(this);", "", "", "", "", "", "", "", "", "", "", "", "", " enforce deep copy, see documentation", "", "", "", "", "", " loader_.imageLabel->setScaledContents(true);", "", "", "", "", "qDebug(\"Save current Frame as: frame%d.png\",currFrame);", "do", "{", "cv::Mat temp = QImage2Mat(localImage_);", "cv::imwrite(img_name.str(),temp);", "loader_.statusLabel->setText(\"Save current Frame as:\" + QString(img_name.str().c_str() )); ", "}while(me->key() != Qt::Key_D);", "", "", "", "", "", "", "", "", "", "", "drawBox();  ", "", "", " namespace pandora_vision"], "annotator_node": ["****************************************************************************", "", " Add custom signal handlers", "", " namespace pandora_vision"], "annotator_loader": ["****************************************************************************", "", "scrollArea->setWidget(imageLabel);", "", "~ ROS_ERROR(\"Shutdown signal!\");", "~ ROS_ERROR(\"Shutting down ros...\");", "", "", "", " namespace pandora_vision"], "annotator_application": ["****************************************************************************", "", "", " namespace pandora_vision"], "annotator_tools": ["****************************************************************************", "", "", "", "", "", "", "", "", "", "", " namespace pandora_vision"], "motion_preprocessor": ["*******************************************************************", " namespace pandora_vision_motion", " namespace pandora_vision"], "motion_postprocessor": ["*******************************************************************", " namespace pandora_vision_motion", " namespace pandora_vision"], "motion_handler": ["*******************************************************************", " namespace pandora_vision_motion", " namespace pandora_vision"], "motion_processor": ["*******************************************************************", "", " Initiliaze the motion detector.", "/ The dynamic reconfigure parameter's callback", "", " namespace pandora_vision_motion", " namespace pandora_vision"], "motion_node": ["*******************************************************************"], "motion_detector": ["*******************************************************************", "/ Check that frame_ has data and that image has 3 channels", "/ Update the background model and create", "/ binary mask for foreground objects", "/ Check that the thresholded difference image has data", "/ Calculate the standard deviation", " ROS_INFO_STREAM(\"Motion stdev=\" << stdDev[0] << \" max_deviation= \" << maxDeviation_);", "/ If not to much changes then the motion is real", "/ find motion Contours", " ROS_INFO_STREAM(\"Contours found=\" << contours.size());", "/ find motion Points", " ROS_INFO_STREAM(\"motion points=\" << motionPoints.size());", "/ Start dbscan to cluster motion Points for localization", " clusters_.reset(new ClusteredPoints);", " dbscan.getClusters(clusters_);", " ROS_INFO_STREAM(\"CLUSTERS FOUND=\" << clusters_.size());", " if (clusters->size() > 0)", " {", " cohesion = dbscan.getCohesion(clusters);", " for (int i = 0; i < cohesion.size(); i++)", " {", " std::cout << cohesion[i] << std::endl;", " }", " }", " Bound clusters into a box", " ROS_INFO_STREAM(\"PROB=\" << probability << \" points=\" << points);", "/ Counts value of non zero pixels in binary image in order", "/ to find the exact number of pixels, that differ from current", "/ frame_ and background", " H component", " S component", " V component", " Convert from 8-bit integers to doubles", " Convert from HSV to RGB, using double ranges 0.0 to 1.0", " achromatic (grey)", " If Hue == 1.0, then wrap it around the circle to 0.0", " sector 0 to 5", " integer part of h (0,1,2,3,4,5 or 6)", " \" \" \" \"", " factorial part of h (0 to 1)", " case 5 (or 6):", " Convert from doubles to 8-bit integers", " Clip the values to make sure it fits within the 8bits.", " Set the RGB cvScalar with G B R, you can use this values as you want too..", " R component", " namespace pandora_vision_motion", " namespace pandora_vision"], "dbscan": ["*******************************************************************", "", " _clusteredPoints.push_back(false);", "", "", "", "", " (calculateDistanceMatrix(p, i) < _eps)// (DP[i*_data.size()+p] <= _eps)", "", "/ For each point in P' neighbor", "/ If P' is not visited", "/ Mark P' as visited", " expandCluster(neighbours[i], neighbours_p);", "", "  if(_labels[j] == -1) ", " noise.push_back(_data[j]); ", " *noisePoints = noise;", "/ calculate centroids", "/ calculate cohesion", " for (int i = 0; i < clusters.size(); i++) ", " {", " ROS_INFO_STREAM(\"d\");", " cohesion.push_back(0.0);", " for( int j = 0; j < clusters[i].size(); j++)", " for (int k = 0; k < clusters[i].size(); k++)", " {", " cohesion[i] += dist2d(clusters[i][j], clusters[i][k]);", " }", " cohesion[i] /= clusters[i].size();", " } ", " ROS_INFO_STREAM(\"DP[\"<<i<<\"][\"<<j<<\"]=\"<<x);", "/ Mark current point as visited", " ROS_INFO_STREAM(\"FIND NEIGHBORS OF POINT \" << i << \" SIZE=\"<< neighbours.size());", "  && i != 0) ", "/ Mark P as noise", " ROS_INFO_STREAM(\"POINT \"<< i <<\" is noise\");", "/ Expand cluster", " ROS_INFO_STREAM(\"EXPAND\" << _cluster_id);", " if (DP[pt1][pt2] != -1.0)  ", " {", " double x = DP[pt1][pt2];", " // ROS_INFO_STREAM(\"dist\"<< pt1 << \" \"<< pt2 <<\"=\" << x);", " return DP[pt1][pt2];", " }  ", "   cv::Rect a = _data[pt1]; ", " cv::Rect b = _data[pt2];", " cv::Point2d tla = cv::Point2d(a.x, a.y);", " cv::Point2d tra = cv::Point2d(a.x + a.width, a.y);", " cv::Point2d bla = cv::Point2d(a.x, a.y + a.height);", " cv::Point2d bra = cv::Point2d(a.x + a.width, a.y + a.height);", " cv::Point2d tlb = cv::Point2d(b.x, b.y);", " cv::Point2d trb = cv::Point2d(b.x + b.width, b.y);", " cv::Point2d blb = cv::Point2d(b.x, b.y + b.height);", " cv::Point2d brb = cv::Point2d(b.x + b.width, b.y + b.height);", " double minDist = 9999999;", " minDist = std::min(minDist, dist2d(tla, tlb));", " minDist = std::min(minDist, dist2d(tla, trb));", " minDist = std::min(minDist, dist2d(tla, blb));", " minDist = std::min(minDist, dist2d(tla, brb));", " minDist = std::min(minDist, dist2d(tra, tlb));", " minDist = std::min(minDist, dist2d(tra, trb));", " minDist = std::min(minDist, dist2d(tra, blb));", " minDist = std::min(minDist, dist2d(tra, brb));", " minDist = std::min(minDist, dist2d(bla, tlb));", " minDist = std::min(minDist, dist2d(bla, trb));", " minDist = std::min(minDist, dist2d(bla, blb));", " minDist = std::min(minDist, dist2d(bla, brb));", " minDist = std::min(minDist, dist2d(bra, tlb));", " minDist = std::min(minDist, dist2d(bra, trb));", " minDist = std::min(minDist, dist2d(bra, blb));", " minDist = std::min(minDist, dist2d(bra, brb)); ", " DP[pt1][pt2] = minDist;", " DP[pt2][pt1] = minDist;", " // ROS_INFO_STREAM(\"DIST\"<< pt1 << \" \"<< pt2 <<\"=\" << minDist);", " namespace pandora_vision_motion", " namespace pandora_vision"], "motion_detector_test": ["*******************************************************************", "", " accessors to private functions ", " Unit Tests ", " namespace pandora_vision_motion", " namespace pandora_vision"], "landoltc_postprocessor": ["*******************************************************************", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc_preprocessor": ["*******************************************************************", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc_node": ["*******************************************************************"], "landoltc_handler": ["*******************************************************************", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc_detector": ["*******************************************************************", "!< Constructor", "", "!< Get the path to the pattern used for detection", "!< Loading reference image passed as argument to main", "!< Turning to gray and binarizing ref image", "", " std::cout << \"Angle of \" << i <<\" is: \" << (angle*(180/3.14159265359)) << std::endl;", " ROS_INFO(\"Angle of %d is %lf \\n\", i, angle*(180/3.14159265359));", "", " std::cout << \"Angle of \" << i <<\" is : \" << angle*(180/3.14159265359) << std::endl;", " ROS_INFO(\"Angle of %d is %lf \\n\", i, angle*(180/3.14159265359));", "", "", "!< if line is out of frame return", "!< X major line", "!< calculation of values of line, gradient and intercept", "!< Y major line", "!< calculation of values of line, gradient and intercept", "", "!< Rasterization of lines between thresholded points", " old _minDiff* _minDiff", "!< Searching for landoltC centers", " old _threshold", "!< Search if there's a bigger center in a smaller area", " std::cout << \"Bullseye \" << bullcount++ << \" xy \" << center.x << \",\" << center.y << std::endl;", "", "", " Corners of the destination image", " Get transformation matrix", " Apply perspective transformation", "", "!< find contours and moments in frame used for shape matching later", "!< Shape matching using Hu Moments, and contour center proximity", " do stuff", "", "", "", "", "", "", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc_parameters": ["*******************************************************************", "!< The dynamic reconfigure parameter's callback", "", "!< Threshold parameters", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc3d_parameters": ["*******************************************************************", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc3d_detection": ["*******************************************************************", "", " Convert field of view from degrees to rads", " Initiliaze and preprocess reference image", " Setting Predator value ON or OFF for the 3DLandoltC Detector", " This is used for the fusion function later, in order to assign", " probabilities according to the predator state", " The dynamic reconfigure parameter's callback", "!< initialize states - robot starts in STATE_OFF", "", "", " Declare publisher and advertise topic", " where algorithm results are posted if it works alone", " Declare subscriber", " where algorithm results are posted if it works with predator", " Get the path to the pattern used for detection", " Get the PredatorOn value", " Get the camera to be used by landoltc3d node;", " Get the Height parameter if available;", " Get the Width parameter if available;", " Get the HFOV parameter if available;", " Get the VFOV parameter if available;", " Get the listener's topic;", "", " Parse robot description", " Get current link and its parent", " Set the parent frame_id to the parent of the frame_id", "", " ROS_INFO(\"Getting Frame From Camera\");", " ROS_INFO(\"Getting Frame From Predator\");", "", " Create message of Landoltc Detector", " Landoltc center's coordinates relative to the center of the frame", " Landoltc center's yaw and pitch", "", " check if datamatrix algorithm should be running now", " shutdown if the robot is switched off", "!< this needs to be called everytime a node finishes transition", "", "", " Threshold parameters", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc3d_node": ["*******************************************************************", ""], "landoltc3d_detector": ["*******************************************************************", "/ Constructor", "/ Destructor", "", " Loading reference image passed as argument to main", " std::cout << path << std::endl;", " std::cout << \"Pattern image not loaded\" << std::endl;", " Turning to gray and binarizing ref image", "", "", "", "", "", " Corners of the destination image", " Get transformation matrix", " Apply perspective transformation", "", " std::cout << \"Angle of \" << i <<\" is : \" << angle*(180/3.14159265359) << std::endl;", " ROS_INFO(\"Angle of %d is %lf \\n\", i, angle*(180/3.14159265359));", " delete[] pts;", "", " delete[] integralImg;", "", " if line is out of frame return", " X major line", " calculation of values of line, gradient and intercept", " Y major line", " calculation of values of line, gradient and intercept", "", " Rasterization of lines between thresholded points", " Searching for landoltC centers", " Search if there's a bigger center in a smaller area", " std::cout << \"Bullseye \" << bullcount++ << \" xy \" << center.x << \",\" << center.y << std::endl;", "", " find contours and moments in frame used for shape matching later", " Shape matching using Hu Moments, and contour center proximity", "", " cv::adaptiveThreshold(dst, thresholded, 255, cv::ADAPTIVE_THRESH_GAUSSIAN_C,", " cv::THRESH_BINARY_INV, 7, Landoltc3DParameters::adaptiveThresholdSubtractSize);", "", " ROS_INFO(\"Probability is %f\", confidence);", "", "", "", "", " namespace pandora_vision_landoltc", " namespace pandora_vision"], "landoltc_detector_test": ["*******************************************************************", "", " process input and call findcenters", " returns possible center", " y=column,i=row", "* test cases *", " TEST_F(LandoltcDetectorTest, rasterizeLineTest)", " {", " cv::Point a(1,1);", " cv::Point b(2,2);", " cv::Point c(4,5);", " cv::Point d(6,3);", " cv::Point e(2,4);", " EXPECT_EQ(1,giveVotingData(a, b, 1, 1));", " EXPECT_EQ(1,giveVotingData(b, c, 2, 2));", " EXPECT_EQ(1,giveVotingData(b, c, 3, 3));", " EXPECT_EQ(1,giveVotingData(b, c, 4, 3));", " EXPECT_EQ(1,giveVotingData(d, c, 5, 4));", " EXPECT_EQ(1,giveVotingData(d, c, 4, 5));", " EXPECT_EQ(1,giveVotingData(b, e, 2, 2));", " EXPECT_EQ(1,giveVotingData(b, e, 3, 2));", " }", " namespace pandora_vision"], "landoltc3d_detector_test": ["*******************************************************************", "", " namespace pandora_vision"], "datamatrix_node": ["*******************************************************************"], "datamatrix_detector": ["*******************************************************************", "", "", "!< Deallocate memory", "", "!< creates and initializes a new DmtxImage structure using pixel", "!< data provided  by  the calling application.", "!< creates and initializes a new DmtxDecode struct, which", "!< designates the image to be scanned and initializes the scan", "!< grid pattern.", "!< add msecs to timeout", "!< searches every pixel location in a grid pattern looking", "!< for potential barcode regions. A DmtxRegion is returned", "!< whenever a potential barcode region is found, or if the final", "!< pixel location has been scanned.", "!< Find datamatrixe's center exact position", "", "", " namespace pandora_vision_datamatrix", " namespace pandora_vision"], "datamatrix_preprocessor": ["*******************************************************************", " namespace pandora_vision_datamatrix", " namespace pandora_vision"], "datamatrix_postprocessor": ["*******************************************************************", " namespace pandora_vision_datamatrix", " namespace pandora_vision"], "datamatrix_handler": ["*******************************************************************", " namespace pandora_vision_datamatrix", " namespace pandora_vision"], "datamatrix_processor": ["*******************************************************************", "", "", "", "!< Deallocate memory", "", " namespace pandora_vision_datamatrix", " namespace pandora_vision"], "datamatrix_detector_test": ["*******************************************************************", "", "", "! Tests DatamatrixDetector::detect_datamatrix", " there shouldn't be any datamatrices", " neither when 3 channels are used", " there shouldn't be any datamatrices", " Vertically concatenated", " there shouldn't be any datamatrices", " there shouldn't be any qrcodes", " there shouldn't be any qrcodes", "TEST_F (DatamatrixDetectorTest, detect_datamatrixFromImage)", "{", "  cv::Mat inputFrame;", "  inputFrame = cv::imread(\"/home/v/Documents/PANDORA/Vision/Qr_Datamatrix_Testing/datamatrix1.jpg\");", "  //cv::resize(inputFrame, inputFrame, cv::Size(WIDTH, HEIGHT));", "  std::vector<POIPtr> datamatrix_list = detectDatamatrix(inputFrame);", "  // there should be one datamatrix", "  ASSERT_EQ(1, datamatrix_list.size());", "  int* center = locateDatamatrix(datamatrix_list[0].datamatrix_center);", "  EXPECT_LE(130, center[0]);   ", "  EXPECT_GE(160, center[0]);   ", "  EXPECT_LE(263, center[1]);   ", "  EXPECT_GE(293, center[1]);   ", "  // inputFrame = cv::imread(\"\");", "  // datamatrix_list = detectDatamatrix(inputFrame);", "  // // there should be four datamatrices", "  // EXPECT_EQ(4, datamatrix_list.size());", "  // inputFrame = cv::imread(\"\");", "  // datamatrix_list = detectDatamatrix(inputFrame);", "  // // there should be one datamatrix", "  // EXPECT_EQ(1, datamatrix_list.size());", "}", " namepsace pandora_vision_datamatrix", " namespace pandora_vision"], "color_processor": ["*******************************************************************", "", " Initiliaze the Colordetector.", "!< The dynamic reconfigure parameter's callback", "", " namespace pandora_vision_color", " namespace pandora_vision"], "color_handler": ["*******************************************************************", " namespace pandora_vision_color", " namespace pandora_vision"], "color_preprocessor": ["*******************************************************************", " namespace pandora_vision_color", " namespace pandora_vision"], "color_node": ["*******************************************************************"], "color_postprocessor": ["*******************************************************************", " namespace pandora_vision_color", " namespace pandora_vision"], "color_detector": ["*******************************************************************", "", "", "", "/ Check that frame has data and that image has 3 channels", "/ blur the image using GaussianBlur", "/ convert RGB image into HSV image", "/ get binary image", " pink*/", "  inRange(hsvFrame_, cv::Scalar(110,50,50), cv::Scalar(130,255,255), binary_);  // blue", "/ morphological opening (remove small objects from the foreground)", "/ morphological closing (fill small holes in the foreground)", "", " find contours", "/ find largest contour area", "/ get index of largest contour", "  double max; ", " cv::Point maxPosition;", " minMaxLoc(cv::Mat(areas), 0, &max, 0, &maxPosition); ", "/ draw largest contour.", " ROS_INFO_STREAM(\"AREAS=\");", "/ draw bounding rectangle around largest contour", " ROS_INFO_STREAM(\"CONTOUR NO \"<< i << \" area=\"<<areas[i]);", " draw rectangle", "  bounding_box->setWidth(r.width); ", " bounding_box->setHeight(r.height); ", "", " namespace pandora_vision_color", " namespace pandora_vision"], "color_detector_test": ["*******************************************************************", "", " accessors to private functions ", " namespace pandora_vision"], "predator_node": ["www.gnu.org/licenses/."], "predator": ["www.gnu.org/licenses/.", "", "!< Set initial value of parent frame id to null", "!< The dynamic reconfigure parameter's callback", "!< Get the path to the pattern used for detection", "!<Get Model Export Path", "!< Convert field of view from degrees to rads", "!< initialize states - robot starts in STATE_OFF", "", "", " user press left button ", " user drag the mouse ", "img->copyTo(imgCopy);", " user release left button ", "", " Parse robot description", " Get current link and its parent", " Set the parent frame_id to the parent of the frame_id", "", " draw bounding box", " end drawing bounding box (Enter)", "", "", "", "!< Get value of annotations state", "! Publishers", "! Declare publisher and advertise topic", "! where algorithm results are posted if it works alone or with annotator", "! Declare publisher and advertise topic", "! where algorithm results are posted if it works in compination with landoltc3d", "! Declare subscriber", "! if it works with annotator", "!< Get value for enabling or disabling TLD learning mode", "!< Get value of current operation state", "!< Get the camera to be used by predator node;", "! Get the Height parameter if available;", "! Get the Width parameter if available;", "!< Get the HFOV parameter if available;", "!< Get the VFOV parameter if available;", "!< Get the listener's topic;", "----------------detectorCascadeParams---------------------//", "", "", " Predator's center's coordinates relative to the center of the frame", " Predator center's yaw and pitch", "", "!< check if predator algorithm should be running now", "!< shutdown if the robot is switched off", "!< this needs to be called everytime a node finishes transition", "", "", " namespace pandora_vision"], "orb_detector": ["*******************************************************************", "", " Initialize the matchers that will be used for the", " detection of the pattern.", " A temporary container for the descriptors of each pattern.", " Add the descriptors of the i-th pattern to the", " container.", " Add the descriptors to the matcher and train it.", " Clear the container for the next iteration.", " Initialize the keypoint detector and the feature extractor", " that will be used.", "", " Detect the Keypoints on the image.", " Extract descriptors for the the detected keypoints.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "feature_matching_detector": ["*******************************************************************", "", " Read the necessary data.", "", " Open the file for reading.", " Check if the file was opened succesfully.", " Go to the xml node that contains the pattern names.", " Check if the node has a sequence.", " Initialize File iterator.", " Iterate over the node and get the names.", " Check if the names of the patters where read successfully.", " Close the file with the pattern names.", " For every pattern name read the necessary training data.", " Open the training file associated with image #i .", " Check if the file was properly opened.", " Read the pattern's descriptors.", " Read the pattern's keypoints.", " Initialize node iterators.", " Iterate over the node to get the keypoints.", " Read the pattern's bounding box.", " Initialize it's iterator.", " Add the pattern to the pattern vector.", " Close the xml file.", "", " Clear the vectors containing the matched keypoints.", " Define the vector of vectors that contains the matches.", " Each element is a vector that contains the first,the second", " up to the n-th best match.", " Check if the keypoints for pattern #patternID have been loaded.", " Check if we have stored the descriptors for pattern #patternID.", " No keypoints detected in the scene so the matching cannot continue.", " No descriptors calculated for the current frame.", " Perfom the matching using the matcher of the patternID-th", " pattern and find the top 2 correspondences.", " The vector containing the best matches", " If we have found any matches.", " We filter that matches by keeping only those", " whose distance ration between the first and the second", " best match is below a certain threshold.", " TO DO : READ THE THRESHOLD FROM FILE.", " No matches found.", " Add the keypoints of the matches found to the corresponding", " vectors for the pattern and the scene.", " Pattern key points.", " Scene key points.", " If we have less than 4 matches then we cannot find the Homography", " and this is an invalid pattern.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "hazmat_postprocessor": ["*******************************************************************", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "sift_detector": ["*******************************************************************", "", " Initialize the matchers that will be used for the", " detection of the pattern.", " A temporary container for the descriptors of each pattern.", " Add the descriptors of the i-th pattern to the", " container.", " Add the descriptors to the matcher and train it.", " Clear the container for the next iteration.", " Initialize the keypoint detector and the feature extractor", " that will be used.", "", " Detect the Keypoints on the image.", " Extract descriptors for the the detected keypoints.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "hazmat_handler": ["*******************************************************************", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "planar_object_detector": ["*******************************************************************", "", " Check if the frame is not an empty matrix.", " Check if that patterns have been read succesfully.", " The matrix that contains the descriptors of the frame.", " The mask that will be applied to the frame so as to limit the", " the search space.", " The detected keypoints of the frame that will be matched to the", " input pattern so as to find the correspondence from the training", " set to the query frame.", " Create the mask that will be used to extract regions of interest", " on the image based on the Image Signature Saliency Map.", " Calculate the keypoints and extract the descriptors from the", " frame.", " Temporary variables used to store the detected center of a pattern.", " For every pattern in the list :", " Try to find key point matches between the i-th pattern", " and the descriptors and the keypoints extracted from the frame.", " If we have succesfully found the matches.", " Find the bounding box for this query pattern.", " If this flag is true then a valid match has been found and", " we have detected the pattern.", " Get the center of the detected pattern.", "", " Check if we have enough points to find the homography between", " the pattern and the scene.", " Calculate the homography matrix using RANSAC algorithm to", " eliminate outliers.", " Transform the bounding box to the frame coordinates.", " Check if every point of the bounding box is inside the image.", " If not then the correspondences are invalid and these keypoints", " are rejected.", " The bounding box has a point out of the screen so it is", " rejected.", " Check if the Bounding box is Convex", " If not the resulting homography is incorrect due to false", " matching between the descriptors.", " A convex bounding box has been found inside the frame.", " Clear the bounding box vector.", " Not enough points for the homography.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "hazmat_processor": ["*******************************************************************", " Get the path of the current package.", " Initiliaze the object detector", " Check if the detector was initialized.", " Check if the features type has changed. If yes create a new detector.", " Check if the debug message printing is enabled.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "detector_factory": ["*******************************************************************", "", " Convert the input string to upper case format.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "hazmat_node": ["*******************************************************************", ""], "hazmat_preprocessor": ["*******************************************************************", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "surf_detector": ["*******************************************************************", "", " Initialize the matchers that will be used for the", " detection of the pattern.", " A temporary container for the descriptors of each pattern.", " Add the descriptors of the i-th pattern to the", " container.", " Add the descriptors to the matcher and train it.", " Clear the container for the next iteration.", " Initialize the keypoint detector and the feature extractor", " that will be used.", "", " Detect the Keypoints on the image.", " Extract descriptors for the the detected keypoints.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "image_signature": ["*******************************************************************", "", " if (array.channels() > 1)", " {", " std::cerr <<  \"Invalid channel number!\\n\" << std::endl;", " signs->data = NULL;", " return;", " }", " Compute the discrete cosine transform of the input image.", " Calculate the signature of the image.", " Convert the frame to a 3-channel float image and scale", " it's values accordingly.", " Resize the frame so as to process it correctly.", " TO DO : read the size from file.", " Split the input frame into it's separate channels.", " The resulting mask is a 1-channel floating point image , so as to", " correctly perform forward and inverse Discrete Cosine", " Transformatios.", " Temporary container for the inverse Discrete Cosine Transform", " for the #i channel of the image.", " For every channel of the image :", " Perform the inverse DCT on the signature.", " Calculate the total map.", " Calculate the mean of the saliency values of the 3 input channels.", " Resize the mask so that it can be applied to the frame.", " Threshold the mask to decrease noise and keep only the regions", " of interest.", " Convert the mask to 1-channel 8 bit format.", " *mask = sum;", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "surf_trainer": ["*******************************************************************", "", " Calculate image keypoints.", " Extract Descriptors from image", "", " Calculate image keypoints.", " Extract Descriptors from the images.", "", " Calculate the bounding box for the current pattern", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "factory": ["*******************************************************************", "", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "sift_trainer": ["*******************************************************************", "", " Calculate image keypoints.", " Extract Descriptors from image", "", " Calculate image keypoints.", " Extract Descriptors from the images.", "", " Calculate the bounding box for the current pattern", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "hazmat_trainer_node": ["*******************************************************************"], "planar_pattern_trainer": ["*******************************************************************", "", " The number of images.", " The temporary container for the images.", " The vector of the training image set.", " Open the file with the different pattern names.", " ROS_INFO(\"Reading the names of the patterns.\");", " Initialize the path to the data that will be used to train the system.", " Create the container for all the files in the directory containing", " the input of the training module.", " Check if the provided path exists.", " Iterate over the provided directory and store all", " the files/paths it contains.", " Sort the resulting data.", " Iterate over all the files/paths in the subdirectory.", " Check if the provided path exists.", " Check if it is a file.", " Check if it is a directory.", " If true then at least the training data for one pattern was acquired", " successfully.", "", " Iterate over the provided directory and store all", " the paths it contains.", " Sort the contained paths.", " Get the path to the image that represents the frontal view of", " the pattern.", " Get the path to the frontal view.", " Find the path in the container for the current subdirectory.", " Vector that contains the training set images.", " Check if the path was found.", " Since the frontal view was not found,training cannot continue.", " Check if it is a file.", " Add the frontal view to the collection.", " Remove the frontal view from the entries.", " Get the path to the file containing the homographies that", " created all the synthetic views.", " Initialize the container for the homographies.", " Check that the provided file is indeed a file.", " Get the homography matrices.", " If we failed to read the homographies then the training cannot", " continue.", " Find the position of the path of the homography input file", " in the list of paths.", " Delete the entry of the homography matrix from the list of", " paths.", " Iterate over all the contents of the folder and read all the images", " it contains.", " Add the current view to the collection.", " Finished parsing the images.", " We will now calculate the descriptors of the pattern", " from all the generating views!", "", " The vector that contains all the keypoints found in the training set.", " The array of all the descriptors detected in the training set.", " Calculate the features for the frontal view of the pattern.", " Find the features for all the images except the front view.", " Insert the frontal view keypoints.", " Perform the inverse transformations on the keypoints and store the", " result.", " For every image multiViewKeypoints.", " Get the homography that corresponds to the current view.", " Copy the keypoints detected in the i-th view.", " Apply the inverse homography transform to get points in the original", " coordinate frame.", " Add the transformed points to the vector containing all the", " keypoints.", " Concatenate the descriptors matrices.", " if(matches[i][0].distance < ratio*matches[i][1].distance)", " saveDataToFile(dirPath, multiViewDescriptors, multiViewKeypoints,", " boundingBox);", " saveDataToFile(dirPath, centroids, multiViewKeypoints,", " boundingBox);", "", " Calculate the image features.", " Save the training data for the i-th image.", "", " Create the file name where the results will be stored.", " Remove the file extension.", " Properly choose the name of the data file.", " TO DO : Change hard coded strings to yaml params.", " fileName = path + fileName;", " ROS_INFO(\"DEBUG MESSAGE : Saving fileName %s\", fileName.c_str());", " Opening the xml file for writing .", " Enter the name of the pattern.", " Save the descriptors.", " Calculate the number of keypoints found.", " Store the detected keypoints.", " Store the bounding box for the pattern.", " Close the xml file .", "", " Create the file name where the results will be stored.", " Remove the file extension.", " Properly choose the name of the data file.", " TO DO : Change hard coded strings to yaml params.", " fileName = path + fileName;", " ROS_INFO(\"DEBUG MESSAGE : Saving fileName %s\", fileName.c_str());", " Opening the xml file for writing .", " Enter the name of the pattern.", " Save the descriptors.", " Calculate the number of keypoints found.", " Store the detected keypoints.", " Store the bounding box for the pattern.", " Close the xml file .", "", " A container for each line.", " Open the file.", " The vector for the tokens.", " The vector used to parse to separate the float values.", " The vector containing the actual numerical values of the coefficients", " of the homography matrix.", " The OpenCV matrix that will be stored.", " Iterate over each line of the file.", " Split the line to get the name of the file.", " Insert the current value in the map and check if it is present.", " Check if any homography was read.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "orb_trainer": ["*******************************************************************", "", " Calculate image keypoints.", " Extract Descriptors from image", "", " Calculate image keypoints.", " Extract Descriptors from the images.", "", " Calculate the bounding box for the current pattern", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "feature_matching_test": ["*******************************************************************", " Check that if the array containing the descriptors calculated", " from the frame is empty then the function returns false.", " This time an empty array of the pattern descriptors is passed to the", " function.", " Pass an empty vector of pattern keypoint. The function must return", " false and not perform any calculations.", " Pass an empty vector of scene keypoints. The function must not do any", " computation and return a false flag.", " The function must return false since there are not enough points for", " the RANSAC algorithm to estimate the homography matrix.", " The function must return false since an empty vector is provided", " as a bounding box.", " Second rotation test.", " Scale test", " Scale and clockwise Rotation test.", " Scale and counter - clockwise Rotation test.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "trainer_test": ["*******************************************************************", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "image_signature_test": ["*******************************************************************", " Create a small image with positive elements .", " Create a matrix with positive elements.", " Create a matrix with positive elements.", " Check that every value is positive.", " Create a matrix with negative elements.", " Check that every value is negative.", " namespace pandora_vision_hazmat", " namespace pandora_vision"], "thermal_node": ["*******************************************************************"], "thermal_hole_detector": ["*******************************************************************", "", "", " Debug", " Detect edges in the thermal image", " Debug", " Find blobs in the edges image. Each blob is represented as", " a keypoint which is the center of the blob found", " Debug", " The final vectors of keypoints, rectangles and blobs' outlines.", "", " Debug", " Debug", " A vector of keypoints", " namespace thermal", " namespace pandora_vision_hole", " namespace pandora_vision"], "thermal_cropper": ["*******************************************************************", "", "", "", " Take NodeHandlers from nodelet manager", " Acquire the names of topics which the thermal_cropper node will be having", " transactionary affairs with", " Subscribe to the thermal poi published by thermal node", " Subscribe to rgb and depth images published by synchronizer node.", " Set the initial on/off state of the Hole Detector package to off", " Advertise enhanced message to victim node", " Advertise empty message to synchronizer node so the thermal process", " circle will start again", " Advertise the topic where any external node(e.g. a functional test node)", " will be subscribed to know that the hole node has finished processing", " the current candidate holes as well as the result of the procedure.", "", "", "", "", " The new on/off state of the Hole Detector package", " off -> on", " The on/off state of the Hole Detector Package is off, so the", " synchronizer must be unlocked to start the thermal procedure", " on -> off", " Shutdown or open publisher of enhanced images", "", " Send message to synchronizer in order for thermal procedure to start.", " namespace thermal", " namespace pandora_vision_hole", " namespace pandora_vision"], "thermal": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "thermal_cropper_node": ["*******************************************************************", ""], "noise_elimination": ["*******************************************************************", "", "", " Found black", "", " Boundaries check.", " If a neighboring points goes out of bounds, discard it", " Find the lowest non-zero value outside this concentration of", " zero-value pixels", " Because we will check for the value of neighboring points,", " if a point happens to be on the edges, it probably won't have any", " non-zero neighbors; discard it", " Scan all the neigbors of point (x, y)", " If the whole of the image is not black", " Now that the lowest value of non-zero neighboring pixels of", " this black concentration of pixels has been found,", " assign it to the whole of the concentration", "", " The number of zero value pixels", " The mean distance of the non-noisy points from the depth sensor", " The percentage of noise in the depth image", " Choose close", "", " interpolate the pixels at the edges of the inImage", " interpolate the rows", " interpolate the columns", " interpolate the corners", " top left", " top right", " bottom left", " bottom right", "", " The non-zero value neighbors' sum of values", " The number of non-zero value neighbors", " Up", " Upper right", " Right", " Lower right", " Down", " Lower left", " Left", " Upper left", "", " in the end, only pixels adjacent to the edge of the", " image are left black", "", "", " Thinning-like interpolation", " Produce the near brushfire image", " Produce the white noise image", "", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "holes_conveyor": ["*******************************************************************", "", "", "", " A conveyor of a single hole", " Assign the keypoint", " Assign the rectangle points", " Assign the outline points", " Append hole into conveyor", "", "", " If the dst is not empty, clear it", " Append the src to the dst", "", " The vector of the rectangle's vertices", " The four vertices of the rectangle", " Push them back into the vector", " Outline construction", "", " The conveyor that will be returned", " Push back the index-th hole of the conveyor into temp", "", " Clear the destination conveyor if not empty", " Append the first source to dst", " Append the second source to dst", "", " Delete the respective keypoint", "", " Clear the dst", " Fill it with the src", "", " Replace the dst's dstIndex-th hole's keypoint", " Replace the dst's dstIndex-th hole's rectangle points", " Replace the dst's dstIndex-th hole's outline points", "", " Keep the original holes' arrangement", " Hollow-out the src", " The vector of holes' indices", " Shuffle the indices", " Fill the src conveyor with the shuffled holes", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "histogram": ["*******************************************************************", "", "", " The vector of backprojection images corresponding to each", " discrete model histogram", " Convert the inImage image from RGB to HSV", " hue varies from 0 to 180", " saturation or value varies from 0 to 256", " Use the 0-th (Hue) and secondaryChannel channels", " Calculate the backproject of the input image depending on the", " i-th histogram", " Combine all backprojections into one. The value of each pixel of the", " overall backprojection shall be the maximum value of the", " sub-backprojections for that pixel", "", " The path to the package where the wall pictures directory lies in", " The actual wall pictures directory", " The number of textures inside the wallsDirectory directory", " The walls directory should exist; otherwise abort.", " Find how many texture directories there are inside the walls directory.", " The name of each directory shall be \"texture_X\" where X denotes an", " integer starting from 0.", " The name of each listing in the walls directory in string format", " The position of the \"_\" separator", " Traverse all textures and create a histogram for each one", " The actual wall pictures directory", " The number of wall picture files inside the textures directory", " Find out how many images there are in each texture_X directory", " If no images are found in the \"texture_X\" directory, shutdown.", " Read the pictures inside the wallPicturesPath, convert them to HSV", " and calculate their histogram", " The first value will always be with regard to Hue", " hue varies from 0 to 179, saturation and value from 0 to 255", " Use the 0-th and secondaryChannel-st channels", " A temporary histogram where the computed histogram will be put", " Calculate the histogram for the walls", " Append the histogram of this collection of texture images to", " the overall vector of histograms", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "blob_vector": ["*******************************************************************", "", " A single hole", " Recreate conveyor.keypoints", " Recreate conveyor.rectangles", " Recreate conveyor.outlines", " Because the outline points do not constitute a coherent shape,", " we need to draw them, connect them linearly and then the", " points that are drawn will be the hole's outline points", " The easiest and most efficient way to obtain the same result as", " if image_representation_method was 0 is to apply the raycast", " algorithm", " Push hole back into the conveyor", " Assign area of interest", " Assign the outline points", " Append hole into conveyor", " Clear the destination conveyor if not empty", " Extend with the first source", " Extend with the second source", " Clear the destination conveyor if not empty", " Extend with the first source", " Extend with the second source", " Clear the destination conveyor if not empty", " Extend with the first source", " Extend with the second source", " Clear the destination conveyor if not empty", " Extend with the first source", " Extend with the second source", " Delete the respective keypoint", " Clear the dst", " Fill it with the src", " Clear the dst", " Fill it with the src", " Replace the dst's dstIndex-th hole's keypoint", " Replace the dst's dstIndex-th hole's keypoint", " Keep the original holes' arrangement", " Hollow-out the src", " The vector of holes' indices", " Shuffle the indices", " Fill the src conveyor with the shuffled holes", " The vector of the rectangle's vertices", " The four vertices of the rectangle", " Push them back into the vector", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "outline_discovery": ["*******************************************************************", "", "", " Get a pointer on the edges image", " The sets needed by the brushfire implementation", " The indices of the blob's outline points stored in a set.", " If the blobOutlineVector was used, in it there would be redundant copies", " of each outline point", " Sweep the neighbors of the current point", " This check is needed because it is possible to access", " a point diagonal to the current one", " that goes out of the image's borders (value == 0),", " while it shouldn't.", " E.g. this happens when there are \"cracks\" to the border of a", " 1-pixel border", " Column-wise coordinate", " Row-wise coordinate", " The index of this neighbor inside image edgesImage", " If this neighbor is not within the image's borders,", " discard it and move on", " The value of the point with index ind in edgesImage", " If this neighbor is a blank pixel and", " it has not been visited, put it in set \"next\"", " If this neighbor has a non-zero value, it is an outline point", " Whatever the condition, this neighbor has been visited", " The set of all future points becomes the one with which the", " brushfire will begin", " Clear set \"next\" for the next iteration", " Fill the blobOutlineVector with the", " transformed content of the blobOutlineSet", " The area of the blob is essentialy the number of points visited", "", " The outline points of the current blob", " The area of the current blob", " Apply the brushfire algorithm for the current keypoint", " Push back the blobOutlineVector to the overall outline points vector", " Push back the area of the blob to the overall areas vector", "", " Get a pointer on the input image", " The sets needed by the brushfire implementation", " sweep the neighbors of the current point", " This check is needed because it is possible to access", " a point diagonal to the current one", " that goes out of the image's borders (value == 0),", " while it shouldn't.", " E.g. this happens when there are \"cracks\" to the border of a", " 1-pixel border", " Column-wise coordinate", " Row-wise coordinate", " The index of this neighbor inside image inImage", " If this neighbor is not within the image's borders,", " discard it and move on", " The value of the point with index ind in edgesImage", " If this neighbor is a blank pixel and", " it has not been visited, put it in set \"next\"", " Whatever the condition, this neighbor has been visited", " The set of all future points becomes the one with which the", " brushfire will begin", " Clear set \"next\" for the next iteration", "", " In order to obtain the outline of the mask quickly,", " the input image is eroded once. The outline is acquired from the", " difference between the input image and the eroded one.", "", " Debug", " Kernels for obtaining boundary pixels", " Invert the image to facilitate floodfill's operation", " A vector that holds floodfill images needed for the final output", " First floodfill operation", " Push the first floodfill operation's result", " back into the floodfillsVector", " Termination flag", " The total number of images needed to obtain a clear result", " Invert the image to facilitate floodfill's operation", " Second floodfill operation", " The prunedFloodFill image will act as termination check", " If it is filled with zeros, that means that there are no", " closed shapes in the floodfill's image.", " If not, we need to iterate the floodfill procedure", " Check the prunedFloodFill image for the numerosity of zeros", " If there are non-zero pixels, reiterate", " Push the second floodfill operation's result", " back into the floodfillsVector", " The final floodfill-ed image", " Dilate twice:", " once to (a) get rid of pesky borders", " and once (b) for the blob's outline to approximate the original's outline", " The floodfill's edges - region borders", " Debug", " Debug", "", " Debug", " Flood the original image from (0, 0) with a value of 255", " The pixels affected by the above floodfill operation are", " backgroung pixels. The ones that remain unaffected are interior to the", " shapes whose outline we wish to identify.", " Store these pixels in the tempImage image", " Kernels for obtaining boundary pixels", " The image whose non-zero pixels indicate the outlines of shapes", " Debug", " Debug", "", " Get a pointer on edgesImage", " A vector storing the non-zero pixels surrounding the keypoint", " The angle of a ray relative to the horizontal axis", " The increment of a ray's angle", " Make a complete revolution", " Indicates whether this ray has hit a non-zero value point", " Variable responsible for advancing the tip of the ray until it", " finds a non-zero value point", " A ray can hit up to 5 outline points, but only one must be chosen.", " Store these points as potential outline points.", " We will select only the first one found", " Advance the tip of the ray forwards", " Has the ray gone out of the image's bounds?", " If yes, impose limits", " The index of the neighbor of the ray's tip", " .. and its value in the edgesImage image", " If the neighbor has a non-zero value, or it is a boundary", " pixel (hence there is no valid value,", " and one has to be imposed), this point is an outline point", " End {while outline not found} loop", " From the, at most 5, outline points found,", " regard only one of them as an outline point, so that, in total,", " their number equals the number of partitions", " (Needed to approximate fairly accurately the blob's area)", " Increase the angle of the ray", " If the area of the blob needs to be returned", " Calculate each blob's approximate area by heron's formula", " https://en.wikipedia.org/wiki/Heron's_formula", " calculate the area of each triangle found", " O is the keypoint and A, B two successive outline points", " Instead of keeping the sparce points that are the product of", " the raycast algorithm, connect them linearly in order to", " have a coherent set of points as the hole's outline", " Draw the connected outline of the i-th hole onto canvas", " Clear the outline vector. It will be filled with the points", " drawn on the canvas image", " Every non-zero point is a point drawn; it is a point that", " belongs to the outline of the hole", " The final outline points vector", "", " The current blob's outline", " The current blob's area", " Find the outline and the area of the current keypoint", " Push the blob's area back into the vector of areas", " Push the blob's outline back into the vector of blobs' outline points", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "image_matching": ["*******************************************************************", "", "", " Counter of holes deleted", " Match the keypoint of each Hole found", " If the keypoint is out of or on rbg image borders reject", " that hole immediately.", " Continue the process", " Match the bounding box and check if it is outside rgb image, if so", " reject that hole. Bounding box check is enough, we dont need to check", " outlines, because they reside entirely inside it.", " If hole rejected skip next process step", " Match the blobs outline points", " The easiest and most efficient way to obtain the new outline is to", " apply the raycast algorithm", " cv::Mat canvas = cv::Mat::zeros(Parameters::Image::HEIGHT,", " Parameters::Image::WIDTH, CV_8UC1);", " unsigned char* ptr = canvas.ptr();", " for (unsigned int a = 0; a < conveyor->holes[i].outline.size(); a++)", " {", " unsigned int ind =", " conveyor->holes[i].outline[a].x + canvas.cols * conveyor->holes[i].outline[a].y;", " ptr[ind] = 255;", " }", " float area = 0.0;", " OutlineDiscovery::raycastKeypoint(conveyor->holes[i].keypoint,", " &canvas,", " Parameters::Outline::raycast_keypoint_partitions,", " false,", " &conveyor->holes[i].outline,", " &area);", " Second method to connect the new outlines", " Put the outline points in order for each hole", " Connect the points in order to have a coherent set of points", " as the hole's outline. For each hole.", "", " The value of thermal image point.x or point.y in Rgb image after", " linear transformation.", " Rotational transformation", "", " Draw the outline of the new ordered points for each hole", " Clear the outline vector so it can be filled with the new outline", " points from the outlineImage image.", " Every non-zero point is a point drawn so pass it to the vector.", "", " Vector of points that will contain the points in order.", " For each hole found.", " Push the first point in the new vector and erase it from the old vector", " Set as starting minimum value width*2, a value that can never", " been surpassed by any distance between points", " Index that shows the place of the new closest point found in", " the old vector.", " Find the x distance between two points and square it.", " Find the y distance between two points and square it.", " Find the euclidean distance between two points.", " Pass the point found to the new vector.", " The new initial point that we check distances changes.", " Erase that point from the starting vector.", " Pass the points found in order to the holesconveyor struct", " Clear the newVector so it can be used for the next hole", "", " Read values of each variable.", " x_thermal variable.", " y_thermal variable.", " C factor on x directions.", " C factor on y directions.", " The angle that thermal image been rotated.", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "wavelets": ["*******************************************************************", "", "", " LowLow contains the inImage's low low frequencies, in CV_32FC1 format", " What we will return will be this image scaled to the actual proportions", " of values of the inImage (also in CV_32FC1 format).", " After obtaining the low-low, reverse the scale operation, in an", " attempt to approximate the initial depth image's values", "", " LowLow contains the inImage's low low frequencies, in CV_32FC1 format", " What we will return will be this image scaled to the actual", " proportions of values of the inImage (also in CV_32FC1 format).", " The outImage. out has to be assigned to *outImage but cannot be done", " in the following loops immediately", " Copy out to the output image", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "visualization": ["*******************************************************************", "", "", " Draw images", " Final resize", "", "", "", " Construct a keypoints vector to feed into the cv::drawKeypoints method", "", "", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "bounding_box_detection": ["*******************************************************************", "", "", " Find the rotated rectangles for each blob based on its outline", " The area of the blob should be greater than a threshold,", " so that tiny formations of pixels are not identified as blobs", " For each rotated rectangle whose corresponding blob exceeds the minimum", " area threshold, if its vertices reside within the image's boundaries,", " store its vertices", " The for vertices of the rotated rectangle", " Check if the vertices reside in the image's boundaries", " If the rotated rectangle's edges reside outside the image's edges,", " discard this rotated rectangle", " If all four vertices reside within the image's boundaries,", " store them in their respective position", " Same as rect_points array, but vector", " Push back the 4 vertices of rectangle i", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "edge_detection": ["*******************************************************************", "", "", " Reduce noise with a kernel with size", " Parameters::Edge::canny_blur_noise_kernel_size ^ 2", " Canny detector", "", " appropriate values for scale, delta and ddepth", " the value for the non-edges", " Generate grad_x and grad_y", " Gradient X", " Gradient Y", " Total Gradient (approximate)", "", " appropriate values for scale, delta and ddepth", " the value for the non-edges", " Generate grad_x and grad_y", " Gradient X", " Gradient Y", " Total Gradient (approximate)", "", " appropriate values for scale, delta and ddepth", " the value for the non-edges", "", " Make the vertical borders of the image black", " Make the horizontal borders of the image black", " Vertically, find the outer white borders", " Horizontally, find the outer white borders", " Iterative contamination.", " Find all the pixels that are iteratively neighboring non-zero value", " pixels that lie next to the borders of the image", "", " The input depth image, in CV_8UC1 format", " The image of edges of the denoised depth image, in CV_32FC1 format", " Detect edges in the visualizableDepthImage", " Apply a threshold to the image of edges", " to get rid of low value - insignificant - edges", " Make all non zero pixels have a value of 255", " Denoise the edges found", "", " The input thermal image, in CV_8UC1 format", " The image of edges of the denoised thermal image, in CV_8UC1 format", " Detect edges in the visualizableDepthImage", " Apply a threshold to the image of edges", " to get rid of low value - insignificant - edges", " The next two steps are insignificant when we process the Temperature", " image extracted from thermal camera", " Make all non zero pixels have a value of 255", " Denoise the edges found", "", " The edges are detected on the segmented RGB image", " The edges are produced directly as a result of the watersheding", " of the rgb image with its backprojection", " Apply a threshold so as to get rid of, what we perceive to be, noise", " Make all non zero pixels have a value of 255", " Denoise the edges image", "", " Debug", " Connects each pair of points via a line", " Connects each pair of points via an arc", " The input image. On it the elliptical arcs will be drawn", " The image on which only the elliptical arcs will be drawn", " The euclidean distance of the pair", " The middle point of the segment connecting the pair points", " The angle that the line connecting the two pair points", " forms with the horizontal axis", " Given the line that is perpendicular to the line that connects", " the pair points, move on it one point at a time, in opposite", " directions. The first non-zero point found will be one of the", " curve that the pair lies on.", " Indicator that a non-zero value point has been found", " The outline point found", " Since there are two rays leaving the bisector point,", " in opposite directions,", " these two variables indicate the presence of the tip of the each ray", " within the image's borders", " Has the tip of the first ray gone out of bounds?", " Has the tip of the second ray gone out of bounds?", " Sweep the neighbors of the tip of the ray in order to find", " a valid non-zero value point, aka the outline point", " that is being sought", " Sweep the neighbors of the tip of the ray in order to find", " a valid non-zero value point, aka the outline point", " that is being sought", " An outline point could not be found", " The distance between the outline point found, and the middle point", " of the segment that connects the pair points", " If the curve that the pair points lie on approximates", " a straight line, do not connect the two pair points", " The major axis of the elliptical curve connecting the pair points", " The minor axis of the elliptical curve connecting the pair points", " The angle that the line that connects the first pair point and the", " outline point found forms with the horizontal axis", " The angle that the line that connects the second pair point and the", " outline point found forms with the horizontal axis", " Map the angles to the standard polar system", " The angle between the line that connects the two pair points", " and the horizontal axis", " The angle between the line that connects the two pair points", " and the horizontal axis. In order for the arc to accurately", " connect the two pair points, we need to know its orientation.", " It's one thing connecting point A to point B with an arc,", " and another connecting point B to point A with an arc.", " In other words, the arc has to have a starting point and an ending", " point in order for the total connected curve to have the same", " curvature orientation", " Both pair points are above the X axis", " Both pair points are below the X axis", " Pair point 2 is above the X axis while pair point 1 below it", " Pair point 1 is above the X axis while pair point 2 below it", " Draw the elliptical curve on the inImageDrawnOnce image", " size arg 1: length of the major axis. always pairsDistance / 2", " size arg 2: length of the minor axis.", " Debug", " Debug", "", " Debug", " Perform edge contamination:", " remove all non-zero pixels iteratively adjacent to the image's borders", " Debug", " Eliminate closed shapes", " Apply thinning to the contaminated original edges", " Debug", " By pruning the thinned image,", " all pixels that are open-ended are eliminated,", " leaving thus behind only shapes whose ends are connected, aka the", " closed shapes", " Debug", " The thinnedOpenLines image now features only the thinned,", " open-ended shapes", " We want to preserve the original (unthinned) outline of the closed shapes", " and connect the ends of open-ended shapes which are thinned to this point.", " So, first, we need to identify the closed shapes in the edge contaminated", " image. These will be stored in the closedLines image.", " The operation has finished when all the original closed shapes have", " been found", " Debug", " Debug", " In the image that features only open-ended shapes, find their end points.", " if they are eligible for connection,", " these points will be connected with each other", " Because the thinnedOpenLines image was wiped clean via the execution", " of the identifyCurvesAndEndpoints method, re-paint the lines found on it", " Connect the end points of open shapes", " Since what could be connected was connected, the rest of the open-ended", " shapes are not needed.", " Debug", " Re-enable the closed shapes", " Debug", " Extract only the outer border of closed shapes", " Debug", " Debug", "", "", "docs.opencv.org/modules/imgproc/doc/", " Get a pointer on mask to speed-up execution", " Fill this segment with a random colour", "", " This is edge", " This is joint", " Find larger dist between nodes", " Delete pointers inside nodes", "", " A point is potentially located along a curve only if its value", " is non-zero; otherwise it is not a point!", " Locate the indices of the points that constitute the curve on", " which point (i, j) is located, along with the end points of it.", " Push the indices of the points constituting the curve on which", " point (i, j) is located, into the overall curves' indices vector.", " Push the end-points of the curve into the overall vector of", " end-points", "", " Backprojection of the RGB inImage", " Get the backprojected image of the frame, based on the precalculated", " vector of histograms", " Locate the inImage's edges by watersheding it based on its", " backprojection", "", " Debug", " Copy the input image to the segmentedHoleFrame one", " Segment the input image.", " Posterize the product of the segmentation", " Fill the various segments with colour", " Convert the posterized image to grayscale", " In order to find the edges of the posterized image,", " first, turn it to grayscale", " Apply edge detection to the grayscale posterized input RGB image", "", " Termination criteria for the segmentation below", " Segment the image", "", " Threshold the backprojection", " The foreground image needed by the watershed algorithm", " Copy the backprojection to the foreground image", " Dilate", " All non-zero pixels have now a value of 255", " Erode. The erosion factor should be greater", " than the dilation factor used above", " The background image needed by the watershed algorithm", " Copy the backprojection to the background image", " Dilate", " All non-zero pixels have now a value of 255", " All zero value pixels turn to white, all white to black", " Erode. The erosion factor should be greater", " than the dilation factor used above. This erosion happens so that", " the background pixels belong surely to the background", " All zero value pixels' values are elevated to 128.", " These belong neither to foreground, nor to background:", " they are labeled as so-called \"unknown\"", " Create the markers image, needed by the watershed algorighm", " The markers array is composed by the foreground, background and", " unknown pixels", " Convert the marker image of type CV_8UC1, to CV_32S", " Watershed the input image, with regard to the markers constructed", " Each pixel p is transformed into", " 255p + 255 before conversion", " Convert the markers image to back to type CV_8UC1.", " This image identifies whole areas that the backprojection partially", " recognizes to be matching the histogram on which it is based", " Convert image markers32S into an edges image", " All zero value pixels turn to white, all white to black.", " In essence, this is the edges of the area whose histogram", " matches inHistogram", " Convert image markers32S into a depth of 8U", " All non-white pixels turn to black", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "blob_detection": ["*******************************************************************", "", "", " 40;", " 60;", " 0.6;", " 0.5;", " 0.3;", " detect blobs. store their center point", " if the keypoint is out of image limits, discard it", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "morphological_operators": ["*******************************************************************", "", "", "", " That's foreground", " Check for all adjacent", " The image's borders where left untouched.", " Dilate them here", " Left-most and right-most columns", " The image's left-most pixels", " The image's right-most pixels", " Upper-most and lower-most rows", " The image's upper-most pixels", " The image's lower-most pixels", " Finally, the 4 edges of the image", " Upper left", " Upper right", " Lower right", " Lower left", "", " That's foreground", " Check for all adjacent", " The image's borders where left untouched.", " Dilate them here", " Left-most and right-most columns", " The image's left-most pixels", " The image's right-most pixels", " Upper-most and lower-most rows", " The image's upper-most pixels", " The image's lower-most pixels", " Finally, the 4 edges of the image", " Upper left", " Upper right", " Lower right", " Lower left", "", " That's foreground", " Check for all adjacent", " The image's borders where left untouched.", " Erode them here", " Left-most and right-most columns", " The image's left-most pixels", " The image's right-most pixels", " Upper-most and lower-most rows", " The image's upper-most pixels", " The image's lower-most pixels", " Finally, the 4 edges of the image", " Upper left", " Upper right", " Lower right", " Lower left", "", "", "", " Check for initial stuff", "", "homepages.inf.ed.ac.uk/rbf/HIPR2/thin.htm)", " if the image is saturated by the thinning operator,", " cease its operation", " Delete pointer pts", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "message_conversions": ["*******************************************************************", "", "", "", " Prepare the output image", " For the depth image", " if element is nan make it a zero", " For the rgb image", " Get the index we need", " CV_32FC1", " it was int", "", " Fill the pandora_vision_msgs::CandidateHolesVectorMsg's", " candidateHoles vector", " Push back the keypoint", " Push back the bounding rectangle's vertices", " Push back the blob's outline points", " Push back one hole to the holes vector message", "", " Fill the ::::pandora_vision_hole::CandidateHolesVectorMsg's", " candidateHoles vector", " Fill the pandora_vision_msgs::CandidateHolesVectorMsg's", " image", " Fill the pandora_vision_msgs::CandidateHolesVectorMsg's", " header", "", "", "", " Normal mode", " A single hole", " Recreate the hole's keypoint", " Recreate the hole's rectangle points", " Recreate the hole's outline points", " Push hole back into the conveyor", " Wavelet mode", " A single hole", " Recreate conveyor.keypoints", " Recreate conveyor.rectangles", " Recreate conveyor.outlines", " Because the outline points do not constitute a coherent shape,", " we need to draw them, connect them linearly and then the", " points that are drawn will be the hole's outline points", " The easiest and most efficient way to obtain the same result as", " if image_representation_method was 0 is to apply the raycast", " algorithm", " Push hole back into the conveyor", "", " Unpack the image", " Recreate the conveyor", "", " The width and height of the input temperature multiarray", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_filters": ["*******************************************************************", "", "", " Locate the outline of blobs via brushfiring", " Find the outline points of each keypoint", " For each outline found, find the rotated rectangle", " with the least area that encloses it.", " Given the outline of the blob, find the least area", " rotated bounding box that encloses it", " Correlate each keypoint with each rectangle found.", " Keep in mind that for a blob to be a potential hole, its area", " must be greater than Parameters::bounding_box_min_area_threshold", " Locate the outline of blobs via raycasting", " Find the (approximate) outline points of each keypoint", " For each outline found, find the rotated rectangle", " with the least area that encloses it.", " Given the outline of the blob, find the least area", " rotated bounding box that encloses it", " Correlate each keypoint with each rectangle found.", " Keep in mind that for a blob to be a potential hole, its area", " must be greater than Parameters::bounding_box_min_area_threshold", " The end product here is a struct (conveyor) of keypoints,", " a set of rectangles that enclose them  and the outline of", " each blob found.", "", " Test to see where (in which rectangle(s)) the keypoint resides.", " If the keypoint resides in exactly one rectangle.", " A single hole", " Accumulate keypoint, rectangle and outline properties onto hole", " Push hole back into the conveyor", " If the keypoint resides in multiple rectangles,", " choose the one with the least area.", " The minimum area of all rectangles", " The index of the rectangle with the least area", " A single hole", " Accumulate keypoint, rectangle and outline properties onto hole", " Push hole back into the conveyor", " If the keypoint has no rectangle attached to it,", " do not insert the hole it corresponds to in struct hole", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "rgb": ["*******************************************************************", "", "", "", " Acquire the names of topics which the rgb node will be having", " transactionary affairs with", " Calculate the vector of histograms of images of wooden walls:", " the rgb node, depending on the procedure of edges extraction of", " rgb image, is going to need it", " Subscribe to the RGB image published by the", " rgb_depth_synchronizer node", " Advertise the candidate holes found by the rgb node", " The dynamic reconfigure (RGB) parameter's callback", "", "", " Obtain the rgb image. Since the image is in a format of", " sensor_msgs::Image, it has to be transformed into a cv format in order", " to be processed. Its cv format will be CV_8UC3.", " Regardless of the image representation method, the RGB node", " will publish the RGB image of original size to the Hole Fusion node", " A value of 1 means that the rgb image is subtituted by its", " low-low, wavelet analysis driven, part", " Obtain the low-low part of the rgb image via wavelet analysis", " Locate potential holes in the rgb image", " Create the candidate holes message", " Pack information about holes found and the rgb image inside a message.", " This message will be published to and received by the hole fusion node", " Publish the candidate holes message", "", " Read the name of the topic from where the rgb node acquires the", " rgb image and store it in a private member variable", " Read the name of the topic to which the rgb node will be publishing", " information about the candidate holes found and store it in a private", " member variable", "", "////////////////// Blob detection - specific parameters //////////////////", " In wavelet mode, the image shrinks by a factor of 4", "//////////////////////////// Debug parameters ////////////////////////////", " Show the rgb image that arrives in the rgb node", "////////////////// Parameters specific to the RGB node ///////////////////", "------------------- Edge detection specific parameters -------------------", " The opencv edge detection method:", " 0 for the Canny edge detector", " 1 for the Scharr edge detector", " 2 for the Sobel edge detector", " 3 for the Laplacian edge detector", " 4 for mixed Scharr / Sobel edge detection", " Canny parameters", "------------- Parameters needed for histogram calculation ----------------", "----------------- Outline discovery specific parameters ------------------", " The detection method used to obtain the outline of a blob", " 0 for detecting by means of brushfire", " 1 for detecting by means of raycasting", " When using raycast instead of brushfire to find the (approximate here)", " outline of blobs, raycast_keypoint_partitions dictates the number of", " rays, or equivalently, the number of partitions in which the blob is", " partitioned in search of the blob's borders", "------------------- Loose ends connection parameters ---------------------", " In wavelet mode, the image shrinks by a factor of 4", " Selects the method for extracting a RGB image's edges.", " Choices are via segmentation and via backprojection", "------------------- RGB image segmentation parameters --------------------", " Parameters specific to the pyrMeanShiftFiltering method", " Term criteria for the pyrMeanShiftFiltering method", " True to posterize the product of the segmentation", " FloodFill options regarding minimum and maximum colour difference", "------------ RGB image edges via backprojection parameters ---------------", " The threshold applied to the backprojection of the RGB image", " captured by the image sensor", " Watershed-specific parameters", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "rgb_hole_detector": ["*******************************************************************", "", "", " Debug", " Detect edges in rgbImage", " Debug", " Find blobs in the edges image. Each blob is represented as", " a keypoint which is the center of the blob found", " Debug", " The final vectors of keypoints, rectangles and blobs' outlines.", "", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "timer": ["*******************************************************************", " Mins", " Sec", " Ms"], "filters": ["*******************************************************************", "", " Initialize structures", " Filter #1 (Color homogeneity inside blob)------------------------------", " Filter #2 (Luminosity difference)------------------------------------", " Check for luminosity difference between the points that constitute", " the blob's bounding box and the points inside the blob's outline", " Filter #3 (Texture difference)---------------------------------------", " Filter #4 (Back project model histogram)-----------------------------", " Filter #5 (through difference of depth)--------------------------------", " Filter #6------------------------------------------------------------", " Inflate the bounding boxes by an inflation size.", " For a blob to be at least a potential hole, all the points that", " constitute the inflated rectangle should lie on exactly one plane.", " Filter #7 (depth & area comparison)----------------------------------", " Filter #8------------------------------------------------------------", " Brushfire from blob outline to blob bounding box", " with an inflation size (inflates the rectangle by x pixels).", " If the points between the blob's outline and the inflated rectangle", " lie on one plane, this blob is a hole.", " Filter #9 (Depth homogeneity)----------------------------------------", " All holes are considered valid except for those that are edgeless", " inside the area denoted by the conveyor->outlines points", " Debug", "", " A mapping of the filters' execution order to an identifier for each", " filter", " The filtering mode permission to application of depth analysis", " condition.", " Active Depth and RGB filters will both be applied", " Depth filtering cannot be applied, hence only RGB filters will", " be utilized", " Debugging images and messages of validity probabilities", " per candidate hole", " Apply each active filter, depending on the interpolation method", " o_it iterator ends", " Debug", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "planes_detection": ["*******************************************************************", "", "", "pointclouds.org/documentation/tutorials/voxel_grid.php)", " The output filtered cloud", "", " Apply voxel filtering", " The vector of planar point clouds", " The coefficients of the planes", " Locate planes", "", "www.pointclouds.org/documentation/tutorials/", " Create the segmentation object", " Optional", " Mandatory", " Maybe a value needs to be set dynamically here, depending on", " the distance of the kinect to the plane.", " Copy the input cloud to a point cloud that we will be processing", " While 100 x num_points_to_exclude % of the original", " cloud is still there", " The plane's coefficients", " The plane's inliers", " Segment the largest planar component from the remaining cloud", " Add the coefficients and inliers to their respective vectors", " Create the filtering object", " Extract the inliers", " Remove the plane found from pointCloudProcessed and place it in", " cloud_p. pointCloudProcessed goes unaffected.", " The inliers of the largest planar component create cloud_p", " Push back the point cloud of the plane found", " We want to extract the rest of the points that were found to lie on", " a plane", " In short: cloud_f = pointCloudProcessed - cloud_p", " pointCloudProcessed is now without cloud_p, that is,", " without the points that were", " found to lie on the largest planar component of pointCloudProcessed", " Increment the number of planes found", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_fusion": ["*******************************************************************", "", "", "", " Initialize the parent frame_id to an empty string", " Acquire the names of topics which the Hole Fusion node will be having", " transactionary affairs with", " Check if Thermal is enabled to run with hole-detection Package", " Thermal is enabled", " Thermal is disabled", " Initialize the numNodesReady variable.", " It acts as a counter of nodes that have published their output to the", " hole fusion node in each execution cycle.", " Advertise the topic that the rgb_depth_synchronizer will be", " subscribed to in order for the hole_fusion_node to unlock it", " Advertise the topic where any external node(e.g. a functional test node)", " will be subscribed to know that the hole node has finished processing", " the current candidate holes as well as the result of the procedure.", " Advertise the topic that the yaw and pitch of the keypoints of the final,", " valid holes will be published to", " Advertise the topic that information about the final holes,", " will be published to", " Command line usage:", " image_view /pandora_vision/hole_detector/debug_valid_holes_image", " _image_transport:=compressed", " Advertise the topic that information about holes found by the Depth", " and RGB nodes will be published to", " Command line usage:", " image_view /pandora_vision/hole_detector/debug_respective_holes_image", " _image_transport:=compressed", " Advertise the topic that the enhanced image", " will be published to", " enhancedImagesPublisher_ = nodeHandle_.advertise", "   <pandora_vision_msgs::EnhancedImage>(", "     enhancedImagesTopic_, 1, true);", " Advertise the topic that the image of the final holes,", " will be published to", " Advertise the topic that the image of the final holes,", " will be published to", " InterpolatedDepthImagePublisher_ = nodeHandle_.advertise", "   <sensor_msgs::Image>(", "     InterpolatedDepthImageTopic_, 1);", " Advertise the topic where the Hole Fusion node requests from the", " synchronizer node to subscribe to the input point cloud topic", " Advertise the topic where the Hole Fusion node requests from the", " synchronizer node to leave its subscription to the", " input point cloud topic", " Subscribe to the topic where the depth node publishes", " candidate holes", " Subscribe to the topic where the rgb node publishes", " candidate holes", " Subscribe to the topic where the synchronizer node publishes", " the point cloud", " Subscribe to the topic where the thermal node publishes", " candidate holes", " The dynamic reconfigure server for debugging parameters", " The dynamic reconfigure server for parameters pertaining to the", " priority of filters' execution:w", "", " The dynamic reconfigure server for parameters pertaining to", " thresholds of filters", " The dynamic reconfigure server for general parameters", " The dynamic reconfigure server for parameters pertaining to", " the validity of holes", " Set the initial on/off state of the Hole Detector package to off", " Initialize the filtering mode variable to an invalid value", " Calculate the collective histogram of images of walls needed", " for comparing against the one of images of the material surrounding", " candidate holes", "", "", " Clear the current depthHolesConveyor struct", " (or else keyPoints, rectangles and outlines accumulate)", " Unpack the message", " The candidate holes acquired from the depth node and the interpolated", " depth image are set", " If the RGB candidate holes and the RGB image are set", " and the point cloud has been delivered and interpolated,", " unlock the synchronizer and process the candidate holes from both sources", "", " Clear the current depthHolesConveyor struct", " (or else keyPoints, rectangles and outlines accumulate)", " Unpack the message", " The candidate holes acquired from the thermal node and the", " thermal image are set", " If the RGB candidate holes and the RGB image are set", " and the point cloud has been delivered and interpolated,", " unlock the synchronizer and process the candidate holes from both sources", "", " A vector of images that each one of them represents the corresponding", " hole's mask: non-zero value pixels are within a hole's outline points", " A vector of sets that each one of them contains indices of points", " inside the hole's outline", " A vector of vertices of each inflated bounding rectangle.", " Since inflated rectangle's vertices may go outside the image's bounds,", " this vector stores the indices of the keypoints whose corresponding", " inflated rectangle is in totality within the image's bounds", " A vector of sets that each one of them contains indices of points", " between the hole's outline and its respective bounding box", " A vector of images that each one of them contains points", " between the hole's outline and its respective bounding box", " Construct the necessary vectors, depending on which filters", " are to run in runtime and on the interpolation method", " Initialize the probabilities 2D vector.", " But first we need to know how many rows the vector will accomodate.", " If a Parameters::HoleFusion::run_checker_* variable is greater than zero,", " the respective filter is set to run", " The number of active RGB filters, regardless of the interpolation method", " The number of active depth filters", " If depth analysis is possible", " Depth analysis is not possible. Reserve positions in the probabilities", " vector only for the amount of RGB filters active.", " The 2D vector that contains the probabilities from the rgb filtering", " regime.", " Each column is a specific hole.", " In each row there are values of probabilities by a specific filter", " Apply all active filters, depending on the interpolation method", " All filters have been applied, all probabilities produced", "", " Parse robot description", " The parameter was not found.", " Set the parent of the frame_id to a default value.", " Get current link and its parent", " Set the parent frame_id to the parent of the frame_id_", "", " Read the name of the topic from where the Hole Fusion node acquires the", " input point cloud", " Read the name of the topic from where the Hole Fusion node acquires the", " candidate holes originated from the Depth node", " Read the name of the topic from where the Hole Fusion node acquires the", " candidate holes originated from the Rgb node", " Read the name of the topic from where the Hole Fusion node acquires the", " candidate holes originated from the Thermal node", " Read the name of the topic that the Hole Fusion node uses to unlock", " the synchronizer node", " Get the topic where the result of the hole processing will be", " published.", " Read the name of the topic that the Hole Fusion node uses to publish", " information about the valid holes found by the Hole Detector package", " Read the name of the topic that the Hole Fusion node uses to publish", " the EnhancedImage msg", " if (!privateNodeHandle_.getParam(\"published_topics/enhanced_images_topic\",", "     enhancedImagesTopic_))", " {", "   NODELET_FATAL(", "     \"[%s] Could not find topic enhanced_images_topic\", nodeName_.c_str());", "   ROS_BREAK();", " }", " Read the name of the topic that the Hole Fusion node uses to publish", " additional information about the valid holes found by the", " Hole Detector package", " Read the name of the topic that the Hole Fusion node uses to publish", " the InterpolatedDepthImage found by the", " Hole Detector package", " if (!privateNodeHandle_.getParam(\"published_topics/interpolated_depth_topic\",", "     InterpolatedDepthImageTopic_))", " {", "   NODELET_FATAL(", "     \"[%s] Could not find topic interpolated_depth_topic\", nodeName_.c_str());", "   ROS_BREAK();", " }", " Read the name of the topic that the Hole Fusion node uses to publish", " messages so that the synchronizer node subscribes to the", " input point cloud", " Read the name of the topic that the Hole Fusion node uses to publish", " messages so that the synchronizer node leaves its subscription to the", " input point cloud", " Read the name of the topic that the Hole Fusion node uses to publish", " an image of holes found by the Depth and RGB nodes", " Read the name of the topic that the Hole Fusion node uses to publish", " an image of the valid holes found", "", "", "//////////////////////////// Debug parameters ////////////////////////////", " Publish the enhancedImage", " Show the holes that each of the depth and RGB nodes transmit to the", " hole fusion node, on top of their respective origin images", " Show all valid holes, from either the Depth or RGB source, or", " the merges between them", " The product of this package: unique, valid holes", " In the terminal's window, show the probabilities of candidate holes", " Show the texture's watersheded backprojection", "", " Depth / Area", " Depth diff", " Outline of rectangle plane constitution", " Intermediate points plane constitution", " Depth homogeneity", " Color homogeneity", " Luminosity diff", " Texture diff", " Texture backproject", "", " Depth / Area", " Depth diff", " Outline of rectangle plane constitution", " Intermediate points plane constitution", " Depth homogeneity", " Colour homogeneity", " Luminosity diff", " Texture diff", " Texture backproject", "", " Threshold parameters", " Histogram parameters", " Backprojection parameters", " The inflation size of the bounding box's vertices", " Depth diff parameters", " 0 for binary probability assignment on positive depth difference", " 1 for gaussian probability assignment on positive depth difference", " The mean expected difference in distance between a hole's keypoint", " and the mean distance of its bounding box's vertices", " from the depth sensor", " The standard deviation expected", " Min difference in depth between the inside and the outside of a hole", " Max difference in depth between the inside and the outside of a hole", " Plane detection parameters", "--------------------------- Merger parameters ----------------------------", " Option to enable or disable the merging of holes", " Holes connection - merger parameters", "--------------------------- Texture parameters ---------------------------", " The threshold for texture matching", " The threshold for texture mismatching", " Method to scale the CV_32FC1 image to CV_8UC1", "----------------- Outline discovery specific parameters ------------------", " The detection method used to obtain the outline of a blob", " 0 for detecting by means of brushfire", " 1 for detecting by means of raycasting", " When using raycast instead of brushfire to find the (approximate here)", " outline of blobs, raycast_keypoint_partitions dictates the number of", " rays, or equivalently, the number of partitions in which the blob is", " partitioned in search of the blob's borders", "------------ RGB image edges via backprojection parameters ---------------", " Backprojection parameters", " Watershed-specific parameters", "", " The validation process", " config.validation_process;", " When depth analysis is applicable", " When depth analysis is not applicable, we can only rely", " on RGB analysis", "", " Convert the header of the point cloud message", " Store the frame_id and timestamp of the point cloud under processing.", " The respective variables in the headers of the published messages will", " be set to these values.", " Because the frame_id will be used to retrieve its parent frame_id from", " the robot's description, and the frame_id starts with a forward slash,", " remove it, in order for the search to be successful.", " The parent frame_id cannot be set in the constructor because the", " frame_id is not known until the first point cloud message arrives.", " In order not to parse the urdf file every time,", " set the parent frame_id string once", " Because the input point cloud is marked as const,", " and we need to interpolate the noise in it,", " copy the input point cloud to a local one.", " Extract the depth image from the point cloud message", " Interpolate the depthImage", " The noise elimination method above defines the interpolation method.", " Only in interpolation_method of zero can the depth filters through which", " each candidate hole is passed be utilized: there is no valid depth", " information available if the value of interpolation_method is set to", " other than zero.", " Set the interpolatedDepthImage's values as the depth values", " of the point cloud", " The interpolated point cloud, frame_id and timestamp are set", " If the depth and RGB candidate holes, the interpolated depth image", " and the RGB image are set,", " unlock the synchronizer and process the candidate holes from both sources", "", " if (Parameters::Debug::publish_enhanced_Images)", " {", "   publishEnhancedImage();", "   publishInterpolatedDepthImage();", " }", " Holes originated from analysis on the depth image,", " on top of the depth image", " Holes originated from analysis on the RGB image,", " on top of the RGB image", " Holes originated from analysis on the depth image,", " on top of the RGB image", " Holes originated from analysis on the RGB image,", " on top of the Depth image", " The four images", " The titles of the images", " If mode is enabled add the information from thermal procedure", " Holes originated from analysis on the thermal image,", " on top of the depth image", " Holes originated from analysis on the thermal image,", " on top of the rgb image", " Holes originated from analysis on the thermal image,", " on top of the resized Thermal image", " Publish an image depicting the holes found by the Depth RGB and Thermal nodes", " Merge the conveyors from the RGB Depth and Thermal sources into one conveyor", " The container in which holes will be assembled before validation", " Check if merging is enabled", " Keep a backup of the original holes found from both the", " RGB and Depth nodes", " Apply the {assimilation, amalgamation, connection} processes", " The original holes and the merged ones now reside under the", " preValidatedHoles conveyor", " Because mergers may have not been deemed valid, the preValidatedHoles", " container may include duplicate holes. Delete them, so that resources", " are not generated for them, and time is not wastefully consumed.", " Apply all active filters and obtain a 2D vector containing the", " probabilities of validity of each candidate hole, produced by all", " active filters", " Write the extracted probabilities to a file. These will be used to", " produce a dataset of values that need to be minimized in order for a", " sound validation procedure to be employed", " produceDataset(rgbdHolesConveyor, probabilitiesVector2D);", " Which candidate holes are actually holes?", " The probabilities obtained above need to be evaluated", " A vector containing images, one per valid hole found.", " A vector of validity probabilities per valid hole found.", " Iterate over the map of valid holes to their validity probabilities", " A vector containing one entry: the validity probability of the", " it->first-th hole", " The it->first-th valid hole", " Project this valid hole onto the rgb image", " Show all valid holes in one window", " In general, the preValidatedHoles conveyor will contain", " merged and um-merged holes, potentially resulting in multiple entries", " inside the conveyor for the same physical hole. The method below", " picks the most probable valid hole among the ones referring to the same", " physical hole.", " Rename the preValidatedHoles to uniqueValidHoles", " Contains the validity probability for each hole considered valid", " Valid holes on top of the interpolated depth image", " Valid holes on top of the RGB image", " The two images", " The titles of the images", " If there are valid holes, publish them", " Publish the enhanced holes message", " regardless of the amount of valid holes", " Open the dataset", " True holes", " << probabilities[4][i] << \", \"", " << probabilities[5][i] << \", \"", " << probabilities[6][i] << \", \"", " << probabilities[7][i] << \", \"", " << probabilities[4][i] << \", \"", " << probabilities[5][i] << \", \"", " << probabilities[6][i] << \", \"", " << probabilities[7][i] << \", \"", "", " void HoleFusion::publishInterpolatedDepthImage()", " {", "   // TO DO changed to ImagePtr", "   sensor_msgs::Image depthMsg;", "   depthMsg = MessageConversions::convertImageToMessage(", "   Visualization::scaleImageForVisualization(interpolatedDepthImage_,", "       Parameters::Image::scale_method),", "       sensor_msgs::image_encodings::TYPE_8UC1,", "       depthMsg);", "   InterpolatedDepthImagePublisher_.publish(depthMsg);", " }", "", " void HoleFusion::publishEnhancedImage()", " {", "   // The overall message of enhanced holes that will be published", "   pandora_vision_msgs::EnhancedImagePtr enhancedImagesMsgPtr(new pandora_vision_msgs::EnhancedImage);", "   // Set the rgbImage in the enhancedImagesMsg message to the rgb image", "   enhancedImagesMsgPtr->rgbImage = MessageConversions::convertImageToMessage(", "   rgbImage_,", "   sensor_msgs::image_encodings::TYPE_8UC3,", "   enhancedImagesMsgPtr->rgbImage);", "   // Set the depthImage in the enhancedImagesMsg message to the depth image", "   enhancedImagesMsgPtr->depthImage = MessageConversions::convertImageToMessage(", "   Visualization::scaleImageForVisualization(interpolatedDepthImage_,", "       Parameters::Image::scale_method),", "       sensor_msgs::image_encodings::TYPE_8UC1,", "       enhancedImagesMsgPtr->depthImage);", "   // Set whether depth analysis is applicable", "   enhancedImagesMsgPtr->isDepth = (filteringMode_ == RGBD_MODE);", "   // Set the message's header", "   enhancedImagesMsgPtr->header.stamp = timestamp_;", "   enhancedImagesMsgPtr->header.frame_id = frame_id_;", "   enhancedImagesPublisher_.publish(enhancedImagesMsgPtr);", " }", "", " The overall message of enhanced holes that will be published", " Set the rgbImage in the enhancedHolesMsg message to the rgb image", " Set the depthImage in the enhancedHolesMsg message to the depth image", " enhancedHolesMsgPtr->depthImage = MessageConversions::convertImageToMessage(", "   interpolatedDepthImage_,", "   sensor_msgs::image_encodings::TYPE_8UC1,", "   enhancedHolesMsgPtr->depthImage);", " Set the thermalImage in the enhancedHolesMsg message to the thermal image", " Set whether depth analysis is applicable", " Set the message's header", " The enhanced hole message. Used for one hole only", " Set the hole's keypoint", " Set the hole's bounding box width and height", " Push back into the enhancedHolesMsg message", " Publish the overall message", "", " Holes originated from analysis on the depth image,", " on top of the depth image", " Holes originated from analysis on the RGB image,", " on top of the RGB image", " The four images", " The titles of the images", " Convert the image into a message", " Publish the image message", "", " The depth sensor's horizontal and vertical field of view", " The frame's height and width", " The overall valid holes found message", " Counter for the holes' identifiers", " A single hole's message", " The hole's keypoint coordinates relative to the center of the frame", " The keypoint's yaw and pitch", " Setup everything needed by the single hole's message", " Fill the overall holes found message with the current hole message", " Publish the message containing the information about all holes found", " Publish an image with the valid holes found", " The holes conveyor containing only the valid holes", " Contains the validity probability for each hole considered valid", " Valid holes on top of the RGB image", " Convert the image into a message", " Publish the image message", "", " Clear the current rgbHolesConveyor struct", " (or else keyPoints, rectangles and outlines accumulate)", " Unpack the message", " The candidate holes acquired from the rgb node and the rgb image are set", " If the depth candidate holes and the interpolated depth image are set", " and the point cloud has been delivered and interpolated,", " unlock the synchronizer and process the candidate holes from both sources", "", " If the inImage is not of type CV_32FC1, return", "", " The new on/off state of the Hole Detector package", " off -> on", " The on/off state of the Hole Detector Package is off, so the", " synchronizer is not subscribed to the input point cloud.", " Make him subscribe to it now", " Set the Hole Detector's on/off state to the new one.", " In this case, it has to be before the call to unlockSynchronizer", " If all three callbacks have finished execution and they are waiting", " a new input while the state changed, the synchronizer needs to be", " unclocked manually here.", " By contrast, if the number of nodes ready is non-zero,", " while maybe impossible due to the halted state of the Hole Detector,", " the last callback that finishes execution will attempt to unlock the", " synchonizer, thus a manual unlock is not needed.", " on -> off", " The on/off state of the Hole Detector package is on and is to be off.", " The synchronizer node is subscribed to the input point cloud and now", " it should leave its subscription to it so that the processing", " resources of the robot's computer pertaining to the Hole Detector", " package are minimized", " Shutdown or open publisher of enhanced images", "", " The Hole Fusion node can request from the synchronizer node to process", " a new point cloud only if the on/off state of the Hole Detector package", " is set to on", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_merger": ["*******************************************************************", "", "", " Now, we need to find the combined outline points", " On an image, draw the holes' masks.", " Invert the image and brushfire in the black space in order to", " obtain the new outline points", " Draw the amalgamator's mask onto canvas", " Draw the amalgamatable's mask onto canvas", " In the meantime, construct the amalgamator's new hole set", " Locate the outline of the combined hole", " Set the discovered outline as the outline of the combined hole", " The amalgamator's new least area rotated bounding box will be the", " one that encloses the new (merged) outline points", " Obtain the four vertices of the new rotated rectangle", " Same as substituteVerticesArray array, but vector", " Store the four vertices to the substituteVerticesVector", " Replace the amalgamator's vertices with the new vertices", " Set the overall candidate hole's keypoint to the center of the", " newly created bounding rectangle", "", " If there are no candidate holes,", " or there is only one candidate hole,", " there is no meaning to this operation", " A vector that indicates when a specific hole has finished", " examining all the other holes in the conveyor for merging.", " Initialized at 0 for all conveyor entries, the specific hole", " that corresponds to a vector's entry is given a 1 when it has", " finished examining all other holes.", " The index of the candidate hole that will", " {assimilate, amalgamate, connect} the passiveId-th candidate hole.", " The activeId always has a value of 0 due to the implementation's", " rationale: The candidate hole that examines each hole in the", " rgbdHolesConveyor is always the first one. When it has finished,", " it goes back into the rgbdHolesConveyor, at the last position", " The index of the candidate hole that will be", " {assimilated, amalgamated, connected} by / with", " the activeId-th candidate hole", " Is the activeId-th candidate hole able to", " {assimilate, amalgamate, connect to} the passiveId-th candidate hole?", " The holesMaskSetVector vector is used in the merging processes", " Indicates the end of the merging process", " If a(n) {assimilation, amalgamation, connection} did happen,", " regenerate the mask sets in order for them to reflect the new", " state of holes", " Is the activeId-th candidate hole able to assimilate the", " passiveId-th candidate hole?", " Is the activeId-th candidate hole able to amalgamate the", " passiveId-th candidate hole?", " Is the passiveId-th candidate hole able to be connected with the", " activeId-th candidate hole?", " Copy the original holes conveyor to a temp one.", " The temp one will be tested through the hole filters", " On success, temp will replace rgbdHolesConveyor,", " on failure, rgbdHolesConveyor will remain unchanged", " Copy the original holes masks set to a temp one.", " If the temp conveyor is tested successfully through the hole", " filters, temp will replace the original.", " On failure, the original will remain unchanged", " Delete the passiveId-th candidate hole", " Delete the passiveId-th candidate hole,", " alter the activeId-th candidate hole so that it has amalgamated", " the passiveId-th candidate hole", " Delete the passiveId-th candidate hole,", " alter the activeId-th candidate hole so that it has been", " connected with the passiveId -th candidate hole", " Since the {assimilator, amalgamator, connector} is able,", " delete the assimilable's entries in the vectors needed", " for filtering and merging", " Obtain the activeId-th candidate hole in order for it", " to be checked against the selected filters", " Create the necessary vectors for each hole checker and", " merger used", " The inflated rectangles vector is used in the", " checkHolesDepthDiff and checkHolesRectangleEdgesPlaneConstitution", " checkers", " The vector of depth-filters-derived probabilities", " Check the difference between the mean depth of the", " vertices of the merged hole's bounding box and the depth of the", " merged hole's keypoint", " The probability that the merged hole is valid by the above filter", " Check the depth / area proportion for the ithHole", " The probability that the merged hole is valid by the above filter", " Probabilities threshold for merge acceptance.", " In the assimilation operation, the temp conveyor unconditionally", " replaces the original conveyor", " Since the tempHolesConveyor's ithHole has been positively tested,", " the tempHolesConveyor is now the new rgbdHolesConveyor", " ..and the new holesMasksSetVector is the positively tested", " temp one", " Delete the passiveId-th entry of the finishVector since the", " passiveId-th hole has been absorbed by the activeId-th hole", " Because of the merge happening, the activeId-th", " candidate hole must re-examine all the other holes", " rgbdHolesConveyor remains unchanged", " passiveId-th hole not merged. let's see about the next one", " isAble == false", " passiveId-th hole not merged. let's see about the next one", " If the passiveId-th hole was the last one to be checked for merge,", " the one doing the merge is rendered obsolete, so go to the next one", " by moving the current activeId-th candidate hole to the back", " of the rgbdHolesConveyor. This way the new activeId-th candidate", " hole still has a value of 0, but now points to the candidate hole", " next to the one that was moved back", " No meaning moving to the back of the rgbdHolesConveyor if", " there is only one candidate hole", " activeId-th hole candidate finished examining the rest of the", " hole candidates. move it to the back of the rgbdHolesConveyor", " Remove the activeId-th candidate hole from its former position", " Remove the activeId-th set from its position and append it", " Since the candidate hole was appended at the end of the", " rgbdHolesConveyor, the finish vector needs to be shifted", " once to the left because the value 1 is always set at the end", " of the finishVector vector. See below.", " Return the passive's candidate hole identifier to the", " next of the active's candidate hole identifier, which is 0", " Since the ith candidate hole was appended at the end of the", " rgbdHolesConveyor, the position to which it corresponds in the", " finishVector is at the end of the vector.", " Place the value of 1 in the last position, indicating that the", " previously activeId-th candidate hole has finished examining all", " other candidate holes for merging", " Count how many aces there are in the finishVector", " If they amount to the size of the vector, that means that", " each hole has finished examining the others, and the current", " operation is complete", "", " If there are no candidate holes,", " or there is only one candidate hole,", " there is no meaning to this operation", " A vector that indicates when a specific hole has finished", " examining all the other holes in the conveyor for merging.", " Initialized at 0 for all conveyor entries, the specific hole", " that corresponds to a vector's entry is given a 1 when it has", " finished examining all other holes.", " The index of the candidate hole that will", " {assimilate, amalgamate} the passiveId-th candidate hole.", " The activeId always has a value of 0 due to the implementation's", " rationale: The candidate hole that examines each hole in the", " rgbdHolesConveyor is always the first one. When it has finished,", " it goes back into the rgbdHolesConveyor, at the last position", " The index of the candidate hole that will be", " {assimilated, amalgamated} by / with", " the activeId-th candidate hole", " The holesMaskSetVector vector is used in the merging processes", " Is the activeId-th candidate hole able to", " {assimilate, amalgamate} the passiveId-th candidate hole?", " Is the activeId-th candidate hole able to assimilate the", " passiveId-th candidate hole?", " Is the activeId-th candidate hole able to amalgamate the", " passiveId-th candidate hole?", " Copy the original holes conveyor to a temp one.", " The temp one will be tested through the hole filters", " On success, temp will replace rgbdHolesConveyor,", " on failure, rgbdHolesConveyor will remain unchanged", " Copy the original holes masks set to a temp one.", " If the temp conveyor is tested successfully through the hole", " filters, temp will replace the original.", " On failure, the original will remain unchanged", " Delete the passiveId-th candidate hole", " Delete the passiveId-th candidate hole,", " alter the activeId-th candidate hole so that it has amalgamated", " the passiveId-th candidate hole", " Since the {assimilator, amalgamator} is able,", " delete the assimilable's entries in the vectors needed", " for filtering and merging", " Since the merge has been uncondionally happened,", " the tempHolesConveyor is now the new rgbdHolesConveyor", " ..and the new holesMasksSetVector is the positively tested", " temp one", " Delete the passiveId-th entry of the finishVector since the", " passiveId-th hole has been absorbed by the activeId-th hole", " Because of the merge happening, the activeId-th", " candidate hole must re-examine all the other holes", " isAble == false", " passiveId-th hole not merged. let's see about the next one", " If the passiveId-th hole was the last one to be checked for merge,", " the one doing the merge is rendered obsolete, so go to the next one", " by moving the current activeId-th candidate hole to the back", " of the rgbdHolesConveyor. This way the new activeId-th candidate", " hole still has a value of 0, but now points to the candidate hole", " next to the one that was moved back", " No meaning moving to the back of the rgbdHolesConveyor if", " there is only one candidate hole", " activeId-th hole candidate finished examining the rest of the", " hole candidates. move it to the back of the rgbdHolesConveyor", " Remove the activeId-th candidate hole from its former position", " Remove the activeId-th set from its position and append it", " Since the candidate hole was appended at the end of the", " rgbdHolesConveyor, the finish vector needs to be shifted", " once to the left because the value 1 is always set at the end", " of the finishVector vector. See below.", " Return the passive's candidate hole identifier to the", " next of the active's candidate hole identifier, which is 0", " Since the ith candidate hole was appended at the end of the", " rgbdHolesConveyor, the position to which it corresponds in the", " finishVector is at the end of the vector.", " Place the value of 1 in the last position, indicating that the", " previously activeId-th candidate hole has finished examining all", " other candidate holes for merging", " Count how many aces there are in the finishVector", " If they amount to the size of the vector, that means that", " each hole has finished examining the others, and the current", " operation is complete", "", " The connection rationale is as follows:", " Since the two holes are not overlapping each other,", " some sort of connection regime has to be established.", " The idea is that the points that consist the outline of each hole", " are connected via a cv::line so that the overall connector's outline", " is the overall shape's outline", " The image on which the hole's outline connection will be drawn", " Construct the connector's new hole mask", " First, clear the former one", " Locate the outline of the combined hole", " Set the discovered outline as the outline of the combined hole", " The connectable's new least area rotated bounding box will be the", " one that encloses the new (merged) outline points", " Obtain the four vertices of the new rotated rectangle", " Same as substituteVerticesArray array, but vector", " Store the four vertices to the substituteVerticesVector", " Replace the connector's vertices with the new vertices", " Replace the connector's vertices with the new vertices", " Set the overall candidate hole's keypoint to the mean of the keypoints", " of the connector and the connectable", "", " If the amalgatamable's area is larger than the amalgamator's,", " this amalgamator is not capable of amalgamating the amalgamatable", " Keep the size of the input assimilatorHoleMaskSet for", " comparing against it", " Clone the amalgamator's hole mask set.", " Try to insert every element of the amalgamatable hole mask set into", " the amalgamator's set.", " This amalgamator can amalgamate the amalgamatable if and only if the", " amalgamatable is not entirely inside the amalgamator or", " the amalgamatable and the amalgamator are not not connected", "", " If the assimilable's area is larger than the assimilator's,", " this assimilator is not capable of assimilating the assimilatable", " Keep the size of the input assimilatorHoleMaskSet for", " comparing against it", " Clone the assimilator's hole mask set.", " Try to insert every element of the assimilable hole mask set into", " the assimilator's set.", " This assimilator can assimilate the assimilable if and only if the", " assimilable is inside the assimilator, in other words, if the", " assimilator's hole mask set size remains unchanged after the", " insertion of the assimilable's elements into it", "", " If the connectable's area is greater than the connector's,", " this connectable is not capable of being connected with the connector", " Keep the size of the input assimilatorHoleMaskSet for", " comparing against it", " Clone the connector's hole mask set.", " Try to insert every element of the assimilable hole mask set into", " the connector's set.", " This connectable can be connected with the connector if and only if the", " connectable is outside of the connector", " The real min distance (in meters) between two points of the", " connector's and connectable's outlines", " The real max distance (in meters) between two points of the", " connector's and connectable's outlines", " The connectable's current outline point x,y,z coordinates", " measured by the depth sensor", " The connector's current outline point x,y,z coordinates", " measured by the depth sensor", " The current outline points distance", " If the minimum distance between the connector's and connectable's", " outlines is greater than a distance thrshold,", " this connectable is not a candidate to be connected with", " the connector", " If the maximum distance between the connector's and connectable's", " outlines is greater than a distance thrshold,", " this connectable is not a candidate to be connected with", " the connector", "", " Keep a copy of the initial (not merged) candidate holes for", " debugging and exibition purposes", " Push back the identifier of each keypoint", " Try to merge holes that can be assimilated, amalgamated or connected.", " If Depth analysis is applicable, {assimilate, amalgamate, connect}", " conditionally, based on depth filters. In the opposite case,", " {assimilate, amalgamate} unconditionally.", " Push back the identifier of each keypoint", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_validation": ["*******************************************************************", "", "", " The map of holes' indices that are valid and", " their respective validity probability that will be returned", "", " The map of holes' indices that are valid and", " their respective validity probability that will be returned", " Commence setting of priorities given to hole checkers.", " Each priority given is not fixed,", " but there is an apparent hierarchy witnessed here.", " In order to reach a valid conclusion, an analytical method had to be", " used, which is one analogous to the one presented in", " {insert link of Manos Tsardoulias's PHD thesis}", " Apply a weight to each probability according to its weight order.", " If depth analysis was not possible, use the urgent weight order.", " Color homogeneity", " Depth / area", " Luminosity diff", " Outline of rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Color homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " The total validity probability of the i-th hole", " The validity acceptance threshold", " If the total validity probability of the i-th hole exceeds a", " pre-determined threshold, we consider the i-th hole to be valid", "", " The map of holes' indices that are valid and", " their respective validity probability that will be returned", " RGB + Depth mode. All RGB and Depth active filters produce", " probabilities that will have to be checked on a per-filter basis,", " against individually-set thresholds.", " Color homogeneity", " Depth / area", " Luminosity diff", " Outline of rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Color homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " If the i-th candidate hole has passed the above checks,", " it surely is valid. Its validity probability will amount to the", " mean value of its separate validity probabilities.", " Return the valid set", "", " The map of holes' indices that are valid and", " their respective validity probability that will be returned", " Commence setting of priorities given to hole checkers.", " Each priority given is not fixed,", " but there is an apparent hierarchy witnessed here.", " In order to reach a valid conclusion, an analytical method had to be", " used, which is one analogous to the one presented in", " {insert link of Manos Tsardoulias's PHD thesis}", " Apply a weight to each probability according to its weight order.", " If depth analysis was not possible, use the urgent weight order.", " Color homogeneity", " Depth / area", " Luminosity diff", " Outline of rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Color homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " The total validity probability of the i-th hole", " The validity acceptance threshold", " If the total validity probability of the i-th hole exceeds a", " pre-determined threshold, we consider the i-th hole to be valid", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "rgb_filters": ["*******************************************************************", "", "", " Copy the input image to inImage_ so as to get a pointer on it", " Reduce the colours of inImage_.", " For a value of 16 for div, the maximum possible number of colours", " is 2^12. For every duplication of div, the number of possible colours", " is divided by a factor of 2^3", " Get the address of row i", " Process each pixel", " Sets featuring all the different colours found inside each image mask", " Collect the different values of colour components for the", " points of the current mask", " The number of distinct colours inside the mask", " Threshold the number of colours", "", " In order to find the luminosity", " convert the input RGB image to YCrCb format.", " Split the image to its three components", " The luminosity of the image is expressed by the Y channel.", " For each inflated rectangle, calculate the luminosity of", " (1) the points between the blob's outline and the edges of the", " inflated rectangle and", " (2) the points inside the blob's outline", " The current hole's inside points luminosity sum", " The current hole's intermediate points luminosity sum", " Mean luminosity of the inside points of the current hole", " Mean luminosity of the intermediate points", " If the luminosity of the inside of the candidate hole is greater", " than the luminosity of the points beyond it and restricted by the", " edges of its bounding box, it surely is not a hole", "", " Obtain the backprojection of the inImage, according to the inHistogram", " Obtain a homogenous backprojection image", " Obtain a pointer on watersheded", " For each inflated rectangle, calculate the probabilities of", " (1) the points between the blob's outline and the edges of the", " inflated rectangle and", " (2) the points inside the blob's outline", " based on the watersheded image", " The average probability of the points consisting the inflated", " rectangle matching the histograms in the inHistogram", " The average probability of the points inside the blob's outline", " matching the histograms in the inHistogram", " This blob is considered valid, with a non zero validity probability,", " if the points consisting the inflated rectangle have a greater", " resemblance (through the probability-expressing values of the", " back project cv::MatND) to the inHistogram than the one of the points", " inside the blob's outline", "", " Since not all rectangles may make it, store the indices", " of the original keypoints that correspond to valid inflated rectangles", " in the validKeyPointsIndices vector", " inImage transformed from BGR format to HSV", " The first value will always be with regard to Hue", " Histogram-related parameters", " hue varies from 0 to 179, saturation or value from 0 to 255", " Use the 0-th and secondaryChannel-st channels", " Produce the histogram for the points in between the blob's outline", " and the inflated rectangle's edges", " Produce the histogram for the points inside the outline of the blob", " For each input histogram compute the largest probability", " Find the correlation between the model histogram and the histogram", " of the inflated rectangle", " Find the correlation between the model histogram and the histogram", " of the points inside the blob", " This blob is considered valid if there is a correlation between", " the histogram of the external to the hole's outline points", " and the model histogram (inHistogram) greater than a threshold and,", " simultaneously, the correlation between the histogram of the points", " inside the hole's outline points and the model histogram is lower", " than a threshold.", " CAUTION: The use of the CV_COMP_HELLINGER for histogram comparison", " inverts the inequality checks", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "filters_resources": ["*******************************************************************", "", "", " Indicate the necessity of creating particular resources", " If the conditions permit for the depth filters to be applied,", " create their resources", " The depth diff filter requires only the contruction of the vectors", " that have to do with the inflation of holes' rectangles", " The depth/area filter requires only the construction of sets that", " hold the indices of points inside holes' outlines", " The intermediate points plane constitution filter requires exactly", " the construction of vectors pertaining to holes' inflation and", " and a vector of sets of indices of points between holes' outline and", " their respective (inflated) bounding rectangle", " The outline of rectangle plane constitution filter requires", " the construction of vectors pertaining to holes' inflation", " The depth homogeneity filter requires the construction of sets of", " points' indices; these points are the ones inside holes' outlines", " The color homogeneity filter requires a vector of holes' masks", " that will be used to extract their histograms", " The luminosity diff filter requires the set of points' indices", " that are inside a hole's outline,", " the set of points' indices that are outside a hole's outline", " but inside its (inflated) bounding rectangle", " and the inflated rectangles and indices of the respective", " valid keypoints", " The texture diff filter requires the construction of an image mask", " vector for the points inside holes' outline and of image and set", " masks for the points outside holes' outline but inside their (inflated)", " bounding box", " as it checks for texture metrics difference between the", " histograms of the points inside a hole's outline and outside", " the hole's outline but inside its (inflated) bounding rectangle", " The texture backproject filter uses two sets: they respectively contain", " the indices of points inside holes' outlines and the indices of points", " outside holes' outlines but inside their (inflated) bounding rectangle.", " Hence, we also need the construction of inflated rectangles' vectors", " Depth-based filters cannot be applied. Create only the necessary", " resources needed by the RGB-based filters, according to the *_urgent", " order", " The color homogeneity filter requires a vector of holes' masks", " that will be used to extract their histograms", " The luminosity diff filter requires the set of points' indices", " that are inside a hole's outline,", " the set of points' indices that are outside a hole's outline", " but inside its (inflated) bounding rectangle", " and the inflated rectangles and indices of the respective", " valid keypoints", " The texture diff filter requires the construction of an image mask", " vector for the points inside holes' outline and of image and set", " masks for the points outside holes' outline but inside their (inflated)", " bounding box", " as it checks for texture metrics difference between the", " histograms of the points inside a hole's outline and outside", " the hole's outline but inside its (inflated) bounding rectangle", " The texture backproject filter uses two sets: they respectively contain", " the indices of points inside holes' outlines and the indices of points", " outside holes' outlines but inside their (inflated) bounding rectangle.", " Hence, we also need the construction of inflated rectangles' vectors", " Create the necessary resources", " The generation of image masks presupposes the generation of set masks", " within method createHolesMasksImageVector", " Generate both types of masks", " The generation of image masks presupposes the generation of set masks", " within method createIntermediateHolesPointsImageVector", " The intermediate points images vector depends on the", " inflated rectangles vectors, which has been created previously", " The intermediate points set vector depends on the", " inflated rectangles vectors, which has been created previously", " The intermediate points set vector depends on the", " inflated rectangles vectors, which has been created previously", "", " Create the masks' set initially", " Draw each mask set onto an image", " The current hole's image mask", " A pointer to the hole mask image", " Draw the current hole's mask", "", " Create the masks' set initially", " Draw each mask set onto an image", " The current hole's image mask", " A pointer to the hole mask image", " Draw the current hole's mask", "", " The image on which the i-th hole's outline will be drawn", " Draw the outline points of the i-th hole onto holeMask", " The set of indices of points inside the i-th hole's outline", " The point from which the floodfill will begin", " Fill the inside of the i-th hole", " Take a pointer on the mask image", " The points with non-zero value are the ones inside the i-th hole.", " Insert them into the desired set.", "", " Store the vertices of the inside-of-image-bounds inflated bounding", " rectangles in the inflatedRectangles vector", " check if the inflated vertex has gone out of bounds", " end for rectangle's points", " If one or more vertices are out of bounds discard the whole", " inflated rectangle", " end for each hole", "", " Create the masks' set initially", " The current hole's intermediate points mask", " A pointer to the hole mask image", " Draw the intermediate points' mask", "", " Create the masks' set initially", " The current hole's intermediate points mask", " A pointer to the hole mask image", " Draw the intermediate points' mask", "", " The current hole's mask", " An image whose non-zero value pixels are the ones inside the", " hole's outline", " Draw the outline of the i-th hole onto holeOutlineFilledImage", " The set of indices of points inside the i-th hole's outline", " The brushfire start point is the hole's seedPoint", " floodFill from the seedPoint to the hole's outline", " to obtain the points inside it", " Take a pointer on the hole's mask image", " The points with non-zero value are the ones inside the i-th hole.", " Insert them into the desired set.", " holeOutlineFilledSet is now constructed", " An image whose non-zero value pixels are the ones inside the", " hole's bounding rectangle", " Draw the bounding rectangle of the i-th hole onto", " rectangleOutlineFilledImage", " The set of indices of points inside the i-th hole's", " bounding rectangle", " floodFill from the seedPoint to the hole's bounding rectangle", " to obtain the points inside it", " Take a pointer on the rectangle's mask image", " The points with non-zero value are the ones inside the i-th hole.", " Insert them into the desired set.", " rectangleOutlineFilledSet is now constructed", " The final set of points' indices", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "depth_filters": ["*******************************************************************", "", "", " The mean depth value of the points inside the i-th hole", " The number of points inside the i-th hole, or else, its area", " area = f(mean) for one circular hole", " Upper-most curve, plus an increase in height", " At most, one complete hole contains three circular ones", " Lower-most curve minus a reduction in height", " At least, one complete hole is one circular hole", "", " The mean distance of this hole's bounding box vertices", " The difference between the distance of this hole's keypoint and", " the mean distance of the vertices of its bounding box", " The keypoint's distance from the depth sensor should be greater than", " that of the mean distance of the vertices of the candidate hole's", " bounding box by at a minimum of depth_diff_cutoff_min_depth cm and at", " maximum of depth_diff_cutoff_max_depth cm.", " The probability is binary. If there is a valid depth difference,", " this hole is marked as valid.", " The probability is gaussian-based. The validity of a hole is a", " continuous function based on a normal distribution", " The gaussian mean", " The gaussian standard deviation", " The gaussian probability of this hole being valid", "", " Facilitate the edge detection by converting the 32FC1 image", " values to a range of 0-255", " From now onwards every image is in the range of 0-255", " Apply a threshold and make all non zero pixels have a value of 255", " Take a pointer on the interpolatedDepthImageEdges image", " The number of non-zero value pixels in the", " interpolatedDepthImageEdges image, inside mask i", "", " From each set of intermediate points, construct the point cloud", " that will be checked for plane constitution", " Check if the intermediatePointsPointCloud's points are on a plane", " The probability (in all probability) of the current hole lying on", " one plane will be the ratio of the number of intermediate points", " that lie on one plane over all the intermediate points", " (max points on one plane) / (all intermediate points)", "", " For each inflated rectangle, store in visitedPoints", " the points that constitute the rectangle.", " We will test if these points all lie on one plane.", " The canvas image will hold the rectangles.", " Draw the rectangle that corresponds to it", " From each set of points lying on the edges of the rectangle,", " construct the point cloud that will be checked for plane constitution", " Check if the edgePointsPointCloud points are on a plane", " The probability (in all probability) of an inflated rectangle", " residing on one plane will be the ratio of", " (max points on one plane) / (all inflated rectangle points)", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_uniqueness": ["*******************************************************************", "", "", " A container in which one of every duplicate hole will be inserted", " A set of sets containing the indices of duplicate holes.", " Each internal set points to one unique hole", " This set is comprised by indices of holes that are identical to the", " i-th hole", " First off, the two holes' keypoints must be identical.", " Second off, it is sufficient to check the identicalness of", " the vertices of the two holes' bounding boxes.", " The i-th hole is part of the overall set", " Populate the uniqueDuplicates container with a copy of each duplicate", " hole. All the duplicate holes will be deleted from the input conveyor,", " and then merged with the uniqueDuplicates conveyor.", " Now, all the duplicate holes must be deleted from the input conveyor.", " Construct ONE set of indices of all holes that need to be deleted.", " Perform the actual deletion of duplicate holes.", " Add one copy of each duplicate hole deleted to the conveyor container", "", " Each set inside the map refers a valid hole inside the conveyor conveyor.", " The entries of each set are indices to valid holes inside", " the conveyor conveyor.", " Each map.first refers to a specific valid hole inside the conveyor", " conveyor.", " map.first-> map.second means the residence of the keypoint of the", " hole with index map.first within the bounding box of holes with", " indices in map.second", " Find the indices of holes that the keypoint of each valid hole", " is located in.", " The keypoint of the i-th hole in cv::Point2f format", " A set of the identifiers of holes inside the conveyor conveyor,", " whose bounding box the i-th hole is inside, recursively.", " The outcome is a map of ints to sets, one per valid hole.", " Each set contains the indices of parent holes", " that have been deemed valid.", " What we want now is to locate which holes need to be", " compared against one another.", " Each set inside the groupSet contains holes whose overall validity", " probability needs to be compared against all the others within that set.", " The largest of them corresponds to a unique hole, whose keypoint,", " outline and bounding rectangle are considered most accurate between", " the holes in its respective set.", " Traverse the parents (the hole_it->second set)", " of this hole (its id is hole_it->first)", " For each parent of the hole_id->first-th hole,", " check the set of its corresponding parent holes", " and add them to the set of the hole_id->first-th hole's parents.", " The grandfathers added are the hole_id->first-th hole's recursive", " parents.", " A parent to the parent of hole hole_it->first is also its parent.", " Insert the set of indices of holes with which the", " hole_it->first-th hole will be compared to inside the overall", " set of sets.", " The conveyor of unique and valid holes", " Maps a unique, valid hole to its validity probability", " A hole counter", " Iterate over the set of sets within which the validity probability", " of holes needs to be compared with one another. We will locate the", " hole in a set within groupSet that has the highest probability among", " the holes inside the set", " The maximum probability of the cluser of nearby holes", " The index of the hole with maximum probability inside the cluster", " of nearby holes", " Iterate over the current set inside the groupSet", " An iterator over the input validHolesMap.", " It points to the index and probability of the *g_it-th hole", " The index-th hole inside this cluster of nearby holes is the most", " accurate one, since its probability is the highest among its rearby", " holes. Append it to the uniqueHoles conveyor.", " Map the most accurate hole to its probability.", " All unique holes have been found.", " Replace the uniqueHoles conveyor with the one containing", " clusters of holes and the input map with the one corresponding to the", " unique holes found.", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "depth_hole_detector": ["*******************************************************************", "", "", " Debug", " Detect edges in the interpolatedDepth image", " Debug", " Find blobs in the edges image. Each blob is represented as", " a keypoint which is the center of the blob found", " Debug", " The final vectors of keypoints, rectangles and blobs' outlines.", "", " Debug", " Debug", " A vector of keypoints", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "depth": ["*******************************************************************", "", "", "", " Acquire the names of topics which the depth node will be having", " transactionary affairs with", " Subscribe to the depth image published by the", " rgb_depth_synchronizer node", " Advertise the candidate holes found by the depth node", " The dynamic reconfigure (depth) parameter's callback", "", " Obtain the depth image. Since the image is in a format of", " sensor_msgs::Image, it has to be transformed into a cv format in order", " to be processed. Its cv format will be CV_32FC1.", " Regardless of the image representation method, the depth node", " will publish the interpolated depth image of original size", " to the Hole Fusion node", " A value of 1 means that the depth image is subtituted by its", " low-low, wavelet analysis driven, part", " Find the minimum and maximum values in depth distance in the", " interpolated depth image", " Obtain the low-low part of the interpolated depth image via", " wavelet analysis", " Locate potential holes in the interpolated depth image", " Create the candidate holes message", " Pack information about holes found and the interpolated depth image", " inside a message.", " This message will be published to and received by the hole fusion node", " Publish the candidate holes message", "", " Read the name of the topic from where the depth node acquires the", " unadulterated depth image and store it in a private member variable", " Read the name of the topic to which the depth node will be publishing", " information about the candidate holes found and store it in a private", " member variable", "", "////////////////// Blob detection - specific parameters //////////////////", " In wavelet mode, the image shrinks by a factor of 4", "//////////////////////////// Debug parameters ////////////////////////////", " Show the depth image that arrives in the depth node", "------------------- Edge detection specific parameters -------------------", " Canny parameters", " Threshold parameters", " Method to scale the CV_32FC1 image to CV_8UC1", "----------------- Outline discovery specific parameters ------------------", " The detection method used to obtain the outline of a blob", " 0 for detecting by means of brushfire", " 1 for detecting by means of raycasting", " When using raycast instead of brushfire to find the (approximate here)", " outline of blobs, raycast_keypoint_partitions dictates the number of", " rays, or equivalently, the number of partitions in which the blob is", " partitioned in search of the blob's borders", "-------------------- Loose ends connection parameters --------------------", " In wavelet mode, the image shrinks by a factor of 4", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "pc_thermal_synchronizer": ["*******************************************************************", "", "", " Take NodeHandlers from nodelet manager", " The synchronizer node starts off in life locked, waiting for the", " hole fusion node to unlock him", " The synchronizer node starts off in life locked for thermal standalone", " procedure , waiting for the thermal cropper node to unlock him.", " Acquire the names of topics which the synchronizer node will be having", " transactionary affairs with", " Acquire the information about the input point cloud that cannot be", " acquired from the point cloud message.", " The parameters concerned are needed only if in simulation mode", "****************************************************************************", " If thermal mode is enabled in launch file message filters is on and", " the two input messages are synchronized packed and sent.", " If not only the pointcloud is sent for further usage", "if (rgbdtMode_ || thermalMode_)", "{", "  syncPointCloudSubscriberPtr_.reset( new PcSubscriber(nh_,", "        inputPointCloudTopic_, queue_) );", "  syncThermalCameraSubscriberPtr_.reset( new ThermalSubscriber(nh_,", "        syncThermalCameraTopic_, queue_) );", "  synchronizerPtr_.reset( new ApprTimePcThermalSynchronizer(", "        ApprTimePcThermalPolicy(queue_),", "        *syncPointCloudSubscriberPtr_,", "        *syncThermalCameraSubscriberPtr_) );", "  synchronizerPtr_->registerCallback(", "      boost::bind(&PcThermalSynchronizer::syncPointCloudThermalCallback, this, _1, _2));", "}", "else if (rgbdMode_)", "{", "}", "****************************************************************************", "if (rgbdMode_ || rgbdtMode_)", "{", "  // Subscribe to the hole_fusion lock/unlock topic", "}", "if (thermalMode_)", "{", "  // Subscribe to the topic where the thermal node requests synchronizer", "  // to act.", "  unlockThermalSubscriber_ = nh_.subscribe(", "    unlockThermalTopic_, 1,", "    &PcThermalSynchronizer::unlockThermalCallback, this);", "}", " Subscribe to the topic where the Hole Fusion node requests from the", " synchronizer node to subscribe to the input point cloud topic", " Subscribe to the topic where the Hole Fusion node requests from the", " synchronizer node to leave its subscription to the", " input point cloud topic", "****************************************************************************", "if (rgbdMode_ || rgbdtMode_j", "{", "  // Advertise the synchronized point cloud", "}", "if (rgbdMode_ || rgbdtMode_)", "{", " Advertise the synchronized depth image", " Advertise the synchronized rgb image", "}", "if (rgbdtMode_ || thermalMode_)", "{", " Advertise the synchronized thermal image and its index", "synchronizedThermalImagePublisher_ = nh_.advertise", "  <distrib_msgs::FlirLeptonMsg>", "  (synchronizedThermalImageTopic_, 1);", "thermalOutputReceiverPublisher_ = nh_.advertise", "  <std_msgs::String>", "  (thermalOutputReceiverTopic_, 1);", "}", "if (thermalMode_)", "{", "  enhancedImageCropperPublisher_ = nh_.advertise<pandora_vision_msgs::EnhancedImage>(", "      enhancedImageCropperTopic_, 1);", "}", " inputPointCloudSubscriber_.shutdown();", "", " syncPointCloudSubscriberPtr_->unsubscribe();", " syncThermalCameraSubscriberPtr_->unsubscribe();", "", " Shutdown the input thermal subscriber", "", "", " if (rgbdtMode_ || thermalMode_)", " {", "   syncPointCloudSubscriberPtr_->subscribe();", "   syncThermalCameraSubscriberPtr_->subscribe();", " }", " else if (rgbdMode_)", " {", "   inputPointCloudSubscriber_ = nh_.subscribe(inputPointCloudTopic_, 1,", "       &PcThermalSynchronizer::inputPointCloudCallback, this);", " }", "", " if (rgbdtMode_ || thermalMode_)", " {", "   syncPointCloudSubscriberPtr_->subscribe();", "   syncThermalCameraSubscriberPtr_->subscribe();", " }", " Exctract the pointcloud from the message and convert it", " to PointCloud<T>::Ptr type.", " pcl::PCLPointCloud2 pcl_pc;", " pcl_conversions::toPCL(*pcMsg, pcl_pc);", " The input point cloud is unorganized, in other words,", " simulation is running. Variables are needed to be set in order for", " the point cloud to be functionally exploitable.", " The point cloud's height", " The point cloud's width", " Extract the RGB image from the point cloud", " cv::Mat rgbImage = hole_fusion::MessageConversions::convertPointCloudMessageToImage(", "   pcPtr, CV_8UC3);", " cv_bridge::CvImagePtr rgbImageConverter( new cv_bridge::CvImage() );", " rgbImageConverter->header = pcMsg->header;", " rgbImageConverter->encoding = sensor_msgs::image_encodings::BGR8;", " rgbImageConverter->image = rgbImage;", " rgbImageMessagePtr = rgbImageConverter->toImageMsg();", " Extract the depth image from the point cloud", " depthImageMessagePtr = boost::make_shared<sensor_msgs::Image>();", " MessageConversions::toROSDepthMsg(*pcMsg, *depthImageMessagePtr);", " depthImageMessagePtr->header = pcMsg->header;", "", " Read \"height\" from the nodehandle", " Read \"width\" from the nodehandle", "", " Read the name of the topic from where the rgb_depth_thermal_synchronizer", " node acquires the input pointcloud2", " Read the name of the topic that the Hole Fusion node uses to unlock", " the synchronizer node", " Read the name of the topic from where the rgb_depth_thermalsynchronizer", " node acquires the input thermal message", " not to thermal standalone node.", " Read the name of the topic that the Hole Fusion node uses to request from", " the synchronizer node to subscribe to the input point cloud", " Read the name of the topic that the Hole Fusion node uses to request from", " the synchronizer node to leave its subscription to the input point cloud", " Read the name of the topic that the synchronizer node will be publishing", " the input point cloud to", " Read the name of the topic that the synchronizer node will be publishing", " the depth image extracted from the input point cloud to", " Read the name of the topic that the synchronizer node will be publishing", " the depth image extracted from the input point cloud to", " Read the name of the topic that the synchronizer node will be publishing", " the thermal info extracted from flir camera", " Read the name of the topic that the synchronizer node will be publishing", " the rgb and depth image to thermal cropper node", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_detector_test": ["*******************************************************************", "", "", " Sets up one image: squares_,", " which features three squares of size 100.", " The first one (order matters here) has its upper left vertex at", " (100, 100),", " the second one has its upper right vertex at (WIDTH - 3, 3)", " (so that the blob it represents can barely be identified)", " and the the third one has its lower right vertex at", " (WIDTH - 1, HEIGHT - 1)", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the squares_ image to 1.0", " Construct the lower right square", " Construct the upper right image", " Construct the upper left square", " Construct the square_ image", " Synthesize the final squares_ image", " The images' width and height", " The image that will be used to locate blobs in", "", " Fill the inside of the desired rectangle with the @param depthIn provided", "! Tests HoleDetector::findHoles", " Run HoleDetector:findHoles", " The number of keypoints found", " There should be two keypoints: the one of the upper left square", " and the one of the upper right square. The lower right square is", " adjacent to the edges of the image and will be clipped by the", " edge contamination method", " For every keypoint found, make assertions and expectations", " The location of the keypoint should be near the center of the square", " in which it lies", " The hole should have exactly four vertices", " There should be 400 outline points", " namespace depth", " namespace pandora_vision_hole", " namespace pandora_vision"], "holes_conveyor_test": ["*******************************************************************", "", " Dummy entries for the src conveyor", " Push back the two holes into the src conveyor", " Dummy entries for the dst conveyor", " Push back the two holes into the dst conveyor", " This is the source conveyor", " This is the destination conveyor", "! Tests HolesConveyorUtils::append", " Backup the original dst", " 2 entries in dst before appending src to it", " Run HolesConveyorUtils::append", " 4 entries in dst after appending src to it", " Check that the initial entries have not been tampered with", " Check the newly appended entries' elements against the original ones", "! Tests HolesConveyorUtils::appendDummyConveyor", " Backup the original dst", " Run HolesConveyorUtils::appendDummyConveyor", " There should now be three entries in dst", " Check that the initial entries have not been tampered with", " The new entry", "! Tests HolesConveyorUtils::clear", " Run HolesConveyorUtils::clear", " The dst conveyor should be empty", "! Tests HolesConveyorUtils::copyTo", " Run HolesConveyorUtils::copyTo", " There should be two hole entries in dst now", " Check the newly appended entries' elements against the original ones", "! Tests HolesConveyorUtils::generateRectangle", " The rectangle's points that will be returned", " The rectangle's vertices that will be returned", " Run HolesConveyorUtils::generateRectangle with intent = 1", " Run HolesConveyorUtils::generateRectangle with intent = 2", " The number of vertices should amount to a number", " lower than the number of points", " There should be four vertices", " There should be 4 * 100 points", "! Tests HolesConveyorUtils::getHole", " Run HolesConveyorUtils::getHole", " There should be one entry inside hole", " src and hole should have exactly the same amount of", " rectangle and outline points", " Check that the entries in src and hole are exactly the same", "! Tests HolesConveyorUtils::merge", " The merged conveyor", " Merge src and dst into merged", " There should be exactly 2 + 2 = 4 entries in merged", " Check the newly appended entries' elements against the original ones", " Check src", " Check dst", "! Tests HolesConveyorUtils::removeHole", " Backup dst", " Two holes before removing one", " Run HolesConveyorUtils::removeHole", " One hole after removing one", " The first entry should be exactly the same as the previously second one", "! Tests HolesConveyorUtils::replace", " Run HolesConveyorUtils::replace", " Check the newly replaced entries' elements against the original ones", "! Tests HolesConveyorUtils::replaceHole", " Backup dst", " Run HolesConveyorUtils::replaceHole", " There should still be two holes inside dst", " The 0-th hole of dst should be the 0-th hole of src", " The 1-st hole of dst should be the 1-st hole of dstBackup", "! Tests HolesConveyorUtils::shuffle", " Backup dst", " Run HolesConveyorUtils::shuffle", " There should still be 2 entries in dst", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "message_conversions_test": ["*******************************************************************", "", " An image of dimensions HEIGHT x WIDTH, representing the conveyor", " A single hole", " Construct a dummy conveyor", " The outline of the hole", " The vertices of the hole's bounding box", " Push hole back into the conveyor", " The images' width and height", " A conveyor of dummy holes", " An image of dimensions HEIGHT x WIDTH, representing the conveyor", "! Tests MessageConversions::convertImageToMessage", " A grayscale image", " Insert randomness into image", " A dummy message. Needed for its header", " Extract the image message and compare this image to the original", " The number of pixels differing between image_8UC1 and extractedImage_8UC1", " There should be no discrepancies", " A RGB image", " Insert randomness into image", " A dummy message. Needed for its header", " Extract the image message and compare this image to the original", " The number of pixels differing between image_8UC3 and extractedImage_8UC3", " There should be no discrepancies", "! Tests MessageConversions::convertPointCloudMessageToImage", " Create a grayscale image", " Fill it with randomness", " Set some NaNs", " Create a RGB image", " Fill it with randomness", " Set some NaNs", " Create a point cloud. The extracted depth values result in image_32FC1", " The extracted RGB values result in image_8UC3.", " Set the depth value for this point", " Set the RGB values for this point", " The extracted depth image", " The number of pixels differing between image_32FC1", " and extracted_32FC1", " There should be 2 pixels different before and after:", " The two NaN values", " The extracted RGB image", " There should be no discrepancies", "! Tests MessageConversions::createCandidateHolesVector", " The vector of messages of candidate holes", " Run MessageConversions::createCandidateHolesVector", " The keypoints should be the same", " The rectangle's vertices should be the same", " The outline points should be the same", "! Tests MessageConversions::createCandidateHolesVectorMessage", " Create a grayscale image", " Fill it with randomness", " The message of candidate holes", " A dummy image. Needed only for its header.", " Run MessageConversions::createCandidateHolesVector", " Check the integrity of image", " The number of pixels differing between image and extracted", " There should be no discrepancies", " Check the integrity of the conveyor", " The keypoints should be the same", " The rectangle's vertices should be the same", " The outline points should be the same", "! Tests MessageConversions::extractImageFromMessage", " Create a grayscale image", " Fill it with randomness", " Run MessageConversions::extractImageFromMessage", " The number of pixels differing between image and extracted", " There should be no discrepancies", "! Tests MessageConversions::extractImageFromMessageContainer", " Create a grayscale image", " Fill it with randomness", " The message of candidate holes", " Run MessageConversions::extractImageFromMessageContainer", " The number of pixels differing between image and extracted", " There should be no discrepancies", "! Tests MessageConversions::fromCandidateHoleMsgToConveyor", " The vector of candidate holes", " The keypoints", " The rectangles", " The outlines", " The conveyor extracted from the message", " Run MessageConversions::fromCandidateHoleMsgToConveyor", " for representationMethod 0", " Check the integrity of the extracted conveyor", " Clear the conveyor", " Run MessageConversions::fromCandidateHoleMsgToConveyor", " for representationMethod 1", " Check the inflated of the extracted conveyor", "! Tests MessageConversions::unpackMessage", " The overall message", " The vector of candidate holes", " The keypoints", " The rectangle points", " The outline points", " A grayscale image", " Insert randomness into image", " Pack image_8UC1 into the message", " The extracted conveyor", " The extracted image", " Run MessageConversions::unpackMessage for representationMethod 0", " Check the integrity of the extracted conveyor", " The number of pixels differing between image_8UC1 and extractedImage", " There should be no discrepancies", " Clear extractedConveyor", " Run MessageConversions::unpackMessage for representationMethod 1", " Check the inflated of the extracted conveyor", " The number of pixels differing between image_8UC1 and extractedImage", " There should be no discrepancies", " rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "morphological_operators_test": ["*******************************************************************", "", " pixel_ holds a single non-zero pixel", " line_ holds a horizontal white line at row 100,", " with width of 1 pixel", " thick_line_ holds horizontal white lines at rows 99, 100 and 101", " square_ is a 100 X 100 opaque square,", " with its upper left corner placed at the upper left corner of the", " image", " frame_ is a white image with only its borders in black colour", " squares_ is an image featuring one square at the edge of each", " corner of the image", " corners_ is an image featuring one square at the very edge of each", " corner of the image", " pixel_ holds a single non-zero pixel", " line_ holds a horizontal white line at row 100,", " with width of 1 pixel", " thick_line_ holds horizontal white lines at rows 99, 100 and 101", " square_ is a 100 X 100 opaque square,", " with its upper left corner placed at the upper left corner of the", " image", " frame_ is a white image with only its borders in black colour", " squares_ is an image featuring one square at the edge of each", " corner of the image", " upper left", " lower left", " upper right", " lower right", " corners_ is an image featuring one square at the very edge of each", " corner of the image", " upper left", " lower left", " upper right", " lower right", " The images' width and height", " pixel_ holds a single non-zero pixel", " line_ holds a horizontal white line at row 100,", " with width of 1 pixel", " thick_line_ holds horizontal white lines at rows 99, 100 and 101", " square_ is a 100 X 100 opaque square,", " with its upper left corner placed at the upper left corner of the", " image", " frame_ is a white image with only its borders in black colour", " squares_ is an image featuring one square at the edge of each", " corner of the image", " corners_ is an image featuring one square at the very edge of each", " corner of the image", " The number of non-zero value pixels before the appliance of an operator", " The number of non-zero value pixels after the appliance of an operator", "! Tests Morphology::closing()", "*************************************************************************", " Keep the original image in the originalPixel image", " Apply the closing operator", " diff_pixel is the difference between the original and the", " closed pixel_ images", " The diff image should be filled with zero value pixels only", "*************************************************************************", " Keep the original image in the originalLine image", " Apply the closing operator", " diff_pixel is the difference between the original and the", " closed line_ mages", " The diff image should be filled with zero value pixels only", "*************************************************************************", " Keep the original image in the originalThick_line image", " Apply the closing operator", " diff_pixel is the difference between the original and the", " closed pixel_ images", " The diff image should be filled with zero value pixels only", "*************************************************************************", " Keep the original image in the originalSquare image", " Apply the closing operator", " diff_square is the difference between the original and the", " closed square_ images", " The diff image should be filled with zero value pixels only", "! Tests Morphology::dilation()", "*************************************************************************", " Perform dilation on the pixel_", " All pixels surrounding immediately the only non-zero one before dilation", " should now have a non-zero value", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", " The number of non-zero pixels before the dilation should be three times", " as many as that of the pixels after", " One row higher and one row lower than 100, all pixels should now", " have a non-zero value", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", " The number of non-zero pixels after the dilation should be", " increased by twice the square_'s size, plus one non-zero pixel", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", " The number of non-zero pixels after the dilation should be equal to the", " area of the image", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", "! Tests Morphology::dilationRelative()", "*************************************************************************", " Perform dilation on the pixel_", " All pixels surrounding immediately the only non-zero one before dilation", " should now have a non-zero value", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", " The number of non-zero pixels before the dilation should be three times", " as many as that of the pixels after", " One row higher and one row lower than 100, all pixels should now", " have a non-zero value", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", " The number of non-zero pixels after the dilation should be", " increased by twice the square_'s size, plus one non-zero pixel", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilationRelative", " The number of non-zero pixels before the dilationRelative should be", " less than that of the pixels after", " The number of non-zero pixels after the dilation should be equal to the", " area of the image", "*************************************************************************", " The number of non-zero pixels before dilation", " Dilate once", " The number of non-zero pixels after dilation", " The number of non-zero pixels before the dilation should be less than", " that of the pixels after", "! Tests Morphology::erosion()", "*************************************************************************", " The number of non-zero pixels before erosion", " Erode once", " The number of non-zero pixels after erosion", " The number of non-zero pixels before the erosion should be", " less than that of the pixels after", " The number of non-zero pixels after the erosion should be exactly zero", "*************************************************************************", " The number of non-zero pixels before erosion", " Erode once", " The number of non-zero pixels after erosion", " The number of non-zero pixels before the erosion should be", " greater than that of the pixels after", " The number of non-zero pixels after the erosion should be", " reduced by the size of frame_, minus its four corners", "*************************************************************************", " Because each square has a width of one, dilate once so that the", " result of the erosion can be visible", " The number of non-zero pixels before erosion", " Erode once", " The number of non-zero pixels after erosion", " The number of non-zero pixels before the erosion should be", " greater than that of the pixels after", " Erode once more", " The number of non-zero pixels after erosion", " The number of non-zero pixels before the erosion should be", " greater than that of the pixels after", "! Tests Morphology::kernelCheck()", "*************************************************************************", " pixel_ has all of its neighbors with a zero value", " This should be true: Point( 100, 100 ) has a non-zero value,", " while it is surrounded by zero value pixels", " This should be false: Point ( 200, 200 ) has a zero value and", " it is surrounded by zero value pixels", "*************************************************************************", " line_ has all of its upwards and downwards neighbors with a zero value", " This should be true: all points in row 100 have a non-zero value,", " while they are surrounded by zero value pixels, upwards and downwards", " This should be false: Point ( cols, 200 ) has a zero value and", " it is surrounded by zero value pixels", "! Tests Morphology::opening()", "*************************************************************************", " Apply the opening operator", " The diff image should be filled with zero value pixels only", "*************************************************************************", " Apply the opening operator", " The diff image should be filled with zero value pixels only", "*************************************************************************", " Keep the original image in the originalSquare image", " Apply the opening operator", " diff_square is the difference between the original and the", " closed square_ images", " The diff image should be filled with zero value pixels only", "! Tests Morphology::pruningStrictIterative()", "*************************************************************************", " Apply the pruningStrictIterative operator", " The image should be filled with zero value pixels only", "*************************************************************************", " Keep the original image in the originalPixel_ image", " Attach some garbage pixels to the line in line_.", " They should be deleted by the pruningStrictIterative operator", " Apply the pruningStrictIterative operator", " Garbage pixels should be deleted", "*************************************************************************", " The number of non-zero pixels before pruningStrictIterative", " Apply the pruningStrictIterative operator", " The number of non-zero pixels after pruningStrictIterative", " Only the bottom right corner should be deleted", "*************************************************************************", " The number of non-zero pixels before pruningStrictIterative", " Apply the pruningStrictIterative operator", " The number of non-zero pixels after pruningStrictIterative", " The frame's four corners should be deleted", "! Tests Morphology::thinning()", "*************************************************************************", " Apply the thinning operator", " The line should be the width of one pixel", "*************************************************************************", " Apply the thinning operator", " square_ should have shrunk by 4 pixels:", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "noise_elimination_test": ["*******************************************************************", "", "", "! Sets up images needed for testing", " Construct interpolationMethod0", " Fill interpolationMethod0 with a value of 1.0", " Insert noise", " Uncomment for visual inspection", " Construct interpolationMethod1", " Fill interpolationMethod1 with a value of 0.5", " Insert noise", " Uncomment for visual inspection", " Construct interpolationMethod2", " Fill interpolationMethod2 with a value of 1.0", " Uncomment for visual inspection", " Three images that will be used to test", " methods of class NoiseElimination", " An image with minimal noise (black pixels)", " An image with considerable amount of noise (black pixels)", " An image heavily noisy (black pixels)", "", " Fill the inside of the desired rectangle with the @param value provided", " Tests NoiseElimination::brushfireNear", " Uncomment for visual inspection", "Visualization::showScaled ( \"before brushfireNear\", interpolationMethod1, 0 );", " Run NoiseElimination::brushfireNear on interpolationMethod1", " Uncomment for visual inspection", "Visualization::showScaled ( \"after brushfireNear\", image, 0 );", " The whole of the image should be at 0.5 value", " Run NoiseElimination::brushfireNear on interpolationMethod0", " The whole of the image should be at a value of 1.0", "! Tests NoiseElimination::brushfireNearStep", " Uncomment for visual inspection", " Run NoiseElimination::brushfireNearStep on image interpolationMethod1", " Uncomment for visual inspection", " All pixels of interpolationMethod1 should now have a value of 0.5", " All non-zero value pixels have a value of 0.5", " Test a blank image", " Run NoiseElimination::brushfireNearStep", " All pixels should be still black", " Test an image with square concentrations of noise in each corner of it.", " The rest of the pixels are at random values", " upper left", " lower left", " upper right", " lower right", " The number of non zero pixels before calling any brushfireNearStep", " Run NoiseElimination::brushfireNearStep on image corners_", " The number of non zero pixels after removing the upper left noise", " concentration", "! Tests NoiseElimination::chooseInterpolationMethod", " On interpolationMethod0, Parameters::Depth::interpolation_method", " should be equal to 0", " On interpolationMethod1, Parameters::Depth::interpolation_method", " should be equal to 1", " On interpolationMethod2, Parameters::Depth::interpolation_method", " should be equal to 2", "! Tests NoiseElimination::interpolateImageBorders", " Create an image whose borders are non-zero but the rest of it is", " Run NoiseElimination::interpolateImageBorders", " All border pixels should now have a value of zero", "! Tests NoiseElimination::interpolateZeroPixel", " The return value of NoiseElimination::interpolateZeroPixel", " Zero-out some pixels in image interpolationMethod0", " Run NoiseElimination::interpolateZeroPixel", " At ( 200, 200 ) and around it, everything is black", " Run NoiseElimination::interpolateZeroPixel", " Around ( 1, 500 ), everything is at 1.0 value", " Run NoiseElimination::interpolateZeroPixel", " Around ( 400, 1 ), everything is at 1.0 value", " Run NoiseElimination::interpolateZeroPixel", " Error should be received here", "! Tests NoiseElimination::interpolation", " Run NoiseElimination::interpolation", "! Tests NoiseElimination::interpolationIteration", " The number of zero pixels before the call to interpolationIteration", " Run NoiseElimination::interpolationIteration", " The number of zero pixels after the call to interpolationIteration", " There should be more black pixels before than after the call to", " interpolationIteration", "! Tests NoiseElimination::performeNoiseElimination", " Remove the noise in interpolationMethod0", " The interpolated input image", " Run NoiseElimination::performeNoiseElimination", " There shouldn't be any black pixels in interpolated", " Remove the noise in interpolationMethod1", " Run NoiseElimination::performeNoiseElimination", " There shouldn't be any black pixels in interpolated", " Remove the noise in interpolationMethod2", " Run NoiseElimination::performeNoiseElimination", " There shouldn't be any black pixels in interpolated", "! Tests NoiseElimination::transformNoiseToWhite", " Count how many noisy pixels there are on interpolationMethod0", " Run NoiseElimination::transformNoiseToWhite on interpolationMethod0", " Count how many pixels have obtained the value dictated inside", " NoiseElimination::transformNoiseToWhite (4.0)", " The number of pixels changed should be equal to the intially noisy ones", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "wavelets_test": ["*******************************************************************", "", " Construct the grayscale image", " It features a filled white square of length 100 at (100, 100)", " Construct the RGB image", " It features a filled blue square of length 100 at (100, 100)", " The images' dimensions", " A grayscale image that will be used for testing", " A RGB image that will be used for testing", "! Tests Wavelets::getLowLow", " Find the min and max values in image grayscale", " The output image", " Run Wavelets::getLowLow", " The dimensions of image out should be half of those of image grayscale,", " plus one apparently", " Count the number of non-zero value pixels inside grayscale and out.", " The latter should be one quarter of the former. Because one more", " column and row are added to the halved dimensions, it is expected that", " the above number should be increased by a number of 50 + 50 + 1:", " one halved non-zero column, one halved non-zero row plus one corner pixel", "! Tests Wavelets::getLowLow", " The output image", " Run Wavelets::getLowLow", " The dimensions of image out should be half of those of image grayscale,", " plus one apparently", " Count the number of non-zero value pixels inside rgb and out.", " The latter should be one quarter of the former. Because one more", " column and row are added to the halved dimensions, it is expected that", " the above number should be increased by a number of 50 + 50 + 1:", " one halved non-zero column, one halved non-zero row plus one corner pixel.", " In order to count the non-zero pixels, image rgb should be split into its", " components", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "outline_discovery_test": ["*******************************************************************", "", "", "! Sets up three images: square_, which features a single non-zero value", "! square of size 100 with its upper left vertex at (100, 100),", "! squares_, which features two non-zero value squares of size 100.", "! The first one (order matters here) has its upper left vertex at", "! ( 100, 100 ) and the second one its lower right vertex at", "! ( WIDTH - 1, HEIGHT - 1 )", "! and corners_ which features two semi-closed squares: one with its", "! lower right vertex at ( 99, 99 ) and one with its upper right vertex", "! at ( HEIGHT - 99, WIDTH -99 )", " A square with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100)", " Construct the square_ image", " Locate the outline points of the square in the square_ image", " The number of actual outline points of the square should be", " 4 x 100 - 4", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 100, HEIGHT - 100),", " B' (WIDTH - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 100)", " Construct the squares_ image", " Construct the lower right square", " Add the vector of outline points of the upper left square to the", " vector holding the vectors of outline points of the squares_ image", " Add the vector of outline points of the lower right square to the", " vector holding the vectors of outline points of the squares_ image", " Add the upper left square and the lower right square", " The number of actual outline points of the squares should be", " 4 x 100 - 4", " Construct image corners_", " The images' width and height", " A square with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100)", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 100, HEIGHT - 100),", " B' (WIDTH - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 100)", " Two semi-closed squares", " The vector holding the outline points", " of the square in the square_ image", " The vector holding the vectors of outline points", " of the squares in the squares_ image", "", " The four vertices of the rectangle", "! Tests OutlineDiscovery::brushfireKeypoint()", "*************************************************************************", " Run OutlineDiscovery::brushfireKeypoint", " As a preliminary test, check if the number of outline points found", " is equal to the one it should be. The four vertices of the square are not", " included in the square's outline due to the cross-expanding nature of the", " brushfire algorithm", " The square's area should be the number of visited points of the brushfire", " algorithm, which, excluding the square's four vertices, is 100 x 100 - 4", " Check whether the outline points found are actually the outline points", " of the square in square_", "*************************************************************************", " Run OutlineDiscovery::brushfireKeypoint", " The square's area should be the number of visited points of the brushfire", " algorithm, which, excluding the square's four vertices, is 100 x 100 - 1", " vertex (the lower right one)", " Run OutlineDiscovery::brushfireKeypoint", " The square's area should be the number of visited points of the brushfire", " algorithm, which, excluding the square's four vertices, is 100 x 100 - 1", " vertex (the lower right one)", "! Tests OutlineDiscovery::brushfireKeypoints()", "*************************************************************************", " Push_back the two keypoints", " Run OutlineDiscovery::brushfireKeypoints", " As a preliminary test, check if the number of outline points found", " is equal to the one it should be", " Check whether the outline points found are actually the outline points", " of the sq-th square in square_", " The square's area should be the number of visited points of the", " brushfire algorithm, which,", " excluding the square's four vertices, is 100 x 100 - 4", "! Tests OutlineDiscovery::brushfirePoint()", "*************************************************************************", " The sets of visted points for each square", " Run OutlineDiscovery::brushfirePoint for the upper left square", " The number of visited points should be the number of visited points", " of the brushfire algorithm, which,", " excluding the square's four vertices, is 100 x 100 - 4", " Run OutlineDiscovery::brushfirePoint for the upper left square", " The number of visited points should be the number of visited points", " of the brushfire algorithm, which,", " excluding the square's four vertices, is 100 x 100 - 4", "*************************************************************************", " Run OutlineDiscovery::brushfireKeypoint", " The square's area should be the number of visited points of the brushfire", " algorithm, which, excluding the square's four vertices, is 100 x 100 - 1", " vertex (the lower right one)", " Run OutlineDiscovery::brushfireKeypoint", " The square's area should be the number of visited points of the brushfire", " algorithm, which, excluding the square's four vertices, is 100 x 100 - 1", " vertex (the lower right one)", "! Tests OutlineDiscovery::getShapesClearBorder", " Construct two squares, one within the other", " The number of non-zero pixels before getting the clear borders", " Run EdgeDetection::getShapesClearBorder", " The number of non-zero pixels after getting the clear borders", " The EdgeDetection::getShapesClearBorder method finds all borders,", " not caring about shapes being inside other shapes", "! Tests OutlineDiscovery::getShapesClearBorderSimple", " Construct two squares, one within the other", " The number of non-zero pixels of the shape that encapsulates the one", " below", " Run EdgeDetection::getShapesClearBorderSimple", " The number of non-zero pixels after getting the clear borders", " The EdgeDetection::getShapesClearBorderSimple method finds borders of", " shapes, discarding everything within them: the square does not get", " to be detected :(", "! Tests OutlineDiscovery::raycastKeypoint", "*************************************************************************", " The keypoint of the lower right square", " The vector of outline points", " The blob's area", "Run OutlineDiscovery::raycastKeypoint", " Due to the approximate nature of the raycastKeypoint algorithm,", " the number of outline points found should be smaller or equal to the", " actual number of outline points of the square", " The keypoint of the upper left square", " The vector of outline points", "Run OutlineDiscovery::raycastKeypoint", " Due to the approximate nature of the raycastKeypoint algorithm,", " the number of outline points found should be smaller or equal to the", " actual number of outline points of the square", "! Tests OutlineDiscovery::raycastKeypoints", "*************************************************************************", " The keypoint of the upper left square", " The keypoint of the lower right square", " The vector of keypoints", " Push back the two keypoints", " The vector of outline points", " The vector of blobs' areas", "Run OutlineDiscovery::raycastKeypoints", " Due to the approximate nature of the raycastKeypoint algorithm,", " the number of outline points found should be smaller or equal to the", " actual number of outline points of the square", "*************************************************************************", " Clear the keypoints vector", " Place a new keypoint in the keypoints vector", " Clear the outline vector", " Clear the areas vector", "Run OutlineDiscovery::raycastKeypoints", " There will be exactly one keypoint, although the rays hit the edges", " of the image", " Approximately, the area of each square will be more than 9500 px2,", " but less than 10000 px2", " rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "edge_detection_test": ["*******************************************************************", "", "", "! Sets up one image: squares_, which features two non-zero value squares", "! of size 100. The first one (order matters here) has its upper left", "! vertex at (100, 100) and the second one its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1). The rest of the image's pixels are with a", "! value of 60", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100)", " The two square outlines", " Construct the upperLeftSquare image", " Locate the outline points of the square in the upperLeftSquare image", " Construct the lower right square", " The edges of this square are not touching the image's borders.", " Remove \"- 1\" for that.", " Locate the outline points of the square in the upperLeftSquare image", " Add the vector of outline points of the upper left square to the", " vector holding the vectors of outline points of the squares_ image", " Add the vector of outline points of the lower right square to the", " vector holding the vectors of outline points of the squares_ image", " Add the upper left square and the lower right square", " The number of actual outline points of the squares should be", " 4 x 100 - 4", " The images' width and height", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100)", " The vector holding the vectors of outline points", " of the squares in the squares_ image", "", " The four vertices of the rectangle", "! Tests EdgeDetection::applyCanny", "! Tests EdgeDetection::applyScharr", "! Tests EdgeDetection::applySobel", "! Tests EdgeDetection::applyLaplacian", "! Tests EdgeDetection::applyEdgeContamination", " Modify the squares_ image. Add squares adjacent to the corners of it.", " The edges of this square are not touching the image's borders.", " Remove \"- 1\" for that.", " Uncomment for visual inspection", "Visualization::show(\"Modified squares_ image\", squares_, 0);", " Obtain the edges image for the squares_ image.", " Here, it does not matter with which operator the edges image is produced,", " provided that the the value tested below changes accordingly", " The number of non-zero pixels before the appliance of edge contamination", " Uncomment for visual inspection", "Visualization::show(\"Before calling applyEdgeContamination\", squares_edges, 0);", " Uncomment for visual inspection", "Visualization::show(\"After calling applyEdgeContamination\", squares_edges, 0);", " The number of non-zero pixels after the appliance of edge contamination", "! Tests EdgeDetection::computeDepthEdges", " Traverse all available edge detectors", " Test the toggle switch", " Convert squares_ into a CV_32FC1 type image", " Add an unfinished square to the squares_32FC1 image", " Uncomment for visual inspection", " Uncomment for visual inspection", "Visualization::show(\"After calling computeDepthEdges\", denoisedEdges, 0);", "! Tests EdgeDetection::computeRgbEdges", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " Uncomment for visual inspection", "Visualization::show(\"Before calling computeRgbEdges\", squares_8UC3, 0);", " The final edges image", " extractionMethod = 0", " A dummy histogram", " Run EdgeDetection::computeRgbEdges", " Uncomment for visual inspection", "Visualization::show(\"After calling computeRgbEdges 0\", denoisedEdges_0, 0);", " The final edges image", " extractionMethod = 1", " Run EdgeDetection::computeRgbEdges", " Because of the void histogram, the edges image is blank", " Uncomment for visual inspection", "Visualization::show(\"After calling computeRgbEdges 1\", denoisedEdges_1, 0);", "! Tests EdgeDetection::connectPairs", " Obtain the edges image for the squares_ image.", " Here, it does not matter with which operator the edges image is produced,", " provided that the the value tested below changes accordingly", " Add an unfinished square to the squares_edges image", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " Uncomment for visual inspection", "Visualization::show(\"squares_edges arc\", squares_edges, 0);", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Connect by line", " The number of non-zero pixels before the connection of the two points", " Connect the two points by line", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"squares_edges line\", squares_edges, 0);", " Commence full blown connectPairs test.", "///////////////////////// Features a U shape /////////////////////////////", " Backup u", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"u arc forward\", u , 0);", " Construct the vector of pairs", " Reverse the order of the graph nodes", " Reset u", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"u arc reverse\", u , 0);", " Connect by line", " Reset u", " The number of non-zero pixels before the connection of the two points", " Connect the two points by line", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"u line\", u , 0);", "///////////////////////// Features a C shape /////////////////////////////", " Backup c", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"c arc forward\", c , 0);", " Construct the vector of pairs", " Reverse the order of the graph nodes", " Reset c", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"c arc reverse\", c , 0);", " Connect by line", " Reset c", " The number of non-zero pixels before the connection of the two points", " Connect the two points by line", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"c line\", c , 0);", "///////////////////////// Features a pi shape ////////////////////////////", " Backup pi", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"pi arc forward\", pi , 0);", " Construct the vector of pairs", " Reverse the order of the graph nodes", " Reset pi", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"pi arc reverse\", pi , 0);", " Connect by line", " Reset pi", " The number of non-zero pixels before the connection of the two points", " Connect the two points by line", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"pi line\", pi , 0);", "///////////////////// Features a backwards C shape ///////////////////////", " Backup bc", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"bc arc forward\", bc , 0);", " Construct the vector of pairs", " Reverse the order of the graph nodes", " Reset bc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"bc arc reverse\", bc , 0);", " Connect by line", " Reset bc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by line", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"bc line\", bc , 0);", "///////////////////// Features a | | shape ///////////////////////", " This is made to test that if no outline point is found,", " the image is preserved and the points are not connected", " Backup ii", " Construct the pair to be connected: it is the two ends of the unfinished", " square", " Construct the vector of pairs", " Connect by arc", " The number of non-zero pixels before the connection of the two points", " Connect the two points by arc", " The number of non-zero pixels after the connection of the two points", " If the two points where connected, that means that there should be more", " non-zero pixels after the connection", " Uncomment for visual inspection", "Visualization::show(\"ii failure\", ii , 0);", "! Tests EdgeDetection::detectEdges", " Traverse all available edge detectors", " Test the toggle switch", " Convert squares_ into a CV_32FC1 type image", " Add an unfinished square to the squares_32FC1 image", " The squares_32FC1 image in 8UC1 format, scaled", " The image of edges", "! Tests EdgeDetection::denoiseEdges", " Obtain the edges image for the squares_ image.", " Here, it does not matter with which operator the edges image is produced,", " provided that the the value tested below changes accordingly", " The number of non-zero pixels in the edges image, before denoising", " Add an unfinished square to the squares_edges image", " Run EdgeDetection::denoiseEdges", " The number of non-zero pixels in the edges image, after denoising", " The type of the edges image should be CV_8UC1", " In this particular test, where the lower right square vanishes due to", " appliance of the edge contamination method, and the unfinished square's", " end points are connected, the number of non-zero pixels after the", " denoising of the edges image should amount to lower than that of before", " Tests EdgeDetection::floodFillPostprocess", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " Run EdgeDetection::floodFillPostprocess", "! Tests EdgeDetection::identifyCurveAndEndpoints", " A gamma shape", " Find the end points of a curve where a point trully lies on", " The point should lie on a curve.", " The curve should indeed be a curve: it is constituted by points", " The first end point's coordinates", " The second end point's coordinates", " Find the end points of a curve where a point trully lies on", " The point should not lie on a curve.", " The first end point's coordinates will be the origin", " The second end point's coordinates will be also be the origin", "! Tests EdgeDetection::identifyCurvesAndEndpoints", " Three gamma shapes", " Valid", " Invalid", " Valid", " Run EdgeDetection::identifyCurvesAndEndpoints", " There should be as many lines as there are pairs of end-points", " The gammas image should be processed and turned void", " There should be two curves exceeding the length threshold,", " hence there are two different entries for curves and end-points", " Every curve found should have a length greater than the threshold set.", " The coordinates of the end-points found", " The second end point's coordinates", " The first end point's coordinates", " The second end point's coordinates", "! Tests EdgeDetection::produceEdgesViaBackprojection", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " A dummy histogram", " Uncomment for visual inspection", " Run EdgeDetection::segmentation", " Uncomment for visual inspection", " The edges image should not be blank", " The edges image should be of type CV_8UC1", "! Tests EdgeDetection::produceEdgesViaSegmentation", " Traverse all available edge detectors", " Posterize?", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " Uncomment for visual inspection", "Visualization::show(\"Before calling produceEdgesViaSegmentation 0\",", "squares_8UC3, 0);", " Segmentation using cv::pyrMeanShiftFiltering", " Run EdgeDetection::segmentation", " segmentation method = 0", " Uncomment for visual inspection", " The image should not be blank", " The edges image should be of type CV_8UC1", " Uncomment for visual inspection", "! Tests EdgeDetection::segmentation", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " Uncomment for visual inspection", "Visualization::show(\"Before calling segmentation\", squares_8UC3, 0);", " Segmentation using cv::pyrMeanShiftFiltering", " Run EdgeDetection::segmentation", " Uncomment for visual inspection", "Visualization::show(\"After calling segmentation\", segmented, 0);", "! Tests EdgeDetection::watershedViaBackprojection", " Convert squares_ into a CV_8UC3 image", " Add an unfinished square to the squares_8UC3 image", " Uncomment for visual inspection", "Visualization::show(\"Before\", squares_8UC3, 0);", " A dummy backprojection image", " The watersheded image", " Run EdgeDetection::watershedViaBackprojection", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "blob_vector_test": ["*******************************************************************", "", " Dummy entries for the src conveyor", " Push back the two holes into the src conveyor", " Dummy entries for the dst conveyor", " Push back the two holes into the dst conveyor", " This is the source conveyor", " This is the destination conveyor", "! Tests BlobVector::extend", " Backup the original dst", " 2 entries in dst before appending src to it", " Run BlobVector::extend", " 4 entries in dst after appending src to it", " Check that the initial entries have not been tampered with", " Check the newly appended entries' elements against the original ones", "! Tests HolesConveyorUtils::appendDummyConveyor", " Backup the original dst", " Run BlobVector::append", " There should now be three entries in dst", " Check that the initial entries have not been tampered with", " The new entry", "", "! Tests BlobVector::clear", " Run BlobVector::clear", " The dst conveyor should be empty", "! Tests BlobVector::copy", " Run BlobVector::copy", " There should be two hole entries in dst now", " Check the newly appended entries' elements against the original ones", "! Tests HolesConveyorUtils::generateRectangle", "~ TEST_F ( HolesConveyorUtilsTest, generateRectangleTest )", "~ {", "~ // The rectangle's points that will be returned", "~ std::vector< cv::Point2f > points_1;", "~ ", "~ // The rectangle's vertices that will be returned", "~ std::vector< cv::Point2f > points_2;", "~ ", "~ // Run HolesConveyorUtils::generateRectangle with intent = 1", "~ points_1 = HolesConveyorUtils::generateRectangle", "~ ( cv::Point2f ( 100, 100 ), 100, 100, 1 );", "~ ", "~ // Run HolesConveyorUtils::generateRectangle with intent = 2", "~ points_2 = HolesConveyorUtils::generateRectangle", "~ ( cv::Point2f ( 100, 100 ), 100, 100, 2 );", "~ ", "~ // The number of vertices should amount to a number", "~ // lower than the number of points", "~ ASSERT_LT ( points_2.size(), points_1.size() );", "~ ", "~ // There should be four vertices", "~ EXPECT_EQ ( 4, points_2.size() );", "~ ", "~ EXPECT_EQ ( 100, points_2[0].x );", "~ EXPECT_EQ ( 100, points_2[0].y );", "~ ", "~ // There should be 4 * 100 points", "~ EXPECT_EQ ( 400, points_1.size() );", "~ ", "~ EXPECT_EQ ( 100, points_1[0].x );", "~ EXPECT_EQ ( 100, points_1[0].y );", "~ ", "~ }", "! Tests BlobVector::getBlob", " Run BlobVector::getBlob", " There should be one entry inside hole", " src and hole should have exactly the same amount of", " outline points", " Check that the entries in src and hole are exactly the same", "! Tests BlobVector::merge", " The merged conveyor", " Merge src and dst into merged", " There should be exactly 2 + 2 = 4 entries in merged", " Check the newly appended entries' elements against the original ones", " Check src", " Check dst", "! Tests BlobVector::removeHole", " Backup dst", " Two holes before removing one", " Run BlobVector::removeHole", " One hole after removing one", " The first entry should be exactly the same as the previously second one", "! Tests BlobVector::replace", " Run BlobVector::replace", " Check the newly replaced entries' elements against the original ones", "! Tests BlobVector::replaceHole", " Backup dst", " Run BlobVector::replaceHole", " There should still be two holes inside dst", " The 0-th hole of dst should be the 0-th hole of src", " The 1-st hole of dst should be the 1-st hole of dstBackup", "! Tests BlobVector::shuffle", " Backup dst", " Run BlobVector::shuffle", " There should still be 2 entries in dst", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "visualization_test": ["*******************************************************************", "", " Construct image floats", " Construct image gray", " Construct image rgb", " Set up the conveyor", " The images' dimensions", " An image containing floats", " A grayscale image", " A RGB image", " A dummy conveyor", "! Tests Visualization::multipleShow", " The input vector of images to show", " Push back the images into the vector", " The vector of titles", " Push back the title of each image into the vector", " Run Visualization::multipleShow", " Uncomment for visual inspection", "Visualization::multipleShow( \"Overall title\", images, titles, 1000, 0 );", "! Tests Visualization::scaleImageForVisualization", " Run Visualization::scaleImageForVisualization", "! Tests Visualization::show", " Run Visualization::show", " Uncomment for visual inspection", "Visualization::show( \"Floats image\", floats, 0 );", "Visualization::show( \"Gray image\", gray, 0 );", "Visualization::show( \"Rgb image\", rgb, 0 );", "! Tests Visualization::showHoles", " The msgs vector", " Run Visualization::showHoles", " Uncomment for visual inspection", "Visualization::showHoles( \"Overall title\", gray, conveyor, 0, msgs, 1 );", " Run Visualization::showHoles", " Uncomment for visual inspection", "Visualization::showHoles( \"Overall title\", rgb, conveyor, 0, msgs, 1 );", "! Tests Visualization::showKeypoints", " The vector of keypoints", " The vector of available images", "! Tests Visualization::showScaled", " Uncomment for visual inspection", "Visualization::showScaled( \"Title\", floats, 0 );", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_filters_test": ["*******************************************************************", "", "", "! Sets up one image: squares_, which features four non-zero value", "! squares of various sizes.", " Four squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100),", " A2 (90, 90), B2 (90, 210), C2 (210, 210), D2 (210, 90),", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100) and", " A'' (200, 200), B'' (200, 300), C'' (300, 300), D'' (300, 200)", " The two square outlines", " Construct the upperLeftSquare image", " Construct the upperLeftSquare2 image", " Construct the lower right square", " Construct the middle square", " Obtain the squares' outline points", " The total squares_ image is the sum of all the square images", " Four squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100),", " A2 (90, 90), B2 (90, 210), C2 (210, 210), D2 (210, 90),", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100) and", " A'' (200, 200), B'' (200, 300), C'' (300, 300), D'' (300, 200)", " Each square's outline points", " Each square's vertices", "", " The four vertices of the rectangle", "! Tests HoleFilters::validateKeypointsToRectangles", " Test two keypoints VS four rectangles", " The inKeyPoints argument", " The inRectangles argument", " The inRectanglesArea argument", " The inContours argument", " The HolesConveyor struct", " Run HoleFilters::validateKeypointsToRectangles", " There should be two entries in the conveyor", " The amount of points in the outlines of the two holes should be", " equal to 4 * 100 - 4", " The first vertex of the first hole", " The last vertex of the first hole", " The first vertex of the second hole", " The last vertex of the second hole", "! Tests HoleFilters::validateBlobs", " The keyPoints argument", " The HolesConveyor struct", " Run HoleFilters::validateBlobs, using Brushfire", " There should be two entries in the conveyor", " The amount of points in the outlines of the two holes should be", " equal to 4 * 100 - 8", " The first vertex of the first hole.", " Upper right corner, going counter-clockwise", " The last vertex of the first hole", " Lower right corner, going counter-clockwise", " The first vertex of the second hole", " Upper right corner, going counter-clockwise", " The last vertex of the second hole", " Lower right corner, going counter-clockwise", " Run HoleFilters::validateBlobs, using Raycast", " First, clear the conveyor", " There should be two entries in the conveyor", " The amount of points in the outlines of the two holes should be", " equal to 4 * 100 - 8", " The first vertex of the first hole.", " Lower right corner, going counter-clockwise", " The last vertex of the first hole", " Upper right corner, going counter-clockwise", " The first vertex of the second hole", " Lower right corner, going counter-clockwise", " The last vertex of the second hole", " Lower right corner, going counter-clockwise", " namespace rgb", " namespace pandora_vision_hole", " namespace pandora_vision"], "bounding_box_detection_test": ["*******************************************************************", "", "", "! Sets up one image: squares_, which features two non-zero value squares", "! of size 100. The first one (order matters here) has its upper left", "! vertex at (100, 100) and the second one its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1). The rest of the image's pixels are with a", "! value of 60", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100)", " The two square outlines", " Construct the upperLeftSquare image", " Locate the outline points of the square in the upperLeftSquare image", " Construct the lower right square", " Locate the outline points of the square in the upperLeftSquare image", " Add the vector of outline points of the upper left square to the", " vector holding the vectors of outline points of the squares_ image", " Add the vector of outline points of the lower right square to the", " vector holding the vectors of outline points of the squares_ image", " Add the upper left square and the lower right square", " The number of actual outline points of the squares should be", " 4 x 100 - 4", " The images' width and height", " Two squares with vertices", " A (100, 100), B (100, 200), C (200, 200), D (200, 100) and", " A' (WIDTH - 1 - 100, HEIGHT - 1 - 100),", " B' (WIDTH - 1 - 100, HEIGHT - 1)", " C' (WIDTH - 1, HEIGHT - 1)", " D' (WIDTH - 1, HEIGHT - 1 - 100)", " The vector holding the vectors of outline points", " of the squares in the squares_ image", "", " The four vertices of the rectangle", "! Tests BoundingBoxDetection::findRotatedBoundingBoxesFromOutline", " The square's area", " Run BoundingBoxDetection::findRotatedBoundingBoxesFromOutline", " Clear the blobsArea vector and replace it with values that should mean", " that the squares' area is lower than the accepted threshold", " Run BoundingBoxDetection::findRotatedBoundingBoxesFromOutline", " namespace rgb", " namespace pandora_vision_victim", " namespace pandora_vision"], "hole_merger_test": ["*******************************************************************", "", "", "", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the squares_ image to 1.0", " Construct the main square. This will be the assimilator,", " amalgamator and connector", " Construct the assimilable", " Construct the amalgamatable", " Construct the connectable", " Construct the outlier", " Compose the final squares_ image", " Construct the point cloud corresponding to the squares_ image", " Fill in the cloud data", " Generate the data", " Row", " Column", " The images' width and height", " The image that will be used to locate blobs in", " The conveyor of holes that will be used to test methods of class", " DepthFilters", " The point cloud corresponding to the squares_ image", "", " Fill the inside of the desired rectangle with the @param depthIn provided", "", " A single hole", " The hole's keypoint", " The four vertices of the rectangle", " The outline points of the hole will be obtained through the depiction", " of the points consisting the rectangle", " Push the hole back into a HolesConveyor", "! Tests HoleMerger::applyMergeOperation", " Keep a backup of the original conveyor", " Run HoleMerger::applyMergeOperation for operationId = 0 : assimilation", " The number of holes should have shrunk by one", " Entry #0 should be intact", " Original entry #2 should now be entry #1", " Original entry #3 should now be entry #2", " Original entry #4 should now be entry #3", " Restore conveyor to its original state", " Run HoleMerger::applyMergeOperation for operationId = 1 : amalgamation", " The number of holes should have shrunk by one", " The amalgamator should have grown in terms of outline points", " The amalgamator's keypoint should have moved a tiny bit to the right,", " but not significantly vertically", " Entry #1 should be intact", " Original entry #3 should now be #2", " Original entry #4 should now be #3", " Run HoleMerger::applyMergeOperation for operationId = 2 : connection", " But first, restore conveyor to its original state", " Modify the connection parameters", " The number of holes should have shrunk by one", " The connector should have grown in terms of outline points", " The connector's keypoint should have moved a bit to the left,", " and a bit lower than before", " Original entry #1 should now be entry #1", " Original entry #2 should now be entry #2", " Original entry #4 should now be entry #3", " Restore conveyor to its original state", " Run HoleMerger::applyMergeOperation for all operations", " The number of holes should have shrunk to two", " Apply preposterous thresholds", " Restore conveyor to its original state", " Run HoleMerger::applyMergeOperation for all operations", " No assimilation or amalgamation or connection should have happened", "! Tests HoleMerger::applyMergeOperationWithoutValidation", " Keep a backup of the original conveyor", " Run HoleMerger::applyMergeOperationWithoutValidation", " for operationId = 0 : assimilation", " The number of holes should have shrunk by one", " Entry #0 should be intact", " Original entry #2 should now be entry #1", " Original entry #3 should now be entry #2", " Original entry #4 should now be entry #3", " Restore conveyor to its original state", " Run HoleMerger::applyMergeOperationWithoutValidation", " for operationId = 1 : amalgamation", " The number of holes should have shrunk by one", " The amalgamator should have grown in terms of outline points", " The amalgamator's keypoint should have moved a tiny bit to the right,", " but not significantly vertically", " Entry #1 should be intact", " Original entry #3 should now be #2", " Original entry #4 should now be #3", " Restore conveyor to its original state", " Run HoleMerger::applyMergeOperationWithoutValidation", " for all operations", " The number of holes should have shrunk to three", "! Tests HoleMerger::isCapableOfAssimilating", " Construct the hole mask sets for all the holes", " Here, the main square will be the assimilator, amalgamator and connector", " Run HoleMerger::isCapableOfAssimilating", " The main square should be able to assimilate only the assimilable", "! Tests HoleMerger::isCapableOfAmalgamating", " Construct the hole mask sets for all the holes", " Here, the main square will be the assimilator, amalgamator and connector", " Run HoleMerger::isCapableOfAmalgamating", " The main square should be able to amalgamate only the amalgamatable", "! Tests HoleMerger::amalgamateOnce", " Construct the hole mask sets for all the holes", " Here, the main square will be the assimilator, amalgamator and connector", " Keep a backup of the original amalgamator", " The amalgamator should have grown in terms of outline points", " The amalgamator's keypoint should have moved a tiny bit to the right,", " but not significantly vertically", "! Tests HoleMerger::isCapableOfConnecting", " Construct the hole mask sets for all the holes", " Here, the main square will be the assimilator, amalgamator and connector", " Modify the connection parameters", " Run HoleMerger::isCapableOfConnecting", " The main square should be able to amalgamate only the amalgamatable", " Modify the connection parameters so as to test that not only distance", " plays a role. There has to be mutual exclusion regarding the points", " inside each hole too", " Run HoleMerger::isCapableOfConnecting", " The main square should be able to connect only with the connectable", " Modify the connection parameters so as to test that not only distance", " plays a role. There has to be mutual exclusion regarding the points", " inside each hole too", " Run HoleMerger::isCapableOfConnecting", " The connectable should not be able to be connected with the", " connector for max_distance = 10", " Default the connection parameters", "! Tests HoleMerger::connectOnce", " Construct the hole mask sets for all the holes", " Here, the main square will be the assimilator, amalgamator and connector", " Keep a backup of the original amalgamator", " Run HoleMerger::connectOnce", " The connector should have grown in terms of outline points", " The connector's keypoint should have moved a bit to the left,", " and a bit lower than before", "! Tests HoleMerger::mergeHoles", " Keep a backup of the original conveyor", " The interpolation method. 0 for using depth filters validation", " Apply reasonable thresholds", " Restore conveyor to its original state", "HolesConveyorUtils::replace( originConveyor, &conveyor );", " Run HoleMerger::mergeHoles", " The number of holes should have shrunk to two", " The interpolation method. 1 for not using depth filters validation", " Restore conveyor to its original state", " Run HoleMerger::mergeHoles", " The number of holes should have shrunk to three", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "rgb_filters_test": ["*******************************************************************", "", "", "", "! Sets up one image: squares_,", "! which features four squares of size 100, and one of size 140", "! The first one (order matters here) has its upper left vertex at", "! (100, 100),", "! the second one has its upper right vertex at (WIDTH - 3, 3)", "! (so that the blob it represents can barely be identified)", "! and the the third one has its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1).", "! It creates a square whose upper left vertex is located", "! at ( 250, 250 ), filled with random colours.", "! Finally, there is the square with edges of length 140px, which", "! surrounds the upper left square, and is of black colour", "! (constructed to test the RgbFilters::checkHolesLuminosityDiff method)", "! It creates the corresponding conveyor entries for these square holes.", " Construct the lower right square", " Construct the upper right image", " Construct the upper left square", " Construct the square surrounding the upper left square", " Construct the middle square. In contrast to the other three", " rectangles, this is scattered with random colours inside it", " The seed for the rand_r method", " The image upon which the squares will be inprinted", " Compose the final squares_ image", " Construct the squares_ image. The entire image is at a colour of", " value approximate the the colour value of the images of walls", " The images' width and height", " The image that will be used to locate blobs in", " The conveyor of holes that will be used to test methods of class", " RgbFilters", "", " Fill the inside of the desired rectangle with the @param rgbIn provided", "", " A single hole", " The hole's keypoint", " The four vertices of the rectangle", " The outline points of the hole will be obtained through the depiction", " of the points consisting the rectangle", " Push hole back into a HolesConveyor", " Tests RgbFilters::checkHolesColorHomogeneity", " Generate the needed resources", " The vector of probabilities returned", " Run RgbFilters::checkHolesColorHomogeneity", " All squares except the one whose internal colours are randomly", " generated are dull.", "! Tests RgbFilters::checkHolesLuminosityDiff", " Generate the needed resources for an inflation size of value 0", " The vector of set masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of sets", " The vector of probabilities returned", " Run RgbFilters::checkHolesLuminosityDiff", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " Generate the needed resources for an inflation size of value 10", " The vector of set masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of sets", " The vector of probabilities returned", " Run RgbFilters::checkHolesLuminosityDiff", " The inflated rectangles of the lower right and upper right rectangles", " are out of the image's bounds.", " The upper left rectangle is surrounded by a black rectangle, so there goes", " The surrounding rectangle and the middle one are just fine", "! Tests RgbFilters::checkHolesTextureBackProject", " Generate the needed resources for an inflation size of value 0", " The vector of set masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of sets", " The vector of probabilities returned", " Generate the histogram of walls", " Run RgbFilters::checkHolesTextureBackProject", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " Generate the needed resources for an inflation size of value 10", " The vector of set masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of sets", " The vector of probabilities returned", " Run RgbFilters::checkHolesTextureBackProject", " The inflated rectangles of the lower right and upper right rectangles", " are out of the image's bounds.", " The upper left rectangle is surrounded by a black rectangle, so there goes", " The surrounding rectangle and the middle one are just fine", "! Tests RgbFilters::checkHolesTextureDiff", " Histogram generation : secondary channel toggle", " Generate the needed resources for an inflation size of value 0", " The vector of image masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of images", " There shouldn't be any non-zero pixels inside each mask", " The vector of probabilities returned", " Generate the histogram of walls", " Run RgbFilters:checkHolesTextureDiff:", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsImageVector_0 vector is zero", " Histogram generation : secondary channel toggle", " Generate the needed resources for an inflation size of value 10", " The vector of set masks", " The vectors of inflated rectangles and in-bounds inflated rectangles'", " indices", " The intermediate points vector of images", " There should be more than zero non-zero pixels inside each mask", " The vector of probabilities returned", " Set the texture threshold to 0.9, or else all probabilities would be", " equal to zero", " Generate the histogram of walls", " Run RgbFilters:checkHolesTextureDiff:", " For some reason, using the saturation as the secondary channel for", " the generation of the histograms, gives all probabilities", " equal to zero. Crappy behaviour.", " The inflated rectangles of the lower right and upper right rectangles", " are out of the image's bounds.", " The upper left rectangle is surrounded by a black rectangle,", " so there goes.", " The surrounding rectangle and the middle one are just fine", " namespace hole_fusion", " namespace pandora_vision_victim", " namespace pandora_vision"], "hole_validation_test": ["*******************************************************************", "", " A vector of probabilities for when in RGBD_MODE,", " when all available filters are active", " A vector of probabilities for when in RGBD_MODE,", " when some of the available filters are active", " A vector of probabilities for when in RGB_ONLY_MODE,", " when all available filters are active", " A vector of probabilities for when in RGB_ONLY_MODE,", " when some of the available filters are active", "! Tests HoleValidation::validateHoles", "////////////////////////////// RGBD_MODE /////////////////////////////////", "////////////////////////////// All filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Luminosity diff", " Rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHoles for RGBD_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of some available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Rectangle plane constitution", " Texture backprojection", " Intermediate points plane constitution", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesfor RGBD_MODE", " Only the second hole should have been deemed valid", "//////////////////////////// RGB_ONLY_MODE ///////////////////////////////", "///////////////////////////// All filters ////////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesfor RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesfor RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "! Tests HoleValidation::validateHolesViaThresholdedWeighting", "////////////////////////////// RGBD_MODE /////////////////////////////////", "////////////////////////////// All filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Luminosity diff", " Rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholdedWeighting for RGBD_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of some available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Rectangle plane constitution", " Texture backprojection", " Intermediate points plane constitution", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholdedWeighting for RGBD_MODE", " Only the second hole should have been deemed valid", "//////////////////////////// RGB_ONLY_MODE ///////////////////////////////", "///////////////////////////// All filters ////////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholdedWeighting for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholdedWeighting for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "! Tests HoleValidation::validateHolesViaThresholding", "////////////////////////////// RGBD_MODE /////////////////////////////////", "////////////////////////////// All filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Luminosity diff", " Rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholding for RGBD_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of some available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Rectangle plane constitution", " Texture backprojection", " Intermediate points plane constitution", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholding for RGBD_MODE", " Only the second hole should have been deemed valid", "//////////////////////////// RGB_ONLY_MODE ///////////////////////////////", "///////////////////////////// All filters ////////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholding for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaThresholding for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "! Tests HoleValidation::validateHolesViaWeighting", "////////////////////////////// RGBD_MODE /////////////////////////////////", "////////////////////////////// All filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Luminosity diff", " Rectangle plane constitution", " Depth homogeneity", " Texture backprojection", " Intermediate points plane constitution", " Depth diff", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaWeighting for RGBD_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of some available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Depth / area", " Rectangle plane constitution", " Texture backprojection", " Intermediate points plane constitution", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaWeighting for RGBD_MODE", " Only the second hole should have been deemed valid", "//////////////////////////// RGB_ONLY_MODE ///////////////////////////////", "///////////////////////////// All filters ////////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Texture diff", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaWeighting for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", "///////////////////////////// Some filters ///////////////////////////////", " Set the priority of all available filters", " Set up filters' responses about two holes", " Colour homogeneity", " Luminosity diff", " Texture backprojection", " Populate the overall probabilities vector, for RGBD_MODE", " Run HoleValidation::validateHolesViaWeighting for RGB_ONLY_MODE", " Only the second hole should have been deemed valid", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "hole_uniqueness_test": ["*******************************************************************", "", "! Tests HoleUniqueness::makeHolesUnique (a)", " The container of holes", " A container of one hole", " Construct hole_1", " A container of another hole", " Construct hole_2", " A container of a third hole", " Construct hole_3", " Holes 1 and 2 will be multiple, in a random order.", " Run HoleUniqueness::makeHolesUnique (a)", " There should be only three unique holes inside the container", "! Tests HoleUniqueness::makeHolesUnique (b)", " What one needs to do here, is to construct a swarm of holes", " around some point and give each hole a validity probability.", " First swarm; swarm a", " Second swarm; swarm b", " Add another, unique, hole", " Push all the holes back into a container", " Construct a validity map", " Run HoleUniqueness::makeHolesUnique (b)", " There should be three unique holes", " Inquire about the internals of the unique holes", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "filters_test": ["*******************************************************************", "", "", "", "", "! Sets up two images: depthSquares_,", "! which features three squares of size 100.", "! The first one (order matters here) has its upper left vertex at", "! (100, 100),", "! the second one has its upper right vertex at (WIDTH - 3, 3)", "! (so that the blob it represents can barely be identified)", "! and the the third one has its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1).", "! It creates the corresponding conveyor entries for these square holes", "! and the corresponding point cloud to match the depthSquares_ depth image.", "! The second image is rgbSquares_,", "! which features four squares of size 100, and one of size 140", "! The first one (order matters here) has its upper left vertex at", "! (100, 100),", "! the second one has its upper right vertex at (WIDTH - 3, 3)", "! (so that the blob it represents can barely be identified)", "! and the the third one has its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1).", "! It creates a square whose upper left vertex is located", "! at ( 250, 250 ), filled with random colours.", "! Finally, there is the square with edges of length 140px, which", "! surrounds the upper left square, and is of black colour", "! (constructed to test the Filters::checkHolesLuminosityDiff method)", "! It creates the corresponding conveyor entries for these square holes.", "/////////// Construct the depth image and the point cloud ////////////", " The image upon which the squares will be inprinted", " Construct the depthSquares_ image", " Set the depth for each point of the depthSquares_ image to 1.0", " Construct the lower right square", " Construct the upper right image", " Construct the upper left square", " Compose the final depthSquares_ image", " Construct the point cloud corresponding to the depthSquares_ image", " Fill in the cloud data", " Generate the data", " Row", " Column", "///////////////////// Construct the rgb image ////////////////////////", " Construct the lower right square", " Construct the upper right image", " Construct the upper left square", " Construct the square surrounding the upper left square", " Construct the middle square. In contrast to the other three", " rectangles, this is scattered with random colours inside it", " The seed for the rand_r method", " Create the conveyor of candidate holes for both images", " The image upon which the squares will be inprinted", " Compose the final rgbSquares_ image", " Construct the rgbSquares_ image. The entire image is at a colour of", " value approximate the the colour value of the images of walls", " The images' width and height", " The depth image", " The RGB image", " The conveyor of holes that will be used to test methods of class", " Filters", " The point cloud corresponding to the depthSquares_ image", "", " Fill the inside of the desired rectangle with the @param depthIn provided", "", " Fill the inside of the desired rectangle with the @param rgbIn provided", "", " What will be returned: the internal elements of one hole", " The hole's keypoint", " The four vertices of the rectangle", " The outline points of the hole will be obtained through the depiction", " of the points consisting the rectangle", " Push hole into a HolesConveyor", "! Tests Filters::applyFilter", " Inflations size : 0", " Create the needed by the Filters::applyFilter method vectors", " The vector of mask images", " The intermediate points vector of sets", " The intermediate points vector of images", " Run Filters::applyFilter for every filter,", " except for the ones that utilize textures", " A dummy histogram", " Run Filters::applyFilter", " Color homogeneity", " All squares except the one whose internal colours are randomly", " generated are dull.", " Luminosity difference", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " Texture-based filters are not tested yet.", " TODO: import an image from the walls directory in order to test them", " Depth difference", " The surrounding square has its vertices closer than its keypoint", " Rectangle points plane constitution", " Depth / area", " Intermediate points plane constitution", " Depth homogeneity", " The east and south edges of the lower right square are clipped", " The surrounding square encloses a hole which actually has edges", " Inflations size : 10", " Create the needed by the Filters::applyFilter method vectors", " The vector of mask images", " The intermediate points vector of images", " Run Filters::applyFilter for every filter", " except for the ones that utilize textures", " Run Filters::applyFilter", " Color homogeneity", " All squares except the one whose internal colours are randomly", " generated are dull.", " Luminosity difference", " The inflated rectangles of the lower right and upper right rectangles", " are out of the image's bounds.", " The upper left rectangle is surrounded by a black rectangle,", " so there goes", " The surrounding rectangle and the middle one are just fine", " Texture-based filters are not tested yet.", " TODO: import an image from the walls directory in order to test them", " Depth difference", " Only the last two holes should have an inflated rectangle", " for inflation size of value 10", " Rectangle points plane constitution", " Depth / area", " Intermediate points plane constitution", " Depth homogeneity", " The east and south edges of the lower right square are clipped", "! Tests Filters::applyFiltersTest:", "///////////////////////// Inflations size : 0 ////////////////////////////", " Create the needed by the Filters::applyFilters method vectors", " The vector of mask images", " The intermediate points vector of sets", " The intermediate points vector of images", " ------------------------------ RGBD_MODE --------------------------------", " Set the order of the filters' execution in random", " Apply all active filters and obtain a 2D vector containing the", " probabilities of validity of each candidate hole, produced by all", " active filters", " Seven RGB + D filters in total", " (Nine excluding the ones using textures)", " A dummy histogram", " Test all RGB and Depth filters", " Run Filters::applyFilters", " Filter-wise", " The east and south edges of the lower right square are clipped", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " ---------------------------- RGB_ONLY_MODE ------------------------------", " Set the order of the filters' execution in random", " Apply all active filters and obtain a 2D vector containing the", " probabilities of validity of each candidate hole, produced by all", " active filters", " (Four excluding the ones using textures)", " Test only the RGB filters", " Run Filters::applyFilters", " Filter-wise", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", "//////////////////////// Inflations size : 10 ////////////////////////////", " Create the needed by the Filters::applyFilters method vectors", " The vector of mask images", " The intermediate points vector of sets", " The intermediate points vector of images", " ------------------------------ RGBD_MODE --------------------------------", " Set the order of the filters' execution in random", " Apply all active filters and obtain a 2D vector containing the", " probabilities of validity of each candidate hole, produced by all", " active filters", " Seven RGB + D filters in total", " (Nine excluding the ones using textures)", " Test all RGB and Depth filters", " Run Filters::applyFilters", " Filter-wise", " The east and south edges of the lower right square are clipped", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " ---------------------------- RGB_ONLY_MODE ------------------------------", " Set the order of the filters' execution in random", " Apply all active filters and obtain a 2D vector containing the", " probabilities of validity of each candidate hole, produced by all", " active filters", " (Four excluding the ones using textures)", " Test only the RGB filters", " Run Filters::applyFilters", " Filter-wise", " All probabilities amount to zero: the size of each set inside the", " intermediatePointsSetVector_0 vector is zero", " namespace hole_fusion", " namespace pandora_vision_victim", " namespace pandora_vision"], "filters_resources_test": ["*******************************************************************", "", "", " An image needed only for its size", " In total, there should be three holes", " An image needed only for its size", " Dimensions of the squares_ image", " The overall conveyor holding the holes", "", " A single hole", " The hole's keypoint", " The four vertices of the rectangle", " The outline points of the hole will be obtained through the depiction", " of the points consisting the rectangle", " Push back hole into a HolesConveyor", "! Tests FiltersResources::createCheckerRequiredVectors", "/////////////////////////////// RGBD_MODE ////////////////////////////////", " The needed resources", " Run FiltersResources::createCheckerRequiredVectors", " Inquire about holesMasksImageVector", " There should be three images of masks of holes", " There should be 100 X 100 points in each mask", " No masks if the corresponding filters to variables", " a and c are disabled", " Inquire about holesMasksSetVector", " There should be three masks of holes", " Each mask should have 100 X 100 points", " No masks if the corresponding filters to variables", " b, d, f and i are disabled", " Inquire about inflatedRectangles*", " The number of rectangles should be equal to the", " number of indices", " In this case, with an inflation size of value 10,", " there should be two holes", " Each rectangle should have exactly four vertices", " The number of rectangles should be equal to the", " number of indices", " No masks if the corresponding filters to variables", " b, c, d, e, g and h are disabled", " Inquire about intermediatePointsImageVector", " There should be two masks of intermediate points", " There should be more than 400 intermediate points", " No masks if the corresponding filter to variable", " c is disabled", " Inquire about intermediatePointsSetVector", " There should be two masks of intermediate points", " There should be more than 400 intermediate points", " No masks if the corresponding filters to variables", " b, d and g are disabled", " Clear the vectors for the next run", "///////////////////////////// RGB_ONLY_MODE //////////////////////////////", " The needed resources", " Run FiltersResources::createCheckerRequiredVectors", " Inquire about holesMasksImageVector", " There should be three images of masks of holes", " There should be 100 X 100 points in each mask", " No masks if the corresponding filters to variables", " a and c are disabled", " Inquire about holesMasksSetVector", " There should be three masks of holes", " Each mask should have 100 X 100 points", " No masks if the corresponding filters to variables", " b, d, f and i are disabled", " Inquire about inflatedRectangles*", " The number of rectangles should be equal to the", " number of indices", " In this case, with an inflation size of value 10,", " there should be two holes", " Each rectangle should have exactly four vertices", " The number of rectangles should be equal to the", " number of indices", " No masks if the corresponding filters to variables", " b, c, d, e, g and h are disabled", " Inquire about intermediatePointsImageVector", " There should be two masks of intermediate points", " There should be more than 400 intermediate points", " No masks if the corresponding filter to variable", " c is disabled", " Inquire about intermediatePointsSetVector", " There should be two masks of intermediate points", " There should be more than 400 intermediate points", " No masks if the corresponding filters to variables", " b, d and g are disabled", " Clear the vectors for the next run", "! Tests FiltersResources::createHolesMasksVectors", " The vector of images of masks", " The indices of points inside the holes in conveyor", " Run FiltersResources::createHolesMasksVectors", " There should be three masks in total", " The number of non-zero value pixels in all of the images", " The total number of non-zero value pixels in all of the images should", " be equal to three times as much as in any image, which is 100 X 100", "! Tests FiltersResources::createHolesMasksImageVector", " The vector of images of masks", " Run FiltersResources::createHolesMasksImageVector", " There should be three images in total", " The images' type should be CV_8UC1", " The number of non-zero value pixels in all of the images", " The total number of non-zero value pixels in all of the images should", " be equal to three times as much as in any image, which is 100 X 100", "! Tests FiltersResources::createHolesMasksSetVector", " The indices of points inside the holes in conveyor", " Run FiltersResources::createHolesMasksSetVector", " Each mask should have 100 X 100 points", " Uncomment for visual inspection", "! Tests FiltersResources::createInflatedRectanglesVector", " The vector holding the inflated rectangles vertices per hole for", " inflation size equal to zero", " The indices of holes inside the conveyor whose inflated rectangles is", " actually inside the image's bounds for", " inflation size equal to zero", " Run FiltersResources::createInflatedRectanglesVector", " with inflation size of value 0", " All holes' inflated rectangles should be inside the image's bounds", " All rectangles should be of size four (four vertices)", " The vector holding the inflated rectangles vertices per hole for", " inflation size equal to two", " The indices of holes inside the conveyor whose inflated rectangles is", " actually inside the image's bounds for", " inflation size equal to two", " Run FiltersResources::createInflatedRectanglesVector", " with inflation size of value 2", " The lower right hole's inflated rectangle should exceed", " the image's bounds", " All rectangles should be of size four (four vertices)", " The first valid inflated rectangle should be conveyor[1]", " The second valid inflated rectangle should be conveyor[2]", "! Tests FiltersResources::createIntermediateHolesPointsVectors", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 0", " The intermediate points vector for all holes", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsVectors", " Intermediate points positions should only exist for all of the holes", " The total number of intermediate points in all of the images", " There shouldn't be any intermediate points for inflation size equal to 0", " There shouldn't be any intermediate points for inflation size equal to 0", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 2", " The intermediate points vector for all holes", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsVectors", " Intermediate points positions should only exist for all of the holes", " whose iflated rectangle is within the image's bounds", " The total number of intermediate points in all of the images", " There shouldn't be any intermediate points for inflation size equal to 0", " There shouldn't be any intermediate points for inflation size equal to 0", "! Tests FiltersResources::createIntermediateHolesPointsImageVector", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 0", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsImageVector", " Intermediate points positions should exist for all of the holes", " The total number of intermediate points in all of the images", " There shouldn't be any intermediate points for inflation size equal to 0", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 2", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsImageVector", " Intermediate points should only exist for the two holes", " The total number of intermediate points in all of the images", " There should be two valid inflated rectangles, so the total number", " of intermediate points should be greater than two times the outline", " of each hole", "! Tests FiltersResources::createIntermediateHolesPointsSetVector", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 0", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsSetVector", " Intermediate points positions should exist for all of the holes", " There shouldn't be any intermediate points for inflation size equal to 0", " First off, we need to obtain the inflated rectangles vector and the", " corresponding vector of indices of holes with valid inflated rectangles", " First, test with an inflation size value of 2", " The intermediate points vector for all holes", " Run FiltersResources::createIntermediateHolesPointsSetVector", " Intermediate points should only exist for the two holes", " There should be more than 4 X 100 intermediate points", " Uncomment for visual inspection", " hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "depth_filters_test": ["*******************************************************************", "", "", "", "! Sets up one image: squares_,", "! which features three squares of size 100.", "! The first one (order matters here) has its upper left vertex at", "! (100, 100),", "! the second one has its upper right vertex at (WIDTH - 3, 3)", "! (so that the blob it represents can barely be identified)", "! and the the third one has its lower right vertex at", "! (WIDTH - 1, HEIGHT - 1).", "! It creates the corresponding conveyor entries for these square holes", "! and the corresponding point cloud to match the squares_ depth image", " The image upon which the squares will be inprinted", " Construct the squares_ image", " Set the depth for each point of the squares_ image to 1.0", " Construct the lower right square", " Construct the upper right image", " Construct the upper left square", " Compose the final squares_ image", " Construct the point cloud corresponding to the squares_ image", " Fill in the cloud data", " Generate the data", " Row", " Column", " The images' width and height", " The image that will be used to locate blobs in", " The conveyor of holes that will be used to test methods of class", " DepthFilters", " The point cloud corresponding to the squares_ image", "", " Fill the inside of the desired rectangle with the @param depthIn provided", "", " What will be returned: the internal elements of one hole", " The hole's keypoint", " The four vertices of the rectangle", " The outline points of the hole will be obtained through the depiction", " of the points consisting the rectangle", " Push hole into a HolesConveyor", "! Tests DepthFilters::checkHolesDepthArea", " Generate the vector of holes' mask (set)", " Needed vectors by the DepthFilters::checkHolesDepthDiff method", " Run DepthFilters::checkHolesDepthDiff", "! Tests DepthFilters::checkHolesDepthDiff", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 0", " Needed vectors by the DepthFilters::checkHolesDepthDiff method", " Run DepthFilters::checkHolesDepthDiff", " All three holes should have an inflated rectangle for inflation", " size of value 0", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 2", " Needed vectors by the DepthFilters::checkHolesDepthDiff method", " Run DepthFilters::checkHolesDepthDiff", " Only the last two holes should have an inflated rectangle", " for inflation size of value 2", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 8", " Needed vectors by the DepthFilters::checkHolesDepthDiff method", " Run DepthFilters::checkHolesDepthDiff", " Only the last two holes should have an inflated rectangle", " for inflation size of value 2", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 180", " Needed vectors by the DepthFilters::checkHolesDepthDiff method", " Run DepthFilters::checkHolesDepthDiff", " Only the last two holes should have an inflated rectangle", " for inflation size of value 2", "! Tests DepthFilters::checkHolesDepthHomogeneity", " Generate the vector of holes' mask (set)", " Needed vectors by the DepthFilters::checkHolesDepthHomogeneity method", " Run DepthFilters::checkHolesDepthHomogeneity", " The east and south edges of the lower right square are clipped", "! Tests DepthFilters::checkHolesOutlineToRectanglePlaneConstitution", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 0", " Generate the intermediate points set vector", " Needed vectors by the", " DepthFilters::checkHolesOutlineToRectanglePlaneConstitution method", " Run DepthFilters::checkHolesOutlineToRectanglePlaneConstitution", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 10", " Generate the intermediate points set vector", " Needed vectors by the", " DepthFilters::checkHolesOutlineToRectanglePlaneConstitution method", " Run DepthFilters::checkHolesOutlineToRectanglePlaneConstitution", "! Tests DepthFilters::checkHolesRectangleEdgesPlaneConstitution", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 0", " Needed vectors by the", " DepthFilters::checkHolesRectangleEdgesPlaneConstitution method", " Run DepthFilters::checkHolesRectangleEdgesPlaneConstitution", " All of the rectangles lie on planes", " Generate the inflated rectangles and corresponding indices vectors", " for an inflation size of value 10", " Needed vectors by the", " DepthFilters::checkHolesRectangleEdgesPlaneConstitution method", " Run DepthFilters::checkHolesRectangleEdgesPlaneConstitution", " The lower right and upper right squares' inflated rectangles", " exceed the image's boundaries, hence, their probability of lying on", " a plane is diminished to zero", " Only the upper left square's inflated rectangle is within the image's", " bounds.", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "planes_detection_test": ["*******************************************************************", "", " Construct the point cloud", " The height and width of the point cloud", " The point cloud which the test are relied on", "! Tests PlanesDetection::applyVoxelGridFilter", " Run PlanesDetection::applyVoxelGridFilter", "! Tests PlanesDetection::locatePlanes", " Run PlanesDetection::locatePlanes without applying voxel filtering", " There should be two planes detected", " The first plane is comprised of the three quarters", " of the entire point cloud", " The remaining quarter is the second point cloud", " Run PlanesDetection::locatePlanes with voxel filtering", " There should be two planes detected", " The first plane is comprised of the one hundredth of three quarters", " of the entire point cloud", " The remaining one hundredth quarter is the second point cloud", "! Tests PlanesDetection::locatePlanesUsingSACSegmentation", " The planar point clouds' vector", " The vector of coefficients per plane", " The vector of inliers per plane", " There should be two planes detected", " The first plane is comprised of the three quarters", " of the entire point cloud", " The remaining quarter is the second point cloud", " namespace hole_fusion", " namespace pandora_vision_hole", " namespace pandora_vision"], "interface_tester": ["*******************************************************************"], "tf_monitor": ["* \\author Wim Meeussen ", "Lookup the authority "], "interfaces_xml_parser": ["*******************************************************************"], "node_diagnostics": ["*******************************************************************", "~ Suppose there is only one package element in each document"], "generic_diagnostic": ["*******************************************************************"], "interface_diagnostics_node": ["*******************************************************************", "~ InterfaceDiagnostics id;"], "interface_diagnostics": ["*******************************************************************", "~ Suppose there is only one package element in each document"], "xmega_hardware_interface": ["*******************************************************************", " connect and register power supply interface", " connect and register range sensor interface", " connect and register joint state interface", " make radians value between [-pi, pi]", " read joint names from param server", " connect and register the joint state interface", " namespace xmega", " namespace pandora_hardware_interface"], "xmega_hardware_interface_node": ["*******************************************************************"], "battery_controller": ["*******************************************************************", " Get sensor names from interface", " Read publish rate from yaml", " Get sensor handles from interface", " Create publisher", " Initialize last time published", " Publish messages", " Fill voltage", " namespace arm", " namespace pandora_hardware_interface"], "range_sensor_controller": ["*******************************************************************", " Get sensor names from interface", " Read publish rate from yaml", " Get sensor handles from interface", " Create publisher for each controller", " resize last times published", " Initialize last time published", " Publish messages", " Fill range msg", " publish the message", " namespace arm", " namespace pandora_hardware_interface"], "encoder_sensor": ["*******************************************************************", "", " namespace xmega", " namespace pandora_hardware_interface"], "test": ["*******************************************************************"], "range_sensor": ["*******************************************************************", " namespace xmega", " namespace pandora_hardware_interface"], "battery_sensor": ["*******************************************************************", " <calculated scale factor error for Electronics line> ", " namespace xmega", " namespace pandora_hardware_interface"], "xmega_serial_interface": ["*******************************************************************", "------------- Private Members -------------------//", " <IDLE_STATE indicates the state waiting for start of transmission characters> ", " +0.5 is used for rounding positive values", " cleanup", " ' ' after sensor id", " ' ' after sensor type", " battery, not i2c sensor", " encoder, not i2c sensor", " ' ' after sensor i2c address", " ' ' after sensor status", " LF after Data", " processing error", " successful processing", "----------SerialIO------------------------//", "serialPtr_->flush(); /* <Flush I/O software buffers on startup.> */", " <Flush Input software buffer on startup.> ", " <Flush Output software buffer on startup.> ", "serialPtr_->flush(); /* <Flush I/O software buffers on termination.> */", " <Flush Input software buffer on termination.> ", " <Flush Output software buffer on termination.> ", "initialize size of data.Size of command data is 1 byte", " <If they match the start of data package char sequence (0x0C , 0x0A)> ", "dataSiz buffer where the size of data is written", "Initialize size of dataSiz.", "to change????", " negative or dekadiko???????????????", " namespace xmega", " namespace pandora_hardware_interface"], "linear_actuator_hardware_interface_node": ["*******************************************************************"], "linear_actuator_hardware_interface": ["*******************************************************************", " initialize position of linear actuator", " connect and register the joint state interface", " connect and register the joint position interface", " get feedback and convert from [cm] to [m]", " clip target command", " namespace linear_actuator", " namespace pandora_hardware_interface"], "firgelli_com_interface": ["*******************************************************************", " set accuracy", " Low", " High", " set retract limit", " Low", " High", " set extend limit", " Low", " High", " set movement threshold", " Low", " High", " set stall time", " Low", " High", " set PWM threshold", " Low", " High", " set Derivative Threshold", " Low", " High", " set max derivative", " Low", " High", " set min derivative", " Low", " High", " set max pwm", " Low", " High", " set min pwm", " Low", " High", " set Kp", " Low", " High", " set Kd", " Low", " High", " set average RC", " Low", " High", " set average ADC", " Low", " High", " set speed", " Low", " High", " Microtech", " ??", " useless", " Low", " High", " namespace linear_actuator", " namespace pandora_hardware_interface"], "jrk_com_interface": ["*******************************************************************", " open serial communication port, the device is connected to", " flush both Input and output buffers", " clear errors of linear actuator controller on startup", " Flush both input and output buffers on exit", " flush written but not send data", " flush received, but unread data", "Gets error flags halting and clears any latched errors", " namespace linear_actuator", " namespace pandora_hardware_interface"], "jrk_communicator": ["*******************************************************************", " Send 'target position' over the serial port", " Get feedback", " Get feedback"], "thermal_sensor_controller": ["*******************************************************************", " Get sensor names from interface", " Read publish rate from yaml", " Get sensor handles from interface", " Create publisher for each controller", " resize last times published", " Initialize last time published", " Publish messages", " namespace arm", " namespace pandora_hardware_interface"], "co2_sensor_controller": ["*******************************************************************", " Get sensor names from interface", " Read publish rate from yaml", " Get sensor handles from interface", " Create publisher for each controller", " resize last times published", " Initialize last time published", " Publish messages", " Fill co2 msg", " namespace arm", " namespace pandora_hardware_interface"], "arm_hardware_interface_node": ["*******************************************************************"], "arm_hardware_interface": ["*******************************************************************", " connect and register co2 sensor interface", " connect and register thermal sensor interface", " connect and register range sensor interface", " connect and register battery interface", " connect and register joint state interface", " ROS_INFO(\"Will read CO2\");", " read CO2 percentage from CO2 sensors", " read thermal image from grideye sensors", " ROS_INFO(\"Will read GEYE loop/n\");", " ROS_INFO(\"Will read SONARS\");", " read distances from range sensors", " ROS_INFO(\"Will read BATTERIES\");", " read voltage of batteries", " read encoder degrees", " make radians value between [-pi, pi]", " read joint names from param server", " connect and register the joint state interface", " namespace arm", " namespace pandora_hardware_interface"], "arm_usb_interface": ["*******************************************************************", "  fcntl(fd, F_SETFL, FNDELAY);    //make read() non-blocking", "  fcntl(fd, F_SETFL, 0);  //make read() blocking", " To make read non-blocking use the following:", " fd = open(\"/dev/arm\", O_RDWR | O_NOCTTY | O_NDELAY);", " Needs some time to initialize, even though it opens succesfully.", " tcflush() didn't work without waiting at least 8 ms", " To save time you can see and change terminal settings in command line with stty command,", " before implementing in software. Note: stty prefixes disabled flags with a dash.", " See:  http://man7.org/linux/man-pages/man3/termios.3.html", " set timeout to 100ms", " flush both data received but not read and data written but not transmitted", " ROS_INFO(\"JUST FLUSHED BUFFER\");", " clear the set ", " add our file descriptor to the set ", "------------- READ NACK -------------", " union", " {", "   uint16_t nackBufInUint16;", " };", " ROS_INFO(\"After Write Process\");", " an error accured ", " a timeout occured ", " ROS_INFO(\"Before NACK read\");", " ROS_INFO(\"After NACK read %x\",*(nackBufInUint8));", " else if (nr != NACK_NBYTES)", " {", "  ROS_ERROR(\"[Arm]: Wrong number of bytes read\\n\");", "  reconnectUsb();", "  return INCORRECT_NUM_OF_BYTES;", " }", " end for", " else", " ROS_INFO(\"Received ACK!!!!!!!!!!!!!! : %x\",nack16);", " ------------------------------------------------------", " an error accured ", " a timeout occured ", " ROS_INFO(\"Before BUFFER READ\");", " blocking", " ROS_INFO(\"After BUFFER READ\");", " else if (nr != read_bytes)", " {", "   ROS_ERROR(\"[Arm]: Wrong number of bytes read, nr = %d, read = %d\",nr,read_bytes);", "   reconnectUsb();", "   return INCORRECT_NUM_OF_BYTES;", " }", " readBuf = buff;", " shouldn't get in there", " reconnectUsb() should be called until communication is restored.", " namespace arm", " namespace pandora_hardware_interface"], "arm_usb_interface_demo": ["*******************************************************************", " 0 in temperature indicates communication problem"], "imu_hardware_interface": ["*******************************************************************", " initialize imu interface", " apply offsets to pitch, roll and yaw", " namespace imu", " namespace pandora_hardware_interface"], "imu_hardware_interface_node": ["*******************************************************************", " ~ ros::Duration(0.1).sleep();"], "imu_rpy_controller": ["*******************************************************************", " get all joint states from the hardware interface", " get publishing period", " sensor handle", " Roll, Pitch, Yaw realtime publisher", " Last published times", " initialize time", " limit rate of publishing", " try to publish", " we're actually publishing, so increment time", " populate message", " namespace imu", " namespace pandora_hardware_interface"], "ahrs_com_interface": ["*******************************************************************", " flush input buffer from remainder packets", " write getData command", " read data from serial port", " check data packet", " parse data packet", " write command to ahrs", " invert pitch reading to comply with pandora conventions", " namespace imu", " namespace pandora_hardware_interface"], "trax_ahrs_configuration_node": ["*******************************************************************", " configure device for ahrs mode (not compass mode)", " configure endianess of data in ahrs packet", " configure packet composition of ahrs", " configure ahrs for polling mode", " tell ahrs to save the configurations"], "imu_com_interface": ["*******************************************************************", " get whole packet", " timeout handling", " namespace imu", " namespace pandora_hardware_interface"], "serial_epos2_handler": ["*******************************************************************", "--<Load epos2 interface configs from parameter server>--", "-------------------------------------------------------", " ---<Initiate Communication with epos2 gateway >--- ", " sleep for a second", " ------------------------------------------------- ", " Initialize motor controller states {Enabled}", " Read current state of the Motors", " Calls the state handler to handle the states", " Set every epos2 controller at profileVelocityMode on startup", " Setting operation mode to velocity_mode", " DISABLE STATE", " ENABLE STATE", " QUICKSTOP STATE", " FAULTY STATE", " CANNOT COMMUNICATE", " Cannot communicate with epos2-Gateway", " UKNOWN STATE", " ----< Read velocity values from Epos2Gateway >---- ", " ------------------------------------------------- ", " ----< Read velocity values from Epos2Gateway >---- ", " ------------------------------------------------- ", " Define new array to store current values", " Fill with current values using getCurrent method", " Convert to Torques", " Step I :Convert Torques to currents", " Step II: Send commands to motors", " Activate Velocity Mode", " Activate Current Mode", " namespace motor", " namespace pandora_hardware_interface"], "epos2_test": ["*******************************************************************"], "epos_serial_gateway": ["*************************************************************************", " gateway is not initialized until we actually connect to the RS232 port", " initialize POSIX thread mutex, for use during read/write operations", " failed to connect to serial port", " we are connected, set object as initialized", " read a single character from the RS232 port", " check the number of characters that were actually read", " no characters read, timeout", " one character read, it's a NACK", " Should never happen, violates EPOS Communication Guide", " RS232 error", " 1 character read, equal to 'O' (ACK)", " ACK signal is a single character equal to 'O'", " Rs232 write method should return 0, if all went well", " Allright", " In order to debug the actual communication between the PC and the RS232 port", " you can define the DEBUG_EposRs232Gateway macro. This will enable debugging", " code that prints the communication to the standard output. This generates", " allot of output, and should be used only for debugging purposes. Having the", " printout of the communication is sometimes the only to way to debug since", " underlying synchronization issues exist (i.e. timeouts)", " #define DEBUG_EposRs232Gateway", " check to see if gateway is initialized", " cannot use the gateway if the object is not initialized first", " frame size must be a positive integer no greater than 255. This restriction", " is enforced by hardware, and protocol specifications", " *** input arguments are valid *** //", " *** Calculate CRC *** //", " CRC is calculated on the transmition data + the op code and the data length", " The op code and the data length are stuffed in a single EPOS word", " load the first word of the data input for the CRC method, opcode + length", " EPOS CRC calculation requires data to be Big-Endian (MSB first)", " get CRC", " Load the transmition buffer", " Frame data are sent LSB first", " Communication variables", " We are about to start transmiting data, lock the communication mutex", "  === State 1: Send opCode ===", "  === State 2: Wait for ACK ===", " === State 3: Send len-1 ===", " === State 4: Send data ===", " === State 5: Send CRC ===", " === State 6: Wait for ACK ===", " Command Sent Successfully", "  === State 7: Wait for responce opCode ===", " === State 8: Send ACK ===", " === State 9: Receive len-1 ===", " === State 10: Receive data ===", " === State 11: Receive CRC ===", " === State 12: Send ACK or NACK ===", " Append a zero-word to packet", " Calculate CRC using polyonym: x^16+x^12+x^5+x^0", " Initialize BitX to Bit15", " Copy next Data uint16_t to c", " Check if Bit15 of CRC is set", " CRC = CRC * 2", " CRC = CRC + 1, if BitX is set in c", " CRC = CRC XOR G(x), if carry is true", " Set BitX to next lower Bit, shifter = shifter/2", " namespace motor", " namespace pandora_hardware_interface"], "Utils": ["*******************************************************************", " file io streams", " string streams", " namespace motor", " namespace pandora_hardware_interface"], "serial_epos_handler": ["*************************************************************************", "--<Fix ST for values above 2^31>--", " Minus because of motor reverse direction torsion", "-------------------------------------------------", "-----<Read Right-Rear Motor velocity>-----", " Minus because of motor reverse direction torsion", "------------------------------------------", "-----<Read Left-Front Motor velocity>-----", "------------------------------------------", "-----<Read Left-Rear Motor velocity>------", "------------------------------------------", "", "---------------------------------------------------", "-----<Read Right-Rear Motor current>-----", "------------------------------------------", "-----<Read Left-Front Motor current>-----", "------------------------------------------", "-----<Read Left-Rear Motor current>------", "------------------------------------------", " Right motor rpm speed needs to be reversed because of its placement in the vehicle", " namespace motor", " namespace pandora_hardware_interface"], "abstract_epos_handler": ["*************************************************************************", " namespace motor", " namespace pandora_hardware_interface"], "error_codes_test": ["*******************************************************************", " Input", " Input"], "epos2_gateway": ["*******************************************************************", " TODO(klpanagi): --- Read number of Nodes from a yaml", " Deleting void pointer is undefined;", " delete comHandler_;", " =================<GATEWAY COMMUNICATION Methods>=====================", " #####################################################################", "--<Open Device Communication Port>--", " =======================<STATE MACHINE Methods>=======================", " #####################################################################", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " Will return error to serial_epos2_handler to handle.", " Command executed succesfully", " isEnabled => 1: Device Enabled, 0: Device NOT Enabled", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " ROS_FATAL(\"\\033[0m[Epos2-Gateway]: Received error {%d} on command \"", " \"execution -- isEnableState, nodeId=%d\",", " _errorCode, nodeId);", " Command executed succesfully", " Device is at Enabled State", " Device is NOT at Enabled State", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " Command executed succesfully", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " ROS_FATAL(\"\\033[0m[Epos2-Gateway]: Received error {%d} on command \"", " \"execution -- isDisableState, nodeId=%d\",", " _errorCode, nodeId);", " Command executed succesfully", " Device is at Disabled State", " Device is NOT at Disabled State", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " Command executed succesfully", " Device is at Fault State", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " Command executed succesfully", " Device is at \"QuickStop\" State", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " =======================PROFILE VELOCITY MODE Methods=================", " #####################################################################", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " input value for target velocity should be int32_t type according to", " the EPOS_COMMAND_LIBRARY but it aint -- BUG_REPORT", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " =======================CURRENT MODE Methods==========================", " #####################################################################", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve errorCode", " Will return error to serial_epos2_handler to handle.", " ======================MOTION INFO Methods============================", " #####################################################################", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " TODO(klpanagi): --- resolve error", " Will return error to serial_epos2_handler to handle.", " namespace motor", " namespace pandora_hardware_interface"], "motor_hardware_interface": ["*******************************************************************", " connect and register the joint state interface", " connect and register the joint velocity interface", " Add effortJointInterface!", " TODO(zisikons): CHANGE COMMAND_VECTOR", " Set motor control mode to velocity control mode", " Initiallize jointLimits", " TODO(gkouros): initialize softLimits_", " Register handle in joint limits interface", " We read the state and read/write the command", " Limits spec", " Soft limits spec.Not required in our implementation.", " to do or not to do ???", "--<Read motors actual velocity value from EPOS controllers>--", "-------------------------------------------------------------", "--<Read motors actual current value from EPOS controllers>---", "-------------------------------------------------------------", "--<Read motors actual torque value from EPOS controllers>---", "-------------------------------------------------------------", "--<Update local velocity, current, and position values>--", "---------------------------------------------------------", "--<Publish motors currents at the specific topic>--", "---------------------------------------------------", " why period needed ?", " Velocity Control Mode", " Probably add if else struct for controlling torque limits", " !!! IMPORTANT : Make sure that torque commands are given in the correct order", " namespace motor", " namespace pandora_hardware_interface"], "motor_hardware_interface_node": ["*******************************************************************"], "skid_steer_velocity_controller": ["*******************************************************************", " min(max(x, minVal), maxVal)", " Load parameters", " Get joint Handles from hw interface", " Physical properties", " Detect if running on simulation", " Measurements for linear velocity", " Measurements for angular velocity", " Get limits from measurement velocities", " Degree of polynoms", " Increase degree because the coefficients also include the constant of the polynom (a0 * x^0)", " Calculate coefficients", " We need (degree + 1) measurements to calculate the polynom, otherwise we set (y = 1.0 * x^1)", " Subscirbe to cmd_vel", " Update cmd_vel commands", " Compute wheels velocities", " namespace motor", " namespace pandora_hardware_interface"], "skid_steer_torque_controller": ["*******************************************************************", " Load Joints from HW Interface , load joint NAMES from YAML", " Get joint Handles from hw interface", " Subscirbe to cmd_vel", " Update command_struct_ with latest information", " namespace motor", " namespace pandora_hardware_interface"], "leddar_hardware_interface": ["*******************************************************************", " initialize serial communication", " connect and register leddar interface", " get the measurements from the serial interface object", " create leddar sensor handle", " register the handle on the leddar sensor interface", " register the leddar sensor interface", " namespace leddar", " namespace pandora_hardware_interface"], "leddar_hardware_interface_node": ["*******************************************************************"], "Leddar": [" *****************************************************************************", " Module..: SDK -- Software development kit for Leddar products. RS-485", "           demonstration program.", "", "/ \\file    Leddar.c", "/", "/ \\brief   Function definitions for the Leddar layer of the demo.", "/", " Copyright (c) 2013 LeddarTech Inc. All rights reserved.", " Information contained herein is or may be confidential and proprietary to", " LeddarTech inc. Prior to using any part of the software development kit", " accompanying this notice, you must accept and agree to be bound to the", " terms of the LeddarTech Inc. license agreement accompanying this file.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarConnect", "", "/ \\brief   Try to connect to a sensor on the given serial port.", "/", "/ \\param   aPortName  Name of serial port to open (e.g.: COM4 on Windows or", "/                     ttyUSB0 on Linux).", "/ \\param   aAddress   The Modbus address of the sensor to talk to.", "/", "/ \\return  LT_SUCCESS or any one of the LT error codes.", " *****************************************************************************", " Identify which of the Leddar sensor model we are talking", " to, to know features are available.", " Module", " Industrial sensor", " Eval kit", " Unrecognized device!", " *****************************************************************************", " Function: LeddarDisconnect", "", "/ \\brief   Disconnect. Has no effect if was not connected.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarConfigurationLevel", "", "/ \\brief   Property reader for the level of configurability of the", "/          currently connected sensor.", "/", "/ \\return  One of the LEDDAR_*_CONFIGURATION constants.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarGetResults", "", "/ \\brief   Use Leddar custom function 0x41 to retrieve the detections and", "/          other acquisition results.", "/          Note that due to the payload length limitation in Modbus, at", "/          most 48 detections can be returned (this maximum can be configured", "/          to a lower value).", "/", "/ \\param   aDetections  Pointer to array where detections will be written.", "/", "/ \\return  The number of detections retrieved. Will be a negative (error code)", "/          in case of problem.", " *****************************************************************************", " Get the extra info after the detections", " *****************************************************************************", " Function: LeddarGetTemperature", "", "/ \\brief   Return the current sensor internal temperature.", "/", "/ \\param   aValue  Pointer to a variable that on output will contain the", "/                  temperature in degree Celsius if no error.", "/", "/ \\return  LT_SUCCESS or any of the LT error codes.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarGetParameter", "", "/ \\brief   Generic configuration parameter read access function (for integer", "/          parameters).", "/", "/ \\param   aNo     Number of parameter to read (one of the LEDDAR_CONFIG_*", "/                  constants).", "/ \\param   aValue  Pointer to a variable that on output will contain the", "/                  value if LT_SUCCESS is returned.", "/", "/ \\return  LT_SUCCESS or any of the LT error codes.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarSetParameter", "", "/ \\brief   Generic configuration parameter write access function (for integer", "/          parameters).", "/", "/ \\param   aNo     Number of parameter to write (one of the LEDDAR_CONFIG_*", "/                  constants).", "/ \\param   aValue  The new value to set.", "/", "/ \\return  LT_SUCCESS or any of the LT error codes.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarGetThreshold", "", "/ \\brief   Get the current detection threshold offset.", "/", "/ \\param   aValue  Pointer to a variable that will contain the value on", "/                  output if LT_SUCCESS is returned.", "/", "/ \\return  LT_SUCCESS or any of the LT error codes.", " *****************************************************************************", " *****************************************************************************", " Function: LeddarSetThreshold", "", "/ \\brief   Set the current detection threshold offset.", "/", "/ \\param   aValue  New value to set.", "/", "/ \\return  LT_SUCCESS or any of the LT error codes.", " *****************************************************************************", " End of file Leddar.c"], "leddar_serial_interface_demo": ["*******************************************************************"], "OS": [" *****************************************************************************", " Module..: SDK -- Software development kit for Leddar products. RS-485", "           demonstration program.", "", "/ \\file    OS.c", "/", "/ \\brief   Function definitions for the OS dependant part of the demo.", "/", "/ You may have to modify this file if you use a non-standard operating", "/ system. Definitions provided are correct for Windows and Fedora Linux.", "/", " Copyright (c) 2013 LeddarTech Inc. All rights reserved.", " Information contained herein is or may be confidential and proprietary to", " LeddarTech inc. Prior to using any part of the software development kit", " accompanying this notice, you must accept and agree to be bound to the", " terms of the LeddarTech Inc. license agreement accompanying this file.", " *****************************************************************************", " *****************************************************************************", " Function: SetNonBlocking", "", "/ \\brief   Special helper function to implement the equivalent of _kbhit and", "/          _getch in Linux.", "/", "/ \\param   aState  If LT_FALSE, the terminal will be put in the state in", "/                  which it was at the start of the program which is", "/                  normally CANONICAL with ECHO. Otherwise the canonical and", "/                  echo mode will be disabled.", " *****************************************************************************", " LT_LINUX", " *****************************************************************************", " Function: KeyPressed", "", "/ \\brief   Verify if a key was pressed and is waiting in the buffer (used", "/          to check if the user has requested to stop when continuously", "/          displaying detections.", "/", "/ \\return  LT_TRUE or LT_FALSE.", " *****************************************************************************", " *****************************************************************************", " Function: GetKey", "", "/ \\brief   Returns the next character in the keyboard buffer without a need", "/          to press enter (used to navigate the menu).", "/", "/ \\return  The character (may have some special values for non printable", "/          keys).", " *****************************************************************************", " *****************************************************************************", " Function: OpenSerialPort", "", "/ \\brief   Open the serial port with the given name.", "/", "/ \\param   aPortName  Name of the device to open (must be valid for the", "/                     platform).", "/ \\param   aHandle    Pointer to variable that will receive the handle on", "/                     output.", "/", "/ \\return  LT_SUCCESS or LT_ERROR.", " *****************************************************************************", " The inter character timeout should be much shorter but it does not seem", " reliable when we put it lower.", " Must be false otherwise we have to call ClearCommError on every error.", " LT_WINDOWS", " 8 bits per char, ignore modem control lines, enable receiver.", " Enable parity checking on input", " So special output processing", " Raw mode", " None of the 4 modes provided by VMIN and VTIME correspond to", " what we need with Modbus, so we set 0 on both which gives", " immediate return on call to read whatever the availability", " of data.", " LT_LINUX", " *****************************************************************************", " Function: CloseSerialPort", "", "/ \\brief   Close the serial port for the given handle.", "/", "/ \\param   aHandle  Handle returned by OpenSerialPort.", " *****************************************************************************", " *****************************************************************************", " Function: WriteToSerialPort", "", "/ \\brief   Write data to the serial port.", "/", "/ \\param   aHandle  Handle returned by OpenSerialPort.", "/ \\param   aData    Pointer to data to write.", "/ \\param   aLength  Number of bytes from aData to write.", "/", "/ \\return  The number of bytes actually written or LT_ERROR.", " *****************************************************************************", " Discard any bytes that could have arrived unexpectedly.", " *****************************************************************************", " Function: ReadFromSerialPort", "", "/ \\brief   Read data from the serial port.", "/", "/ \\param   aHandle  Handle returned by OpenSerialPort.", "/ \\param   aData    Pointer to where to put the data read.", "/ \\param   aLength  Maximum number of bytes to read (number read may", "/                   actually be lower).", "/", "/ \\return  The number of bytes actually read or LT_ERROR.", " *****************************************************************************", " Wait for the first byte with a long timeout to let time for the sensor", " to process the command.", " In theory we want an inter-character timeout of 2 character but", " in practice setting a value too low is not reliable.", " Now read the data with a short inter-byte timeout.", " We end either when we have received the number of bytes or", " there is a too long interval between 2 bytes (indicating", " the end of the message).", " End of file OS.c"], "leddar_serial_interface": ["*******************************************************************", " namespace leddar", " namespace pandora_hardware_interface"], "leddar_usb_interface_demo": ["*******************************************************************", " create publisher to publish all the readings from the leddar", " create the msg to be published", " TODO(gKouros): reexamine", " TODO(gKouros): reexamine", " TODO(gKouros): reexamine", " If a live connection is active we need to ping it periodically.", " fill the msg with the detections", " publish the msg", " sleep for 0.5 seconds"], "leddar_usb_interface": ["*******************************************************************", " Spawn a worker thread that continuously reads the sensor", " spawn a worker thread that activates for receiving the measurements", " 1->gets called again, 0->gets called only once", " namespace leddar", " namespace pandora_hardware_interface"], "leddar_sensor_controller": ["*******************************************************************", " Get sensor names from interface", " Read publish rate from yaml", " Get sensor handles from interface", " Create publisher for each controller", " TODO set params of msg (angle_min, angle_max, angle_increment, ", " time_increment, scan_time, range_min, range_max) from yaml", "    controllerNodeHandle.getParam(\"time_increment\", temp_param); ", "    &realtimePublishers_[ii]->msg_.time_increment = (float)temp_param;", " resize last times published", " Initialize last time published", " Publish messages", " Fill leddar msg", " namespace leddar", " namespace pandora_hardware_interface"], "joint_states_wrapper": ["*******************************************************************", " namespace dynamixel", " namespace pandora_hardware_interface", " PANDORA_DYNAMIXEL_HARDWARE_INTERFACE_JOINT_STATES_WRAPPER_H"], "gio_gazebo_interface": ["*******************************************************************", " namespace", " Physical properties", " Number of elements", " The rate that each element gets updated", " Resizing vector according to num of elements", " Register each hardware_interface", " Load gazebo joints", " Load PID controllers and initialize/set the limits", " const ros::NodeHandle nh (modelNh_, robotnamespace_ + \"/gazebo_ros_control/pid_gains/\" + jointName_[i]);", " pidController_[i].init (nh);", " Load gazebo imu link", " CO2 sensors subscriber", " Range sensors subscriber", " Wheel joints", " Side joints", " Laser roll joint", " Laser pitch joint", " Kinect pitch joint", " Kinect yaw joint", " Linear actuaator joint", " Camera effector pan joint", " Camera effector tilt joint", " Connect and register the joint state interface", " Connect and register the joint interfaces", " Imu sensor", " Connect and register the imu sensor interface", " Imu RPY", " Connect and register the imu rpy interface", " CO2 sensors", " Connect and register the co2 sensor interface", " Electronics battery sensor", " Motors battery sensor", " Connect and register the battery interface", " Range sensors", " Connect and register the range sensor interface", " Read joint position", " Read joint velocity", " Read robot orientation for IMU", " Read robot rpy for IMU", " Read co2 sensors", " Read battery sensors", " immobilizeRobot (batteryName_[n], batteryVoltage_[n]);", " Read range sensors", " namespace pandora_gazebo_interface"], "pandora_wheel_physics_plugin": ["*******************************************************************", " Implementations ", " Load Parameters", " Load SDF Parameters", " Initiallize NodeHandle for Dynamic Reconfigure Namespace", " Set Up dynamic Reconfgure Server", " ############################ LOAD NAMESPACE (from sdf) ############################", " Load Namespace from sdf", " ######################### LEFT FRONT WHEEL #########################", " Load Link", " Load Surface Parameters", " ######################### LEFT REAR WHEEL #########################", " Load Link", " Load Surface Parameters", " ######################### RIGHT FRONT WHEEL #########################", " Load Link", " Load Surface Parameters", " ######################### RIGHT REAR WHEEL #########################", " Load Link", " Load Surface Parameters", " mu1", " mu2", " slip1", " slip2", " kp", " kd", " minDepth", " maxVel", " bounce", " bounceThreshold", " namespace gazebo"], "pandora_fdir_plugin": ["*******************************************************************", " Load Parameters", " Connect with world update Event", " Load SDF Parameters", " ############### LOAD NAMESPACE (from sdf) ############### ", " Load Namespace from sdf", " ############### LEFT REAR WHEEL ############### ", " ############### LEFT FRONT WHEEL ############### ", " ############### RIGHT REAR WHEEL ############### ", " ############### RIGHT FRONT WHEEL ###############", "_info", " Read Yaw", " Change fdir vector to ALL wheels:", " namespace gazebo"], "pandora_differential_plugin": ["*******************************************************************", " Register this plugin with the simulator", " Constructor", " Destructor", " Differential Dynamic Reconfigure", " Finalize the controller", " Save pointers", " ROS callback queue for processing subscription", " Initialize the variables used in the PID algorithm", " Make sure the ROS node for Gazebo has already been initialized", " Publish multi queue", " /\\brief Start a thread for the differential dynamic reconfigure node", " FIXME: Wait for the rest of the plugin to load", " Advertise services on the custom queue", " New Mechanism for Updating every World Cycle", " Listen to the update event. This event is broadcast every", " simulation iteration.", " TODO(gerom): Get the value directly from the joints.", " TODO(gerom): Test when callback is executed.", " Returns true always", " Initialize the forces to be set", " Calculate and normalize the positive angle difference", " Calculate the forces for each link", " TODO(gerom): Test if the force are applied with the correct sign.", " Set the forces to the wheel links", " TODO(gerom): Implement maximum side joint damping", "       and normalize side joint damping.", " Get the linear velocity of each link in the z axis in ( mm / sec )", " Initialize the downforces to be set", " Calculate the downforce for each link", " Set the downforces to the wheel links", " TODO(gerom): Implement integral clamping.", " Calculate the time between two engine iterations", " Calculate the proportional contribution to output", " Calculate the integral contribution to output", " Calculate the derivative error & update the previous error", " Calculate the derivative contribution to output", " Calculate the output", " Calculate the error of the loop ( target - state )", " double error = ( left_angle_abs - right_angle_abs );", " Normalize the error", " Initialize the force to be applied", " Calculate the force", " Apply the correction force at the base link", " Separate the sign and the value of the angles.", " Calculate the error", " Maximum hardcoded force to be applied", " Apply the correction forces at the side joints accordingly", " left_front_wheel_link_->AddRelativeForce(math::Vector3(0, 0, force_multiplier * (left_front_z - min_z)));", " left_rear_wheel_link_->AddRelativeForce(math::Vector3(0, 0, force_multiplier * (left_rear_z - min_z)));", " right_front_wheel_link_->AddRelativeForce(math::Vector3(0, 0, force_multiplier * (right_front_z - min_z)));", " right_rear_wheel_link_->AddRelativeForce(math::Vector3(0, 0, force_multiplier * (right_rear_z - min_z)));", " ROS_INFO(\"LEFT:%f\", left_front_wheel_link_->GetRelativeForce().z);", " ROS_ERROR(\"RIGHT:%f\", right_front_wheel_link_->GetRelativeForce().z);", " Get the angles in the current iteration of the engine", " Add PID controlled force at base link (marginally stable)", " GazeboRosDifferential::AddBaseCorrectionForce ( );", " Add hardcoded forces (semi-control, working - error not well defined)", " Add forces at z axis to overcome high side joint damping (virtual forces)", " GazeboRosDifferential::AddDownforces ( );", " Add forces at y / z axes (real forces, applied due to the differential)", " GazeboRosDifferential::AddDifferentialForces ( );", " Add forces to improve robot's behaviour (due to poorly simulated physics)", " GazeboRosDifferential::AddPhysicsForces ( );", " Publish joint states to be used in RViz", " namespace gazebo"], "pandora_microphone_plugin": ["*******************************************************************", " Load the controller", " load plugin", " Get then name of the parent sensor", " Get the world name.", " Make sure the ROS node for Gazebo has already been initialized", " resolve tf prefix", " set size of cloud message, starts at 0!! FIXME: not necessary", " this->cloud_msg_.points.clear();", " this->cloud_msg_.channels.clear();", " this->cloud_msg_.channels.push_back(sensor_msgs::ChannelFloat32());", " Custom Callback Queue", " sensor generation off by default", " start custom queue for laser", " Increment count", "//////////////////////////////////////////////////////////////////////////////", " Decrement count", " soundMsg_.header.stamp = ros::Time::now ( );", " soundMsg_.header.frame_id = this->frame_name_;", " sound is represented by blue", " soundMsg_.certainty = certainty;", " Sound detection condition", " namespace gazebo"], "pandora_co2_plugin": ["*******************************************************************", " Load the controller", " load plugin", " Get then name of the parent sensor", " Get the world name.", "  Probability of not intented namespace", " Make sure the ROS node for Gazebo has already been initialized", " resolve tf prefix", " set size of cloud message, starts at 0!! FIXME: not necessary", " this->cloud_msg_.points.clear();", " this->cloud_msg_.channels.clear();", " this->cloud_msg_.channels.push_back(sensor_msgs::ChannelFloat32());", " Custom Callback Queue", " sensor generation off by default", " start custom queue for laser", " Increment count", " Decrement count", " co2 is represented by green", " namespace gazebo"], "pandora_sonar_plugin": ["*******************************************************************", " Register this plugin with the simulator", " Constructor", " Destructor", " Finalize the controller / Custom Callback Queue", " Load the controller", " load plugin", " Get then name of the parent sensor", " Get the world name.", " Make sure the ROS node for Gazebo has already been initialized", " resolve tf prefix", " set size of cloud message, starts at 0!! FIXME: not necessary", " Custom Callback Queue", " sensor generation off by default", " start custom queue for laser", " Increment count", " Decrement count", " Update the controller", " Put laser data to the interface", " four corners indices", " four corner values + interpolated range", " set size of cloud message everytime!", " int r_size = rangeCount * verticalRangeCount;", " point scan from laser", " Add Frame Name", " interpolating in vertical direction", " fraction from min", " Interpolate the range readings from the rays in horizontal direction", " fraction from min", " indices of 4 corners", " range readings of 4 corners", " Range is linear interpolation if values are close,", " and min if they are very different", " Intensity is averaged", " get angles of ray to get xyz for point", " point scan from laser", " no noise if at max range", " pAngle is rotated by yAngle:", " pAngle is rotated by yAngle:", " only 1 channel", " Utility for adding noise", " using Box-Muller transform to generate two independent standard normally disbributed normal variables", " normalized uniform random variable", " normalized uniform random variable", " double Y = sqrt(-2.0 *::log(U)) * sin( 2.0*M_PI * V); // the other indep. normal variable", " we'll just use X", " scale to our mu and sigma", " custom callback queue thread", " namespace gazebo"], "pandora_thermal_plugin": ["*******************************************************************", " Load the controller", " load plugin", " Get then name of the parent sensor", " Get the world name.", " Make sure the ROS node for Gazebo has already been initialized", " resolve tf prefix", " set size of cloud message, starts at 0!! FIXME: not necessary", " this->cloud_msg_.points.clear();", " this->cloud_msg_.channels.clear();", " this->cloud_msg_.channels.push_back(sensor_msgs::ChannelFloat32());", " Custom Callback Queue", " sensor generation off by default", " start custom queue for laser", " Increment count", " Decrement count", " temperature is represented by red", " namespace gazebo"], "pandora_p3d_plugin": ["www.apache.org/licenses/LICENSE-2.0", "//////////////////////////////////////////////////////////////////////////////", " Constructor", "//////////////////////////////////////////////////////////////////////////////", " Destructor", " Finalize the controller", "//////////////////////////////////////////////////////////////////////////////", " Load the controller", " Get the world name.", " load parameters", " Make sure the ROS node for Gazebo has already been initialized", " publish multi queue", " resolve tf prefix", " initialize body", " if frameName specified is \"world\", \"/map\" or \"map\" report", " back inertial values in the gazebo world", " init reference frame state", " start custom queue for p3d", " New Mechanism for Updating every World Cycle", " Listen to the update event. This event is broadcast every", " simulation iteration.", "//////////////////////////////////////////////////////////////////////////////", " Update the controller", " rate control", " differentiate to get accelerations", " copy data into pose message", " get inertial Rates", " Get Pose/Orientation", " Apply Reference Frame", " convert to relative pose", " convert to relative rates", " Apply Constant Offsets", " apply xyz offsets and get position and rotation components", " apply rpy offsets", " compute accelerations (not used)", " Fill out messages", " pass euler angular rates", " fill in covariance matrix", "/ @todo: let user set separate linear and angular covariance values.", " publish to ros", " save last time stamp", "////////////////////////////////////////////////////////////////////////////", " Utility for adding noise", " using Box-Muller transform to generate two independent standard", " normally disbributed normal variables see wikipedia", " normalized uniform random variable", " normalized uniform random variable", " double Y = sqrt(-2.0 * ::log(U)) * sin(2.0*M_PI * V);", " there are 2 indep. vars, we'll just use X", " scale to our mu and sigma", "//////////////////////////////////////////////////////////////////////////////", " Put laser data to the interface", " namespace gazebo"], "pandora_imu_stabilizer_plugin": ["www.apache.org/licenses/LICENSE-2.0", " Register this plugin with the simulator", "//////////////////////////////////////////////////////////////////////////////", " Constructor", "//////////////////////////////////////////////////////////////////////////////", " Destructor", " Finalize the controller", "//////////////////////////////////////////////////////////////////////////////", " Load the controller", " save pointers", " ros callback queue for processing subscription", "//////////////////////////////////////////////////////////////////////////////", " Load the controller", " load parameters", " Make sure the ROS node for Gazebo has already been initialized", " publish multi queue", " assert that the body by link_name_ exists", " if topic name specified as empty, do not publish", " advertise services on the custom queue", " Initialize the controller", " this->initial_pose_ = this->link->GetPose();", " start custom queue for imu", " New Mechanism for Updating every World Cycle", " Listen to the update event. This event is broadcast every", " simulation iteration.", "//////////////////////////////////////////////////////////////////////////////", " returns true always, imu is always calibrated in sim", "//////////////////////////////////////////////////////////////////////////////", " Update the controller", " Get Pose/Orientation ///@todo: verify correctness", " apply xyz offsets and get position and rotation components", " apply rpy offsets", " get Rates", " differentiate to get accelerations", " copy data into pose message", " orientation quaternion", " uncomment this if we are reporting orientation in the local frame", " not the case for our imu definition", " // apply fixed orientation offsets of initial pose", " rot = this->initial_pose_.rot*rot;", " rot.Normalize();", " pass euler angular rates", " rotate into local frame", " @todo: deal with offsets!", " pass accelerations", " rotate into local frame", " @todo: deal with offsets!", " fill in covariance matrix", "/ @todo: let user set separate linear and angular covariance values.", "/ @todo: apply appropriate rotations from frame_pose", " publish to ros", " save last time stamp", " publish to ros", "////////////////////////////////////////////////////////////////////////////", " Utility for adding noise", " using Box-Muller transform to generate two independent standard", " normally disbributed normal variables see wikipedia", " normalized uniform random variable", " normalized uniform random variable", " double Y = sqrt(-2.0 * ::log(U)) * sin(2.0*M_PI * V);", " there are 2 indep. vars, we'll just use X", " scale to our mu and sigma", "//////////////////////////////////////////////////////////////////////////////", " Put laser data to the interface", " namespace gazebo"], "state_server": ["", "Create watchdog", "Subcriber and Publisher declaration", "! Wait 10 seconds for all nodes to start.", " Disable watchdog.", " The client sent a wrong request code and the server responds with an", " error code.", "First retrieve all nodes", "Disable watchdog"], "state_client": ["*******************************************************************", " ROS_INFO(\"[%s] Received new information from state server\", node_name_.c_str());", " namespace state_manager"], "state_client_nodelet": ["*******************************************************************", " ROS_INFO(\"[%s] Received new information from state server\", node_name_.c_str());", " namespace state_manager"], "state_changer": ["*******************************************************************", " namespace state_manager"], "dummy_handler": ["*******************************************************************", " ................", " namespace sensor_processor"], "dummy_preprocessor": ["*******************************************************************", " namespace sensor_processor"], "dummy_processor_node": ["*******************************************************************"], "dummy_postprocessor": ["*******************************************************************", " namespace sensor_processor"], "bag_player_for_tests": ["", "", "~ ros::Rate loop_rate(10);", "~ while(ros::ok() && !_playedBags){", "~ ros::spinOnce();", "~ loop_rate.sleep();", "~ }", ""], "customized_player": ["*******************************************************************", " PlayerOptions", " Player", " Open all the bag files", " Publish all messages in the bags", " Advertise all of our messages", " Set up our time_translator and publishers", " Call do-publish for each message", " If immediate specified, play immediately", " If skip_empty is specified, skip this region and shift.", "Keep pushing ourself out in 10-sec increments (avoids fancy math dealing with the end of time)", " don't actually need anything but the default, alternatively try this", "DWORD event_mode = ENABLE_WINDOW_INPUT | ENABLE_MOUSE_INPUT;", "if (! SetConsoleMode(input_handle, event_mode) )", "{", " std::cout << \"Failed to set the console mode.\" << std::endl;", " return;", "}", " set raw (unset canonical modes)", " i.e. min 1 char for blocking, 0 chars for non-blocking", " block if waiting for char", " namespace rosbag"], "map_loader": ["*******************************************************************", "", " The document loading process changed in yaml-cpp 0.5.", " dirname can modify what you pass it", " namespace map_loader"], "watchdog": [""], "watchdog_monitor": ["", "! WDT already exists", "! WDT does not exist"], "mutex_guard": [""], "standalone_mutex": [""], "remote_mutex": [""], "kinect_movement_filter": ["*******************************************************************", " namespace pandora_common"], "exploration_controller": ["*******************************************************************", " register preempt callback", " load max goal searches", " proporsional to number of frontiers?", " robot has that many seconds to reach a goal", " TODO(czalidis): it could be proportional to path's length", " start exploration server", " Check if given exploration_type is known to the explorer, if it's not abort", " Check if we hold a goal selector of the appropriate exploration_type, if", " we do not, then create one and insert it into the goal_selector_map_", " wait for move_base to set-up", " reset aborts from previous time, this shouldn't really happen", " while we didn't receive a preempt request", " if we can't find more frontiers and we have reached our goal we end the exploration", " Check for timeouts", " if the exploration_type is DEEP(coverage_exploration) and coverage_goal_selector_", " is not NULL, then we do coverage based exploration. To create the coverage", " goal_selector we have to set the param use_coverage to true.", " to current goal gemizetai me to stoxo pou tha vrei o goal selector", " If success is false that means we cant find more frontiers", " if succes is false, dld an den exei vrei stoxo, auksanoume ta goal searches", " wait a little", " we have a valid goal", " reset failures", " prepare a MoveBaseGoal", " send new goal to move_base", " cancel goals before?", " set selected goal to all goal selectors", " end of outer while", " goal should never be active at this point", " check if we are close to target", " TODO(czalidis): check for race condition", " Auto ousiastika klanei to navi gt den perimenei na tou pei an eftase, alla", " to apofasizei mono tou, omws den douleuei swsta gt otan ftanei to navi,", " o explorer perimenei na faei timeout gia na vgalei epomeno stoxo.", " something is wrong here", " goal_expired_count_ ++;", " if (goal_expired_count_ >= 5)", " goal_expired_count_ = 0;", " namespace pandora_explorer"], "exploration_controller_node": ["*******************************************************************"], "navfn_frontier_path_generator": ["*******************************************************************", " get planner's name", " check if planner plugin exists", " create planner, exception is throwed if plugin is not available", " calculate path for each frontier", " Here we will store the plan to", " check to what point we want to plan", " start pose, goal pose, plan filled by the planner", " TODO(dimkirt) isws edw kati den paei kala, an xrhsimopoiithei autos o generator", " to make plan epistrefei true an vrhke ena valid plan alliws false.", " store the calculated plan to frontier.path variable", " namespace pandora_explorer"], "navfn_service_frontier_path_generator": ["*******************************************************************", " service name will be loaded here from parameter server", " find service", " track start", " calculate path for each frontier", " check to what point we want to plan", " send a valid pose", " call service", " if max time alloted return", " namespace pandora_explorer"], "map_frontier_search": [" make sure map is consistent and locked for duration of search", " Sanity check that robot is inside costmap bounds before searching", " initialize flag arrays to keep track of visited and frontier cells", " initialize breadth first search", " find closest clear cell to start search", " iterate over 4-connected neighbourhood", " add to queue all free, unvisited cells, use descending search in case initialized on", " non-free cell", " check if cell is new frontier cell (unvisited, NO_INFORMATION, free neighbour)", " initialize frontier structure", " htan 1", " record initial contact point for frontier", " push initial gridcell onto queue", " cache reference position in world coords", " try adding cells in 8-connected neighborhood to frontier", " check if neighbour is a potential frontier cell", " mark cell as frontier", " update frontier size", " update frontier points", " update centroid of frontier", " determine frontier's distance from robot, going by closest gridcell to robot", " add to queue for breadth first search", " find midpoint of frontier", " output.size -> segfault", " average out frontier centroid", " keep track of creation time", "~     output.header.frame_id = \"map\";", " check that cell is unknown and not already marked as frontier", " frontier_flag[idx] = true means that this frontier has already marked as a valid frontier", " frontier cells should have at least one cell in 4-connected neighbourhood that is free", " namespace pandora_explorer"], "frontier_goal_selector": ["*******************************************************************", " setup exploration costmap", " setup marker publisher", " load path distance scale and straight scale", " load frontier size scale", " load frontier alignment scale", " load frontier alignment scale", " valid types: initial, middle, centroid", " visualize paths to all frontiers", " planner timeout duration;", " set-up map frontier search", " set-up navfn path generator", "frontier_path_generator_.reset( new NavfnFrontierPathGenerator(frontier_representation_,", "explore_costmap_ros_) );", " set-up cost functions, using the scales previously loaded", " set-up frontier list", " clear previous frontiers", " get robot pose", " iterate over all frontier searches and find new frontiers", " insert new frontiers to global list", " if no frontiers found return false", " sort frontier list so closer frontier are first", " sorting in respect with min_distance", " find paths to all frontiers", " run all cost functions", " visualize new frontiers", " find the best frontier", " correct final target orientation", " keep track of selected frontier", " set as goal the last point in plan", " search over all frontier to find max cost", " did not found a frontier with positive cost", " path at least of 10 points, otherwise unstable orientations calculated", " find orientation of last 2 points", " assign orientation to last point in path", " no point to run, if no one is listening", " find also best frontier", " visualize frontier as sphere", "marker.color.g = 0.0;", "marker.color.b = 0.0;", " visualize frontier cost as marker text", " visualize frontier size", " visualize path size", " visualize paths to all frontiers as line strip", "paths_marker.color.r = 0.0;", "paths_marker.color.b = 0.0;", " visualize frontier as a line", " update best frontier", " add best frontier as blue sphere", "marker.color.r = 0.0;", "marker.color.g = 0.0;", " \"a\" is by default \"0\" if you forget it marker will be invisble", " publish markers", " namespace pandora_explorer"], "distance_cost_function": ["*******************************************************************", " for the usage of M_E", " iterate over all frontiers and find max distance", " iterate over all frontiers", " if frontier has a already negative cost no point to run this cost function", " find path distance based on path", " frontier.path", " if no path found penalize frontier", " size of path shows \"straightness\" and lenght of the path, this has to be reviewed", " update frontier's cost", " namespace pandora_explorer"], "visited_cost_function": ["*******************************************************************", " iterate over all frontiers", " if frontier has a already negative cost no point to run this cost function", " how many times we have send a similar goal", " iterate over all previous goals", " find distance between selected_goal and frontier", " using initial point, maybe get from param later", "    std::cout << (1.0 - pow((1.0/freq), 1.0/5.0)) << std::endl;", "    std::cout << exp(-static_cast<double>(times_seen)) << std::endl;", " update cost", "    frontier.cost += scale_ * (1.0 - pow((1.0/freq), 1.0/5.0));", " namespace pandora_explorer"], "alignment_cost_function": ["*******************************************************************", " iterate over all frontiers", " if frontier has already negative cost no point to run this cost function", " select a point in path to find angle to", " if no valid plan to frontier, cost should already be negative", " and this function will never run", " this is done to calculate the true alignment to goal of the robot footprint", " find angle from robot to goal", " find shortest angle, result from -pi to pi", " update frontier's cost", " namespace pandora_explorer"], "size_cost_function": ["*******************************************************************", " for M_E usage", " iterate over all frontiers and find max distance", " iterate over all frontiers", " if frontier has a already negative cost no point to run this cost function", " update frontier's cost", " Cost are normalized, frontier with the highest size scores 1.", " namespace pandora_explorer"], "map_frontier_search_test": ["*******************************************************************", " Needed for ros::Time:now()", " create a new costmap2D 10x10", " Now pass the costmap created to mapFronterSearch ", " HELPER FUNCTIONS ", "", "", "", " MAP CREATORS ", "", " fill the first half of the map with zeros", "fill the second half with ones", "", " fill the first half of the map with zeros", "fill the second half with ones", "", " fill costmap with zeros", "", " fill costmap with 255", "", " fill costmap with 255", " put middle known point on costmap", "", " fill costmap with zeros", " put middle unknown point on costmap", " Accessors", " Given the coordinates returns the index", " Variables", "", " NORMAL CASE", "vector with 1 zero element", " NO_INFO SPACE CASE", " KNOWN CELL CASE", "**** CASES WERE ALL FRONTIERS ARE MARKED  *******", " NO_INFO SPACE CASE", " KNOWN CELL CASE", "", " Map creation", " origin of robot", " To build the frontier initial must be a cell with a neighbour in nhood8, who is frontier cell.", " mark reference", " mark initial cell", " fill col 5 with zeros", " robot pose", " To size genika vgainei oso einai +1, akomh ki an den xtistei frontier dinei size 1.", " initial frontier point", " centroid frontier point", " We can test the precision by looking the frontier", " tolerance of one cell", "EXPECT_NEAR();", "EXPECT_NEAR();", "EXPECT_EQ();", "EXPECT_EQ();", "", " Map creation", " To build the frontier initial must be a cell with a neighbour in nhood8, who is frontier cell.", "fillCostmapRow(4,0);", " robot pose", " To size genika vgainei oso einai +1, akomh ki an den xtistei frontier dinei size 1.", "", " Map creation", " To build the frontier initial must be a cell with a neighbour in nhood8, who is frontier cell.", "fillCostmapRow(4,0);", " robot pose", " To size genika vgainei oso einai +1, akomh ki an den xtistei frontier dinei size 1."], "costmap_tools_test": ["*******************************************************************", " create a new costmap2D 10x10", " create costmap2D, sizeX,sizeY,res,originX,originY", " Variables", " All possible cases of nhood4 and nhood8", " 4,4 is a centric point", " nhood returns a vector, so we check its size", " Create a list of edge points to check the nhoods", " Create a list of all corner points to check the nhoods", " Nearest Cell Function Tests ", " create a new costmap2D 10x10", " create costmap2D, sizeX,sizeY,res,originX,originY", " fill the first half of the map with zeros", "fill the second half with ones", " Prints the costmap ", " Prints the coordinates of the expected result and the real result ", " Variables", "  TODO more tests, for bfs accuracy.", " Case where the value we want is at the starting cell ", " result will hold the nearest cell with the value we want", " bfs is used to decide the nearest cell.", " Searches for value=1 starting from cell 95", " Checks if nearestCell bfs is working ", " Case where the cell is out off the map ", " Check if bfs works properly ", " mark the starting cell for visualization reasons", " namespace pandora_explorer"], "surface_checker": ["*******************************************************************", " Declare helper variables.", " For every direction in sensor's field of view, ray trace on 3d map.", " If it hits successfully find its corresponding coverage (metric) and", " save ray to surface coverage.", " coveredSurfacePtr_->updateInnerOccupancy();", " if surface coverage is to be taken as a binary quantity.", " else it is assumed that coverage is a percentage of the best view", " one can get at the wall.", " find for constant z = point.z, the normal vector on the line which", " results from intersection of the surface-wall (approx. a plane) with the", " plane z = point.z", " find the intersection of the plane [1] (\u03bbx, \u03bby, z) ~\u03bb,z with the plane which", " results from the far-most points on wall and on the plane [1]. This is going", " to be wall's normal vector.", " namespace pandora_sensor_coverage", " namespace pandora_exploration"], "sensor_coverage": ["*******************************************************************", "  initialize NodeHandle and Map.", "  Subscribe to 3d slam topic.", "  Subscribe to 2d slam topic.", " Server of flushing service", "  Set up occupancy grid 2d map occupancy threshold.", "  Set up maximum height of interest.", "  Set up footprint's width.", "  Set up footprint's height.", "  Set up orientation circle.", "  Set up maps' global static frame.", "  Set up robot's base frame name.", "  Get map's origin (can be either SLAM or TEST).", "  Get frames that will be tracked to produce their coverage patch maps.", "  For each frame make a Sensor object.", " namespace pandora_sensor_coverage", " namespace pandora_exploration"], "main": ["*******************************************************************"], "sensor": ["*******************************************************************", " nav_msgs::OccupancyGridPtr", " Sensor::", " getCoverage() const", " {", "   return spaceChecker_->getSpaceCoverage();", " }", " If sensor is not open and working, do not update coverage patch.", " DANGER ZONE dereferencing boost shr_ptr to share ptr", " If it does, fetch current transformation.", "  Update coverage perception.", "  Publish updated coverage perception.", " namespace pandora_sensor_coverage", " namespace pandora_exploration"], "utils": ["*******************************************************************", "", " namespace pandora_sensor_processing"], "coverage_checker": ["*******************************************************************", " namespace pandora_sensor_coverage", " namespace pandora_exploration"], "sensor_planner": ["*******************************************************************", "  initialize NodeHandle and Map.", "  Subscribe to Octomap topic.", "  Subscribe to Occupancy Grid topic."], "interactive_command_publisher_marker": [" create an interactive marker server on the topic namespace", " interactive_tf_publisher_marker", " get params from param server", " create an interactive marker for our server", " create a red sphere marker", " create a non-interactive control which contains the box", " add the control to the interactive marker", " create publishers", " create a control which will move the marker around x", " add the control to the interactive marker", " create a control which will move the marker around y", " add the control to the interactive marker", " create a control which will move the marker around z", " add the control to the interactive marker", " create a control which will rotate the marker around x", " add the control to the interactive marker", " create a control which will rotate the marker around y", " add the control to the interactive marker", " create a control which will rotate the marker around z", " add the control to the interactive marker", " add the interactive marker to our collection &", " tell the server to call processFeedback() when feedback arrives for it", " 'commit' changes and send to all clients", " namespace pandora_visualization"], "interactive_tf_publisher_marker": [" create an interactive marker server on the topic namespace", " interactive_tf_publisher_marker", " get params from param server", " initialize transform_", " create an interactive marker for our server", " create a red sphere marker", " create a non-interactive control which contains the box", " add the control to the interactive marker", " create a control which will move the marker around x", " create a control which will move the marker around y", " create a control which will move the marker around z", " create a control which will rotate the marker around x", " create a control which will rotate the marker around y", " create a control which will rotate the marker around z", " add the control to the interactive marker", " add the interactive marker to our collection &", " tell the server to call processFeedback() when feedback arrives for it", " 'commit' changes and send to all clients", " namespace pandora_visualization"], "temprature_visualization": ["FIXME: Receive from param                             ", "Grid-eye sensor limits", "TODO: Take temprature limits from dynamic reconfigure"], "data_fusion_object_visualization": ["!< Timers for visualization", "~ ros::Duration(15).sleep();"], "pandora_qr_csv_node": ["*******************************************************************"], "qr_csv_creator": ["*******************************************************************", "", "", "", " A blank line is needed.", " Body descripion.", " Sort QRs.", " Append QRs to the csv file.", " Sort Obstacles.", " Append Obstacles to the csv file.", " namespace pandora_qr_csv"], "server": ["*******************************************************************", "", "", "", "", "", "", "", "", "", "", "", "", "", "", "", " Save geotiff to the home directory.", " Reset the environment.", " namespace pandora_geotiff"], "creator": ["*******************************************************************", " Create a QApplication cause otherwise drawing text will crash.", " These parameters should be moved in a yaml file in a later version.", " These parameters are given theris real values in a different state.", " This function must only be called after geotiffMapIm is initialized!", " Draw (checkerboard) grid.", " Drawing the main length unit side.", " Drawing the length unit up side (1/12 of the checker size).", " Drawing the length unit down side (1/12 of the checker size).", " Draw the length unit point 1m.", " Drawing the lines.", " Drawing the Y arrow.", " Drawing The X arrow.", " Drawing Y.", " Drawing X.", " i,j MUST BE xsize and J must be y size if you want to swap y with x u must change a lot of things", " namespace pandora_geotiff"], "pandora_geotiff_node": ["*******************************************************************"], "utilities": ["*******************************************************************", " Create random poses with times in descending order.", " namespace pandora_geotiff"], "geotiff_creator_test": ["*******************************************************************", " Save to the home directory.", " namespace pandora_geotiff"], "ros_tf_listener": ["*******************************************************************", " namespace pandora_data_fusion_utils", " namespace pandora_data_fusion"], "utils_test": ["*******************************************************************", " namespace pandora_sensor_processing"], "pandora_alert_handler_node": ["*******************************************************************", " ros::MultiThreadedSpinner spinner(2); // Use 2 threads", " spinner.spin(); // spin"], "object_factory": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "alert_handler": ["*******************************************************************", "", " Alert-concerned Subscribers", " Map Subscriber", " Publishers", " Action Servers", " Service Servers", " Dynamic Reconfigure Server", " Timers", "  Other Callbacks  ", "/////////////////////////////////////////////////////", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "landoltc": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "motion": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "obstacle": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "visual_victim": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "qr": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "sound": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "co2": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "soft_obstacle": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "hard_obstacle": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "hole": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "hazmat": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim": ["*******************************************************************", "", "", "", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "barrel": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "data_matrix": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "filter_model": ["*******************************************************************", "", "!< System Model Initialization", "!< Filter's combined matrix", "!< Filter's system matrix A", "!< Filter's system matrix B", "!< Filter's system noise mean", "!< Filter's system noise covariance", "!< Measurement Model Initialization", "!< Filter's measurement matrix H", "!< Filter's measurement noise mean", "!< Filter's measurement noise covariance", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_clusterer": ["*******************************************************************", "", "", " if (currentObj->getType() != Sound::getObjectType() &&", "     currentObj->getType() != Co2::getObjectType())", "", "", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "object_handler": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_list": ["*******************************************************************", "", "", "", "", "", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "obstacle_list": ["*******************************************************************", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "object_list_test": ["*******************************************************************", " Constructor/Destructor ", " SetUp/TearDown definitions ", " Helper functions ", " Function to fill qrList.qrs_ ", "!< Spawns Qrs In a fixed radius Around the qrX", "!< Returns distance between 2 qrs.", " Accessors for private methods/members of QrList ", " Variables ", " It shouldn't find that Qr4 already exists.", " Qr4 won't correlate with Qr1 because dist equals DIST_THRES!", " It should find that qr5  exists in 2 places.", " It should find that qr6 exists only  in 1 place( same as qr 3).", " Changed distance must find Qr 6 in  3 places( qr1 qr2 qr3).", " Or it doesn't find it.", " Zero Distance Threshold makes impossible same Qr recognition.", " Maximum (Infinite) Distance Threshold makes impossible Qr distinction.", " Add (0.4,0.1,0)", " Add (0.5, 0, 0) Qr 3 will not be Added Same as Qr 9", " Add (0.125, 0.125, 0) Qr 8 will not be Added Same as Qr 9", " Add (0.6, 0.2, 0.1) Qr 10 will not be Added Same as Qr 9", " Add (0.6, 0.2, 0.1) Qr 10 will not be Added Same as Qr 9", " Add (0.125, 0.125, 0) Qr 9 will not be Added Same as Qr 9", " Add (0.125, 0.125, 0) Qr 8 will not be Added Same as Qr 9", " Add (0.125, 0.125, 0) Qr 9 will not be Added Same as Qr 9", " Qr  1(-0,5,0,0) Qr 4 (-1 ,0,0) Qr11 (-0.75 ,0, 0)", " This will spawn Qrs in the middle so both Qrs should became legit", " They should have moved closer to each other", " They should become Legit!", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "object_factory_test": ["*******************************************************************", " Constructor SetUp ", "!< Loading the Map and initializing Objectfactory with a", "!< very small orientation circle(The other Params are the same)", "!< Creating all the Different Alerts we will use", " Helper Functions ", "!< Creating 3 HoleAlerts two on Walls and one very High", " Creating 3 QrAlerts two on Walls and one very High", " Creating 3 HazmatAlerts two on Walls and one very High", " Creating 2 ThermalAlerts one on Wall and one very High", " variables ", " The tf that is used is created in mock object tfFinder", " With origin (5,5,0.3) and (roll.info.pitch.info.yaw)=(0,0,0)", " Test Cases ", "!<  A vector is returned although thermal will always be alone :(", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_clusterer_test": ["*******************************************************************", " Helper functions ", "!< We create manually Thermal1(0, 3.87, 4),", "!< Thermal2(1, 0, 2), Hole1(-1, 0, 2)", "!< We create manually Thermal1(2, 3, 4),", "!< Hole1(4, 3, 2), Hole2(0, 4, 2) with yaw=PI/4", "!< We create manually Thermal1(0, 3.87, 4), Thermal2(1, 0, 2), Hole1(-1, 0, 2)", " Accesing private functions ", " Accesing private variables ", " variables ", "!< Checks if construstors behave correctly.", " Thermal1(0, 3.87, 4), Thermal2(1, 0, 2), Hole1(-1, 0, 2)", " Thermal1(2, 3, 4), Hole1(4, 3, 2), Hole2(0, 4, 2)", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_test": ["*******************************************************************", "!< create the Objectvector1 and fill it with various objects", "!< Thermal1(2, 3, 4) Thermal2(4, 3, 2) Hole1(1, 2, 0)", "!< (yaw = 0) ApproachDist = 5", "!< create the Objectvector2 and fill it with various objects", "!< Thermal1(2, 3, 4) Hole1(4, 3, 2) Hole2(0, 4, 2)", "!< (yaw = PI/4) ApproachDist = 6", "!< create the Objectvector3 and fill it with various objects", "!< Thermal1(2, 3, 4) Hole1(4, 3, 2) Hole2(0, 4, 2)", "!< (yaw = PI/4) ApproachDist = 6", " Helper functions ", "!< Returns distance between 2 objects.", "!< We create manually Thermal1(2, 3, 4),", "!< Thermal2(4, 3, 2), Hole1(1, 2, 0)", "!< We create manually Thermal1(2, 3, 4),", "!< Hole1(4, 3, 2), Hole2(0, 4, 2) with yaw=PI/4", "!< We create manually thermal1(2, 3, 4) thermal2(4, 3, 2) thermal3(0, 4, 2)", "!< Yaw = PI/4", "!< We create manually thermal1(2, 3, 4) thermal2(4, 3, 2) thermal3(0, 4, 2)", "!< Yaw = PI/4", " Accessors to private functions ", " Accessors to private variables ", " Variables ", " There will be 2 objects left in victim1_. One Hole and one Thermal type.", " Hole objects are prefered over Thermal objects regarding representatives.", " victim1_'s Thermal object should be the thermalPtr1! thermalPtr1 had more confidence", " in its belief about position that thermalPtr2, so it was prefered during", " setObject()", " thermalPtr1 object should be updated so that its position is", " closer to thermalPtr2's", " There will be 2 objects left in victim1_. One Hole and one Thermal type.", " Hole objects are prefered over Thermal objects regarding representatives.", " victim1_'s Thermal object should be the thermalPtr1! thermalPtr1 had more confidence", " in its belief about position that thermalPtr2, so it was prefered during", " setObject()", " thermalPtr1 object should be updated so that its position is", " closer to thermalPtr2's", " Thermal1(2, 3, 4) Thermal2(4, 3, 2) Hole1(1, 2, 0)", " thermal1 is erased.", " hole1 is erased", " Thermal1(2, 3, 4) Hole1(4, 3, 2) Hole2(0, 4, 2)", " Erase hole1. Now thermal1 is the representative object.", " Erase the last object (thermal1).", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "objects_test": ["*******************************************************************", " Seting up all the different objects that will be used", " for our test cases. The distance between the points", " (0,0,0), (4,3,0) is 5.", "!< Check that initializeObjectFilter works as intended!", " Helper functions ", " Variables ", " TEST_F(ObjectsTest, updateWithZeroProbability)", " {", "   qr2_->setProbability(0);", "   qr2_->initializeObjectFilter();", "   float probabilityBefore = qr1_->getProbability();", "   float stdDevBefore = qr1_->getStdDevX();", "   geometry_msgs::Pose poseBefore = qr1_->getPose();", "   qr1_->update(qr2_);", "   EXPECT_FALSE(qr1_->getLegit());", "   EXPECT_LT(qr1_->getProbability(), probabilityBefore);", "   EXPECT_GT(qr1_->getStdDevX(), stdDevBefore);", "   EXPECT_LT(distance(qr1_->getPose(), poseBefore), 0.6);", " }", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "victim_list_test": ["*******************************************************************", " Helper functions ", "!< We fill the iteratorList_ specifically around victim2_.", "!< Thermal1(-1, 0, 0), Thermal2(1, 0, 0), Hole1(0 , 1, 0)", "!< Thermal1(2, 3, 0), Hole1(3, 3, 0), Hole2(2, 2.5, 0)", "!< Thermal1(2.7, 3, 0), Thermal2(3, 3, 0)", "!< Thermal1(3, 3, 0), Hole1(10, 3, 0)", " Accesors to private functions ", " Variables ", " Victim1 Thermal(1, 0, 0) Hole(0, 1, 0)", " Victim2 Thermal(2, 3, 0) Hole(3, 3, 0)", " Victim3 Thermal(3, 3, 0)", " Victim4 Thermal(3, 3, 0) Hole(10, 3, 0)", " victim 3 is the same as victim 2 (samePosition)", " VictimList2 has all 4 victims inside", " Victim3 will be removed", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "clusterer": ["*******************************************************************", "", " get current measurement time", "", "!< Implementation of 2-means clustering", "!< Choosing cluster according to datum euclidean distance from means.", " dist1 = Utils::getMahalanobisDistance(dataSet_.col(jj), mean1_, covariance1_);", " dist2 = Utils::getMahalanobisDistance(dataSet_.col(jj), mean2_, covariance2_);", "!< Tracking data in cluster which correspond to current measurement.", "!< Resizing cluster1_ by on column and appending qualified datum.", "!< Tracking data in cluster which correspond to current measurement.", "!< Resizing cluster2_ by on column and appending qualified datum.", "!< Calculate clusters' means and covariances and check for convergence.", "!< If converged then return success and find for each cluster", "!< current measurement's means. If there is no data in a cluster from", "!< current measurement, then this procedure is skipped.", "", "", "!< Choosing cluster according to datum euclidean distance from means.", "!< Resizing cluster1_ by on column and appending qualified datum.", "!< Resizing cluster2_ by on column and appending qualified datum.", " namespace pandora_sensor_processing"], "co2_processor": ["*******************************************************************", " spikeFound_ = false;", " spikeTime_ = 0;", "", " Measurement has no information because it has the same value with the ambience.", " namespace pandora_sensor_processing"], "co2_node": ["*******************************************************************"], "thermal_processor": ["*******************************************************************", "", "", " OK. Warmer cluster has a cell from current measurement.", " Considering cluster to be a valid alert!", " namespace pandora_sensor_processing"], "thermal_processor_test": ["*******************************************************************", " helper functions ", "", " accessors to private functions ", " accessors to private variables ", " variables ", " Unit Tests ", " Functional Tests ", " This is cool because raw measurement is to be qualified to an alert.", " This in not cool because image is not the same size as the other images", " of frame \"pur\"", " This is not cool because this image does not contain info that can make", " an alert.", " Failing or not qualifying images do not interfere with the processor.", " This image shall qualify to an alert.", " namespace pandora_sensor_processing"], "clusterer_test": ["*******************************************************************", "", " Helper Functions ", "", "", "", "", "", "", " Accessors to private variables ", " Accessors to private methods ", " Variables ", " Test Cases ", " namespace pandora_sensor_processing"], "pose_finder": ["*******************************************************************", " Absolute depth and depth difference are evaluated at", " pandora_vision_obstacle", " geometry_msgs::Point lowPoint = findAlertPosition(pointsYaw[3],", "     pointsPitch[3], tfTransform);", " geometry_msgs::Point rightPoint = findAlertPosition(pointsYaw[1],", "     pointsPitch[1], tfTransform);", " namespace pose_finder", " namespace pandora_data_fusion"], "pose_finder_test": ["*******************************************************************", "", " Accessors for private methods of PoseFinder ", " Methods ", "", "", " Variables ", " Expect default parameters", " Expect updated parameters", " Make a tfTransform [tf::Transform], check for various yaw [float]", " and pitches [float] for the expected geometry_msgs::Pose", " With given map [OccupancyGrid], make points [geometry_msgs::Point] and test", " their supposed positions on wall with various angles [float]", " Given the height [float] of the robot coord. frame origin, check for", " various distances from wall (distFromAlert) [float] and pitches [float]", " the corresponding alert height on wall", " EXPECT_THROW( calcHeight(1.04720, h, -1) , AlertException );", " EXPECT_THROW( calcHeight(0.52360, h, -1) , AlertException );", " EXPECT_THROW( calcHeight(-0.52360, h, -1) , AlertException );", " EXPECT_THROW( calcHeight(-0.26180, h, -1) , AlertException );", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Near corner (inside)", " Test if the returned normal vector on wall is right", " [geometry_msgs::Quaternion] with the given map [OccupancyGrid]", " and various frame points [geometry_msgs::Point] and alert points [geometry_msgs::Point]", " Near corner (outside)", " Given various vectors of points [std::vector<geometry_msgs::Point>] test if the", " largest distance between them id given by the two points", " [std::pair<geometry_msgs::Point, geometry_msgs::Point>] returned.", " namespace pandora_alert_handler", " namespace pandora_data_fusion"], "keypoint_transformer": ["*******************************************************************", " #1 Calculate yaw and pitch from origin camera frame towards the point we", " want to transform", " #2 Calculate position of the point we want to transform in the world", " #3 Calculate yaw and pitch from target camera frame towards the point we", " want to transform", " change this later", " #4 Calculate point on target camera frame on which we see the same object", " in the world", " namespace frame_matcher", " namespace pandora_data_fusion"], "view_pose_finder": ["*******************************************************************", " namespace frame_matcher", " namespace pandora_data_fusion"], "roi_transformer": ["*******************************************************************", " namespace frame_matcher", " namespace pandora_data_fusion"], "frame_matcher_node": ["*******************************************************************"], "frame_matcher": ["*******************************************************************", " loadPreProcessor<EnhancedImagePreProcessor>(\"~\");", " loadPostProcessor(\"~postprocessor\", postprocessor_type_);", " namespace frame_matcher", " namespace pandora_data_fusion"], "matcher_processor": ["*******************************************************************", "", "", " Set output correctly from input", " Give Roi rgb sensor image and points", " ROS_INFO(\"[%s] Map callback called\", this->getName().c_str());", " ROS_INFO(\"[%s] Target image callback called\", this->getName().c_str());", " namespace frame_matcher", " namespace pandora_data_fusion"], "enhanced_image_postprocessor": ["*******************************************************************", "", "", " namespace frame_matcher", " namespace pandora_data_fusion"], "candidate_hole_postprocessor": ["*******************************************************************", "", " namespace frame_matcher", " namespace pandora_data_fusion"], "enhanced_image_preprocessor": ["*******************************************************************", "", "", " namespace frame_matcher", " namespace pandora_data_fusion"]}, "code_comments_python": {"setup": ["!/usr/bin/env python"], "test_flow": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "test_move_end_effector_server": ["!/usr/bin/env python"], "test_effector_clients": ["!/usr/bin/env python", " Following three must be in accordance to client_dict", " Following three must be in accordance to client_dict", " Following three must be in accordance to client_dict"], "test_client_factory": ["!/usr/bin/env python"], "command_mapping_dict": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "client_factory": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "effector_clients": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "move_end_effector_server": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "move_eef_script": ["! /usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "topics": [" Action to delete a victim from the data fusion's registry.", " Action to validate a victim.", " Action to notify data fusion about the current target.", " Publishing QR notificatios from the data fusion's registry.", " Holds the score for the robocup competition.", " Keeps track of the covered area.", " Used by data fusion to publish the world model.", " Action to wait for validation from the operator.", " Used to reset the robot.", " Used to restart the robot.", " Close the agent's process", " Action to communicate with the navigation node.", " Subscriber on the navigation node.", " Possible arena types:", "   - Yellow         -> 0", "   - Orange         -> 1", "   - YellowAndBlack -> 2", "   - Red            -> 3", " Moves the robot.", " Action to change the global state.", " Monitors the number of clients registered in the State Manager.", " Stops the current task.", " Moves end effector to a point of interest."], "client_dict": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "client_list": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "end_effector_controller_node": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas"], "states": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Voulgarakis George", " class HeadOrientationState(SimpleActionState):", "     def __init__(self):", "         SimpleActionState.__init__(self, move_head_topic,", "                                    MoveSensorAction,", "                                    goal_cb=self.goal_cb,", "                                    outcomes=['succeeded',", "                                              'aborted',", "                                              'preempted'],", "                                    input_keys=['move_end_effector_msg'],", "                                    output_keys=['move_end_effector_msg'])", "     def goal_cb(self, userdata, goal):", "         goal = MoveSensorGoal()", "         goal.command = userdata.move_end_effector_msg.command", "         goal.point_of_interest = \\", "             userdata.move_end_effector_msg.point_of_interest", "         return goal", " class LinearActuatorState(SimpleActionState):", "     def __init__(self):", "         SimpleActionState.__init__(self, linear_actuator_topic,", "                                    MoveLinearActuatorAction,", "                                    goal_cb=self.goal_cb,", "                                    outcomes=['succeeded',", "                                              'aborted',", "                                              'preempted'],", "                                    input_keys=['move_end_effector_msg'],", "                                    output_keys=['move_end_effector_msg'])", " def goal_cb(self, userdata, goal):", "     goal = MoveLinearActuatorGoal()", "     goal.command = userdata.move_end_effector_msg.command", "     goal.point_of_interest = \\", "         userdata.move_end_effector_msg.point_of_interest", "     goal.center_point = userdata.move_end_effector_msg.center_point", "     return goal"], "mock_end_effector_planner": [" !/usr/bin/env python", " !/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "goal_maker": ["!/usr/bin/env python"], "action_servers": ["! /usr/bin/env python", " Messages", " Make a move.", " Send feedback"], "test_pandora_stabilizer_node": ["!/usr/bin/env python"], "move_kinect_script": ["! /usr/bin/env python"], "move_head_script": ["! /usr/bin/env python"], "move_linear_actuator_script": ["! /usr/bin/env python"], "motors_joyop": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2015, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Peppas Kostas", " Open the js0 device as if it were a file in read mode.", " Create an empty list to store read characters.", " Loop forever.", " For each character read from the /dev/input/js0 pipe...", " append the integer representation of the unicode character read to the msg list.", " If the length of the msg list is 8...", " Button event if 6th byte is 1", " Axis event if 6th byte is 2", " Axis 3", " Reset msg as an empty list.", "~ while not rospy.is_shutdown():"], "keyop": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2015, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: George Kouros", " kinect - xtion pan n' tilt mode key", " linear actuator mode key", " motors mode key", " pi-cam pan n' tilt mode key", " motors linear velocity", " motors angular velocity", " linear actuator vertical position", " xtion yaw", " xtion pitch", " picam yaw", " picam pitch", " initialize mode to motors mode", " motors velocity msg", " linear actuator msg", " xtion yaw msg", " xtion pitch msg", " picam yaw msg", " picam pitch msg", " ctr-c or q"], "joyop": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2015, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: George Kouros", " launch joystick node", " erase previous prints"], "dataset_utils": ["# -- Set and hold RlData directory path -- ##", "# ---------------------------------------- ##", "# ------------------- Usefull Path Definitions -------------------------- ##", "# ---------------------------------------------------------------------- ##", "#", "  Create symbolic link to repository", "", " Symlinc || directory allready exists", "#", "  Copies from local data dir to repo dir", "#"], "motion_reward": [" Cost_to_Reward function Parameters", " If total_cost > cost_threshold , then reward shall be negatives", " Clear Trajectories from trajectory node.", " # Reset Case:", " if clear:", "     self.trajectory_cost_node.clear_trajectories()", " Checks trajectory", " Goal Related"], "experiment": [" Keep latest agent's action until update", " State Change steps", " If SLAM failed , reduce loacal step so next callback is also final", " get informed about vehicle's current state", " get informed about last action's reward", " inform agent about last action's reward", " inform agent about vehicle's current state", " ask agent to decide what the current action will be", " ask agent to update its estimations about expected returns", " perform cmd command in the environment , using agent's last action", " Save Action Value Table"], "kinodynamic_control": ["!/usr/bin/env python", " Navigation Task", " Number of States : (read from params)", " Total number of states:", " Number of actions", " Action Value Table directory", " Action Value Table setup", " Declare ROS Service to store Action Value Table", " Set up task parameters:", " Agent set up", " Experiment set up", " Start print table thread", "thread.start_new_thread(self.print_table,())", " Terminate visualization thread", " Copy learned data to repo", " Spawn ROS node , create controller and spin!", " try:", "     # Spawn ROS node , create controller and spin!", "     rospy.init_node('kinodynamic_controller')", "     controller = KinodynamicController()", "     rospy.spin()", " except:", "     # Case when RL modules fails for some reason , reset velocity controller", "     # to nomral control mode (all parameters set to 1)", "     pub = rospy.Publisher(COMMAND_TOPIC, KinematicParameters, queue_size=1)", "", "     # Fill reset msg", "     params = KinematicParameters()", "     params.scale_left = 1", "     params.scale_right = 1", "     params.terrain_param = 1", "", "     pub.publish(params)", "     print \"RL module failed.Switching to controller-only mode\"", " try:", "     # Spawn ROS node , create controller and spin!", "     rospy.init_node('kinodynamic_controller')", "     controller = KinodynamicController()", "     rospy.spin()", " except:", "     # Case when RL modules fails for some reason , reset velocity controller", "     # to nomral control mode (all parameters set to 1)", "     pub = rospy.Publisher(COMMAND_TOPIC, KinematicParameters, queue_size=1)", "", "     # Fill reset msg", "     params = KinematicParameters()", "     params.scale_left = 1", "     params.scale_right = 1", "     params.terrain_param = 1", "", "     pub.publish(params)", "     print \"RL module failed.Switching to controller-only mode\""], "params": [" Reinforcement Learning Related:", " 1) States:", " i) Number of States", " ii) Limits of each state [format = (low,high)]", " input in rads", " input in rads", " in m/s", " in rad/s", " 2) Actions:", " i) Number of Actions", " ii) Action ranges", " 3) Agent", " default value = 0.29", " 4) Cost Function :", " 5) General:", " cmd_vel callbacks ,until agent learn", " 6) Store Results:"], "navigation_environment": [" Find x y yaw from Tranformation", " Initiallization of time for limiting actual_trajectory from SLAM", " Read trajecotry from SLAM /robot_trajecotry", " The list must be reversed , otherwise it will immedatelly break", "Stop if point time stamp < than last_time_stamp", "Tranformation from geometry_msgs.quaternion to numpy array", " transform quaternion to euler angles , using tf library", "for every point belonging in last trajectory , save needed information", " Case actual_path is empty (which means SLAM hasn't updated /robot_trajecotry yet)", " Form a new empty parameter message", " Scale left/right not used in this version", " Fill terrain parameter", " Terrain parameter (= agent's action)"], "navigation_task": [" Navigation Command related", " Parameters", " Discretization Parameters", " (list containing number of states to produce in each element of sensros list)", " Flags", " State Processing:", " 1) Read Info from environment", " Find current pose, return pitch, roll denormalized states", " 2) Trajectory Related:", " Get actual trajectory as resulted from last command", " Read Data:", " Set latest action's expected trajectory in motion reward object", " Construct current expected trajectory from current pose, velocity", " command and trajectory duration in time", " 3)Retruns:", " returns True so that callback can continue process", " Make a state vector of (roll,pitch, linear, angular)", " Discretization can be applied only to normalized values", " Map sub-states to a total state:", " Make a final action vector of (velocity command, params)", " Delegate interaction with environment to NavigationEnvironment", " Task Related", " Reward Related", " Adjust sensor limits:"], "utils": [" Input Data", " Case 1: Linear Movement (angular velocity  = 0)", " Distance to travel", " Step size", " Pick Points", " Calculate (x,y)", " Insert points list in an numpy matrix for tranformations", " Case 2: Linear + Angular Movement (works also on Linear = 0)", " Movement metrics", " Point Counter", " Pick Points:", " Calculate (x,y) based on polar coordinates", " Add new point to lists", " Insert points list in an numpy matrix for tranformations", " 1) Transform first point to (0,0)", " 2) If angular velocity is negative , then , reverse over x axis", " --------------------- Transformations ---------------------", " Rotate points around (0,0)", " 4) Transform to robot_origin", " 5) Output Form", " Ensure ,input pair is vectors of same dimension", " Rotation Matrix", " Multiply points with rotation matrix", " Transformation from [-1,1] to [0,2]", " Split a number into the integer and decimal", " Construct Coefficients vector:", " Possible actions must be at least 2", " Low Limit", " High Limit"], "goal_cost": [" Relative Reward mode:", " Absolute Rewards:   (BEWARE : requires retuning of cost_to_reward function)", "self._cost = find_distance(self.expected_pose, self.actual_pose)"], "fuse_cost_node": [" In current Implementation , cost is calculated only from child nodes", " self._inside_update_cost()", " self.process_cost()"], "mock_local_patcher": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Constructor", " Publisher to the HardLayer", " Copy data from slam map", " Fill origin orientation", " (roll, pitch, yaw), in rads", " initialize the map with NO_INFORMATION cells", " Set the patch", " Set the timestamp"], "static_patch": [" 10 Hz", " se rads", " (roll, pitch, yaw)", " Msg creation", " TODO Assure that slam doesnt clear the patch", "", " map_update_msg.info.origin.orientation.x = quat[0]", " map_update_msg.info.origin.orientation.y = quat[1]", " map_update_msg.info.origin.orientation.z = quat[2]", " map_update_msg.info.origin.orientation.w = quat[3]", "for i in range(0,map_update_msg.info.width * map_update_msg.info.height/2):", "  temp_array[i] = 0;", " Initialize the node "], "move_base": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "mock_data_fusion": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " 1Hz", " Do message stuff", " 0.9013425", " 0.5", " publish message", " obs = ObstacleInfo()", " obs.id = 2", " obs.obstaclePose.header.frame_id = \"map\"", " obs.timeFound = rospy.get_rostime()", " obs.obstaclePose.pose.position.x = 9", " obs.obstaclePose.pose.position.y = 9", " obs.obstaclePose.pose.position.z = 0", " obs.obstaclePose.pose.orientation.x = 0", " obs.obstaclePose.pose.orientation.y = 0", " obs.obstaclePose.pose.orientation.z = 0", " obs.obstaclePose.pose.orientation.w = 1", " obs.length = 1", " obs.width = 1", " obs.type = 2", " publish message"], "hard_obstacle_patcher": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "\tnotice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "\tcopyright notice, this list of conditions and the following", "\tdisclaimer in the documentation and/or other materials provided", "\twith the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "\tcontributors may be used to endorse or promote products derived", "\tfrom this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Publisher of the hard obstacle map", " Subscriber to the SLAM map", " initialize the map with NO_INFORMATION cells", " The initial patch center", " The new center is the position we get from the obstacle_msg", " Position is in meters, th in radians, we rotate clockwise so the", " angle th is negative", " PLUS the position of the slam map", " print str(dx)+\" \"+str(dy)", " Transformation (Rotation and Translation)", " Set the timestamp and publish the hard_map"], "tururu": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "\tnotice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "\tcopyright notice, this list of conditions and the following", "\tdisclaimer in the documentation and/or other materials provided", "\twith the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "\tcontributors may be used to endorse or promote products derived", "\tfrom this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Publisher of the hard obstacle map", " Subscriber to the SLAM map", " initialize the map with NO_INFORMATION cells", " The initial patch center", " The new center is the position we get from the obstacle_msg", " Position is in meters, th in radians, we rotate clockwise so the", " angle th is negative", " PLUS the position of the slam map", " print str(dx)+\" \"+str(dy)", " Transformation (Rotation and Translation)", " Set the timestamp and publish the hard_map"], "mock_params": [" The topic where the mock data_fusion posts the obstacles"], "obstacle_test": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Case where obstacle is not initialized", "obs = Obstacle()", " Case where obstacle is initialized", "obs_normal = Obstacle()", " Message Creation", " Obstacle creation"], "map_utils_test": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " [m]", " [m]", " [m]", " [m/cell]", " [cells]", " [cells]", " An array of 20 cells with values of 100", " Call the function", " [m]", " [m]", " [m]", " [m/cell]", " [cells]", " [cells]", " inits everything with zeros (0,0,0,0)", " inits everything with zeros (0,0,0,0)", " Normal Cases", " Case 1", " The old map is equal to the new because we don't have NO_INFOs", " Case 2", " The old map didn't change because we only have NO_INFOs", " Case 3", " The old map change only at the cells without NO_INFO", " Extreme Cases", " Empty list case", " Both lists empty case", " Lists with same meta data but different array size", " Lists are ok but width and height are different", " Width and height are the same but they are zero", " Maps not initialized", " Normal Cases", " Case 1", " The old map will always be equal to the new map", " Case 2", " The old map should change even though we have only NO_INFOs", " Case 3", " The old map change at every cell", " Extreme Cases", " Empty list case", " Both lists empty case", " Lists with same meta data but different array size", " Lists are ok but width and height are different", " Width and height are the same but they are zero", " Maps not initialized", " Used to test invalid quaternions", " Case where both maps are empty", " False because we have initialized quaternions", " Case where everything is not initialized except the quaternion", " Case where we have not valid quaternions in both maps", " Case where we have valid but different quaternions", " Case where we have different widths", " [cells]", " [cells]", " Case where we have different heights", " [cells]", " [cells]", " [cells]", " [cells]", " Case where we have different resolutions", " [cells]", " [cells]", " [cell/m]", " [cells]", " [cells]", " [cell/m]", " Case where we have different frame_id", " [cells]", " [cells]", " [cell/m]", " [cells]", " [cells]", " [cell/m]", " Case where all MapMetaData are the same", " [cells]", " [cells]", " [cell/m]", " [cells]", " [cells]", " [cell/m]", " We print the map in row major order", " Both maps are empty", " Only new map is empty", " Only old map is empty", " One of the two maps has zero resolution", " Normal case with no origin difference, just resizing"], "__init__": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "obstacle": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " We store only the data we use from the message", " This is the frame id of the pose that defines the obstacle patch", " Not the frame of the obstacle itself.", " It must be /map", " in radians", " in meters", " in meters", " if type equals 1 we have soft obstacle, if equals 2 we have hard obstacle", " Create the quaternion to pass it"], "map_utils": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " # # # Map Patcher Utilities  # # # # #", " initialize the map with NO_INFORMATION cells", " Save the old map", " Set the MetaData of the old map to the new map", " clear old map", " resize the old map", " Find x,y,yaw differences", " print str(x_diff) + \",\" + str(y_diff)", " Find old and new yaw to find yaw_diff", " This would never happen because we get the orientation from SLAM", " old_quat = [", "     oldMap.info.origin.orientation.x, oldMap.info.origin.orientation.y,", "     oldMap.info.origin.orientation.z, oldMap.info.origin.orientation.w", " ]", "", " (old_roll, old_pitch, old_yaw) = euler_from_quaternion(old_quat)", "", " new_quat = [", "     newMap.info.origin.orientation.x, newMap.info.origin.orientation.y,", "     newMap.info.origin.orientation.z, newMap.info.origin.orientation.w", " ]", " (new_roll, new_pitch, new_yaw) = euler_from_quaternion(new_quat)", "", " yaw_diff = new_yaw - old_yaw", "print \"Yaw diff: \" + str(yaw_diff)", " print \"xdiff:\" + str(x_diff) + \",\" + \"ydiff:\" + str(y_diff)", " print \"width old:\" + str(oldMap.info.width) + \",\" + \"height old:\" + str(", "     oldMap.info.height)", "", " print \"width new:\" + str(newMap.info.width) + \",\" + \"height new:\" + str(", "     newMap.info.height)", " Transform the old map to the new size", " for i in xrange(0, oldMap.info.width):", "     for j in xrange(0, oldMap.info.height):", "         # old x,y in meters", "         x = i * oldMap.info.resolution", "         y = j * oldMap.info.resolution", "", "         # new x,y in meters", "         xn = math.cos(yaw_diff) * x - math.sin(yaw_diff) * y - x_diff", "         yn = math.sin(yaw_diff) * x + math.cos(yaw_diff) * y - y_diff", "         #print \"x_diff: [\" + str(x_diff) + \"]\"", "         #print \"y_diff: [\" + str(y_diff) + \"]\"", "         # new x,y in cells", "         xn_cell = int(round((xn / res), 0))", "         yn_cell = int(round((yn / res), 0))", "", "         coords = xn_cell + yn_cell * i - 1", "         if (coords < 0) or (coords > new_size):", "             rospy.logerr(\"[Map Resizer] Error in resizing xn_cell: [%d] \\", "             yn_cell: [%d] coords: [%d] new_size[%d]\", xn_cell, yn_cell,", "                          coords, new_size)", "         else:", "             temp = temp_old_map[i + j * oldMap.info.width]", "             #print \"coords: \" + str(coords)", "             oldMap.data[coords] = temp", "             # Dilation ??", "", "             # Copy the MapMetaData of the new map", " Copy the header (problems with the stamp?)", " Check frame_id of incoming OGM", " Check resolution of incoming OGM", " Check width of incoming OGM", " Check height of incoming OGM", " Check if quaternion contains NaNs or Infs", " Check if quaternion contains only zeros (not valid)", " Check the origin of the OGM", " noqa", " Maybe check something about the time?", " If everything is OK we return True", " noqa", " noqa", " noqa", " noqa"], "map_patch_params": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " The topic of the map we take from SLAM", " The topic that sends the obstacle messages", " The topic where we post the new map with obstacle on it", " Unknown cost param"], "map_patch": ["! /usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " An occupancy grid to hold the hard obstacles", " Subscriber to SLAM to get the map info", " Subscriber to the obstacles posted by data_fusion", " Publisher to the HardLayer", " Init soft_obstacle map, using slam MapMetaDeta and set every cell to NO_INFO", " If obstacle list is empty then we just fill the map layer with no", " information and then we post it.", " If we have obstacles in the list we transform each object and publish the map", " If list is empty", " Set the timestamp", " Publish the map with NO_INFORMATION", " If obstacle list is not empty", " Set the patch, in meters to the bottom left corner, yaw in radians", " 1.57 rad = 90 deg, 0.785 rad = 45 deg", " Check if the obstacle is in the right map frame", " The initial patch center", " The new center is the position we get from the obstacle_msg", " Position is in meters, th in radians, we rotate clockwise so the", " angle th is negative", " PLUS the position of the slam map", " print str(dx)+\" \"+str(dy)", " Transformation (Rotation and Translation)", " Set the timestamp and publish the map_patch", " Check type of obstacle and quaternion", " noqa", " noqa", " TODO (dimkirts) Check if length and width are very big", " Create an obstacle from the message of the callback", " Search inside the list if we have an obstacle with the same id", " If we do, we delete it and then append the new version of this obstacle", " If we can't find a duplicate obstacle we append it"], "co2_widget": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Load UI and name the widget.", " Create the subcribers.", " Create and connect the timer.", " Connected slot to the timer in order to refresh."], "widget_info": ["!/usr/bin/env python", " Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "message_data_model": [" Software License Agreement (BSD License)", "", " Copyright (c) 2012, Willow Garage, Inc.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of Willow Garage, Inc. nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", " the column names must match the message attributes", " BEGIN Required implementations of QAbstractTableModel functions", "%d' % msg.id", " map severity enum to label", " implode topic names", " append row number to define strict order", " append row number to define strict order", " shortest string representation to compare stamps", " print(column, data, str(index.row()).zfill(len(str(len(self._messages)))))", " decorate message column with severity icon", " colorize severity label", " <font> tag enables word wrap by forcing rich text", "')", " END Required implementations of QAbstractTableModel functions", " never try to insert more message than the limit", " reduce model before insert", " insert newest messages"], "battery_widget": [" Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Load Ui and name the widget", " create the subcribers", " create and connect the timer", " Connected slot to the timer in order to refresh", " Method called when the Widget is terminated"], "pandora_gui": [" Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "console": [" Software License Agreement (BSD License)", "", " Copyright (c) 2012, Willow Garage, Inc.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of Willow Garage, Inc. nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", " Queue to store incoming data which get flushed periodically", " to the model.", " Required since QSortProxyModel can not handle a high insert rate."], "save_mission_client": ["!/usr/bin/env python"], "probability_info": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Create the subcribers.", " Create and connect the timer.", " Connected slot to the timer in order to refresh."], "rpc_client": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "console_widget": [" Software License Agreement (BSD License)", "", " Copyright (c) 2012, Willow Garage, Inc.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of Willow Garage, Inc. nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", " These are lists of Tuples = (,)", " self.exclude_group_box.close()", " self.highlight_group_box.close()", " Filter factory dictionary:", " index 0 is a label describing the widget, index 1 is the class that provides filtering logic", " index 2 is the widget that sets the data in the filter class,", " index 3 are the arguments for the widget class constructor", " list of TextBrowserDialogs to close when cleaning up", " This defaults the filters panel to start by taking 50% of the available space", " flattens the _highlight filters list and only adds the item if it doesn't already exist", " pack the new filter tuple onto the filter list", " place the widget in the proper location", " flattens the _exclude filters list and only adds the item if it doesn't already exist", " pack the new filter tuple onto the filter list", " place the widget in the proper location", " Test if the filter we are adding already exists if it does use the existing filter", " Test if the filter we are adding already exists if it does use the existing filter", " menutext entries turned into", " This processes the dynamic list entries (severity, node and topic)", " extract column header", " join wrapped lines", " ignore empty lines", " check for quotes and remove them", " ignore line without prefix if previous line was not wrapped", " remove wrapped line which is not continued on the next line", " add/append lines", " add line without quote prefix", " generate message for each row"], "sonars_widget": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Load UI and name the widget.", " Create the subcribers.", " Create and connect the timer.", " Connected slot to the timer in order to refresh."], "temp_widget": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Load Ui and name the widget.", " Create the subcribers.", " Create and connect the timer.", " Connected slot to the timer in order to refresh."], "standar_widget": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Load the UI", " Add Console in the 2,1 position of InternalGrid", " Use full ABSOLUTE path to the image, not relative", " ValidateVictimActionServer is used called when a victim is found", " Dynamic_reconfigure client is used to change the parameters", " self.dynamic_reconfigure_client =", " dynamic_reconfigure.client.Client(\"agent\")", " The SaveMissionClient is used to save the mission geotiff", " RPC client", " Subscribe the score the world_model_info and Info", " Connecting the radioButtons", " Connecting the Buttons", " Connecting the CheckBoxes", " In the beggining all the checkboxes are unchecked.", " The left panel is visible", " Resize at first", " Show the console options at first", " Refresh timer", " Refreshing the topics", " Enable the victim found Options if it is found", " Start the timer", " Bring up the agent.", " Stop the timer and The robot", " Shutdown the agent.", " The checkboxes slots.", " Method called when the Widget is terminated."], "main_widget": [" Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Widgetlists created for dynamic show", " Create and set the Layouts.", " Timers to refresh 1 sec.", " Add the extra widget if checked or remove if unckecked", " Add if not already added.", " Remove if not already removed."], "gui_state_client": [" Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "victim_found_server": ["!/usr/bin/env python", " Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Victim action found callback", " store  Info", " helper variables"], "rqt_gui": ["!/usr/bin/env python", " Software License Agreement", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "listener": ["!/usr/bin/env python", " in ROS, nodes are unique named. If two nodes with the same", " node are launched, the previous one is kicked off. The", " anonymous=True flag means that rospy will choose a unique", " name for our 'listener' node so that multiple listeners can", " run simultaenously.", " spin() simply keeps python from exiting until this node is stopped"], "victim_action_client": ["! /usr/bin/env python", " Creates the SimpleActionClient, passing the type of the action", " Waits until the action server has started up and started", " listening for goals.", " Create a random goal to send to the action server.", " Sends the goal to the action server.", " Waits for the server to finish performing the action.", " Prints out the result of executing the action"], "talker": ["!/usr/bin/env python"], "victim_propabilities": ["!/usr/bin/env python"], "pandora_rqt_gui": ["!/usr/bin/env python"], "accuracy_test": ["!/usr/bin/env python", " Read the next image."], "victim_benchmark_test": ["!/usr/bin/env python", " Wait for the alert to arrive.", " Set the processor block to notify the program that the processor", " answered", " Notify the program that an alert has been received.", " Initialize the node"], "random_dataset_creator": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Check that the file exists.", " Check that the file extension is appropriate.", " Read the annotations file.", " Ensure that the file was read successfully.", " Read file and save contents in a dictionary.", " Check that the path exists.", " Check that the file extension is appropriate.", " Open the annotations file.", " Save new annotations in file.", " Save new annotations in file.", " Create random sub-sets for positive and negative images.", " Create the new annotations dictionary.", " Set the auto completion scheme"], "check_annotations_file": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "transform_annotations_to_full_frame": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "benchmark_tests_automation": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Set the auto completion scheme", " Sleep for a while until the process is fully finished."], "rename_dataset": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "training_automation": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Set the auto completion scheme", " Sleep for a while until the process is fully finished."], "qrcode_benchmark_test": ["!/usr/bin/env python", " Initialize the node"], "barrel_benchmark_test": ["!/usr/bin/env python", " Initialize the node"], "rgb_to_enhanced": ["!/usr/bin/env python", " encoding: utf-8", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", "\"):"], "vision_benchmark_test_base": [" Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Read the next image.", " If the image was not read succesfully continue to the", " next file.", " If the tested algorithm is not Victim, there is no need to use", " depth and thermal images.", " Store the image.", " Read the next bag.", " If the bag was not read succesfully continue to the", " next file.", " Store the bag.", "\"):", "\"):", " Wait for the alert to arrive.", " Set the processor block to notify the program that the processor", " answered", " Notify the program that an alert has been received.", " Read Annotations for a Set of Images", " Create Helper Structures for Benchmarking", " Test Parameters and Variables", " Read Benchmark Parameters for a Set of Images", " Read Images Sequentially", " Publish image files sequentially and wait for an alert.", " Confirm the authenticity of the alert using the annotator", " groundtruth set.", " Estimate alert center point from message parameters", " Calculate the Benchmarking Results.", " Estimate Recall values for each set of", " (Distance, Horizontal Angle, Vertical Angle)"], "pkg.develspace.context.pc": [" generated from catkin/cmake/template/pkg.context.pc.in"], "pkg.installspace.context.pc": [" generated from catkin/cmake/template/pkg.context.pc.in"], "images_to_bag": ["!/usr/bin/python", " this package name"], "split_bag": ["!/usr/bin/python"], "landoltc_benchmark_test": ["!/usr/bin/env python"], "hazmat_benchmark_test": ["!/usr/bin/env python", " Initialize the node"], "hole_detector_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " tests the function of the hole detector package", " how many alert messages have been published", " how many alerts have been sent with the first message", " the coordinates of the first valid hole's keypoint", " the coordinates of the first valid hole's keypoint relative to the", " center of the image", " the hole's expected yaw", " the hole's expected pitch", " tests the function of the depth node", " how many alert messages have been published", " how many alerts have been sent with the first message", " make assertions about the first candidate hole", " the coordinates of the first valid hole's data", " are halved because of the wavelet analysis used", " The first hole's keypoint", " There should be equal number of elements in both vertices vectors", " The first hole's bounding box is itself bounded", " in a bounding box", " There should be equal number of elements in both outline vectors", " The minimum x coordinate of the bounding box's points", " The minimum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The first hole's outline is bounded by its bounding box", " make assertions about the second candidate hole", " the coordinates of the second valid hole's data", " are halved because of the wavelet analysis used", " The second hole's keypoint", " There should be equal number of elements in both vertices vectors", " The second hole's bounding box is itself bounded in a bounding box", " There should be equal number of elements in both outline vectors", " The minimum x coordinate of the bounding box's points", " The minimum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The first hole's outline is bounded by its bounding box", " tests the function of the rgb node", " how many alert messages have been published", " how many alerts have been sent with the first message", " make assertions about the first candidate hole", " the coordinates of the first valid hole's data", " are halved because of the wavelet analysis used", " The first hole's keypoint", " There should be equal number of elements in both vertices vectors", " The first hole's bounding box is itself bounded", " in a bounding box", " There should be equal number of elements in both outline vectors", " The minimum x coordinate of the bounding box's points", " The minimum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The first hole's outline is bounded by its bounding box", " make assertions about the second candidate hole", " the coordinates of the second valid hole's data", " are halved because of the wavelet analysis used", " The second hole's keypoint", " There should be equal number of elements in both vertices vectors", " The second hole's bounding box is itself bounded in a bounding box", " There should be equal number of elements in both outline vectors", " The minimum x coordinate of the bounding box's points", " The minimum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The maximum x coordinate of the bounding box's points", " The first hole's outline is bounded by its bounding box", " how many alert messages have been published", " how many alerts have been sent with the first message", " depth analysis is possible", " the first hole", " The first hole's keypoint", " There should be equal number of elements in both vertices vectors", " The first hole's bounding box is itself bounded", " in a bounding box"], "hole_benchmark_test": ["!/usr/bin/env python", " Initialize the node"], "rgb_depth_thermal_synchronizer": ["!/usr/bin/env python", "Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", " * Redistributions of source code must retain the above copyright", " notice, this list of conditions and the following disclaimer.", " * Redistributions in binary form must reproduce the above", " copyright notice, this list of conditions and the following", " disclaimer in the documentation and/or other materials provided", " with the distribution.", " * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", " contributors may be used to endorse or promote products derived", " from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Here the synchronized messages from kinect and flir are sent", " to the synchronizer node as one united message.", " Check if topic for synchronized message has been given properly if yes pass it to the variable", " Make topic's name absolute", "rospy.loginfo(\"[Rgbdt_synchronizer] is publishing to: %s\", synch_topic)", " Publisher of PointCloud2 and flirLeptonMsg messages", " Pack the message to be sent.", " Publish the message to the synchronizer node", " Check if topic for synchronized message has been given properly if yes pass it to the variable", " Make topic's name absolute", "rospy.loginfo(\"[Rgbdt_synchronizer] is publishing to: %s\", synch_topic)", " Publisher of PointCloud2 and flirLeptonMsg messages", " Pack the message to be sent.", " Publish the message to the synchronizer node", " Initialization of rgbdt_synchronizer node", " Check if kinect topic has been given properly if yes pass it to the variable", " Check if flir topic has been given properly if yes pass it to the variable", " Check in which mode Hole package is running", " Continue the process based on packages mode. If mode = true thermal", " included", " Subscribers of kinect and flir messages", " Synchronize kinect and flir topics"], "cpu_temperature_monitor": ["!/usr/bin/env python", " Hz", " read temperature", " find the number of thermal_zone dirs in /sys/class/thermal", "initialize temperature buffer", " initialize msg", " for each core", " remove oldest temperature in buffer of each core", " store temperature file path in filename", " append new temperature at end of buffer of each core", " calculate average of temperatures in the buffer of the core", " store average temperature of core in msg", " publish the message", " if (high temperature) enable beeper"], "battery_monitor": ["!/usr/bin/env python"], "state_indicator": ["!/usr/bin/env python"], "end": ["!/usr/bin/env python"], "init": ["!/usr/bin/env python", " If the end effector is not responsive the init", " task will loop forever. Using this decorator", " we limit the execution time of the task.", " Wrap your function and test the wrapper."], "sensor_hold": ["!/usr/bin/env python"], "identification": ["!/usr/bin/env python", " The mock should be called only once because the updated goal is", " within the acceptable limits"], "fusion_validation": ["!/usr/bin/env python"], "victim_deletion": ["!/usr/bin/env python"], "operator_validation": ["!/usr/bin/env python"], "exploration": ["!/usr/bin/env python", " This goal will move the agent to the end state.", " Long goals that will not affect the test.", " Only one thread should acquire the lock."], "fsm_framework": ["!/usr/bin/env python", " Define with list of dictionaries", " Define with list of lists", " First pass positional and keyword args directly to the callback", " Now wrap arguments in an EventData instance", " Should fail if auto transitions is off...", " Include initial state in loop", " Test user-determined sequence and trigger name", " Via init argument"], "utilities": ["!/usr/bin/env python", " Make sure the action clients are instantiated.", " Make sure the subscribers are instantiated.", " Make sure global state transition functios have been generated.", " Empty variables", " TODO Write test with full functionality"], "world_model": ["!/usr/bin/env python", " Set up testing mocks"], "navigator": ["!/usr/bin/env python", " Register the mock servers."], "effector": ["!/usr/bin/env python", " Register the mock servers."], "explorer": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "data_fusion": ["%d as %s.', victim_id, victim_status)", "%d', victim_id)", "%d, selected as the current target', victim_id)"], "gui": ["!/usr/bin/env python"], "mocks": ["!/usr/bin/env python", " Action Servers"], "agent_standalone": ["!/usr/bin/env python", " Start the agent."], "target": [" Reset the target's state.", "%d with probability %.2f', id, probability)", "%d is verified with %.2f',", "%d is identified with %.2f',"], "agent": [" Configuration folder", " Dispatcher for event based communication.", " SUBSCRIBERS.", " ACTION CLIENTS.", " State client", " General information.", " Victim information.", " Between-transition information.", " Utility Variables", " Expose client methods to class", "#####################################################", "                   UTILITIES                        #", "#####################################################", " Removing the implementation of the given state.", " Read the configuration file.", " Setting up the FSM", " Get all the states for the given strategy.", " Set up states tasks.", " Create the transition table.", " Sets up the initial state", "#####################################################", "               DISPATCHER'S CALLBACKS               #", "#####################################################", " This is a bug.", " Ensure that poi found is not called twice with the same target.", "%d.', self.target.info.id)", " The agent tries again.", " The agent changes state.", " The target is valid and the next state is hold_sensors.", " The target is not valid and we delete it.", "#####################################################", "               SUBSCRIBER'S CALLBACKS               #", "#####################################################", " Change to teleoperation", " Cancel all goals", " Kill the process", " If no targets are available there is nothing to do.", " Remember the available targets.", " Set a new target from the available ones.", " Check for invalid target acquisition.", "%d has been acquired.', idx)", " Update the current target.", "#####################################################", "                 AGENT'S ACTIONS                    #", "#####################################################", " Move base to the target.", " Point sensors to the target.", " Start timer to cancel all goals if the move base is unresponsive.", " Point sensors to the target.", "%s' % (target_id))", "#####################################################", "                  AGENT LOGIC                       #", "#####################################################", " Should never be called with empty targets.", " self.current_pose = self.explorer.pose_stamped.pose", "#####################################################", "               GLOBAL STATE TRANSITIONS             #", "#####################################################"], "config": [" Probability limit for a target to be verified as victim.", " Probability limit for a target to be identified as a potential victim.", " Time needed for the sensors to verify the current target.", " Time limit for a global state change.", " Number of MoveBase failures before the agent aborts the current goal.", " Time limit for the MoveBase to succeed at a given goal.", " Minimum radius to classify a pose as different from the current goal."], "msgs": ["! /usr/bin/env python"], "publishers": ["! /usr/bin/env python", " Messages"], "transition": [" Check if all the conditions are met.", " Starting the transition.", " First run all the before callbacks.", " Exit the current state and run the on_exit", " callback for the current state.", " Enter the next state.", " Run the on_enter callback for the next state.", " Finally run all the after callbacks.", " The transition completed."], "machine": [" Creates a `state` attribute in the context class", " holding the name of the current state of the machine.", " The `states` lists holds all the available State instances.", " Creates an is_`state` method in the context class for this state,", " checking whether the context class is in the `state`.", " Creates a on_enter_`state` and on_exit_`state` method for the", " context class.", " Add automatic transitions after all states have been created.", " Use the wildcard `*` to use all the available states as the source.", " need to listify for Python3"], "state": [" Holds all the callbacks for the enter event.", " Holds all the callbacks for the exit event."], "event": [" Encapsulating arguments from higher levels into an EventData object."], "agent_end_effector_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " does end effector test?", " does end effector park?", " is end effector tracking?", " is end effector scanning?", " does end effector track?", " does end effector track?", " does end effector track?", " is end effector scanning?"], "data_fusion_agent_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", "DataFusionAgentTest.disconnect()", "rospy.signal_shutdown(\"test_finished\")"], "agent_explorer_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "hole_data_fusion_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", "self.assertTrue(self.replied)"], "processing": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Nikolaos Tsipas", " 64 windows (~8 seconds)", " 16 windows (~2 second)", " similarity distance in radians (~30 degrees)", " excluding the last element which is the most recent"], "capture": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Nikolaos Tsipas"], "monitor": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Nikolaos Tsipas"], "record": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Author: Nikolaos Tsipas"], "transport_image_topics": ["!/usr/bin/env python", " System calls", " System calls as subprocesses", " Regular Expressions", "# @brief Execute a shell command as a subprocess", "  @param command Command to execute as subprocess", "  @return", "# @brief Execute a shell command as a subprocess -- Detatched", "  @param command Command to execute as a detatched subprocess", "  @return Bool True if command executed succesfully. False otherwhise", " Execute command", " On failed to execute command", " On success execution", "# @brief Extracts Topic-Name and Topic-Type from given publisher", "  @param publisher Publisher to extract info from", "  @return List. Containes 'name' and 'type' parameters", "# @brief TSearch for active publishers from a given node", "  @param node Node to search for publishers", "  @return Found publishers", "# @brief Tries to match a machine namespace from a given topic name", "  @return Returns True if RegExpr mathced with success.", "# @brief Checks for sensor_msgs/Image topic type", "  @param topic Topic to check for.", "  @return Bool. True on found. False otherwise", "# @brief Search for active nodes on remote machone", "  @param machine The machine nodes to search for.", "  @return Nodes found on remote machine", "# @brief Republish a topic using image_transport", "   Use this re republish nodes running on remote machine, on local machine.", "  @param in_topic Topic to transport (e.g Remote machine topic)", "  @param out_topic Transported topic (e.g Local machine topic)", "print cmd", " ----------------Initialize console args parser------------------------- #", " Parse console arguments.", " Did not set machine", "machine = \"rpi2\""], "state_manager_test": ["!/usr/bin/env python"], "state_client": ["!/usr/bin/env python", " Software License Agreement (BSD License)", "", " Copyright (c) 2014, P.A.N.D.O.R.A. Team.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Authors: Chris Zalidis <zalidis@gmail.com>", "          Konstantinos Sideris <siderisk@auth.gr>", " There is a bug with the server.", " There is a bug with the server."], "test_client": ["!/usr/bin/env python"], "sensor_processor_test": ["!/usr/bin/env python", " encoding: utf-8"], "dummy_node": ["!/usr/bin/env python"], "test_dummy_node": ["!/usr/bin/env python"], "mocksubscriber": ["~ rospy.loginfo('got data %s', data)"], "moxcomparators": ["~ self.recurseRepr(self.obj_,'')"], "messageInfoParser": ["'"], "generic_mock": ["!/usr/bin/env python", "~ construct a dictionary holding for each topic requested, a mock object ", "~ subscribing to it", "~ open a bag and register all the messages to the ", "~ mock object of the corresponding topic (if the topic is listed in the given)", "~ Tell the mock objects that we finished registering method calls and are now", "~ verifying", "~ Call the action that replays the bag. Here we use the same bag to check if everything works", "~ In real testing this should be replaced by waiting for the real code to produce output", "~ Nevertheless, the bag replay action could still be used for something else", "~ (maybe change to service??)", "~ Verify that the registered callbacks are called , i.e. all the messages in the ", "~ bag we opened were heard in this order"], "test_base": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "alert_delivery": ["!usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "integration_tester": ["!usr/bin/env python"], "parse_extra_files": ["!/usr/bin/env python", " relative to the dir of the 'extra_files.yml'", " if destination is absolute", " project source dir", " project devel dir", " try to compose something that makes sense", "print(arguments)"], "download_checkmd5": ["!/usr/bin/env python", " on first connection check server capabilities", " on resume verify that server understood range header and responded accordingly", " if no bytes have been received abort download", " when content length is unknown it is assumed that the download is complete", " or when enough data has been downloaded (> is especially a valid case)", " Create intermediate directories as necessary, #2970", " delete partially downloaded data"], "exploration_caller": ["! /usr/bin/env python", "if client.get_state() == actionlib.GoalStatus.ACTIVE:"], "objects_srv": ["!/usr/bin/env python", "rospy.Service('data_fusion_geotiff', GetGeotiff, send_objects)"], "save_csv": ["!/usr/bin/env python"], "subscriber_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " Benchmark new subscriber style..."], "mass_alert_publisher": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "alert_handler_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "alert_handler_static_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " The order had only holes in it!", " If measurement does not differ from the expected position, the updated", " expected position will not change.", " I expect that 3-4 alerts would bring the conviction high enough to be", " recognised as a victim, but no less.", " If the measurement differs the same way, then the updated expected position", " should draw closer to that measurement - towards the same direction.  That", " means that expected position's distance from the initial expected position", " should be greater as the different measurement insists.", " We consider that conviction of the object about its position is lot higher now.", " I assume that its expected position will be around position0.  So:", " The order had only holes in it!", " A measurement off will not throw away very much a stable object.", " That measurement off will throw away the object even less, if more", " stable measurements have occured.", " Filtering makes object resistant to gaussian noise!", "self.assertGreater(self.currentVictimList[0].probability, 0.9) #"], "co2_processor_test": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", ""], "frame_matcher_functional": ["!/usr/bin/env python", " Software License Agreement", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of P.A.N.D.O.R.A. Team nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", " # At least one message has been published by node", " self.assertTrue(self.repliedList[self.output_topic])", " # Only one message has been published by node", " print rospy.loginfo(self.messageList[self.output_topic])", " self.assertEqual(len(self.messageList[self.output_topic]), 1)", " message = self.messageList[self.output_topic][0]", " # Only one ROI has been included in output EnhancedImage", " self.assertEqual(len(message.regionsOfInterest), 1)", " annotation = self.annotations[\"frame0.png\"]", " expected_roi = rgb_to_enhanced.annotation_to_roi(annotation)", " actual_roi = message.regionsOfInterest[0]", " distance = utils.distance_keypoints(expected_roi.center, actual_roi.center)", " rospy.loginfo(\"Distance between centers is: \"+str(distance))", " self.assertLess(distance, 5)", " width_error = math.fabs(actual_roi.width - expected_roi.width)", " self.assertLess(width_error, 3)", " height_error = math.fabs(actual_roi.height - expected_roi.height)", " self.assertLess(height_error, 3)"]}}
,{"git_repo_name": "pr2_mechanism", "code_comments_file_names": ["joint", "pr2_gripper_transmission", "robot", "pr2_belt_transmission", "chain", "tree", "wrist_transmission", "simple_transmission", "joint_calibration_simulator", "test_joint_calibration_simulator", "test_chain", "test_wrist_transmission", "controller_diagnostics", "pr2_mechanism_diagnostics", "joint_diagnostics", "pub_mech_stats", "mech_diag_test", "setup", "controller_manager", "scheduler", "__init__", "pr2_controller_manager_interface", "test", "robot", "test_controller"], "md_file_names": ["README"], "md_contents": {"README": ["pr2_mechanism [![Build Status](https://travis-ci.org/pr2/pr2_mechanism.svg?branch=kinetic-devel)](https://travis-ci.org/pr2/pr2_mechanism)\n", "==========================================================================================================================================\n"]}, "code_comments_c++": {"joint": ["*******************************************************************", " for std::numeric_limits", " limit the commanded effort based on position, velocity and effort limits", " only enforce joints that specify joint limits and safety code", " enforce position bounds on rotary and prismatic joints that are calibrated", " Computes the velocity bounds based on the absolute limit and the", " proximity to the joint limit.", " Computes the effort bounds based on the velocity and effort bounds."], "pr2_gripper_transmission": [" set robot actuator enabled", " look for joint_names_ in robot", " init successful", "myfile.open(\"transmission_data.txt\");", " get the mechanical reduction", " get the screw drive reduction", " get the gear_ratio", " get the theta0 coefficient", " get the phi0 coefficient", " get the t0 coefficient", " get the L0 coefficient", " get the h coefficient", " get the a coefficient", " get the b coefficient", " get the r coefficient", " Print all coefficients", " Get passive joint informations", " add joint name to list", " Get screw joint informations", " get the thread pitch", " get any additional joint introduced from this screw joint implementation", " for the gripper, this is due to the limitation that screw constraint", " requires axis of rotation to be aligned with line between CG's of the two", " connected bodies.  For this reason, an additional slider joint was introduced", " thus, requiring joint state to be published for motion planning packages", " and that's why we're here.", " assuming simulated gripper prismatic joint exists, use it", "/////////////////////////////////////////////////////////", "/ given actuator states (motor revolustion, joint torques), compute gap properties.", "", " below transforms from encoder value to gap size, based on 090224_link_data.xls provided by Functions Engineering", "", " limit theta", "theta = theta > 0 ? theta : 0;", " force theta to be greater than theta0_", "theta = angles::normalize_angle_positive(angles::shortest_angular_distance(theta0_,theta))+theta0_;", "", " compute jacobians based on transforms, get the velocity of the gripper gap size based on encoder velocity", "", " for jacobian, we want to limit MR >= 0", " then recompute u and theta based on restricted MR", "", "LIMIT: CAP u at TOL artificially", " d(arg)/d(MR)", " derivative of acos", "", " get the effort at the gripper gap based on torque at the motor", " gap effort = motor torque         * dmotor_theta/dt", "            = MT                   * dmotor_theta_dt", "            = MT                   * dMR_dt          / (2*pi)", "            = MT                   / dt_dMR          * 2*pi", "", "ROS_WARN(\"debug: %f %f %f\",gap_effort,MT,dt_dMR,RAD2MR);", "/////////////////////////////////////////////////////////", "/ inverse of computeGapStates()", "/ need theta as input", "/ computes MR, dMR_dtheta, dtheta_dt, dMR_dt", " get theta for jacobian calculation", " compute inverse transform for the gap joint, returns MR and dMR_dtheta", "/////////////////////////////////////////////////////////", "/ inverse of computeGapStates()", "/ need theta as input", "/ computes MR, dMR_dtheta, dtheta_dt, dMR_dt", " limit theta", "theta = theta > 0 ? theta : 0;", " force theta to be greater than theta0_", "theta = angles::normalize_angle_positive(angles::shortest_angular_distance(theta0_,theta))+theta0_;", " now do the reverse transform", " compute gap_size from theta", " in mm", " compute inverse jacobians for the transform", " for this, enforce dMR_dtheta >= 0", " since there are two roots, take the positive root", " @todo: this affects sim only, need to check this for sim.", "LIMIT: CAP arg2 at TOL artificially", " derivative of asin", " remember, here, t is gap_size", "/////////////////////////////////////////////////////////", "/ assign joint position, velocity, effort from actuator state", "/ all passive joints are assigned by single actuator state through mimic?", " js has passive joints and 1 gap joint and 1 screw joint", "/ \\brief motor revolutions = encoder value * gap_mechanical_reduction_ * RAD2MR", "/        motor revolutions =      motor angle(rad)                     / (2*pi)", "/                          =      theta                                / (2*pi)", "/ \\brief motor revolustions per second = motor angle rate (rad per second) / (2*pi)", "/", "/  old MT definition - obsolete", "/", "/        but we convert it to Nm*(MR/rad)", "/        motor torque = actuator_state->last_meausured_effort", "/        motor torque = I * theta_ddot", "/        MT           = I * MR_ddot  (my definition)", "/                     = I * theta_ddot / (2*pi)", "/                     = motot torque   / (2*pi)", "double MT        = as[0]->state_.last_measured_effort_ / gap_mechanical_reduction_ * RAD2MR ;", "/ \\brief gripper motor torque: received from hardware side in newton-meters", "/ internal theta state, gripper closed it is theta0_.  same as finger joint angles + theta0_.", "/ information on the fictitious joint: gap_joint", " compute gap position, velocity, measured_effort from actuator states", " Determines the state of the gap joint.", " function engineering's transmission give half the total gripper size", "ROS_ERROR(\"prop pos eff=%f\",js[0]->measured_effort_);", " Determines the states of the passive joints.", " we need to do this for each finger, in simulation, each finger has it's state filled out", " screw joint state is not important to us, fill with zeros", " treat passive simulation joints as \"calibrated\"", " screw joint state is not important to us, fill with zeros", " treat passive simulation joints as \"calibrated\"", " this is needed for simulation, so we can recover encoder value given joint angles", " keep the simulation stable by using the minimum rate joint to compute gripper gap rate", " new gripper model has an actual physical slider joint in simulation", " use the new slider joint for determining gipper position, so forward/backward are consistent", " js position should be normalized", " compute inverse transform for the gap joint, returns MR and dMR_dtheta", "ROS_ERROR(\"prop pos back eff=%f\",gap_effort);", "/ should be exact inverse of propagatePosition() call", "/ state velocity                  = MR_dot                    * gap_mechanical_reduction_ / rad2mr", "/                                 = theta_dot    * dMR_dtheta * gap_mechanical_reduction_ / rad2mr", "/ motor torque                    = inverse of getting gap effort from motor torque", "/                                 = gap_effort * dt_dMR / (2*pi)  * gap_mechanical_reduction_", "/                                 = gap_effort / dMR_dt * RAD2MR * gap_mechanical_reduction_", " Update the timing (making sure it's initialized).", " Set the time stamp to zero (it is measured relative to the start time).", " Try to set the start time.  Only then do we claim initialized.", " Measure the time stamp relative to the start time.", " Set the historical (double) timestamp accordingly.", " simulate calibration sensors by filling out actuator states", "", " in hardware, the position of passive joints are set by propagatePosition, so they should be identical and", " the inverse transform should be consistent.", " note for simulation:", "   new gripper model has an actual physical slider joint in simulation", "   use the new slider joint for determining gipper position, so forward/backward are consistent", " js position should be normalized", " now do the reverse transform", " compute inverse transform for the gap joint, returns MR and dMR_dtheta", "/ Newtons", "ROS_ERROR(\"prop eff eff=%f\",gap_effort);", "/ actuator commanded effort = gap_dffort / dMR_dt / (2*pi)  * gap_mechanical_reduction_", "", " below transforms from encoder value to gap size, based on 090224_link_data.xls provided by Functions Engineering", "", "/ \\brief taken from propagatePosition()", "/ internal theta state, gripper closed it is theta0_.  same as finger joint angles + theta0_.", "/ information on the fictitious joint: gap_joint", " compute gap position, velocity, measured_effort from actuator states", " propagate fictitious joint effort backwards", " ROS_ERROR(\"prop eff back eff=%f\",js[0]->commanded_effort_);", " set screw joint effort if simulated"], "robot": ["*******************************************************************", " Author: Wim Meeussen ", " create fake hardware interface with an actuator", " read robot description from parameter server", " Initialize controller manager from robot description"], "pr2_belt_transmission": ["*******************************************************************", " Initializes the filters", " Initialize the backward transmission state variables.", " Initializes the filters", " Initialize the backward transmission state variables.", " These are not the actual \"motor\" positions.  They are the", " theoretical joint positions if there were no belt involved.", " Get the motor position, velocity, measured force.  Note we do not", " filter the motor velocity, because we want the least lag for the", " motor damping feedback.  We will filter the joint velocity.", " Estimate the actual joint position and velocity.  We use two", " distinct methods (each with their own pros/cons and combine).", " Method 1: Twice filter the motor position at the resonance mode", " of the joint against the transmission and locked motor.  This", " duplicates the mechanical filtering occuring in the", " transmission.  Obviously, this is an approximation.  In", " particular the resonance frequency is unknown (we have to assume", " that lambda_joint_ over-estimates it).  Also, this doesn't", " account for steady-state forces, i.e. transmission stretch.  So", " the method is better at higher frequencies.  For numerical", " stability, upper bound the bandwidth by 2/dt.", " Method 2: Estimate the transmission deflection explicitly.  This", " uses only the transmission stiffness (compliance) and motor mass.", " The later is combined with the compliance to give a transmission", " time constant (tau).  This method assumes the motor mass is much", " smaller than the joint mass and the resonance of the motor", " against the transmission is damped.  It does NOT need to know the", " joint/link mass (i.e. is independent of joint configurations) and", " adds the appropriate DC transmission stretch.  However, it", " assumes zero motor friction to ground and no Coulomb fiction.", " Also, it uses the encoder directly at high frequency, remaining", " noisy.  For numerical stability, if the time constant is zero,", " implement a 0th order system.  Else lower bound the time constant", " by dt/2.", " Combine the two joint position estimates and calculate the", " velocity: High pass method 1, low pass method 2.  In the end, the", " encoder and measured force are both filtered at least once before", " reaching the joint estimate.  I.e. the velocity is smooth.  For", " numerical stability, upper bound the combination bandwidth.  If", " the bandwidth is zero, take just method 1.", " Push the joint info out.", " Stores values used by propogateEffort", " Saves the current values for use in the next servo cycle.  These", " are used to filter the signals", " Calculate the damping force for the motor vibrations against the", " transmission.  As we don't have a true vibration measurement,", " dampen the motor simply at high frequency.  For numerical", " stability, upper bound the cutoff bandwidth.  If the bandwidth is", " zero, use damping over all frequencies, i.e. regular damping.", " Add to the joint force.", " Send out!", " The backward transmission is a entirely separate entity for the", " forward transmission.  Both contain state information, that is NOT", " shared.  In particular, the backward transmission implements a", " 4th-order model of the motor mass, belt stiffness, and joint mass,", " which is what the forward transmission expects.  It should be used", " ONLY in Gazebo, i.e. when simulating the robot.  As such, we assume", " here that a cycle starts with a given actuator effort,", " propagateEffortBackwards() is called first (setting the time step) to", " set the joint effort, Gazebo then calculates a new joint position,", " and propagatePositionBackwards() is called last to provide the new", " actuator position.", " Check the arguments.  This acts only on a single actuator/joint.", " We are simulating a motor-mass / belt-spring-damper / joint-mass", " system.  Note all calculations are done if joint-space units, so", " that the motor position/velocity/acceleration/force are scaled", " appropriately by the mechanical reduction.  Also note, the joint", " mass is actually simulated in Gazebo, so for the purposes of this", " belt simulation, we assume an infinite joint mass and hence zero", " joint acceleration.  Finally, we assume the belt-spring/motor-mass", " dynamics are critically damped and set the damping accordingly.", " Calculate the time step.  Should be the same as the forward", " transmission, but we don't want/need to assume that.  Furthermore,", " given this is used only to simulate a transmission, the time-steps", " should be perfectly constant and known in advance.  But to keep", " this clean we recalculate.  The question remains who defines the", " time step.  Like the forward transmission, we can only use the time", " step in the actuator state, though this makes little sense here...", " Get the actuator force acting on the motor mass, multipled by the", " mechanical reduction to be in joint-space units.  Note we are", " assuming the command is perfectly executed, i.e. will completely", " act on the motor.", " If the transmission compliance is zero (infinitely stiff) or the", " motor mass is zero (infinitely light), then the transmission time", " constant is also zero (infinitely fast) and the entire transmission", " collapses to a regular rigid connection.", " Immediately propagate the motor force to the spring, ignoring", " the (infinitely fast) model dynamics.", " Update the model.  Note for numerical stability, the", " transmission dynamics need to be slower than the integration", " time step.  Specifically we need to lower bound the tranmission", " time constant by dt/2.", " Calculate the new motor position/velocity assuming a new motor", " acceleration of zero (simply integrate the last information).", " Calculate the new joint position/velocity assuming a new joint", " acceleration of zero, equivalent to an extremely large joint", " mass (relatively to the motor).  This is also \"fixed\" in the", " second half of the backward transmission after the simulator", " has provided a new joint position/velocity.", " Calculate the spring force between the two masses.", " This gives us the new motor acceleration (still assuming no", " joint acceleration).", " Recalculate the motor position/velocity, using this new acceleration.", " Recalculate the spring force.", " The spring force becomes the force seen by the joint.", " Save the information that is to be used in the second half, i.e. in", " propagatePositionBackwards().  This includes the motor force", " (driving this cycle) and the time step (calculated here).", " Check the arguments.  This acts only on a single actuator/joint.", " Again (as in the first half of the backward transmission) simulate", " the motor-mass / belt-spring-damper / joint-mass system.  And", " again, all variables are in joint-space units.  Only this time use", " the joint position/velocity provided by the simulator.", " Get the time step and motor force from the first half of the", " backward transmission.", " Get the new joint position and velocity, as calculated by the", " simulator.", " As in the first half, if the transmission compliance or time", " constant are zero, the transmission collapses to a regular rigid", " transmission.", " Immediately propagate the joint position/velocity to the motor,", " ignoring the (infinitely fast) model dynamics.", " Update the model.  Note for numerical stability, we again lower", " bound the tranmission time constant by dt/2.", " Calculate the new motor position/velocity assuming a new motor", " acceleration of zero.", " Calculate the spring force between the two masses.", " This gives us the new motor acceleration.", " Recalculate the motor position/velocity, using this new acceleration.", " Save the current state for the next cycle.", " Push the motor position/velocity to the actuator, accounting for", " the mechanical reduction.", " Also push the motor force to the actuator.  Note we already assumed", " that the commanded actuator effort was accurately executed/applied,", " so the measured actuator effort is just the motor force.", " By storing the new actuator data, we are advancing to the next", " servo cycle.  Always make sure the timing has been initialized.", " Set the time stamp to zero (it is measured relative to the start time).", " Try to set the start time.  Only then do we claim initialized.", " Measure the time stamp relative to the start time.", " Set the historical (double) timestamp accordingly.", " Simulate calibration sensors by filling out actuator states", " namespace"], "chain": [" Author: Stuart Glaser, Wim Meeussen", " Constructs the kdl chain", " Pulls out all the joint indices"], "tree": [" construct the kdl tree", " the first step of extracting the joints from the tree is to go through all tree_elements, check for a joint,", " and check in case a joint is found, if it is not of not of type KDL::Joint::None", " map for saving the temporary result of the joint extraction from the tree", " in the second step the joints found get checked, if they appear in the JointState vector of the robot", " namespace"], "wrist_transmission": ["*******************************************************************", " Update the timing (making sure it's initialized).", " Set the time stamp to zero (it is measured relative to the start time).", " Try to set the start time.  Only then do we claim initialized.", " Measure the time stamp relative to the start time.", " Set the historical (double) timestamp accordingly.", " simulate calibration sensors by filling out actuator states", " this is where to embed the hack which joint connects to which mcb"], "simple_transmission": ["*******************************************************************", " Get screw joint informations", " The first joint is the gap joint", " get the thread pitch", " Get screw joint informations", " The first joint is the gap joint", " get the thread pitch", " screw joint state is not important to us, fill with zeros", " treat passive simulation joints as \"calibrated\"", " Update the timing (making sure it's initialized).", " Set the time stamp to zero (it is measured relative to the start time).", " Try to set the start time.  Only then do we claim initialized.", " Measure the time stamp relative to the start time.", " Set the historical (double) timestamp accordingly.", " simulate calibration sensors by filling out actuator states", " set screw joint effort if simulated"], "joint_calibration_simulator": [" Author: Wim Meeussen", " simulate calibration backward propagation", " continuous joints", " check", " setup calibration information for the joint", " current joint_angle", " compute calibration reading", " in low part", " tripped calibration flag", "ROS_ERROR(\"debug: %s %d %d\",js->joint_->name.c_str(),old_calibration_reading_ ,as->state_.calibration_reading_);", " low to high", " joint pos increasing and we are in the high region", " high to low", " joint pos increasing and we are in the low region", " store state", "namespace"], "test_joint_calibration_simulator": ["*******************************************************************", " Author: Wim Meeussen ", "/ constructor", "/ Destructor", " test cont1", " test cont2", " test rev"], "test_chain": [" Just three links", " Test no longer valid because joint state is empty when actuators are not present", " extract chain"], "test_wrist_transmission": ["virtual void SetUp()", " ******* Sets all the gearings to 1. This is a very basic test *******", " ******* Check joint gearing *******", " ******* Check motor gearing *******", " ******* Check both directions *******"], "controller_diagnostics": ["*******************************************************************", " Controller statistics"], "pr2_mechanism_diagnostics": ["*******************************************************************", " Diagnostic publisher", " Update joints", " Update controllers", " Update joints", " Update controllers. Note controllers that haven't update are discarded", " Publish even if we have no controllers loaded"], "joint_diagnostics": ["*******************************************************************", "*", " Joint statistics"], "controller_manager": ["//////////////////////////////////////////////////////////////////////////", " Copyright (C) 2008, Willow Garage, Inc.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions are met:", "   * Redistributions of source code must retain the above copyright notice,", "     this list of conditions and the following disclaimer.", "   * Redistributions in binary form must reproduce the above copyright", "     notice, this list of conditions and the following disclaimer in the", "     documentation and/or other materials provided with the distribution.", "   * Neither the name of Willow Garage, Inc. nor the names of its", "     contributors may be used to endorse or promote products derived from", "     this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"", " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE", " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE", " ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE", " LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR", " CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF", " SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS", " INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN", " CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)", " ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "////////////////////////////////////////////////////////////////////////////", " pre-allocate for realtime publishing", " get the publish rate for mechanism state", " create controller loader", " Advertise services (this should be the last thing we do in init)", " Must be realtime safe.", " Restart all running controllers if motors are re-enabled", " Update all controllers in scheduling order", " publish state", " there are controllers to start/stop", " stop controllers", " start controllers", " lock controllers", " get reference to controller list", " Copy all controllers from the 'from' list to the 'to' list", " Checks that we're not duplicating controllers", " Constructs the controller", " Backwards compatibility for using non-namespaced controller types", " checks if controller was constructed", " Initializes the controller", " Adds the controller to the new list", "  Do the controller scheduling", " Resize controller state vector", " Destroys the old controllers list when the realtime thread is finished with it.", " lock the controllers", " get reference to controller list", " check if no other controller depends on this controller", " Transfers the running controllers over, skipping the one to be removed and the running ones.", " Fails if we could not remove the controllers", "  Do the controller scheduling", " Resize controller state vector", " Destroys the old controllers list when the realtime thread is finished with it.", " lock controllers", " list all controllers to stop", " list all controllers to start", " start the atomic controller switching", " wait until switch is finished", " joint state", " actuator state", " controller state", " lock services", " only reload libraries if no controllers are running", " kill running controllers if requested", " create new controller loader", " pretend to use the request", " lock services", " pretend to use the request", " lock services", " add controller state", " lock services", " lock services", " lock services"], "scheduler": ["///////////////////////////////////////////////////////////////////////////", " Copyright (C) 2008, Willow Garage, Inc.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions are met:", "   * Redistributions of source code must retain the above copyright notice,", "     this list of conditions and the following disclaimer.", "   * Redistributions in binary form must reproduce the above copyright", "     notice, this list of conditions and the following disclaimer in the", "     documentation and/or other materials provided with the distribution.", "   * Neither the name of Willow Garage, Inc. nor the names of its", "     contributors may be used to endorse or promote products derived from", "     this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\"", " AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE", " IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE", " ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE", " LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR", " CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF", " SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS", " INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN", " CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE)", " ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "////////////////////////////////////////////////////////////////////////////", " found next controller to schedule", " remove this controller form graph ", " remove this controller form before lists", " build graph", " do the scheduling", " find controller id", " show result"], "test": ["*******************************************************************", " Author: Wim Meeussen ", "/ constructor", "/ Destructor", " test spawner", " wait until all controllers are loaded", " this should be the controller state if spawner worked", " check initial state", " these are already loaded", " this one is not loaded yet", " this one is wrongly configured", " this one is not configured", " check end state", " check initial state", " these are running, so unloading should fail", " these are stopped, so unloading should succeed", " this one is not loaded, so unloading should fail", " check end state", " check initial state", " starting already started controller", " starting unloaded controller", " starting one already stated, 1 stopped", " start and stop same controller", " stop unloaded controller", " stop unloaded and running controller", " stop running and stopped controller", " stop 2 stopped controllers, and 1 running controller", " check initial state", " starting already started controller", " starting unloaded, started and stopped controller", " connect to topic", " avoid problem with simultanious access to callback1_name_", " check for effort limits", " connect to topic", " gathering debugging info", " connect to topic", " connect to topic"], "test_controller": ["/ Controller initialization in non-realtime", " copy robot pointer so we can access time", " get joint", " ----------", " get chain", " ----------", " advertise topic", " ----------", " advertise service ", " ----------", "/ Controller startup in realtime", "/ Controller update loop in realtime", " this should never be greater than zero", " above max effort", " above max effort", "/ Controller stopping in realtime", "/ Service call ", "/ Register controller to pluginlib"]}, "code_comments_python": {"pub_mech_stats": ["!/usr/bin/env python", "", " Software License Agreement (BSD License)", "", " Copyright (c) 2010, Willow Garage, Inc.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of the Willow Garage nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", "#\\author Kevin Watts"], "mech_diag_test": ["!/usr/bin/env python", "", " Software License Agreement (BSD License)", "", " Copyright (c) 2010, Willow Garage, Inc.", " All rights reserved.", "", " Redistribution and use in source and binary forms, with or without", " modification, are permitted provided that the following conditions", " are met:", "", "  * Redistributions of source code must retain the above copyright", "    notice, this list of conditions and the following disclaimer.", "  * Redistributions in binary form must reproduce the above", "    copyright notice, this list of conditions and the following", "    disclaimer in the documentation and/or other materials provided", "    with the distribution.", "  * Neither the name of the Willow Garage nor the names of its", "    contributors may be used to endorse or promote products derived", "    from this software without specific prior written permission.", "", " THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS", " \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT", " LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS", " FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE", " COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,", " INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,", " BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;", " LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER", " CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT", " LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN", " ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE", " POSSIBILITY OF SUCH DAMAGE.", "", "#\\author Kevin Watts", " Calibrated, Nan for joints", " Ignore special \"No controllers\" status"], "setup": ["# ! DO NOT MANUALLY INVOKE THIS setup, USE CATKIN INSTEAD", " fetch values from package.xml"], "pr2_controller_manager_interface": ["! /usr/bin/env python", " Wrappers around the services provided by MechanismControlNode"]}}
]
